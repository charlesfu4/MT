{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## assume std is always constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# split the data into a train and validation sets \n",
    "X1, X2, y1, y2 = train_test_split(X_train, y_train, test_size=0.5) \n",
    "# base_model can be any regression \n",
    "modelbase_mode.fit(X1, y1)\n",
    "base_prediction = base_model.predict(X2) \n",
    "\n",
    "#compute the RMSE value \n",
    "error = mean_squared_error(base_prediction, y2) ** 0.5 \n",
    "# compute the mean and standard deviation of the distribution \n",
    "mean = base_model.predict(X_test) \n",
    "st_dev = error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit model to learn error itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data in train a validation set \n",
    "X1, X2, y1, y2 = train_test_split(X, y, test_size=0.5)\n",
    "# base_model can be any regression model, a \n",
    "# sklearn.ensemble.GradientBoostingRegressor for instance \n",
    "base_model.fit(X1, y1) \n",
    "base_prediction = base_model.predict(X2) \n",
    "# compute the prediction error vector on the validation set\n",
    "validation_error = (base_prediction - y2) ** 2 \n",
    "error_model.fit(X2, validation_error) \n",
    "# compute the mean and standard deviation of the distribution \n",
    "mean = base_model.predict(X_test)\n",
    "st_dev = error_model.predict(X_test)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantileLossFunction(RegressionLossFunction):\n",
    "    \"\"\"Loss function for quantile regression.\n",
    "    Quantile regression allows to estimate the percentiles\n",
    "    of the conditional distribution of the target.\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_classes : int\n",
    "        Number of classes.\n",
    "    alpha : float, optional (default = 0.9)\n",
    "        The percentile\n",
    "    \"\"\"\n",
    "    def __init__(self, n_classes, alpha=0.9):\n",
    "        super().__init__(n_classes)\n",
    "        self.alpha = alpha\n",
    "        self.percentile = alpha * 100.0\n",
    "\n",
    "    def init_estimator(self):\n",
    "        return QuantileEstimator(self.alpha)\n",
    "\n",
    "    def __call__(self, y, pred, sample_weight=None):\n",
    "        \"\"\"Compute the Quantile loss.\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : array, shape (n_samples,)\n",
    "            True labels\n",
    "        pred : array, shape (n_samples,)\n",
    "            Predicted labels\n",
    "        sample_weight : array-like, shape (n_samples,), optional\n",
    "            Sample weights.\n",
    "        \"\"\"\n",
    "        pred = pred.ravel()\n",
    "        diff = y - pred\n",
    "        alpha = self.alpha\n",
    "\n",
    "        mask = y > pred\n",
    "        if sample_weight is None:\n",
    "            loss = (alpha * diff[mask].sum() -\n",
    "                    (1.0 - alpha) * diff[~mask].sum()) / y.shape[0]\n",
    "        else:\n",
    "            loss = ((alpha * np.sum(sample_weight[mask] * diff[mask]) -\n",
    "                    (1.0 - alpha) * np.sum(sample_weight[~mask] * diff[~mask])) /\n",
    "                    sample_weight.sum())\n",
    "        return loss\n",
    "\n",
    "    def negative_gradient(self, y, pred, **kargs):\n",
    "        \"\"\"Compute the negative gradient.\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : array, shape (n_samples,)\n",
    "            The target labels.\n",
    "        pred : array, shape (n_samples,)\n",
    "            The predictions.\n",
    "        \"\"\"\n",
    "        alpha = self.alpha\n",
    "        pred = pred.ravel()\n",
    "        mask = y > pred\n",
    "        return (alpha * mask) - ((1.0 - alpha) * ~mask)\n",
    "\n",
    "    def _update_terminal_region(self, tree, terminal_regions, leaf, X, y,\n",
    "                                residual, pred, sample_weight):\n",
    "        terminal_region = np.where(terminal_regions == leaf)[0]\n",
    "        diff = (y.take(terminal_region, axis=0)\n",
    "                - pred.take(terminal_region, axis=0))\n",
    "        sample_weight = sample_weight.take(terminal_region, axis=0)\n",
    "\n",
    "        val = _weighted_percentile(diff, sample_weight, self.percentile)\n",
    "        tree.value[leaf, 0] = val\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tpot",
   "language": "python",
   "name": "tpot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
