{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mysql.connector\n",
    "from pandas import datetime\n",
    "from matplotlib import pyplot as plt\n",
    "from weather.darksky import weather_request\n",
    "from statsmodels.graphics.tsaplots import plot_acf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_missing(df):\n",
    "    data = pd.DataFrame(df)\n",
    "    df_cols = list(pd.DataFrame(data))\n",
    "    dict_x = {}\n",
    "    for i in range(0, len(df_cols)):\n",
    "        dict_x.update({df_cols[i]: data[df_cols[i]].isnull().sum()})\n",
    "    \n",
    "    return dict_x\n",
    "\n",
    "## Extract funciton for Elia Total load data\n",
    "def elia_extract(name):\n",
    "    excludes = [\"02:00*\",\"02:15*\",\"02:30*\",\"02:45*\"]\n",
    "    elia_load = pd.read_csv(name)\n",
    "    elia_load.replace('NOT VALID', np.NaN, inplace=True)\n",
    "    for ex in excludes:\n",
    "        elia_load = elia_load.loc[elia_load['RowTime'] != ex]\n",
    "    elia_load.to_csv(\"{}_clean\".format(name), index = True)\n",
    "    ## combine to datetime\n",
    "    elia_load = pd.read_csv(\"{}_clean\".format(name), parse_dates=[['RowDate','RowTime']])\n",
    "    elia_load.drop(columns=['Unnamed: 0'], inplace = True)\n",
    "    elia_load['TotalLoad'] = elia_load['TotalLoad'].interpolate(method='linear')\n",
    "    ## fix index and weekday extraction\n",
    "    elia_load = elia_load.rename(columns={'RowDate_RowTime':'time'})\n",
    "    elia_load[\"Weekday\"] = elia_load['time'].dt.day_name()\n",
    "    elia_load.set_index(elia_load['time'], inplace = True)\n",
    "    elia_load.drop(columns=['time'], inplace = True)\n",
    "    return elia_load\n",
    "\n",
    "## Extract funciton for Elia Grid load data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elia Total Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "elia_2020 = elia_extract(\"Total_load_2020.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "elia_2019 = elia_extract(\"Total_load_2019.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elia grid load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## expanse by rows * columns\n",
    "elia = pd.read_csv(\"ELIA_LOAD_2019.csv\",header = 1)\n",
    "elia.replace('NOT VALID', np.NaN, inplace=True)\n",
    "elia = elia.iloc[:,:99]\n",
    "\n",
    "date_list = []\n",
    "for i in range(elia.shape[0]):\n",
    "    date_list.append(\"{}-{}-{}\".format(elia['yyyy'][i],elia['mm'][i],elia['dd'][i]))\n",
    "elia[\"time\"] = date_list\n",
    "\n",
    "elia.drop(columns = ['dd','mm'], inplace = True)\n",
    "elia.set_index(elia[\"time\"], inplace= True)\n",
    "elia.drop(columns = ['time'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fuchucheng/.local/lib/python3.6/site-packages/ipykernel_launcher.py:28: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime instead.\n"
     ]
    }
   ],
   "source": [
    "## fix 24:00 to the next day 00:00\n",
    "elia['0:00'] = elia.iloc[:,-1].shift()\n",
    "## swap\n",
    "cols = list(elia.columns)\n",
    "a, b = cols.index('yyyy'), cols.index('0:00')\n",
    "cols[b], cols[a] = cols[a], cols[b]\n",
    "elia = elia[cols]\n",
    "\n",
    "elia.drop(columns=['24:00','yyyy'], inplace = True)\n",
    "\n",
    "\n",
    "## Expanse the data set\n",
    "index_list = []\n",
    "energy_list = []\n",
    "for date in elia.index:\n",
    "    for time in elia.columns:\n",
    "        #special case handling\n",
    "        #if time == \"24:00\":\n",
    "        #    index_list.append(\"{} {}\".format(date , \"00:00\"))\n",
    "        #else:\n",
    "        index_list.append(\"{} {}\".format(date, time))\n",
    "        energy_list.append(elia.loc[date, time])\n",
    "elia_qh = pd.DataFrame(list(zip(index_list,energy_list)),  columns=['time','grid_load'])\n",
    "elia_qh.head()\n",
    "\n",
    "\n",
    "##type transformation\n",
    "elia_qh['time'] = elia_qh['time'].apply(lambda x: datetime.strptime(x, \"%Y-%m-%d %H:%M\"))\n",
    "elia_qh[\"grid_load\"] = elia_qh[\"grid_load\"].astype(\"float64\")\n",
    "elia_qh['time'] = elia_qh['time'].astype(\"datetime64\")\n",
    "elia_qh.dtypes\n",
    "## index setting\n",
    "elia_qh.set_index(elia_qh['time'], inplace = True)\n",
    "elia_qh.drop(columns = ['time'], inplace = True)\n",
    "elia_qh.to_csv(\"elia_qh.csv\", index = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35040, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elia_qh = pd.read_csv(\"elia_qh.csv\", index_col='time')\n",
    "elia_qh.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To prevent data leakage we split trian and test first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5781, 1), (29256, 1))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##8256\n",
    "elia_train = elia_qh.iloc[:5781,:]\n",
    "elia_test = elia_qh.iloc[5784:,:]\n",
    "elia_train.shape, elia_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**then deal with missing value**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'grid_load(MW)': 0}\n",
      "{'grid_load(MW)': 0}\n"
     ]
    }
   ],
   "source": [
    "## missing value train\n",
    "missing = count_missing(elia_train)\n",
    "print(missing)\n",
    "## missing value test\n",
    "missing = count_missing(elia_test)\n",
    "print(missing)\n",
    "\n",
    "#missing = count_missing(elia_qh)\n",
    "#print(missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//miniconda3/envs/tpot/lib/python3.6/site-packages/pandas/core/generic.py:6245: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    }
   ],
   "source": [
    "elia_train.fillna(elia_train.median(), inplace=True)\n",
    "elia_test.fillna(elia_test.median(), inplace=True)\n",
    "#elia_qh.fillna(elia_qh.median(), inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**scale down the grid load**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fuchucheng/.local/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/fuchucheng/.local/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "//miniconda3/envs/tpot/lib/python3.6/site-packages/pandas/core/frame.py:3997: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "elia_train['grid_load(MW)'] = elia_train['grid_load'].apply(lambda x: x/1000000)\n",
    "elia_test['grid_load(MW)'] = elia_test['grid_load'].apply(lambda x: x/1000000)\n",
    "elia_train.drop(['grid_load'],axis = 1, inplace = True)\n",
    "elia_test.drop(['grid_load'],axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "elia_qh['grid_load(MW)'] = elia_qh['grid_load'].apply(lambda x: x/1000000)\n",
    "elia_qh.drop(['grid_load'],axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "elia_train.to_csv(\"elia_train.csv\", index = True)\n",
    "elia_test.to_csv(\"elia_test.csv\", index = True)\n",
    "#elia_qh.to_csv(\"elia_2019.csv\", index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### weather data from darksky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_list = [51.2803, 50.8259, 50.8467, 50.4161]\n",
    "long_list = [4.2256, 3.2207, 4.3607, 4.4477]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## request weather data in brussels\n",
    "                    # lat, long, start_date, ndays, timezone, api_key     \n",
    "for i in range(3,4):\n",
    "    wr = weather_request(lat_list[i], long_list[i], \"2018-12-31 00:00\", 367, 'CET', 'a4b2112ada4def81849c098853d6fd76')\n",
    "    wr.request()\n",
    "    wr.get_pandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_2020_1 = pd.read_csv(\"weather_2020_51.2803_4.2256.csv\", index_col = \"time\")\n",
    "weather_2019_1 = pd.read_csv(\"weather_2019_51.2803_4.2256.csv\", index_col = \"time\")\n",
    "weather_2020_2 = pd.read_csv(\"weather_2020_50.8467_4.3607.csv\", index_col = \"time\")\n",
    "weather_2019_2 = pd.read_csv(\"weather_2019.csv\", index_col = \"time\")\n",
    "weather_2020_3 = pd.read_csv(\"weather_2020_50.4161_4.4477.csv\", index_col = \"time\")\n",
    "weather_2019_3 = pd.read_csv(\"weather_2019_50.4161_4.4477.csv\", index_col = \"time\")\n",
    "weather_2020_4 = pd.read_csv(\"weather_2020_50.8259_3.2207.csv\", index_col = \"time\")\n",
    "weather_2019_4 = pd.read_csv(\"weather_2019_50.8259_3.2207.csv\", index_col = \"time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**temperature concatination**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_2020 = pd.concat([weather_2020_1.temperature,\n",
    "                          weather_2020_2.temperature,\n",
    "                          weather_2020_3.temperature,\n",
    "                          weather_2020_4.temperature], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## remove duplicate rows\n",
    "weather_2019_1.drop('2019-10-27 02:00:00', inplace = True)\n",
    "weather_2019_2.drop('2019-10-27 02:00:00', inplace = True)\n",
    "weather_2019_3.drop('2019-10-27 02:00:00', inplace = True)\n",
    "weather_2019_4.drop('2019-10-27 02:00:00', inplace = True)\n",
    "weather_2019 = pd.concat([weather_2019_1.temperature,\n",
    "                          weather_2019_2.temperature,\n",
    "                          weather_2019_3.temperature,\n",
    "                          weather_2019_4.temperature],\n",
    "                         \n",
    "                         join = 'inner', \n",
    "                         axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge weather and load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_elia = weather_2019.merge(elia_2019, how ='right', left_index = True, right_index = True)\n",
    "test_elia = weather_2020.merge(elia_2020, how = 'right', left_index = True, right_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**then deal with missing value by interpolation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## interpolate nan\n",
    "for col in train_elia.columns:\n",
    "    train_elia[col] = train_elia[col].interpolate(method='linear')\n",
    "for col in test_elia.columns:\n",
    "    test_elia[col] = test_elia[col].interpolate(method = \"linear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_elia.to_csv(\"train_elia.csv\",index = True)\n",
    "test_elia.to_csv(\"test_elia.csv\", index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  ----------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# London electricity consumption smart meter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fuchucheng/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3051: DtypeWarning: Columns (2) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "elec = pd.read_csv(\"../smart-meters-in-london/halfhourly_dataset/block_0.csv\")\n",
    "for num in range(1,111):    \n",
    "    elec = elec.append(pd.read_csv(\"../smart-meters-in-london/halfhourly_dataset/block_\"+str(num)+\".csv\"))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "elec.replace('Null', np.NaN, inplace=True)\n",
    "energy = elec.iloc[:,:]\n",
    "energy[\"energy\"] = energy[\"energy(kWh/hh)\"].astype(\"float64\")\n",
    "energy = energy.drop([\"energy(kWh/hh)\"],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy = elec.iloc[:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Missing values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of missing data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('energy(kWh/hh)', 5544), ('energy', 5544), ('LCLid', 0), ('tstp', 0)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing = count_missing(train)\n",
    "df_miss = sorted(missing.items(), key=lambda x: x[1], reverse=True)\n",
    "print('Count of missing data')\n",
    "df_miss[0:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy[\"energy\"] = energy[\"energy\"].astype(\"float64\")\n",
    "energy[\"tstp\"] = energy[\"tstp\"].astype(\"datetime64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split train test first by time masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask1 = energy.tstp < pd.Timestamp(2013,11,24)\n",
    "mask2 = energy.tstp >= pd.Timestamp(2013,11,24)\n",
    "train = energy.loc[mask1, ]\n",
    "test = energy.loc[mask2,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fill up na with median of each LCLid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//miniconda3/envs/tpot/lib/python3.6/site-packages/pandas/core/indexing.py:965: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAC000002\n",
      "MAC000246\n",
      "MAC000450\n",
      "MAC001074\n",
      "MAC003223\n",
      "MAC003239\n",
      "MAC003252\n",
      "MAC003281\n",
      "MAC003305\n",
      "MAC003348\n",
      "MAC003388\n",
      "MAC003394\n",
      "MAC003400\n",
      "MAC003422\n",
      "MAC003423\n",
      "MAC003428\n",
      "MAC003449\n",
      "MAC003463\n",
      "MAC003482\n",
      "MAC003553\n",
      "MAC003557\n",
      "MAC003566\n",
      "MAC003579\n",
      "MAC003597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAC003613\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/fuchucheng/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3319, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-55-f6237f3a2208>\", line 2, in <module>\n",
      "    m = (train.LCLid == lclid)\n",
      "  File \"//miniconda3/envs/tpot/lib/python3.6/site-packages/pandas/core/ops/common.py\", line 64, in new_method\n",
      "    return method(self, other)\n",
      "  File \"//miniconda3/envs/tpot/lib/python3.6/site-packages/pandas/core/ops/__init__.py\", line 526, in wrapper\n",
      "    res_values = comparison_op(lvalues, rvalues, op)\n",
      "  File \"//miniconda3/envs/tpot/lib/python3.6/site-packages/pandas/core/ops/array_ops.py\", line 247, in comparison_op\n",
      "    res_values = comp_method_OBJECT_ARRAY(op, lvalues, rvalues)\n",
      "  File \"//miniconda3/envs/tpot/lib/python3.6/site-packages/pandas/core/ops/array_ops.py\", line 57, in comp_method_OBJECT_ARRAY\n",
      "    result = libops.scalar_compare(x.ravel(), y, op)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/fuchucheng/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2034, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/fuchucheng/.local/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/Users/fuchucheng/.local/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/fuchucheng/.local/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"//miniconda3/envs/tpot/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"//miniconda3/envs/tpot/lib/python3.6/inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"//miniconda3/envs/tpot/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"//miniconda3/envs/tpot/lib/python3.6/inspect.py\", line 732, in getmodule\n",
      "    for modname, module in list(sys.modules.items()):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "for lclid in train.LCLid.unique():\n",
    "    m = (train.LCLid == lclid)   \n",
    "    train.loc[m,'energy'] = train.loc[m, 'energy'].fillna(train.loc[m, 'energy'].median())\n",
    "    print(lclid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## group by time stamp and aggregate \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.groupby('tstp').agg({'energy': lambda x: x.sum(skipna=True),\n",
    "                                      'LCLid': lambda x: len(x.unique())})\n",
    "train['tstp'] = train.index\n",
    "\n",
    "test = test.groupby('tstp').agg({'energy': lambda x: x.sum(skipna=True),\n",
    "                                      'LCLid': lambda x: len(x.unique())})\n",
    "test['tstp'] = test.index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('london_skna_trian.csv', index = 'tstp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('london_skna_test.csv', index = 'tstp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single household"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fuchucheng/.local/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/Users/fuchucheng/.local/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "def extract_single(df, lclid):\n",
    "    single = df.loc[df[\"LCLid\"] == lclid]\n",
    "    single.drop(['LCLid'], axis = 1)\n",
    "    single[\"energy\"] = single[\"energy\"].astype(\"float64\")\n",
    "    single[\"tstp\"] = single[\"tstp\"].astype(\"datetime64\")\n",
    "    single = single.groupby('tstp').agg({'energy': lambda x: x.sum(skipna=False)})\n",
    "    single['tstp'] = single.index\n",
    "    return single\n",
    "energy_MAC1 = extract_single(energy, \"MAC000010\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To prevent data leakage we split trian and test first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_s = energy_MAC1.iloc[:20000, :]\n",
    "test_s = energy_MAC1.iloc[20000:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**then deal with missing value half-hr**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//miniconda3/envs/tpot/lib/python3.6/site-packages/pandas/core/generic.py:6245: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    }
   ],
   "source": [
    "train_s.fillna(train_s.median(), inplace = True)\n",
    "test_s.fillna(test_s.median(), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_s =  weather.merge(train_s, how ='right', left_index = True, right_index = True)\n",
    "test_s = weather.merge(test_s, how = 'right', left_index = True, right_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_s['wd'] = train_s.tstp.apply(lambda x: x.weekday())\n",
    "test_s['wd'] = test_s.tstp.apply(lambda x: x.weekday())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_s.drop(['tstp'],axis = 1, inplace = True)\n",
    "test_s.drop(['tstp'],axis = 1, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "## interpolate nan\n",
    "for col in train_s.columns:\n",
    "    train_s[col] = train_s[col].interpolate(method = 'linear')\n",
    "for col in test_s.columns:\n",
    "    test_s[col] = test_s[col].interpolate(method = \"linear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_s = train_s.iloc[1:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_s = test_s.iloc[1:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_s.to_csv(\"train_s_hh.csv\", index = True)\n",
    "test_s.to_csv(\"test_s_hh.csv\", index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**resampling to 1hr**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_s_h = train_s.resample('1H').sum()\n",
    "test_s_h = test_s.resample('1H').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Save to csv\n",
    "train_s_h.to_csv(\"train_s_h.csv\", index = True)\n",
    "test_s_h.to_csv(\"train_s_h.csv\", index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregated   household"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Group by LCLid and aggregate over per hour**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## deal with missing value by interpolating mean of whole column\n",
    "# energy[\"energy\"].fillna(energy[\"energy\"].median(), inplace = True)\n",
    "## group by time stamps and aggregate through mean\n",
    "energy[\"energy\"] = energy[\"energy\"].astype(\"float64\")\n",
    "energy[\"tstp\"] = energy[\"tstp\"].astype(\"datetime64\")\n",
    "energy = energy.groupby('tstp').agg({'energy': lambda x: x.mean(skipna=False)})\n",
    "energy['tstp'] = energy.index\n",
    "energy.drop(['tstp'], axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To prevent data leakage we split trian and test first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_e = energy.iloc[:28750, :]\n",
    "test_e = energy.iloc[28750:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**deal with missing value sampling rate: 30 mins**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//miniconda3/envs/tpot/lib/python3.6/site-packages/pandas/core/generic.py:6245: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    }
   ],
   "source": [
    "train_e.fillna(train_e.median(), inplace = True)\n",
    "test_e.fillna(test_e.median(), inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of missing data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('energy', 0)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## check if there is still missing value\n",
    "missing = missing_count(test_e)\n",
    "df_miss = sorted(missing.items(), key=lambda x: x[1], reverse=True)\n",
    "print('Count of missing data')\n",
    "df_miss[0:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**then deal with missing value and resampling to 1hr**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//miniconda3/envs/TPOT/lib/python3.5/site-packages/pandas/core/generic.py:5208: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "train_e.fillna(train_e.median(), inplace = True)\n",
    "test_e.fillna(test_e.median(), inplace = True)\n",
    "train_e = train_e.resample('1H').sum()\n",
    "test_e = test_e.resample('1H').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of missing data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('energy', 673)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## check if there is still missing value\n",
    "missing = missing_count(train_e)\n",
    "df_miss = sorted(missing.items(), key=lambda x: x[1], reverse=True)\n",
    "print('Count of missing data')\n",
    "df_miss[0:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weather datan processing: Londo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weather = pd.read_csv('../smart-meters-in-london/weather_hourly_darksky.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "## set index as time stamp\n",
    "weather = weather.set_index(\"time\")\n",
    "weather.index = weather.index.astype(\"datetime64[ns]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "## apparently the sequence in between is not correct\n",
    "weather = weather.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Missing values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of missing data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('pressure', 13),\n",
       " ('visibility', 0),\n",
       " ('windBearing', 0),\n",
       " ('temperature', 0),\n",
       " ('dewPoint', 0),\n",
       " ('apparentTemperature', 0),\n",
       " ('windSpeed', 0),\n",
       " ('precipType', 0),\n",
       " ('icon', 0),\n",
       " ('humidity', 0),\n",
       " ('summary', 0)]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing = count_missing(weather)\n",
    "df_miss = sorted(missing.items(), key=lambda x: x[1], reverse=True)\n",
    "print('Percent of missing data')\n",
    "df_miss[0:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "## drop columns wont be used later\n",
    "weather.drop(['precipType','icon','summary'], axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "##merge trian and test seperately\n",
    "train_w =  weather.merge(train, how ='right', left_index = True, right_index = True)\n",
    "test_w = weather.merge(test, how = 'right', left_index = True, right_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_w['wd'] = train_w['tstp'].apply(lambda x: x.weekday())\n",
    "test_w['wd'] = test_w['tstp'].apply(lambda x: x.weekday())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_w.drop(['tstp'],axis = 1, inplace = True)\n",
    "test_w.drop(['tstp'],axis = 1, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_w.to_csv(\"hh_train_nan.csv\", index = True)\n",
    "test_w.to_csv(\"hh_test_nan.csv\", index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "## interpolate nan\n",
    "for col in train_w.columns:\n",
    "    train_w[col] = train_w[col].interpolate(method = 'linear')\n",
    "for col in test_w.columns:\n",
    "    test_w[col] = test_w[col].interpolate(method = \"linear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "## data set without catagorical features\n",
    "train_w.to_csv(\"train_nocat_hh.csv\", index = True)\n",
    "test_w.to_csv(\"test_nocat_hh.csv\", index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**One hot encoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Examine unique categories in categorical features\n",
    "p = list(weather[\"precipType\"].unique()) \n",
    "i = list(weather[\"icon\"].unique()) \n",
    "u = list(weather[\"summary\"].unique())\n",
    "# Sort them for one hot encoding labels\n",
    "p.sort()\n",
    "i.sort()\n",
    "u.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "## One hot encoding these features above\n",
    "onehot = OneHotEncoder(dtype=np.int, sparse=True)\n",
    "nominals = pd.DataFrame(onehot.fit_transform(weather[['precipType', 'icon','summary']]).toarray(),columns=p+i+u)\n",
    "nominals.index = weather.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of ['time'] are in the columns\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-a43aedab6b50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Concate nominals with origin weather dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mweather\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweather\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"time\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mweather\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweather\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"datetime64\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#weather.drop([\"precipType\",\"icon\",\"summary\"],axis = 1, inplace = True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#weather =  weather.merge(nominals, left_index = True, right_index = True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//miniconda3/envs/TPOT/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mset_index\u001b[0;34m(self, keys, drop, append, inplace, verify_integrity)\u001b[0m\n\u001b[1;32m   4409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4410\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4411\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"None of {} are in the columns\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4413\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of ['time'] are in the columns\""
     ]
    }
   ],
   "source": [
    "#Concate nominals with origin weather dataframe\n",
    "weather = weather.set_index(\"time\")\n",
    "weather.index = weather.index.astype(\"datetime64\")\n",
    "#weather.drop([\"precipType\",\"icon\",\"summary\"],axis = 1, inplace = True)\n",
    "weather =  weather.merge(nominals, left_index = True, right_index = True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tpot",
   "language": "python",
   "name": "tpot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
