{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import datetime\n",
    "from matplotlib import pyplot as plt\n",
    "from weather.darksky import weather_request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_missing(df):\n",
    "    data = pd.DataFrame(df)\n",
    "    df_cols = list(pd.DataFrame(data))\n",
    "    dict_x = {}\n",
    "    for i in range(0, len(df_cols)):\n",
    "        dict_x.update({df_cols[i]: data[df_cols[i]].isnull().sum()})\n",
    "    \n",
    "    return dict_x\n",
    "\n",
    "## Extract funciton for Elia Total load data\n",
    "def elia_extract(name):\n",
    "    excludes = [\"02:00*\",\"02:15*\",\"02:30*\",\"02:45*\"]\n",
    "    elia_load = pd.read_csv(name)\n",
    "    elia_load.replace('NOT VALID', np.NaN, inplace=True)\n",
    "    for ex in excludes:\n",
    "        elia_load = elia_load.loc[elia_load['RowTime'] != ex]\n",
    "    elia_load.to_csv(\"{}_clean\".format(name), index = True)\n",
    "    ## combine to datetime\n",
    "    elia_load = pd.read_csv(\"{}_clean\".format(name), parse_dates=[['RowDate','RowTime']])\n",
    "    elia_load.drop(columns=['Unnamed: 0'], inplace = True)\n",
    "    elia_load['TotalLoad'] = elia_load['TotalLoad'].interpolate(method='linear')\n",
    "    ## fix index and weekday extraction\n",
    "    elia_load = elia_load.rename(columns={'RowDate_RowTime':'time'})\n",
    "    elia_load[\"Weekday\"] = elia_load['time'].dt.day_name()\n",
    "    elia_load.set_index(elia_load['time'], inplace = True)\n",
    "    elia_load.drop(columns=['time'], inplace = True)\n",
    "    return elia_load\n",
    "\n",
    "## Extract funciton for Elia Grid load data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elia Total Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "elia_2020 = elia_extract(\"Total_load_2020.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "elia_2019 = elia_extract(\"Total_load_2019.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elia grid load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## expanse by rows * columns\n",
    "elia = pd.read_csv(\"ELIA_LOAD_2019.csv\",header = 1)\n",
    "elia.replace('NOT VALID', np.NaN, inplace=True)\n",
    "elia = elia.iloc[:,:99]\n",
    "\n",
    "date_list = []\n",
    "for i in range(elia.shape[0]):\n",
    "    date_list.append(\"{}-{}-{}\".format(elia['yyyy'][i],elia['mm'][i],elia['dd'][i]))\n",
    "elia[\"time\"] = date_list\n",
    "\n",
    "elia.drop(columns = ['dd','mm'], inplace = True)\n",
    "elia.set_index(elia[\"time\"], inplace= True)\n",
    "elia.drop(columns = ['time'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fuchucheng/.local/lib/python3.6/site-packages/ipykernel_launcher.py:28: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime instead.\n"
     ]
    }
   ],
   "source": [
    "## fix 24:00 to the next day 00:00\n",
    "elia['0:00'] = elia.iloc[:,-1].shift()\n",
    "## swap\n",
    "cols = list(elia.columns)\n",
    "a, b = cols.index('yyyy'), cols.index('0:00')\n",
    "cols[b], cols[a] = cols[a], cols[b]\n",
    "elia = elia[cols]\n",
    "\n",
    "elia.drop(columns=['24:00','yyyy'], inplace = True)\n",
    "\n",
    "\n",
    "## Expanse the data set\n",
    "index_list = []\n",
    "energy_list = []\n",
    "for date in elia.index:\n",
    "    for time in elia.columns:\n",
    "        #special case handling\n",
    "        #if time == \"24:00\":\n",
    "        #    index_list.append(\"{} {}\".format(date , \"00:00\"))\n",
    "        #else:\n",
    "        index_list.append(\"{} {}\".format(date, time))\n",
    "        energy_list.append(elia.loc[date, time])\n",
    "elia_qh = pd.DataFrame(list(zip(index_list,energy_list)),  columns=['time','grid_load'])\n",
    "elia_qh.head()\n",
    "\n",
    "\n",
    "##type transformation\n",
    "elia_qh['time'] = elia_qh['time'].apply(lambda x: datetime.strptime(x, \"%Y-%m-%d %H:%M\"))\n",
    "elia_qh[\"grid_load\"] = elia_qh[\"grid_load\"].astype(\"float64\")\n",
    "elia_qh['time'] = elia_qh['time'].astype(\"datetime64\")\n",
    "elia_qh.dtypes\n",
    "## index setting\n",
    "elia_qh.set_index(elia_qh['time'], inplace = True)\n",
    "elia_qh.drop(columns = ['time'], inplace = True)\n",
    "elia_qh.to_csv(\"elia_qh.csv\", index = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35040, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elia_qh = pd.read_csv(\"elia_qh.csv\", index_col='time')\n",
    "elia_qh.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To prevent data leakage we split trian and test first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5781, 1), (29256, 1))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##8256\n",
    "elia_train = elia_qh.iloc[:5781,:]\n",
    "elia_test = elia_qh.iloc[5784:,:]\n",
    "elia_train.shape, elia_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**then deal with missing value**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'grid_load(MW)': 0}\n",
      "{'grid_load(MW)': 0}\n"
     ]
    }
   ],
   "source": [
    "## missing value train\n",
    "missing = count_missing(elia_train)\n",
    "print(missing)\n",
    "## missing value test\n",
    "missing = count_missing(elia_test)\n",
    "print(missing)\n",
    "\n",
    "#missing = count_missing(elia_qh)\n",
    "#print(missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//miniconda3/envs/tpot/lib/python3.6/site-packages/pandas/core/generic.py:6245: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    }
   ],
   "source": [
    "elia_train.fillna(elia_train.median(), inplace=True)\n",
    "elia_test.fillna(elia_test.median(), inplace=True)\n",
    "#elia_qh.fillna(elia_qh.median(), inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**scale down the grid load**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fuchucheng/.local/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/fuchucheng/.local/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "//miniconda3/envs/tpot/lib/python3.6/site-packages/pandas/core/frame.py:3997: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "elia_train['grid_load(MW)'] = elia_train['grid_load'].apply(lambda x: x/1000000)\n",
    "elia_test['grid_load(MW)'] = elia_test['grid_load'].apply(lambda x: x/1000000)\n",
    "elia_train.drop(['grid_load'],axis = 1, inplace = True)\n",
    "elia_test.drop(['grid_load'],axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "elia_qh['grid_load(MW)'] = elia_qh['grid_load'].apply(lambda x: x/1000000)\n",
    "elia_qh.drop(['grid_load'],axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "elia_train.to_csv(\"elia_train.csv\", index = True)\n",
    "elia_test.to_csv(\"elia_test.csv\", index = True)\n",
    "#elia_qh.to_csv(\"elia_2019.csv\", index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### weather data from darksky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_list = [51.2803, 50.8259, 50.8467, 50.4161]\n",
    "long_list = [4.2256, 3.2207, 4.3607, 4.4477]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## request weather data in brussels\n",
    "                    # lat, long, start_date, ndays, timezone, api_key     \n",
    "for i in range(3,4):\n",
    "    wr = weather_request(lat_list[i], long_list[i], \"2018-12-31 00:00\", 367, 'CET', 'a4b2112ada4def81849c098853d6fd76')\n",
    "    wr.request()\n",
    "    wr.get_pandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_2020_1 = pd.read_csv(\"weather_2020_51.2803_4.2256.csv\", index_col = \"time\")\n",
    "weather_2019_1 = pd.read_csv(\"weather_2019_51.2803_4.2256.csv\", index_col = \"time\")\n",
    "weather_2020_2 = pd.read_csv(\"weather_2020_50.8467_4.3607.csv\", index_col = \"time\")\n",
    "weather_2019_2 = pd.read_csv(\"weather_2019.csv\", index_col = \"time\")\n",
    "weather_2020_3 = pd.read_csv(\"weather_2020_50.4161_4.4477.csv\", index_col = \"time\")\n",
    "weather_2019_3 = pd.read_csv(\"weather_2019_50.4161_4.4477.csv\", index_col = \"time\")\n",
    "weather_2020_4 = pd.read_csv(\"weather_2020_50.8259_3.2207.csv\", index_col = \"time\")\n",
    "weather_2019_4 = pd.read_csv(\"weather_2019_50.8259_3.2207.csv\", index_col = \"time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**temperature concatination**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_2020 = pd.concat([weather_2020_1.temperature,\n",
    "                          weather_2020_2.temperature,\n",
    "                          weather_2020_3.temperature,\n",
    "                          weather_2020_4.temperature], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## remove duplicate rows\n",
    "weather_2019_1.drop('2019-10-27 02:00:00', inplace = True)\n",
    "weather_2019_2.drop('2019-10-27 02:00:00', inplace = True)\n",
    "weather_2019_3.drop('2019-10-27 02:00:00', inplace = True)\n",
    "weather_2019_4.drop('2019-10-27 02:00:00', inplace = True)\n",
    "weather_2019 = pd.concat([weather_2019_1.temperature,\n",
    "                          weather_2019_2.temperature,\n",
    "                          weather_2019_3.temperature,\n",
    "                          weather_2019_4.temperature],\n",
    "                         \n",
    "                         join = 'inner', \n",
    "                         axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge weather and load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_elia = weather_2019.merge(elia_2019, how ='right', left_index = True, right_index = True)\n",
    "test_elia = weather_2020.merge(elia_2020, how = 'right', left_index = True, right_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**then deal with missing value by interpolation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## interpolate nan\n",
    "for col in train_elia.columns:\n",
    "    train_elia[col] = train_elia[col].interpolate(method='linear')\n",
    "for col in test_elia.columns:\n",
    "    test_elia[col] = test_elia[col].interpolate(method = \"linear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_elia.to_csv(\"train_elia.csv\",index = True)\n",
    "test_elia.to_csv(\"test_elia.csv\", index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  ----------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# London electricity consumption smart meter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fuchucheng/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3051: DtypeWarning: Columns (2) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "elec = pd.read_csv(\"../smart-meters-in-london/halfhourly_dataset/block_0.csv\")\n",
    "for num in range(1,111):    \n",
    "    elec = elec.append(pd.read_csv(\"../smart-meters-in-london/halfhourly_dataset/block_\"+str(num)+\".csv\"))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "elec.replace('Null', np.NaN, inplace=True)\n",
    "energy = elec.iloc[:,:]\n",
    "energy[\"energy\"] = energy[\"energy(kWh/hh)\"].astype(\"float64\")\n",
    "energy = energy.drop([\"energy(kWh/hh)\"],axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Missing values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of missing data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('energy', 5544), ('LCLid', 0), ('tstp', 0)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing = missing_count(energy)\n",
    "df_miss = sorted(missing.items(), key=lambda x: x[1], reverse=True)\n",
    "print('Count of missing data')\n",
    "df_miss[0:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single household"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_MAC1 = energy[energy[\"LCLid\"] == \"MAC000010\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of missing data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('energy', 1), ('LCLid', 0), ('tstp', 0)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing = missing_count(energy_MAC1)\n",
    "df_miss = sorted(missing.items(), key=lambda x: x[1], reverse=True)\n",
    "print('Count of missing data')\n",
    "df_miss[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fuchucheng/.local/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/fuchucheng/.local/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "energy_MAC1[\"energy\"] = energy_MAC1[\"energy\"].astype(\"float64\")\n",
    "energy_MAC1[\"tstp\"] = energy_MAC1[\"tstp\"].astype(\"datetime64\")\n",
    "energy_MAC1 = energy_MAC1.groupby('tstp').agg({'energy': lambda x: x.mean(skipna=False)})\n",
    "energy_MAC1['tstp'] = energy_MAC1.index\n",
    "energy_MAC1.drop(['tstp'], axis = 1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To prevent data leakage we split trian and test first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_s = energy_MAC1.iloc[:20000, :]\n",
    "test_s = energy_MAC1.iloc[20000:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**then deal with missing value half-hr**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_s.fillna(train_s.median(), inplace = True)\n",
    "test_s.fillna(test_s.median(), inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**resampling to 1hr**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_s_h = train_s.resample('1H').sum()\n",
    "test_s_h = test_s.resample('1H').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Save to csv\n",
    "train_s.to_csv(\"train_s_hh.csv\", index = True)\n",
    "test_s.to_csv(\"train_s_hh.csv\", index = True)\n",
    "train_s_h.to_csv(\"train_s_h.csv\", index = True)\n",
    "test_s_h.to_csv(\"train_s_h.csv\", index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregated   household"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Group by LCLid and aggregate over per hour**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## deal with missing value by interpolating mean of whole column\n",
    "# energy[\"energy\"].fillna(energy[\"energy\"].median(), inplace = True)\n",
    "## group by time stamps and aggregate through mean\n",
    "energy[\"energy\"] = energy[\"energy\"].astype(\"float64\")\n",
    "energy[\"tstp\"] = energy[\"tstp\"].astype(\"datetime64\")\n",
    "energy = energy.groupby('tstp').agg({'energy': lambda x: x.mean(skipna=False)})\n",
    "energy['tstp'] = energy.index\n",
    "energy.drop(['tstp'], axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To prevent data leakage we split trian and test first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_e = energy.iloc[:28750, :]\n",
    "test_e = energy.iloc[28750:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**deal with missing value sampling rate: 30 mins**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//miniconda3/envs/tpot/lib/python3.6/site-packages/pandas/core/generic.py:6245: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    }
   ],
   "source": [
    "train_e.fillna(train_e.median(), inplace = True)\n",
    "test_e.fillna(test_e.median(), inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of missing data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('energy', 0)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## check if there is still missing value\n",
    "missing = missing_count(test_e)\n",
    "df_miss = sorted(missing.items(), key=lambda x: x[1], reverse=True)\n",
    "print('Count of missing data')\n",
    "df_miss[0:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**then deal with missing value and resampling to 1hr**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//miniconda3/envs/TPOT/lib/python3.5/site-packages/pandas/core/generic.py:5208: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "train_e.fillna(train_e.median(), inplace = True)\n",
    "test_e.fillna(test_e.median(), inplace = True)\n",
    "train_e = train_e.resample('1H').sum()\n",
    "test_e = test_e.resample('1H').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of missing data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('energy', 673)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## check if there is still missing value\n",
    "missing = missing_count(train_e)\n",
    "df_miss = sorted(missing.items(), key=lambda x: x[1], reverse=True)\n",
    "print('Count of missing data')\n",
    "df_miss[0:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weather datan processing: Londo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weather = pd.read_csv('../smart-meters-in-london/weather_hourly_darksky.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## set index as time stamp\n",
    "weather = weather.set_index(\"time\")\n",
    "weather.index = weather.index.astype(\"datetime64[ns]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## apparently the sequence in between is not correct\n",
    "weather = weather.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Missing values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of missing data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('pressure', 1300),\n",
       " ('visibility', 0),\n",
       " ('windBearing', 0),\n",
       " ('temperature', 0),\n",
       " ('dewPoint', 0),\n",
       " ('apparentTemperature', 0),\n",
       " ('windSpeed', 0),\n",
       " ('precipType', 0),\n",
       " ('icon', 0),\n",
       " ('humidity', 0),\n",
       " ('summary', 0)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing = count_missing(weather)\n",
    "df_miss = sorted(missing.items(), key=lambda x: x[1], reverse=True)\n",
    "print('Percent of missing data')\n",
    "df_miss[0:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## drop columns wont be used later\n",
    "weather.drop(['precipType','icon','summary'], axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "##merge trian and test seperately\n",
    "train =  weather.merge(train_e, how ='right', left_index = True, right_index = True)\n",
    "test = weather.merge(test_e.iloc[1:,:], how = 'right', left_index = True, right_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(\"hh_train_nan.csv\", index = True)\n",
    "test.to_csv(\"hh_test_nan.csv\", index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"hh_train_nan.csv\", index_col='tstp')\n",
    "test = pd.read_csv(\"hh_test_nan.csv\", index_col='tstp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "## interpolate nan\n",
    "for col in train.columns:\n",
    "    train[col] = train[col].interpolate(method='linear')\n",
    "for col in test.columns:\n",
    "    test[col] = test[col].interpolate(method = \"linear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "## data set without catagorical features\n",
    "train.to_csv(\"train_nocat_hh.csv\", index = True)\n",
    "test.to_csv(\"test_nocat_hh.csv\", index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**One hot encoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Examine unique categories in categorical features\n",
    "p = list(weather[\"precipType\"].unique()) \n",
    "i = list(weather[\"icon\"].unique()) \n",
    "u = list(weather[\"summary\"].unique())\n",
    "# Sort them for one hot encoding labels\n",
    "p.sort()\n",
    "i.sort()\n",
    "u.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "## One hot encoding these features above\n",
    "onehot = OneHotEncoder(dtype=np.int, sparse=True)\n",
    "nominals = pd.DataFrame(onehot.fit_transform(weather[['precipType', 'icon','summary']]).toarray(),columns=p+i+u)\n",
    "nominals.index = weather.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of ['time'] are in the columns\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-a43aedab6b50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Concate nominals with origin weather dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mweather\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweather\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"time\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mweather\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweather\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"datetime64\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#weather.drop([\"precipType\",\"icon\",\"summary\"],axis = 1, inplace = True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#weather =  weather.merge(nominals, left_index = True, right_index = True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//miniconda3/envs/TPOT/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mset_index\u001b[0;34m(self, keys, drop, append, inplace, verify_integrity)\u001b[0m\n\u001b[1;32m   4409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4410\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4411\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"None of {} are in the columns\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4413\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of ['time'] are in the columns\""
     ]
    }
   ],
   "source": [
    "#Concate nominals with origin weather dataframe\n",
    "weather = weather.set_index(\"time\")\n",
    "weather.index = weather.index.astype(\"datetime64\")\n",
    "#weather.drop([\"precipType\",\"icon\",\"summary\"],axis = 1, inplace = True)\n",
    "weather =  weather.merge(nominals, left_index = True, right_index = True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tpot",
   "language": "python",
   "name": "tpot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
