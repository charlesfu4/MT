{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/anaconda3/envs/autosk07/lib/python3.7/site-packages/pyparsing.py:3190: FutureWarning: Possible set intersection at position 3\n",
      "  self.re = re.compile(self.reString)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import autosklearn.regression as autoreg\n",
    "from autosklearn.experimental.askl2 import AutoSklearn2Classifier\n",
    "from autosklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from pandas import datetime\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.stattools import acf, pacf\n",
    "from functions import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import BaseCrossValidator\n",
    "class BlockingTimeSeriesSplit(BaseCrossValidator):\n",
    "    def __init__(self, n_splits):\n",
    "        self.n_splits = n_splits\n",
    "    \n",
    "    def get_n_splits(self, X, y, groups):\n",
    "        return self.n_splits\n",
    "    \n",
    "    def split(self, X, y=None, groups=None):\n",
    "        n_samples = len(X)\n",
    "        k_fold_size = n_samples // self.n_splits\n",
    "        indices = np.arange(n_samples)\n",
    "\n",
    "        margin = 0\n",
    "        for i in range(self.n_splits):\n",
    "            start = i * k_fold_size\n",
    "            stop = start + k_fold_size\n",
    "            mid = int(0.8 * (stop - start)) + start\n",
    "            yield indices[start: mid], indices[mid + margin: stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantile_loss(solution, prediction, quantile):\n",
    "    e = solution - prediction\n",
    "    return np.mean(np.maximum(e*quantile, e*(quantile - 1)))\n",
    "\n",
    "qloss_05= make_scorer(\n",
    "        name=\"quantile_loss_05\",\n",
    "        score_func=quantile_loss,\n",
    "        optimum=1,\n",
    "        greater_is_better=False,\n",
    "        needs_proba=False,\n",
    "        needs_threshold=False,\n",
    "        quantile=0.05,\n",
    "    )\n",
    "qloss_95= make_scorer(\n",
    "        name=\"quantile_loss_95\",\n",
    "        score_func=quantile_loss,\n",
    "        optimum=1,\n",
    "        greater_is_better=False,\n",
    "        needs_proba=False,\n",
    "        needs_threshold=False,\n",
    "        quantile=0.95,\n",
    "    )\n",
    "\n",
    "qloss_10= make_scorer(\n",
    "        name=\"quantile_loss_10\",\n",
    "        score_func=quantile_loss,\n",
    "        optimum=1,\n",
    "        greater_is_better=False,\n",
    "        needs_proba=False,\n",
    "        needs_threshold=False,\n",
    "        quantile=0.10,\n",
    "    )\n",
    "\n",
    "qloss_90= make_scorer(\n",
    "        name=\"quantile_loss_90\",\n",
    "        score_func=quantile_loss,\n",
    "        optimum=1,\n",
    "        greater_is_better=False,\n",
    "        needs_proba=False,\n",
    "        needs_threshold=False,\n",
    "        quantile=0.90,\n",
    "    )\n",
    "qloss_025= make_scorer(\n",
    "        name=\"quantile_loss_025\",\n",
    "        score_func=quantile_loss,\n",
    "        optimum=1,\n",
    "        greater_is_better=False,\n",
    "        needs_proba=False,\n",
    "        needs_threshold=False,\n",
    "        quantile=0.025,\n",
    "    )\n",
    "\n",
    "qloss_975= make_scorer(\n",
    "        name=\"quantile_loss_975\",\n",
    "        score_func=quantile_loss,\n",
    "        optimum=1,\n",
    "        greater_is_better=True,\n",
    "        needs_proba=False,\n",
    "        needs_threshold=False,\n",
    "        quantile=0.975,\n",
    "    )\n",
    "qloss_5 = make_scorer(\n",
    "        name=\"quantile_loss_5\",\n",
    "        score_func=quantile_loss,\n",
    "        optimum=1,\n",
    "        greater_is_better=True,\n",
    "        needs_proba=False,\n",
    "        needs_threshold=False,\n",
    "        quantile=0.5,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../data/train_solar.csv\", index_col = 'timestamp')\n",
    "test = pd.read_csv(\"../data/test_solar.csv\", index_col = 'timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f7f82746cd0>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train.energy.to_numpy())\n",
    "plt.plot(test.energy.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('f_agg_\"mean\"__maxlag_300', 0.12146818748667855)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tsfresh.feature_extraction.feature_calculators import agg_autocorrelation\n",
    "agg_autocorrelation(train.energy, param=[{\"f_agg\":'mean', \n",
    "                                         \"maxlag\":300}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = extract_dmhq(train)\n",
    "test = extract_dmhq(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "## Shuffle by every two days\n",
    "data = pd.concat([train, test],axis = 0)\n",
    "data = extract_dmhq(data)\n",
    "cols = ['yd']\n",
    "ftrain, ttrain = feature_target_construct(data, 'energy', 200, 192, 0, 1, cols, 4,\n",
    "                                          wd_on = False, d_on = False,\n",
    "                                          m_on = False, h_on = False, q_on = False)\n",
    "data = pd.concat([ftrain, ttrain], axis = 1)\n",
    "\n",
    "# now define random split groups\n",
    "groups = [data for _, data in data.groupby('yd1(t+0)')]\n",
    "random.shuffle(groups,)\n",
    "\n",
    "for i, df in enumerate(groups):\n",
    "    data['yd1(t+0)'] = i+1\n",
    "shuffled = pd.concat(groups).reset_index(drop=True)\n",
    "ftrain = shuffled.iloc[:,1:201]\n",
    "ttrain = shuffled.iloc[:,201:]\n",
    "\n",
    "## split in 7/3 manner\n",
    "train_X, test_X, train_Y, test_Y = train_test_split(ftrain, ttrain, train_size = 0.7, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['cloudCover','uvIndex']\n",
    "ftrain, ttrain = feature_target_construct(train, 'energy', 200, 192, 0, 1, cols, 4,\n",
    "                                          wd_on = False, d_on = False,\n",
    "                                          m_on = False, h_on = False, q_on = False)\n",
    "\n",
    "ftest, ttest = feature_target_construct(test, 'energy', 200, 192, 0, 1, cols, 4, \n",
    "                                        wd_on = False, d_on = False,\n",
    "                                        m_on = False, h_on = False, q_on = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "rr = Ridge(alpha=10000)\n",
    "rr.fit(ftrain, ttrain)\n",
    "ypred = rr.predict(ftest)\n",
    "yhat = rr.predict(ftrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesRegressor, RandomForestRegressor\n",
    "etr = RandomForestRegressor(n_jobs=3, bootstrap=True, warm_start = True)\n",
    "etr.fit(ftrain, ttrain)\n",
    "ypred = etr.predict(ftest)\n",
    "yhat = etr.predict(ftrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 2.4511249482112514\n",
      "MAE: 0.8838524104818203\n",
      "r2_score: 0.69171781862523\n",
      "MSE: 0.49736038143063094\n",
      "MAE: 0.37839468044687097\n",
      "r2_score: 0.3758864150837292\n"
     ]
    }
   ],
   "source": [
    "get_eval(ttrain, yhat)\n",
    "get_eval(ttest, ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 2.556127100034985\n",
      "MAE: 0.912709083963818\n",
      "r2_score: 0.6774605416186056\n",
      "MSE: 0.5364453795046394\n",
      "MAE: 0.4269374202416481\n",
      "r2_score: 0.3189546438393651\n"
     ]
    }
   ],
   "source": [
    "get_eval(ttrain, yhat)\n",
    "get_eval(ttest, ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pacf_val, conf = pacf(train.energy, nlags = 700, alpha = 0.05)\n",
    "# indices = np.argwhere((np.abs(pacf_val) > 0.025))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_pacf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-cf1719ecbeec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mncols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplot_pacf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menergy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'plot_pacf' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize = (15,7))\n",
    "plt.ylim(-0.1,0.1)\n",
    "plot_pacf(train.energy, lags = 500, ax = ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tsFresh featuer construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../data/train_solar.csv\", )\n",
    "test = pd.read_csv(\"../data/test_solar.csv\", )\n",
    "ftrain, ttrain = tf_construct(train, 'energy', 200, 192)\n",
    "ftest, ttest = tf_construct(test, 'energy', 200, 192)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 66.06it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.64it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 67.30it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.59it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 70.92it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  7.43it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 68.34it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.61it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 54.34it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.04it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 67.54it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.33it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 68.14it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  3.99it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 60.40it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.21it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 66.81it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  5.85it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 69.29it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  5.79it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 45.54it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  5.45it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 68.12it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.42it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 64.71it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  5.92it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 54.06it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  5.94it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 67.39it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.02it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 63.42it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.37it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 63.93it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.69it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 46.27it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.07it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 65.08it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.59it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 67.50it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  5.20it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 63.50it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  5.93it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 65.07it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.30it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 66.00it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.10it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 65.02it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.71it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 65.88it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  5.65it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 68.11it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.60it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 70.34it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.01it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 56.29it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.57it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 66.23it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.73it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 64.34it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.04it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 60.04it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.74it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 67.95it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  7.49it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 65.41it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  3.63it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 51.90it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.72it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 66.80it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.66it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 60.22it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.48it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 65.64it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.28it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 45.61it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.37it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 66.43it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  5.92it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 67.15it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.45it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 49.80it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.14it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 65.86it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  5.95it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 65.88it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.50it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 67.21it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.71it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 62.70it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.66it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 67.76it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.41it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 66.23it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  5.57it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 54.84it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.59it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 66.90it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.00it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 62.94it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  7.45it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 62.16it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.53it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 62.22it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  7.49it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 66.20it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  5.73it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 65.71it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.54it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 57.70it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.22it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 66.09it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.30it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 66.15it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  3.72it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 46.81it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.56it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 64.87it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.41it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 66.16it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.55it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 50.42it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.01it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 66.70it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.73it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 61.77it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  7.46it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 67.19it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.17it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 43.52it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.48it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 67.71it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.56it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 66.04it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.59it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 62.11it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.22it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 64.81it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  7.25it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 61.60it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.37it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 63.53it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  7.54it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 53.67it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.56it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 63.53it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.52it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 60.80it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.66it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 61.50it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.12it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 63.16it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.66it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 60.59it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  7.11it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 61.57it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.11it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 55.74it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.65it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 64.59it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.59it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 62.42it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  4.10it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 56.48it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.08it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 64.68it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  5.36it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 68.01it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.55it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 46.84it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.62it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 65.18it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.39it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 64.58it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.24it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 54.61it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.23it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 67.94it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.38it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 66.07it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.02it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 67.22it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.17it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 57.24it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.41it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 65.57it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.51it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 66.01it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.65it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 67.02it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.65it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 66.80it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.50it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 68.05it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.76it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 68.34it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.71it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 56.63it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.05it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 67.01it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  7.32it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 68.28it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.15it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 60.56it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.74it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 64.44it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.63it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 67.35it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  3.71it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 51.89it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.57it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 65.29it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  7.55it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 68.77it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.25it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 64.83it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  3.75it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 47.71it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.62it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 65.75it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.35it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 68.78it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  7.06it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 52.02it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.47it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 66.58it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.59it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 67.10it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.72it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 65.54it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.28it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 43.80it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  5.65it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 69.62it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.69it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 67.99it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  5.88it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 67.87it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.76it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 66.50it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.19it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 70.41it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  7.15it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 67.66it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.26it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 63.43it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.64it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 66.60it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.45it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 69.61it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  7.61it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 62.30it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.61it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 66.75it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.49it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 67.16it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.51it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 62.58it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.33it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 55.98it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.33it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 68.18it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.46it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 67.69it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  4.16it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 57.84it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.65it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 70.21it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.69it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 61.62it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.33it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 51.55it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.38it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 67.60it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.69it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 68.90it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  7.26it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 65.77it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.51it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 46.84it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.52it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 66.17it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  7.54it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 68.30it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.20it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 57.56it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.39it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 68.86it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.16it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 63.88it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  7.63it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 68.06it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.11it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 42.41it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.40it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 66.80it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.57it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 67.62it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.22it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 60.97it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  7.58it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 66.45it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.63it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 66.97it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.60it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 64.16it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  5.64it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 64.81it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.59it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 65.78it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.59it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 69.41it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.50it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 58.66it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.65it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 67.39it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.51it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 65.33it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  4.17it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 62.19it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.21it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 68.80it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.24it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 67.50it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.33it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 51.23it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.54it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 72.22it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  5.99it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 66.67it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  7.60it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 67.21it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  5.56it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 47.80it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.58it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 71.02it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.38it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 68.36it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  7.36it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 67.92it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.47it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 65.39it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.43it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 66.76it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.47it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 65.31it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.54it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 45.37it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.22it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 65.84it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.52it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 65.76it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.38it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 66.20it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  5.99it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 69.79it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.30it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 69.89it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.20it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 67.84it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.28it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 54.46it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.34it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 65.44it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.46it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 67.63it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.18it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 60.09it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.63it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 70.29it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.04it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 65.15it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.48it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 66.83it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.57it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 66.48it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.16it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 65.03it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.28it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 66.17it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.50it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 56.50it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.62it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 71.19it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.61it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 69.76it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  7.07it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 46.22it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.57it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 64.22it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.56it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 69.61it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.36it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 51.30it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.28it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 64.91it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.14it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 66.11it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.60it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 68.70it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.53it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 43.25it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.44it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 68.70it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.56it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 63.58it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.56it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 64.02it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.55it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 60.76it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  5.79it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 64.58it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.30it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 62.70it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.57it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 53.60it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.41it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 60.44it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  5.79it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 62.50it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  7.45it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 59.59it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.35it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 65.77it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.26it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 63.22it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.31it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 62.90it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  7.14it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 52.00it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.35it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 57.77it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  5.61it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 64.91it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.17it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 65.85it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.44it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 62.72it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.23it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 60.68it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.06it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 60.33it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.58it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 49.93it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.36it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 62.96it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.51it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 58.24it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  5.81it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 42.63it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.35it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 63.57it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  7.38it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 64.02it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.59it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 44.41it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  5.95it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 64.03it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  7.31it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 60.77it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.14it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 59.75it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  7.43it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 43.26it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.39it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 62.52it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.52it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 62.55it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.29it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 63.53it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.61it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 42.06it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.45it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 63.20it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.39it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 62.73it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.07it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 57.48it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.34it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 60.78it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.40it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 60.24it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  7.41it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 63.81it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.44it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 66.29it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.17it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 64.57it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  5.76it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 68.89it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.62it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 57.70it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.90it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 69.68it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  7.46it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 66.60it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  4.06it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 59.08it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.50it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 67.61it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.61it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 68.73it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.34it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 53.46it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.44it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 64.91it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.62it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 67.14it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.50it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 68.83it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.23it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 49.44it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.68it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 68.02it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.52it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 67.03it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.55it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 67.72it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.36it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 65.50it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.37it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 68.45it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.23it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 67.04it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.45it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 50.62it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.25it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 67.52it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.96it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 66.48it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.48it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 65.37it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.44it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 66.79it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.54it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 67.40it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.56it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 69.63it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.16it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 59.59it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  7.41it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 67.09it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.02it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 64.73it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.13it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 67.21it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.22it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 68.28it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.32it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 68.08it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.02it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 68.23it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.72it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 60.31it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  5.88it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 67.36it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.42it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 63.21it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  4.01it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 52.27it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  5.92it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 66.28it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  7.42it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 65.41it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.10it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 64.35it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  5.97it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 45.75it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.50it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 69.26it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.47it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 69.03it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.54it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 51.88it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.39it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 68.93it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.04it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 68.33it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.50it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 66.50it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.30it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 49.21it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.37it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 67.15it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.00it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 67.42it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  7.34it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 66.30it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.09it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 42.74it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.41it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 70.00it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.45it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 67.58it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  5.70it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 60.76it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  7.10it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 65.24it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  5.88it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 66.94it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.52it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 60.20it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.02it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 58.26it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.39it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 58.14it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.74it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 60.86it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.53it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 52.76it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  5.92it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 56.57it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  7.52it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 59.15it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  4.07it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 54.48it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.39it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 65.20it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.59it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 59.57it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  7.24it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 45.54it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.37it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 65.16it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.65it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 61.57it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  7.15it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 59.01it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.52it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 45.85it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.45it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 63.46it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.47it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 64.69it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.51it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 63.49it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  5.43it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 64.87it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.51it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 65.45it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  7.55it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 63.62it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.61it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 46.68it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.41it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 65.94it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.17it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 70.85it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  5.96it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 67.15it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  5.57it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 68.78it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.39it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 67.23it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  5.30it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 67.41it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.51it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 65.87it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.20it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 68.11it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.35it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 67.34it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  5.69it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 69.40it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.55it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 58.80it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  7.29it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 66.12it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.52it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 68.72it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.94it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 70.79it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.47it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 65.73it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  7.31it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 68.10it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.05it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 65.45it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.09it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 56.39it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.39it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 69.52it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.16it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 66.47it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  3.82it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 56.81it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.39it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 67.65it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  5.96it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 67.24it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.01it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 51.70it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.39it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 66.11it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.40it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 68.20it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.51it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 64.51it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  7.04it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 45.28it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.17it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 66.74it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.05it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 65.81it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  7.34it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 51.75it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  3.64it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 50.69it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.45it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 69.32it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.52it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 66.19it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.98it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 45.68it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.21it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 70.55it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.37it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 68.30it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.43it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 67.67it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  5.94it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 66.30it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.31it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 67.69it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.59it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 69.83it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.46it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 69.40it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.52it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 67.81it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  5.59it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 67.78it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.47it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 66.69it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  7.46it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 58.49it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.28it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 63.50it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.41it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 63.32it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.24it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 66.35it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.51it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 67.03it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.23it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 69.07it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  5.91it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 67.77it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.86it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 53.28it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  5.82it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 54.22it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  3.94it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 65.46it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  4.11it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 58.08it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.34it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 67.52it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  5.68it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 68.67it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  5.87it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 50.51it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.40it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 69.26it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.59it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 68.19it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.44it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 66.26it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.40it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 46.27it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.48it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 67.78it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.36it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 69.66it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  7.41it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 51.47it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  3.67it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 48.84it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.33it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 66.93it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.37it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 67.72it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.08it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 44.68it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.29it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 69.03it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  5.99it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 69.44it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.42it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 70.41it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.52it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 61.09it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  7.36it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 67.35it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.51it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 64.67it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  5.99it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 67.71it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.05it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 66.42it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.25it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 67.73it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.34it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 66.43it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  5.68it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 61.65it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  7.42it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 66.76it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  5.76it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 69.20it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.05it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 66.65it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.33it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 67.74it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.50it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 63.28it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.73it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 68.60it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.53it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 56.62it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.57it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 67.75it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.55it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 66.38it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  4.03it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 59.80it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.05it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 66.32it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.55it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 66.46it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 53.09it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  5.69it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 70.48it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.15it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 67.18it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.11it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 71.42it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  7.31it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 50.04it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.16it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 71.25it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  5.97it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 69.99it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  7.24it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 69.29it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.14it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 67.98it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  5.52it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 59.11it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  7.17it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 59.85it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  5.70it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 46.90it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  5.94it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 64.17it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.50it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 61.74it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.45it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 62.57it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.39it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 64.31it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.35it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 62.31it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  5.93it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 65.29it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.51it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 54.60it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.41it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 58.40it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  5.80it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 60.85it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  7.32it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 59.91it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.08it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 62.87it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.60it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 62.62it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  5.83it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 63.61it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  7.31it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 53.45it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.62it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 62.88it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  7.39it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 57.13it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  3.63it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 48.10it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  5.85it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 67.95it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.22it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 65.86it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  5.93it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 65.23it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  3.99it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 58.41it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.23it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 64.02it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.30it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 63.41it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.58it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 45.37it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  5.49it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 68.53it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.31it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 68.92it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.56it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 67.78it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.34it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 44.37it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.17it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 70.38it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  5.83it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 70.74it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.27it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 49.33it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.10it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 71.34it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  5.86it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 69.58it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.56it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 65.62it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  5.44it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 44.37it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.29it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 68.64it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.48it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 66.66it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  7.30it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 67.57it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  5.99it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 68.97it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  5.37it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 67.34it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.29it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 60.00it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  5.78it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 61.83it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.18it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 64.23it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  5.84it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 65.56it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.35it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 61.42it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  7.18it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 51.06it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  5.57it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 64.26it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.00it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 63.68it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  7.34it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 61.55it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.47it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 63.89it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  5.92it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 63.03it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.08it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 63.96it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  5.61it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 55.17it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.58it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 62.09it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.14it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 61.66it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  7.18it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 60.70it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.36it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 61.87it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  7.32it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 59.55it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.26it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 58.76it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  7.18it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 53.10it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.08it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 64.77it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.42it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 63.95it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  4.03it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 66.69it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.55it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 64.57it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.22it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 64.28it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.61it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 60.11it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  3.71it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 42.40it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.19it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 66.09it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.02it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 64.21it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.35it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 49.76it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.29it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 64.23it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  7.38it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 66.92it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  5.61it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 66.90it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.07it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 44.71it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  5.71it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 67.03it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  7.13it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 66.63it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  7.61it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 67.98it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.17it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 67.29it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.27it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 68.38it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  5.86it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 71.19it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.20it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 68.30it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.31it/s]\n",
      "Rolling: 100%|██████████| 30/30 [00:00<00:00, 69.32it/s]\n",
      "Feature Extraction: 100%|██████████| 1/1 [00:00<00:00,  6.85it/s]\n"
     ]
    }
   ],
   "source": [
    "from tsfresh.utilities.dataframe_functions import make_forecasting_frame\n",
    "from tsfresh import extract_features\n",
    "\n",
    "# ftrain_tf = pd.DataFrame()\n",
    "# for i in range(5000):\n",
    "#     df_time, y = make_forecasting_frame(ftrain.iloc[i,:].to_numpy(), kind = 'time', max_timeshift=300, rolling_direction=1)\n",
    "#     df_time.drop(['time','kind'],axis = 1, inplace = True)\n",
    "#     df_time = df_time.loc[df_time['id'] == 'id=id,timeshift=299']\n",
    "#     extracted_features = extract_features(df_time, column_id='id').dropna(axis = 1)\n",
    "#     ftrain_tf = ftrain_tf.append(extracted_features)\n",
    "\n",
    "ftest_tf = pd.DataFrame()\n",
    "for i in range(ftest.shape[0]):\n",
    "    df_time, y = make_forecasting_frame(ftest.iloc[i,:].to_numpy(), kind = 'time', max_timeshift=300, rolling_direction=1)\n",
    "    df_time.drop(['time','kind'],axis = 1, inplace = True)\n",
    "    df_time = df_time.loc[df_time['id'] == 'id=id,timeshift=299']\n",
    "    extracted_features = extract_features(df_time, column_id='id').dropna(axis = 1)\n",
    "    ftest_tf = ftest_tf.append(extracted_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4509, 758), (509, 758))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ftrain_tf.to_csv(\"tftrain_solar300_n5000.csv\", index= 'id')\n",
    "ftest_tf.to_csv(\"tftest_solar300_p1000.csv\", index= 'id')\n",
    "ftrain_tf.shape, ftest_tf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train:3000, test:500 (384)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftrain_tf = pd.read_csv('tftrain_solar300_n5000.csv', index_col='id')\n",
    "ftest_tf = pd.read_csv('tftest_solar300_p1000.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tsfresh Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "ldata = load_diabetes()\n",
    "X = ldata.data\n",
    "Y = ldata.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((442, 10), (442,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] [2020-07-14 12:54:12,756:smac.runhistory.runhistory.RunHistory] Encountered exception Expecting ',' delimiter: line 1224 column 1276 (char 86614) while reading runhistory from /tmp/autosklearn_tmp_ab07e214-c5bf-11ea-a55b-19c14d88d1e3/smac3-output/run_3722177746/runhistory.json. Not adding any runs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/anaconda3/envs/autosk07/lib/python3.7/site-packages/sklearn/base.py:197: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AutoSklearnRegressor(delete_output_folder_after_terminate=False,\n",
       "                     delete_tmp_folder_after_terminate=False,\n",
       "                     disable_evaluator_output=False, ensemble_memory_limit=5120,\n",
       "                     ensemble_nbest=20, ensemble_size=50,\n",
       "                     exclude_estimators=None, exclude_preprocessors=None,\n",
       "                     get_smac_object_callback=None, include_estimators=None,\n",
       "                     include_preprocessors=None,\n",
       "                     initial_configurations_via_metalearning=0,\n",
       "                     logging_config=None, max_models_on_disc=50,\n",
       "                     metadata_directory=None, metric=None, ml_memory_limit=6144,\n",
       "                     n_jobs=6, output_folder=None, per_run_time_limit=100,\n",
       "                     resampling_strategy='holdout',\n",
       "                     resampling_strategy_arguments=None, seed=123,\n",
       "                     shared_mode=False, smac_scenario_args=None,\n",
       "                     time_left_for_this_task=300, tmp_folder=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "reg_tf = autoreg.AutoSklearnRegressor(time_left_for_this_task=300,\n",
    "                                           per_run_time_limit=100,\n",
    "                                           initial_configurations_via_metalearning=0,\n",
    "                                           ensemble_size=50, \n",
    "                                           ensemble_nbest=20,\n",
    "                                           ensemble_memory_limit=5120, \n",
    "                                           seed=123, ml_memory_limit=6144, \n",
    "                                           include_estimators=None,\n",
    "                                           exclude_estimators=None, \n",
    "                                           include_preprocessors=None, \n",
    "                                           exclude_preprocessors=None, \n",
    "                                           resampling_strategy='holdout',\n",
    "#                                           resampling_strategy_arguments={'folds':5},\n",
    "                                           tmp_folder=None, \n",
    "                                           output_folder=None,\n",
    "                                           delete_tmp_folder_after_terminate=False, \n",
    "                                           delete_output_folder_after_terminate=False, \n",
    "                                           shared_mode=False, \n",
    "                                           n_jobs = 6, \n",
    "                                           disable_evaluator_output=False, \n",
    "                                           get_smac_object_callback=None, \n",
    "                                           smac_scenario_args=None, \n",
    "                                           logging_config=None,\n",
    "                                           metadata_directory=None)\n",
    "\n",
    "\n",
    "reg_tf.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_test_score': array([  0.        ,  -0.54433127,  -1.24104785,  -0.09887468,\n",
       "         -0.52743447,  -0.53437705,  -0.52275845,  -0.5209111 ,\n",
       "         -0.49431656,   0.        ,   0.        ,  -0.54433127,\n",
       "          0.        ,  -0.21273305,  -0.52132784,   0.        ,\n",
       "          0.        ,  -0.53427398,  -0.54433127,  -0.35746065,\n",
       "         -0.49464094,   0.        ,   0.        ,  -0.57642399,\n",
       "         -0.79894038,   0.        ,   0.        ,  -0.45666207,\n",
       "          0.        ,   0.        ,  -0.54012977,  -0.50128339,\n",
       "          0.        ,  -0.54352875,   0.        ,   0.        ,\n",
       "         -1.8786891 ,   0.        ,   0.        ,   0.        ,\n",
       "         -3.7725321 ,   0.        ,   0.        ,  -0.51001161,\n",
       "         -0.54433127,   0.        ,   0.        ,  -0.54433127,\n",
       "          0.        ,  -0.65756299,   0.        ,   0.        ,\n",
       "          0.        ,  -2.19906358,  -0.54433127,  -0.53347609,\n",
       "          0.        ,  -2.8591011 ,  -0.43516198,   0.        ,\n",
       "          0.        ,   0.        ,  -0.54351943,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         -0.54389535,  -1.24104785,   0.        ,   0.        ,\n",
       "          0.        ,  -0.51170328,  -1.24104785,   0.        ,\n",
       "          0.        ,  -0.54433127,   0.        ,   0.        ,\n",
       "         -0.54433127,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,  -0.44177294,   0.        ,   0.        ,\n",
       "          0.        ,  -0.44917562,   0.        ,  -0.4827614 ,\n",
       "         -0.37888946,  -0.54226564,   0.        ,   0.        ,\n",
       "         -1.58825943,  -0.41029794,  -0.54433127,   0.        ,\n",
       "         -0.54433127,   0.        ,   0.        ,  -0.54433127,\n",
       "          0.        ,   0.        ,  -1.1847861 ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,  -1.63916928,\n",
       "          0.        ,  -0.48667944,   0.        ,  -0.54433127,\n",
       "         -0.54433127,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,  -3.73056903,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         -0.54424976,   0.        ,  -0.54433127,   0.        ,\n",
       "         -1.9898741 ,   0.        ,  -0.54433127,   0.        ,\n",
       "         -5.94773071,   0.        ,  -0.54433127,   0.        ,\n",
       "         -0.54433127,  -0.54433127,   0.        ,   0.        ,\n",
       "         -0.54433127,  -0.54433127,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,  -0.39485589,  -0.54433127,\n",
       "        -11.78815829,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,  -0.53288   ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,  -0.54433127,  -0.54433127,\n",
       "          0.        ,  -0.46183244,   0.        ,   0.        ,\n",
       "         -0.54433127,   0.        ,  -0.54433127,   0.        ,\n",
       "          0.        ,  -0.53644352,  -0.54433127,  -0.54433127,\n",
       "         -0.54419534,  -0.53969939,   0.        ,   0.        ,\n",
       "          0.        ,  -2.19906358,  -2.35229916,   0.        ,\n",
       "          0.        ,  -0.57642393,  -0.53867709,   0.        ,\n",
       "          0.        ,  -0.57642399,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,  -0.51414523,\n",
       "          0.        ,  -0.54433127,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,  -0.54432482,\n",
       "         -0.54433127,   0.        ,   0.        ,  -0.51004745,\n",
       "          0.        ,  -0.54246378,   0.        ,  -0.3261154 ,\n",
       "          0.        ,   0.        ,   0.        ,  -0.54433127,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,  -0.77027099,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         -0.61177966,  -0.54433127,   0.        ,  -0.51502352,\n",
       "          0.        ,   0.        ,   0.        ,  -0.53468127,\n",
       "          0.        ,   0.        ,  -0.47543674,   0.        ,\n",
       "          0.        ,  -0.54433127,  -0.54433127,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,  -0.49181582,\n",
       "         -1.9898741 ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,  -1.91534716,  -0.54433127,\n",
       "          0.        ,  -0.53130419,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,  -0.68074514,\n",
       "          0.        ,   0.        ,  -0.54433127,  -1.91534716,\n",
       "         -1.25763403,  -2.02504969,  -0.57642393,  -0.54433127,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,  -0.54433127,   0.        ,   0.        ,\n",
       "         -0.54433127,   0.        ,   0.        ,  -0.35379108,\n",
       "         -0.35379108,  -0.54433127,   0.        ,  -0.54431688,\n",
       "          0.        ,  -0.54433127,   0.        ,  -7.35674133,\n",
       "          0.        ,  -0.50767372,  -0.51835552,   0.        ,\n",
       "         -1.24104785,   0.        ,   0.        ,   0.        ,\n",
       "         -0.35428207,  -0.57777525,   0.        ,  -1.27574694,\n",
       "         -0.54433127,  -2.19906358,   0.        ,  -0.54433127,\n",
       "         -1.24104785,   0.        ,  -0.51262331,  -5.69039913,\n",
       "         -2.19906358,   0.        ,   0.        ,   0.        ,\n",
       "         -0.54433127,   0.        ,   0.        ,  -0.3261154 ,\n",
       "         -0.3261154 ,  -0.63147654,  -0.9333528 ,   0.        ,\n",
       "          0.        ,  -0.54433127,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,  -1.8786891 ,  -0.54433127,\n",
       "          0.        ,   0.        ,  -0.50699279,  -0.54433127,\n",
       "          0.        ,  -0.53869914,  -1.27574694,  -5.53944297,\n",
       "         -0.54433127,   0.        ,   0.        ,  -0.54433127,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         -0.50736791,   0.        ,  -0.75544876,   0.        ,\n",
       "         -2.35102574,  -0.60350718,  -0.42407769,   0.        ,\n",
       "         -0.54433127,   0.        ,  -0.54433127,  -0.54433127,\n",
       "         -0.54433127,   0.        ,  -1.24104785,  -0.51103236,\n",
       "          0.        ,  -0.54433127,  -0.40415808,   0.        ,\n",
       "          0.        ,   0.        ,  -0.54433127,   0.        ,\n",
       "         -0.49359427,  -0.54433127,   0.        ,   0.        ,\n",
       "          0.        ,  -0.46848039,  -0.51262132,  -1.3841247 ,\n",
       "         -0.54433127,   0.        ,   0.        ,   0.        ,\n",
       "         -2.54435632,   0.        ,  -0.41170866,   0.        ,\n",
       "          0.        ,   0.        ,   0.        , -20.73388801,\n",
       "        -20.73388801,   0.        ,  -0.54433127,  -0.40599971,\n",
       "         -3.88622569,  -0.64032267,   0.        ,  -0.54433127,\n",
       "         -0.54433127,  -0.54433127,  -0.50058359,  -0.54433127,\n",
       "         -0.54433127,  -0.54433127,   0.        ,  -0.54433127,\n",
       "          0.        ,  -0.45938401,   0.        ,  -0.54433127,\n",
       "         -0.54433127,  -0.54433127,   0.        ,  -0.50736791,\n",
       "          0.        ,  -0.61177966,  -0.54433127,  -0.54433127,\n",
       "          0.        ,  -0.61177966,  -0.54433127,  -0.54433127,\n",
       "          0.        ,   0.        ,  -0.61177966,   0.        ,\n",
       "         -0.54433127,  -0.54433127,   0.        ,  -0.54315885,\n",
       "         -0.52894124,   0.        ,  -1.24104785,  -1.21733414,\n",
       "         -0.30880147,  -0.51624293, -16.60238116,  -0.40052311,\n",
       "          0.        ,  -0.54208711,  -0.54433127,  -0.54433127,\n",
       "         -0.54433127,   0.        , -16.60238116,  -1.64171916,\n",
       "         -0.51498751,  -0.54433127,  -0.54433127,  -0.57777525,\n",
       "         -1.08140444,  -0.54433127,   0.        ,   0.        ,\n",
       "         -0.54433127,  -0.53280863,   0.        ,   0.        ,\n",
       "         -0.54433127,  -0.54433127,  -2.19906358,  -0.54433127,\n",
       "         -3.88622569,  -0.47519137,  -0.43476497,   0.        ,\n",
       "         -0.54433127,  -0.41459229,  -1.3753399 ,  -0.54433127,\n",
       "         -0.54433127,  -0.54433127,  -0.54433127,  -1.24104785,\n",
       "         -0.54433127,  -2.00732153,  -2.00732153,  -0.54433127,\n",
       "          0.        ,  -1.43040362,  -1.83996391,  -0.54433127,\n",
       "         -0.54433127,  -0.54433127,   0.        ,  -0.53346448,\n",
       "        -20.73388801,   0.        ,   0.        ,  -0.53763257,\n",
       "         -2.54435632,  -0.48667944,  -0.54433127,   0.        ,\n",
       "          0.        ,   0.        ,  -0.53118072,  -0.54379244,\n",
       "         -0.54433127,  -0.54433127,  -0.54433127, -20.73388801,\n",
       "         -0.54433127,  -0.54433127,   0.        ,  -0.54433127,\n",
       "        -20.73388801,   0.        ,  -0.54433127,  -0.54433127,\n",
       "         -0.54433127, -20.73388801,  -0.54433127,  -0.53234139,\n",
       "         -0.09887468,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,  -1.24104785,  -1.43040362,\n",
       "          0.        ,  -1.24104785,  -0.51426949,  -0.50454552,\n",
       "         -0.54433127,  -0.54433127,   0.        ,  -0.54433127,\n",
       "         -0.54433127,  -0.54433127,  -0.54433127, -16.60238116,\n",
       "         -1.45240348,  -1.25483867,  -1.3753399 ,  -0.29414178,\n",
       "         -0.29414178, -20.73388801,  -0.54433127,  -0.54433127,\n",
       "         -0.50751564,  -0.5392706 ,  -0.52678014, -20.73388801,\n",
       "          0.        ,  -0.54433127,  -0.54433127,  -0.54433127,\n",
       "          0.        ,  -0.54433127,  -0.54433127,  -1.24104785,\n",
       "         -0.54093176,   0.        ,  -0.29414178,  -0.54433127,\n",
       "          0.        ,  -0.29414178,  -0.54126571,  -0.54433127,\n",
       "          0.        ,  -0.54433127,  -0.54433127,  -2.68724644,\n",
       "          0.        ,  -0.29414178,  -0.79226861,  -0.54433127,\n",
       "         -0.54433127,  -0.54433127,  -2.68724644,  -0.51160719,\n",
       "         -0.54433127,  -0.29414178,  -0.54433127,  -0.29414178,\n",
       "         -0.54433127,  -0.30880147,  -0.42434316,   0.        ,\n",
       "         -1.24104785,  -0.54433127,  -6.59680939,  -3.88622569,\n",
       "         -3.88622569,   0.        ,  -0.54433127,  -0.54433127,\n",
       "          0.        ,   0.        ,  -0.29414178,   0.        ,\n",
       "         -0.54433127,   0.        ,  -3.88622569,  -0.29414178,\n",
       "          0.        ,  -0.54433127,  -0.54433127,  -0.54433127,\n",
       "         -5.53944297, -20.73388801,   0.        ,   0.        ,\n",
       "        -20.73388801,   0.        ,  -3.7725321 ,  -1.24104785,\n",
       "          0.        ,   0.        ,  -0.53396326,   0.        ,\n",
       "          0.        ,  -0.54433127,  -0.53348075,   0.        ,\n",
       "         -0.54143141,  -0.54433127,  -0.21273305,  -0.29414178,\n",
       "         -0.54433127,  -0.54433127,  -0.54433127,  -0.54433127,\n",
       "         -0.36299985,   0.        ,  -0.28059254,  -0.54433127,\n",
       "         -1.24104785,  -0.54348416,  -0.54433127,  -2.68724644,\n",
       "         -1.64171916,   0.        ,  -0.04039101,   0.        ,\n",
       "         -5.94773071,  -0.35428207,   0.        ,  -0.47001154,\n",
       "         -1.24104785,   0.        ,  -0.29414178,  -0.54433127,\n",
       "         -0.54433127,  -0.09887468,  -1.64171916,  -0.54433127,\n",
       "         -0.54433127,  -0.54433127,  -0.54433127,   0.        ,\n",
       "         -0.54433127,  -0.54433014,  -0.54433127,   0.        ,\n",
       "          0.        ,   0.        ,  -0.49571256,  -0.49434769,\n",
       "         -0.54047833,  -1.24104785,   0.        ,   0.        ,\n",
       "         -4.93357972,   0.        ,  -0.54433127,   0.        ,\n",
       "          0.        ,  -0.54433127,  -0.53189497,  -0.5252171 ,\n",
       "          0.        ,  -0.52377629,  -0.04039101,  -0.54433127,\n",
       "         -0.54433127,   0.        ,  -0.54433127,  -0.04039101,\n",
       "         -1.74482002,  -0.54433127,   0.        ,  -0.54433127,\n",
       "         -0.51613489,   0.        ,   0.        ,  -0.54433127,\n",
       "          0.        ,  -0.54047432,  -1.25483867,  -0.54433127,\n",
       "         -0.04039101,  -0.04039101,  -0.64524468,  -0.04039101,\n",
       "         -0.04039101,  -1.92734197,  -0.04039101,  -0.04039101,\n",
       "         -0.04039101,  -1.6049316 ,   0.        ,  -0.04039101,\n",
       "         -1.24104785,   0.        ,  -0.54433127,   0.        ,\n",
       "          0.        ,  -0.5160776 ,  -1.45240348,  -0.04039101,\n",
       "          0.        ,  -0.54433127,  -0.54433127,  -1.25483867,\n",
       "         -2.68724644,   0.        ,  -1.08140444,  -1.08140444,\n",
       "         -2.68724644,  -2.68724644,   0.        ,  -0.52367172,\n",
       "         -2.00732153,  -1.24104785,   0.        ,  -0.54433127,\n",
       "         -0.54109373,  -0.43498653,  -0.54433127,  -0.5282865 ,\n",
       "          0.        ,  -0.49921142,   0.        ,  -0.53353614,\n",
       "         -0.54433127,  -0.04039101,   0.        ,   0.        ]),\n",
       " 'mean_fit_time': array([0.68868017, 0.18206096, 0.14177084, 0.20103526, 0.19524288,\n",
       "        0.28238988, 0.18794155, 0.17011356, 0.21763396, 0.67866087,\n",
       "        0.18311024, 0.14086008, 0.72988963, 0.20243335, 0.19429779,\n",
       "        0.54665971, 0.16604543, 0.23125601, 0.17627311, 0.24286938,\n",
       "        0.19037557, 0.7107451 , 0.6983068 , 0.22808695, 0.32158184,\n",
       "        0.77353907, 0.6930387 , 0.20447636, 0.86483908, 0.51847482,\n",
       "        0.2126646 , 0.19303823, 0.15504909, 0.18816829, 0.56256199,\n",
       "        0.13033533, 0.15091705, 0.5332911 , 0.55555606, 0.73866487,\n",
       "        0.26480055, 0.14625788, 1.03020144, 0.17071128, 0.26865649,\n",
       "        0.21874118, 0.7047317 , 0.18203545, 0.79777551, 0.20851183,\n",
       "        0.56248784, 0.65021563, 0.23234558, 0.26717186, 0.24538994,\n",
       "        0.29542899, 0.79735899, 0.17105007, 0.16859627, 0.18449068,\n",
       "        0.16078234, 0.60881186, 0.21584463, 0.21567678, 0.31966257,\n",
       "        0.79324508, 0.23274493, 0.71728563, 0.24838901, 0.23752761,\n",
       "        0.19721055, 0.69078588, 0.81485415, 0.26853704, 0.19717979,\n",
       "        0.16031909, 0.88990545, 0.19399357, 0.76557827, 0.20803809,\n",
       "        0.32165861, 0.74760842, 0.18307924, 0.20083904, 0.53405309,\n",
       "        0.19950533, 0.20508242, 0.26374078, 0.54828835, 0.18304038,\n",
       "        0.14583993, 0.19738936, 0.2042563 , 0.20583177, 0.79386234,\n",
       "        0.55645323, 0.13714457, 0.24703217, 0.22709036, 0.86310816,\n",
       "        0.15184736, 0.62005544, 0.82312703, 0.20542026, 0.183671  ,\n",
       "        0.22580671, 0.17544365, 0.77264428, 0.14800453, 0.534199  ,\n",
       "        0.71696925, 0.15339422, 0.62345481, 0.15297747, 0.17305398,\n",
       "        0.23928165, 0.21083283, 0.24576545, 0.63783693, 0.79261208,\n",
       "        0.63157463, 0.24664307, 0.17194271, 1.11629272, 0.16491771,\n",
       "        0.80293608, 0.52664542, 0.65871763, 0.20414996, 0.16754937,\n",
       "        0.22149515, 0.14155626, 0.20231175, 0.63351607, 0.21239901,\n",
       "        0.24313498, 0.34194779, 0.66252732, 0.23030257, 0.25595212,\n",
       "        0.3642664 , 0.29200888, 0.15858173, 0.6264267 , 0.32808399,\n",
       "        0.18602753, 0.73440027, 0.81575847, 0.16805768, 0.22423601,\n",
       "        0.23599148, 0.22177505, 0.19041061, 0.22336197, 0.19747567,\n",
       "        0.59414959, 0.20559859, 0.71492767, 0.31670785, 0.70058751,\n",
       "        0.65046239, 0.56733513, 0.19573879, 0.57048512, 1.0360868 ,\n",
       "        0.79682422, 0.16248608, 0.27649212, 0.77468443, 0.3260324 ,\n",
       "        0.63783836, 0.60645509, 0.22871351, 0.7571044 , 0.27516317,\n",
       "        0.77714729, 0.74211383, 0.2255497 , 0.2280035 , 0.23226857,\n",
       "        0.18262959, 0.21114635, 0.8624053 , 0.25517035, 0.70199323,\n",
       "        0.32087064, 0.19383597, 0.71925974, 0.9242835 , 0.43289185,\n",
       "        0.20330334, 0.20398378, 0.69857049, 0.22046471, 0.8047595 ,\n",
       "        0.68669534, 0.22196746, 0.19161272, 0.20427942, 0.98482299,\n",
       "        0.71100998, 0.17296624, 0.59592724, 0.25751734, 0.68800259,\n",
       "        0.21121001, 0.65554786, 0.74535131, 0.63609529, 0.17764378,\n",
       "        0.76663589, 0.2093637 , 0.18931103, 0.22421956, 0.17545605,\n",
       "        0.24689627, 0.18742204, 0.25501442, 0.18356061, 0.38852239,\n",
       "        0.2164135 , 0.28054404, 0.24287605, 0.34308934, 0.61742997,\n",
       "        0.79460979, 0.60248947, 0.2810607 , 0.89096141, 0.23695493,\n",
       "        0.19569778, 0.67692232, 0.58193946, 0.27610683, 0.71165633,\n",
       "        0.20932126, 0.22374701, 0.21387553, 0.21489596, 0.19785213,\n",
       "        0.84875941, 0.6102736 , 0.20320034, 0.22867942, 0.18636942,\n",
       "        0.63275146, 0.19879103, 0.68890023, 0.5551095 , 0.18617129,\n",
       "        0.2550385 , 0.67350221, 0.63872075, 0.2416923 , 0.87367988,\n",
       "        0.8704133 , 0.22530055, 0.36076999, 0.90497994, 0.28094172,\n",
       "        0.23205757, 0.94960952, 0.79121494, 0.70144629, 0.2193222 ,\n",
       "        0.23968983, 0.18649268, 0.32594347, 0.60249472, 0.27568746,\n",
       "        0.7480402 , 0.94662452, 0.77340555, 0.56086016, 0.18229055,\n",
       "        0.21061492, 0.22217417, 0.89747119, 0.29767537, 0.30397296,\n",
       "        0.24660993, 0.23181486, 0.22386479, 0.21975493, 0.59744287,\n",
       "        0.94613504, 0.63992262, 0.63782525, 0.14056134, 0.20838046,\n",
       "        0.23042226, 0.18990302, 0.57556009, 0.23030615, 0.92446208,\n",
       "        0.89778304, 0.23416328, 0.155617  , 0.63610291, 0.21587396,\n",
       "        0.27890563, 0.18757606, 0.187047  , 0.19573927, 0.18211889,\n",
       "        0.15168977, 0.28441715, 0.30721498, 0.17893219, 0.25866151,\n",
       "        0.21582556, 0.23491955, 0.25229883, 0.74711156, 0.71013951,\n",
       "        0.2296896 , 0.26465321, 0.2762754 , 0.18186402, 0.19391608,\n",
       "        0.20011258, 0.26525974, 0.87009692, 0.25314307, 0.1536212 ,\n",
       "        0.71555114, 0.21462727, 0.20548868, 0.1646781 , 0.22655725,\n",
       "        0.75034475, 0.63093185, 0.25695682, 0.206424  , 0.24670863,\n",
       "        0.21012902, 0.20320773, 0.31157017, 0.26485634, 0.17937994,\n",
       "        0.23200583, 0.22535896, 0.23321104, 0.1868813 , 0.1961906 ,\n",
       "        0.1450069 , 0.15453959, 0.21628284, 0.86098766, 0.18766141,\n",
       "        0.21863008, 0.22323155, 0.24002028, 0.24516654, 0.20540261,\n",
       "        0.26152277, 0.32991576, 0.72789502, 0.79042959, 0.21486664,\n",
       "        0.2295692 , 0.23257828, 0.72187114, 0.73098969, 0.25296307,\n",
       "        0.22614026, 0.22222018, 0.15583944, 0.21945143, 0.16505289,\n",
       "        0.19466162, 0.2458241 , 0.18655014, 0.14278555, 0.25166273,\n",
       "        0.21947861, 0.21305227, 0.17641568, 0.24841762, 0.19219208,\n",
       "        0.8399477 , 0.24998379, 0.21630669, 0.67007971, 0.81922722,\n",
       "        0.16382217, 0.25275803, 0.23156357, 0.26194978, 0.24366689,\n",
       "        0.81611061, 0.52942586, 0.16502094, 0.24153304, 0.33409047,\n",
       "        0.23551273, 0.15009713, 0.20293236, 0.63804364, 0.20326042,\n",
       "        0.2730484 , 0.2363112 , 0.20753431, 0.6773684 , 1.00316453,\n",
       "        0.19076967, 0.20026135, 0.29163933, 0.21772432, 0.63823414,\n",
       "        0.32079434, 0.37314558, 0.2226882 , 0.23584771, 0.14111853,\n",
       "        0.31927872, 0.18234968, 0.20512938, 0.24188018, 0.23719907,\n",
       "        0.16666937, 0.22302246, 0.93264794, 0.21670103, 0.90952516,\n",
       "        0.32984209, 0.17842841, 0.26896691, 0.15087032, 0.20329928,\n",
       "        0.59986043, 0.2668097 , 0.63243341, 0.31653214, 0.26496434,\n",
       "        0.26672673, 0.64574552, 0.21545053, 0.17397904, 0.21764517,\n",
       "        0.86471987, 0.21108627, 0.27757645, 0.2011652 , 0.22468781,\n",
       "        0.37861872, 0.205235  , 0.2350347 , 0.22266197, 0.30015898,\n",
       "        0.19409585, 0.22477317, 0.24021149, 0.19982505, 0.23264003,\n",
       "        0.22762918, 0.58901429, 0.22231507, 0.23221946, 0.24793625,\n",
       "        0.23487282, 0.21947432, 0.20283628, 0.15348601, 0.2208724 ,\n",
       "        0.20295739, 0.2326479 , 0.28948069, 0.18593693, 0.23608422,\n",
       "        0.79355359, 0.19709682, 0.22879815, 0.31523299, 0.54880261,\n",
       "        0.20375967, 0.21133161, 0.24026322, 0.16325498, 0.30060959,\n",
       "        0.24034643, 0.24225688, 0.30289459, 0.64665866, 0.21313739,\n",
       "        0.32493162, 0.24562383, 0.20294642, 0.18970227, 0.33863187,\n",
       "        0.21995234, 0.18834639, 0.15043473, 0.21280766, 0.18003964,\n",
       "        0.24780631, 0.69324732, 0.19377899, 0.18905878, 0.24331641,\n",
       "        0.20083499, 0.20714211, 0.79021549, 0.22933412, 0.22326636,\n",
       "        0.58052492, 0.8348999 , 0.22328949, 0.24743748, 0.15340257,\n",
       "        0.20546889, 0.63531208, 0.66337752, 0.22791648, 0.24509287,\n",
       "        0.29128647, 0.29578757, 0.28202176, 0.28219461, 0.23505139,\n",
       "        0.21159315, 0.25030565, 0.82738447, 0.29098058, 0.34187007,\n",
       "        0.79365635, 0.21937561, 0.23880839, 0.21193695, 0.2475009 ,\n",
       "        0.23500681, 0.22012472, 0.21083474, 0.22442985, 0.19253945,\n",
       "        0.17959499, 0.76378322, 0.18255377, 0.25062871, 0.20592546,\n",
       "        0.24284816, 0.27512932, 0.27192998, 0.20495605, 0.28965497,\n",
       "        0.29191732, 0.76634455, 0.23727655, 0.26669979, 0.20027256,\n",
       "        0.27013779, 0.31460738, 0.25232744, 0.2045455 , 0.20937157,\n",
       "        0.19281387, 0.24337029, 0.2132864 , 0.24170017, 0.24567509,\n",
       "        0.20613766, 0.21735954, 0.20273876, 0.20043731, 0.58634543,\n",
       "        0.23445725, 0.20602846, 0.25386548, 0.80756283, 0.28556323,\n",
       "        0.29350591, 0.25035405, 0.21933556, 0.61436439, 0.25522494,\n",
       "        0.2010622 , 0.13668442, 0.22425246, 0.2150209 , 0.31939864,\n",
       "        0.21114278, 0.20430088, 0.20499229, 0.23197198, 0.70143151,\n",
       "        0.24530005, 0.18342566, 0.20187545, 0.24057436, 0.19398046,\n",
       "        0.23067999, 0.24056029, 0.22297382, 0.20336413, 0.27154422,\n",
       "        0.2104063 , 0.25162435, 0.2775147 , 0.2090106 , 0.63817263,\n",
       "        0.19003105, 0.22725105, 0.255126  , 0.20724988, 0.19246888,\n",
       "        0.58966279, 0.3091495 , 0.29131365, 0.23896241, 0.70271897,\n",
       "        0.21093225, 0.21651816, 0.24035811, 0.82481217, 0.23638868,\n",
       "        0.2037797 , 0.2267127 , 0.20358062, 0.22012949, 0.19429946,\n",
       "        0.23105979, 0.20139217, 0.88049126, 0.80990458, 0.19054127,\n",
       "        0.65373611, 0.17773247, 0.3826611 , 0.88650441, 0.68741202,\n",
       "        0.23665309, 0.88892055, 0.68831682, 0.2140615 , 0.22500396,\n",
       "        0.85264039, 0.30072141, 0.22062659, 0.23827744, 0.26500225,\n",
       "        0.16697001, 0.27101994, 0.2899251 , 0.20075464, 0.21104074,\n",
       "        0.17939234, 0.15092015, 0.15352106, 0.21878386, 0.29841614,\n",
       "        0.2150259 , 0.25599885, 0.25500345, 0.67951131, 0.21674943,\n",
       "        0.63418293, 0.17673802, 0.20684052, 0.694628  , 0.23248196,\n",
       "        0.22789645, 0.65121126, 0.16972852, 0.19984984, 0.26874614,\n",
       "        0.17146993, 0.20978737, 0.20581222, 0.33140731, 0.20860624,\n",
       "        0.22791982, 0.20572066, 0.19755363, 0.21803474, 0.25960326,\n",
       "        0.71041727, 0.59277415, 0.59030914, 0.21290016, 0.25148726,\n",
       "        0.18819332, 0.14992261, 0.87297487, 0.76355267, 0.21196437,\n",
       "        0.20215058, 0.23938608, 0.69765019, 0.7567656 , 0.15567327,\n",
       "        0.29819894, 0.23824072, 0.81409097, 0.21105456, 0.30375886,\n",
       "        0.21889377, 0.3316083 , 0.80094886, 0.19147563, 0.1951611 ,\n",
       "        0.23726845, 0.22275543, 0.85918236, 0.23824048, 0.2795155 ,\n",
       "        0.85431933, 0.22604156, 0.230757  , 0.8868928 , 0.18478131,\n",
       "        0.31233382, 0.28742886, 0.25819063, 0.21464324, 0.19795609,\n",
       "        0.23029351, 0.20789003, 0.19865203, 0.20281935, 0.2109406 ,\n",
       "        0.28217268, 0.31259108, 0.76720786, 0.2777884 , 0.23466182,\n",
       "        0.15359807, 0.22075391, 0.73022699, 0.85622358, 0.24273324,\n",
       "        0.2395823 , 0.2308588 , 0.63301229, 0.23186922, 0.23463845,\n",
       "        0.23121047, 0.23198414, 0.55257249, 0.19366384, 0.19197226,\n",
       "        0.2083497 , 0.23110676, 0.90245533, 0.23091364, 0.23623109,\n",
       "        0.35205054, 0.883178  , 0.15169406, 0.28785992, 0.28336573,\n",
       "        0.20990729, 0.31933117, 0.81264234, 0.3337779 , 0.25425553,\n",
       "        0.23030424, 0.25762129, 0.226542  , 0.64216137, 0.24962783]),\n",
       " 'params': [{'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.01,\n",
       "   'regressor:random_forest:bootstrap': 'True',\n",
       "   'regressor:random_forest:criterion': 'mse',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 1.0,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 1,\n",
       "   'regressor:random_forest:min_samples_split': 2,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'False',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 8,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 16,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 5,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 37,\n",
       "   'regressor:ridge_regression:alpha': 173.52078030595007,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 8.350228451576657e-05},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'feature_agglomeration',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'feature_preprocessor:feature_agglomeration:affinity': 'cosine',\n",
       "   'feature_preprocessor:feature_agglomeration:linkage': 'complete',\n",
       "   'feature_preprocessor:feature_agglomeration:n_clusters': 398,\n",
       "   'feature_preprocessor:feature_agglomeration:pooling_func': 'mean',\n",
       "   'regressor:decision_tree:criterion': 'mae',\n",
       "   'regressor:decision_tree:max_depth_factor': 1.0055563958082605,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 8,\n",
       "   'regressor:decision_tree:min_samples_split': 4,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 792,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'normal',\n",
       "   'feature_preprocessor:pca:keep_variance': 0.5150397929969202,\n",
       "   'feature_preprocessor:pca:whiten': 'False',\n",
       "   'regressor:decision_tree:criterion': 'mae',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.30043377411209327,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 2,\n",
       "   'regressor:decision_tree:min_samples_split': 13,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.9922478571006341,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.28916478076740876,\n",
       "   'regressor:ridge_regression:alpha': 1629.8131509973832,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 2.0946013955443033e-06},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0011679258777861955,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'False',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'friedman_mse',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.6031462814361489,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 20,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 13,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:ridge_regression:alpha': 2801.8018189555287,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 5.252842350951952e-06},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.857856422838131,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.16270327064031528,\n",
       "   'regressor:ridge_regression:alpha': 1265.454796122566,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 8.254938687894747e-05},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'nystroem_sampler',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0006988218955545649,\n",
       "   'feature_preprocessor:nystroem_sampler:kernel': 'cosine',\n",
       "   'feature_preprocessor:nystroem_sampler:n_components': 7194,\n",
       "   'regressor:ridge_regression:alpha': 314.9876956524643,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 3.410730962937692e-05},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'regressor:ridge_regression:alpha': 516.588967642959,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 4.1644432614591594e-07},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'feature_agglomeration',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 563,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'uniform',\n",
       "   'feature_preprocessor:feature_agglomeration:affinity': 'euclidean',\n",
       "   'feature_preprocessor:feature_agglomeration:linkage': 'ward',\n",
       "   'feature_preprocessor:feature_agglomeration:n_clusters': 4,\n",
       "   'feature_preprocessor:feature_agglomeration:pooling_func': 'median',\n",
       "   'regressor:extra_trees:bootstrap': 'False',\n",
       "   'regressor:extra_trees:criterion': 'mae',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.15174026608915236,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 15,\n",
       "   'regressor:extra_trees:min_samples_split': 3},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.005682022063001382,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.8308440801417805,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.0010487218901351699,\n",
       "   'feature_preprocessor:pca:keep_variance': 0.5783606461422713,\n",
       "   'feature_preprocessor:pca:whiten': 'False',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 50,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'distance'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0009298748419912689,\n",
       "   'feature_preprocessor:polynomial:degree': 2,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'False',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'True',\n",
       "   'regressor:decision_tree:criterion': 'friedman_mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.3674271434444325,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 13,\n",
       "   'regressor:decision_tree:min_samples_split': 7,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.00013879650933019193,\n",
       "   'feature_preprocessor:pca:keep_variance': 0.9097752246818678,\n",
       "   'feature_preprocessor:pca:whiten': 'False',\n",
       "   'regressor:random_forest:bootstrap': 'True',\n",
       "   'regressor:random_forest:criterion': 'mse',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.17361565672710066,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 12,\n",
       "   'regressor:random_forest:min_samples_split': 16,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'feature_preprocessor:pca:keep_variance': 0.6102908450519211,\n",
       "   'feature_preprocessor:pca:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.800195617625348,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 5,\n",
       "   'regressor:decision_tree:min_samples_split': 6,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'feature_agglomeration',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.00016213197545826907,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.8287644412071582,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.0461766024960606,\n",
       "   'feature_preprocessor:feature_agglomeration:affinity': 'manhattan',\n",
       "   'feature_preprocessor:feature_agglomeration:linkage': 'average',\n",
       "   'feature_preprocessor:feature_agglomeration:n_clusters': 188,\n",
       "   'feature_preprocessor:feature_agglomeration:pooling_func': 'max',\n",
       "   'regressor:ridge_regression:alpha': 1183.594096216625,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 3.033234603257519e-07},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.013363138290388014,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.8122675946384508,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.15400195951322834,\n",
       "   'feature_preprocessor:pca:keep_variance': 0.9671377476120258,\n",
       "   'feature_preprocessor:pca:whiten': 'False',\n",
       "   'regressor:random_forest:bootstrap': 'False',\n",
       "   'regressor:random_forest:criterion': 'mae',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.37138576468393947,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 15,\n",
       "   'regressor:random_forest:min_samples_split': 6,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.1909928329387177,\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 87,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0002967529383081362,\n",
       "   'regressor:ridge_regression:alpha': 2772.6003277693567,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 4.152884927148613e-06},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.00015684662078155833,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.8793811923717466,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.14571265895719981,\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'False',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 9,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 3,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 11,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 33,\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.03153163250803037,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 16,\n",
       "   'regressor:decision_tree:min_samples_split': 18,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.07390120164542405,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 1167,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'normal',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 11,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'distance',\n",
       "   'feature_preprocessor:fast_ica:n_components': 12},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.09178868574434537,\n",
       "   'feature_preprocessor:pca:keep_variance': 0.9344482753632339,\n",
       "   'feature_preprocessor:pca:whiten': 'False',\n",
       "   'regressor:ridge_regression:alpha': 507.4744030912921,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 4.008953772397296e-06},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'feature_agglomeration',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.3576171257664492,\n",
       "   'feature_preprocessor:feature_agglomeration:affinity': 'manhattan',\n",
       "   'feature_preprocessor:feature_agglomeration:linkage': 'complete',\n",
       "   'feature_preprocessor:feature_agglomeration:n_clusters': 317,\n",
       "   'feature_preprocessor:feature_agglomeration:pooling_func': 'max',\n",
       "   'regressor:random_forest:bootstrap': 'True',\n",
       "   'regressor:random_forest:criterion': 'friedman_mse',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.6250525905667202,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 15,\n",
       "   'regressor:random_forest:min_samples_split': 19,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.7029373207705987,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.19089509441218294,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'False',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'mae',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.47267049795789906,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 11,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 14,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:random_forest:bootstrap': 'False',\n",
       "   'regressor:random_forest:criterion': 'mae',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.12451623391967058,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 11,\n",
       "   'regressor:random_forest:min_samples_split': 14,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'gaussian_process',\n",
       "   'feature_preprocessor:pca:keep_variance': 0.6883498821937447,\n",
       "   'feature_preprocessor:pca:whiten': 'True',\n",
       "   'regressor:gaussian_process:alpha': 1.4163529997253153e-08,\n",
       "   'regressor:gaussian_process:thetaL': 2.019075896160975e-07,\n",
       "   'regressor:gaussian_process:thetaU': 2422.9473854075172},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0966475757611034,\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'True',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 2,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 17,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 3,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 69,\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 3,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'distance'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'feature_preprocessor:pca:keep_variance': 0.8608936859645954,\n",
       "   'feature_preprocessor:pca:whiten': 'True',\n",
       "   'regressor:extra_trees:bootstrap': 'True',\n",
       "   'regressor:extra_trees:criterion': 'mae',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.44443335354819347,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 5,\n",
       "   'regressor:extra_trees:min_samples_split': 7},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'feature_agglomeration',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'feature_preprocessor:feature_agglomeration:affinity': 'euclidean',\n",
       "   'feature_preprocessor:feature_agglomeration:linkage': 'average',\n",
       "   'feature_preprocessor:feature_agglomeration:n_clusters': 123,\n",
       "   'feature_preprocessor:feature_agglomeration:pooling_func': 'max',\n",
       "   'regressor:random_forest:bootstrap': 'True',\n",
       "   'regressor:random_forest:criterion': 'friedman_mse',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.10152147514845246,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 3,\n",
       "   'regressor:random_forest:min_samples_split': 15,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.004051161203697263,\n",
       "   'feature_preprocessor:pca:keep_variance': 0.9661723340966253,\n",
       "   'feature_preprocessor:pca:whiten': 'True',\n",
       "   'regressor:ridge_regression:alpha': 102.35574469304287,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 1.6998287886973953e-05},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0026723628332913215,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.8171729658747383,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.17269988075066917,\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'False',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 7,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 18,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 3,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 43,\n",
       "   'regressor:random_forest:bootstrap': 'True',\n",
       "   'regressor:random_forest:criterion': 'mse',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.1451565735468404,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 1,\n",
       "   'regressor:random_forest:min_samples_split': 13,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'feature_agglomeration',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0033035980008628064,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.7172523673281742,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.2626282879753452,\n",
       "   'feature_preprocessor:feature_agglomeration:affinity': 'manhattan',\n",
       "   'feature_preprocessor:feature_agglomeration:linkage': 'complete',\n",
       "   'feature_preprocessor:feature_agglomeration:n_clusters': 134,\n",
       "   'feature_preprocessor:feature_agglomeration:pooling_func': 'mean',\n",
       "   'regressor:extra_trees:bootstrap': 'False',\n",
       "   'regressor:extra_trees:criterion': 'mae',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.7684696840084816,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 7,\n",
       "   'regressor:extra_trees:min_samples_split': 18},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.06168018197582326,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.7417696923339766,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.11908259577495996,\n",
       "   'regressor:ridge_regression:alpha': 6707.71030571148,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 9.152420329446992e-07},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.45208205650974276,\n",
       "   'feature_preprocessor:pca:keep_variance': 0.9566043734590466,\n",
       "   'feature_preprocessor:pca:whiten': 'True',\n",
       "   'regressor:ridge_regression:alpha': 232.38582725627515,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 2.3865399053543293e-07},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.8972032234584776,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.12071545121478301,\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'False',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 8,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 13,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 15,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 24,\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 28,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'kitchen_sinks',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0002936424716414241,\n",
       "   'feature_preprocessor:kitchen_sinks:gamma': 0.49992769333482023,\n",
       "   'feature_preprocessor:kitchen_sinks:n_components': 185,\n",
       "   'regressor:ridge_regression:alpha': 3185.2199191698483,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 1.4064507728075262e-06},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'feature_preprocessor:polynomial:degree': 3,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'True',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'False',\n",
       "   'regressor:random_forest:bootstrap': 'False',\n",
       "   'regressor:random_forest:criterion': 'friedman_mse',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.6275601704575671,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 4,\n",
       "   'regressor:random_forest:min_samples_split': 15,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'feature_preprocessor:polynomial:degree': 2,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'False',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'True',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 66,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'feature_agglomeration',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.00011883517326313243,\n",
       "   'feature_preprocessor:feature_agglomeration:affinity': 'euclidean',\n",
       "   'feature_preprocessor:feature_agglomeration:linkage': 'complete',\n",
       "   'feature_preprocessor:feature_agglomeration:n_clusters': 90,\n",
       "   'feature_preprocessor:feature_agglomeration:pooling_func': 'mean',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 3,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.012511082513128205,\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'False',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 10,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 15,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 14,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 23,\n",
       "   'regressor:random_forest:bootstrap': 'False',\n",
       "   'regressor:random_forest:criterion': 'friedman_mse',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.7575181816657064,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 15,\n",
       "   'regressor:random_forest:min_samples_split': 10,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'False',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 9,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 16,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 5,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 41,\n",
       "   'regressor:random_forest:bootstrap': 'False',\n",
       "   'regressor:random_forest:criterion': 'mse',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.16151937910417372,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 7,\n",
       "   'regressor:random_forest:min_samples_split': 12,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'feature_agglomeration',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'feature_preprocessor:feature_agglomeration:affinity': 'euclidean',\n",
       "   'feature_preprocessor:feature_agglomeration:linkage': 'ward',\n",
       "   'feature_preprocessor:feature_agglomeration:n_clusters': 47,\n",
       "   'feature_preprocessor:feature_agglomeration:pooling_func': 'max',\n",
       "   'regressor:random_forest:bootstrap': 'True',\n",
       "   'regressor:random_forest:criterion': 'mae',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.9289300348279892,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 6,\n",
       "   'regressor:random_forest:min_samples_split': 3,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.00026614849041013905,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.8610406631913199,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.2823605861179491,\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'False',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 5,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 19,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 15,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 71,\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 1,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'distance'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 1114,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'uniform',\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'True',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 5,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 2,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 20,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 17,\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 17,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'distance'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 1230,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'uniform',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'exp',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'False',\n",
       "   'regressor:random_forest:bootstrap': 'True',\n",
       "   'regressor:random_forest:criterion': 'friedman_mse',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.8121254819968173,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 3,\n",
       "   'regressor:random_forest:min_samples_split': 19,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0018426246803094804,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.8684798635168272,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.12335387053501023,\n",
       "   'regressor:ridge_regression:alpha': 776.4407618884782,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 5.02820100935429e-07},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'gaussian_process',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.06908285889290702,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'False',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'friedman_mse',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.2354628613765028,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 16,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 14,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:gaussian_process:alpha': 3.3573835588699042e-06,\n",
       "   'regressor:gaussian_process:thetaL': 6.9114845976782165e-06,\n",
       "   'regressor:gaussian_process:thetaU': 7155.3735232242225},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.13747485305343582,\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'False',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 4,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 16,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 12,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 99,\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 28,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.010540728968686353,\n",
       "   'feature_preprocessor:pca:keep_variance': 0.6167438010763403,\n",
       "   'feature_preprocessor:pca:whiten': 'True',\n",
       "   'regressor:random_forest:bootstrap': 'True',\n",
       "   'regressor:random_forest:criterion': 'mae',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.282206585929519,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 18,\n",
       "   'regressor:random_forest:min_samples_split': 5,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0018161796291229762,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'exp',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'False',\n",
       "   'regressor:decision_tree:criterion': 'friedman_mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.6738734972905724,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 19,\n",
       "   'regressor:decision_tree:min_samples_split': 8,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'True',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 4,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 6,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 18,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 50,\n",
       "   'regressor:random_forest:bootstrap': 'True',\n",
       "   'regressor:random_forest:criterion': 'mse',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.7135553614375547,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 18,\n",
       "   'regressor:random_forest:min_samples_split': 15,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.3169504448474022,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.9665152097370466,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.15515031093647985,\n",
       "   'feature_preprocessor:polynomial:degree': 3,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'False',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'False',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 10,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'distance'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.014289469344544552,\n",
       "   'feature_preprocessor:polynomial:degree': 2,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'False',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'False',\n",
       "   'regressor:random_forest:bootstrap': 'False',\n",
       "   'regressor:random_forest:criterion': 'friedman_mse',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.3023993424587932,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 2,\n",
       "   'regressor:random_forest:min_samples_split': 11,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0404755789329183,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'True',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'mse',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.8521314247974944,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 4,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 8,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:random_forest:bootstrap': 'False',\n",
       "   'regressor:random_forest:criterion': 'mse',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.7835289444936782,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 2,\n",
       "   'regressor:random_forest:min_samples_split': 17,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0038073363161950126,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'True',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'friedman_mse',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.5751330178298871,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 6,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 8,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 90,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'distance'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0004849060790770139,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'True',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'mae',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.6927681645723903,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 20,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 9,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 1,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'distance'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'gaussian_process',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0027945067330199594,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'cube',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'False',\n",
       "   'regressor:gaussian_process:alpha': 5.485290306051494e-05,\n",
       "   'regressor:gaussian_process:thetaL': 4.6032669578907194e-05,\n",
       "   'regressor:gaussian_process:thetaU': 3461.111573380696},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.018237795813167968,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'False',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'mse',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.5440415317368462,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 7,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 18,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:ridge_regression:alpha': 2565.116198863405,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 3.597585057849383e-05},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'feature_preprocessor:pca:keep_variance': 0.8425952962565404,\n",
       "   'feature_preprocessor:pca:whiten': 'True',\n",
       "   'regressor:random_forest:bootstrap': 'True',\n",
       "   'regressor:random_forest:criterion': 'mse',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.10262589064142413,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 16,\n",
       "   'regressor:random_forest:min_samples_split': 9,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'regressor:decision_tree:criterion': 'friedman_mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.7178331182723261,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 2,\n",
       "   'regressor:decision_tree:min_samples_split': 7,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.2327663189643284,\n",
       "   'feature_preprocessor:polynomial:degree': 3,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'False',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'False',\n",
       "   'regressor:ridge_regression:alpha': 2016.395342809712,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 6.222361479591972e-05},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'feature_agglomeration',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.00015977807530727866,\n",
       "   'feature_preprocessor:feature_agglomeration:affinity': 'manhattan',\n",
       "   'feature_preprocessor:feature_agglomeration:linkage': 'complete',\n",
       "   'feature_preprocessor:feature_agglomeration:n_clusters': 244,\n",
       "   'feature_preprocessor:feature_agglomeration:pooling_func': 'mean',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 84,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.2545530201786845,\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'True',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 4,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 18,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 17,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 23,\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 15,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.00038825387382819814,\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'True',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 10,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 1,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 15,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 15,\n",
       "   'regressor:random_forest:bootstrap': 'False',\n",
       "   'regressor:random_forest:criterion': 'mae',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.9549830588935443,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 16,\n",
       "   'regressor:random_forest:min_samples_split': 10,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'kernel_pca',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'feature_preprocessor:kernel_pca:kernel': 'rbf',\n",
       "   'feature_preprocessor:kernel_pca:n_components': 565,\n",
       "   'regressor:ridge_regression:alpha': 2935.44400869741,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 2.3309023039977313e-07,\n",
       "   'feature_preprocessor:kernel_pca:gamma': 0.342770773052593},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'True',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 9,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 10,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 2,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 78,\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 83,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.00014942294630736707,\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'True',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 3,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 1,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 9,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 86,\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 33,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.7311257127724968,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.2413907755972501,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'True',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'mse',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.2880128328671823,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 4,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 8,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:random_forest:bootstrap': 'True',\n",
       "   'regressor:random_forest:criterion': 'mae',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.36843174101550646,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 2,\n",
       "   'regressor:random_forest:min_samples_split': 14,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.010000000000000004,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 996,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'uniform',\n",
       "   'feature_preprocessor:pca:keep_variance': 0.9999,\n",
       "   'feature_preprocessor:pca:whiten': 'False',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 15,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'feature_agglomeration',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.08876488298149353,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.9793562442982197,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.24121833094677253,\n",
       "   'feature_preprocessor:feature_agglomeration:affinity': 'euclidean',\n",
       "   'feature_preprocessor:feature_agglomeration:linkage': 'complete',\n",
       "   'feature_preprocessor:feature_agglomeration:n_clusters': 234,\n",
       "   'feature_preprocessor:feature_agglomeration:pooling_func': 'max',\n",
       "   'regressor:random_forest:bootstrap': 'True',\n",
       "   'regressor:random_forest:criterion': 'friedman_mse',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.14738059468868145,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 15,\n",
       "   'regressor:random_forest:min_samples_split': 20,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'cube',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:ridge_regression:alpha': 3834.883710176195,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 1.4588763563386215e-05,\n",
       "   'feature_preprocessor:fast_ica:n_components': 971},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.04155487164663673,\n",
       "   'feature_preprocessor:pca:keep_variance': 0.7751815548232117,\n",
       "   'feature_preprocessor:pca:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'mae',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.9669651761509541,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 10,\n",
       "   'regressor:decision_tree:min_samples_split': 18,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'False',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 5,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 9,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 14,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 27,\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 14,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.9310271164513015,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.05500322145529406,\n",
       "   'regressor:random_forest:bootstrap': 'False',\n",
       "   'regressor:random_forest:criterion': 'mae',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.858313402538514,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 9,\n",
       "   'regressor:random_forest:min_samples_split': 17,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'feature_agglomeration',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0002145882041254209,\n",
       "   'feature_preprocessor:feature_agglomeration:affinity': 'manhattan',\n",
       "   'feature_preprocessor:feature_agglomeration:linkage': 'average',\n",
       "   'feature_preprocessor:feature_agglomeration:n_clusters': 400,\n",
       "   'feature_preprocessor:feature_agglomeration:pooling_func': 'mean',\n",
       "   'regressor:random_forest:bootstrap': 'True',\n",
       "   'regressor:random_forest:criterion': 'mae',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.8340287905055578,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 17,\n",
       "   'regressor:random_forest:min_samples_split': 11,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0012837019682791723,\n",
       "   'regressor:ridge_regression:alpha': 819.3527158367367,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 1.0529735570763943e-05},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'feature_preprocessor:pca:keep_variance': 0.5834574753485161,\n",
       "   'feature_preprocessor:pca:whiten': 'False',\n",
       "   'regressor:decision_tree:criterion': 'mae',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.2158669126632733,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 20,\n",
       "   'regressor:decision_tree:min_samples_split': 6,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'feature_preprocessor:polynomial:degree': 2,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'True',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'False',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 18,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'regressor:extra_trees:bootstrap': 'True',\n",
       "   'regressor:extra_trees:criterion': 'mse',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.6204801914419285,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 5,\n",
       "   'regressor:extra_trees:min_samples_split': 17},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.007848244270198477,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 913,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'normal',\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'True',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 8,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 12,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 7,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 42,\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 13,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'False',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 10,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 4,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 14,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 37,\n",
       "   'regressor:extra_trees:bootstrap': 'True',\n",
       "   'regressor:extra_trees:criterion': 'friedman_mse',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.4318708528781241,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 12,\n",
       "   'regressor:extra_trees:min_samples_split': 8},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.9065478212865403,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.0942543401396613,\n",
       "   'feature_preprocessor:polynomial:degree': 2,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'False',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'False',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 21,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0055580993593109486,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 1000,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'normal',\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'False',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 9,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 15,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 8,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 91,\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 13,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.9341735249977134,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.03751803716434402,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'False',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'mae',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.23469763835846824,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 8,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 13,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:extra_trees:bootstrap': 'True',\n",
       "   'regressor:extra_trees:criterion': 'friedman_mse',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.4328992384838738,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 1,\n",
       "   'regressor:extra_trees:min_samples_split': 13},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.9513880535742931,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.2626839624374468,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'cube',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'False',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 27,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 1189,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'uniform',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 17,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.014554240633797177,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 1494,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'uniform',\n",
       "   'regressor:extra_trees:bootstrap': 'False',\n",
       "   'regressor:extra_trees:criterion': 'mse',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.7753733361833163,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 3,\n",
       "   'regressor:extra_trees:min_samples_split': 8},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.99389801951307,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.21619345035356985,\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'False',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 9,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 2,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 7,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 54,\n",
       "   'regressor:ridge_regression:alpha': 269.2269900098719,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 8.647440038949547e-05},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.010000000000000004,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.7654178018743998,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.25,\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'False',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 4,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 17,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 17,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 17,\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 17,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'distance'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.7638704337309284,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.25,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'True',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'mae',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.6165419827233979,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 6,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 17,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 90,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'distance'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.7311132038720384,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.2910568673177784,\n",
       "   'regressor:random_forest:bootstrap': 'False',\n",
       "   'regressor:random_forest:criterion': 'mae',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.6068399649684288,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 8,\n",
       "   'regressor:random_forest:min_samples_split': 15,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'feature_agglomeration',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'feature_preprocessor:feature_agglomeration:affinity': 'euclidean',\n",
       "   'feature_preprocessor:feature_agglomeration:linkage': 'average',\n",
       "   'feature_preprocessor:feature_agglomeration:n_clusters': 15,\n",
       "   'feature_preprocessor:feature_agglomeration:pooling_func': 'max',\n",
       "   'regressor:ridge_regression:alpha': 246.57639111008808,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 1.614428946992549e-06},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'feature_agglomeration',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.7380069422556008,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.23384526404551378,\n",
       "   'feature_preprocessor:feature_agglomeration:affinity': 'euclidean',\n",
       "   'feature_preprocessor:feature_agglomeration:linkage': 'average',\n",
       "   'feature_preprocessor:feature_agglomeration:n_clusters': 74,\n",
       "   'feature_preprocessor:feature_agglomeration:pooling_func': 'mean',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 14,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'kernel_pca',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.00266932594699517,\n",
       "   'feature_preprocessor:kernel_pca:kernel': 'cosine',\n",
       "   'feature_preprocessor:kernel_pca:n_components': 1445,\n",
       "   'regressor:ridge_regression:alpha': 109.98669387729639,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 2.2964188398190233e-05},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.3548933343030698,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.8643024280228802,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.2487694008353517,\n",
       "   'feature_preprocessor:pca:keep_variance': 0.8503409103322925,\n",
       "   'feature_preprocessor:pca:whiten': 'False',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 9,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.006390402476840058,\n",
       "   'feature_preprocessor:pca:keep_variance': 0.6233090897331361,\n",
       "   'feature_preprocessor:pca:whiten': 'True',\n",
       "   'regressor:ridge_regression:alpha': 4926.239793036449,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 4.2889960027861224e-06},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.00659498797437954,\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'True',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 2,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 17,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 18,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 91,\n",
       "   'regressor:random_forest:bootstrap': 'False',\n",
       "   'regressor:random_forest:criterion': 'mae',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.23637037945782638,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 13,\n",
       "   'regressor:random_forest:min_samples_split': 18,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.007689619853255995,\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'False',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 10,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 17,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 6,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 16,\n",
       "   'regressor:random_forest:bootstrap': 'False',\n",
       "   'regressor:random_forest:criterion': 'mae',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.2829540799311099,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 8,\n",
       "   'regressor:random_forest:min_samples_split': 12,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.00026839176367698193,\n",
       "   'regressor:decision_tree:criterion': 'mae',\n",
       "   'regressor:decision_tree:max_depth_factor': 1.442639486324955,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 1,\n",
       "   'regressor:decision_tree:min_samples_split': 8,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.017152202203432405,\n",
       "   'regressor:ridge_regression:alpha': 159.32764558288181,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 1.363093741531062e-07},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'gaussian_process',\n",
       "   'regressor:gaussian_process:alpha': 4.1791499313470473e-05,\n",
       "   'regressor:gaussian_process:thetaL': 1.6389034578508525e-07,\n",
       "   'regressor:gaussian_process:thetaU': 2.0590948997394065},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.9301896779725476,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.12271156833480264,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'cube',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:extra_trees:bootstrap': 'True',\n",
       "   'regressor:extra_trees:criterion': 'friedman_mse',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.2372816182585037,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 20,\n",
       "   'regressor:extra_trees:min_samples_split': 18,\n",
       "   'feature_preprocessor:fast_ica:n_components': 55},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'feature_preprocessor:polynomial:degree': 3,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'False',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'False',\n",
       "   'regressor:decision_tree:criterion': 'friedman_mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.520735227961066,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 20,\n",
       "   'regressor:decision_tree:min_samples_split': 10,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.7339570009058797,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.14689789754639004,\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'False',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 4,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 17,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 3,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 12,\n",
       "   'regressor:random_forest:bootstrap': 'False',\n",
       "   'regressor:random_forest:criterion': 'mse',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.44355733378940587,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 9,\n",
       "   'regressor:random_forest:min_samples_split': 20,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.06419067360160154,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.9032659210517124,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.18234068612159854,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'False',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'friedman_mse',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.7087732242505305,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 6,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 8,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:extra_trees:bootstrap': 'True',\n",
       "   'regressor:extra_trees:criterion': 'friedman_mse',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.39548844400302974,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 7,\n",
       "   'regressor:extra_trees:min_samples_split': 5},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'cube',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 1.0392881611506182,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 19,\n",
       "   'regressor:decision_tree:min_samples_split': 9,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 1735},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'False',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 6,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 7,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 15,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 37,\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 16,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'feature_preprocessor:pca:keep_variance': 0.5603296801927988,\n",
       "   'feature_preprocessor:pca:whiten': 'True',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 14,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'feature_preprocessor:polynomial:degree': 2,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'False',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'False',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 4,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'distance'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 1824,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'normal',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'cube',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:random_forest:bootstrap': 'True',\n",
       "   'regressor:random_forest:criterion': 'friedman_mse',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.8813317559529642,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 13,\n",
       "   'regressor:random_forest:min_samples_split': 17,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 511},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'feature_agglomeration',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'feature_preprocessor:feature_agglomeration:affinity': 'manhattan',\n",
       "   'feature_preprocessor:feature_agglomeration:linkage': 'average',\n",
       "   'feature_preprocessor:feature_agglomeration:n_clusters': 149,\n",
       "   'feature_preprocessor:feature_agglomeration:pooling_func': 'median',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 67,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'distance'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'feature_preprocessor:polynomial:degree': 2,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'True',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'True',\n",
       "   'regressor:random_forest:bootstrap': 'False',\n",
       "   'regressor:random_forest:criterion': 'mae',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.8803951188555903,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 9,\n",
       "   'regressor:random_forest:min_samples_split': 8,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'exp',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'False',\n",
       "   'regressor:extra_trees:bootstrap': 'True',\n",
       "   'regressor:extra_trees:criterion': 'mse',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.23277331416962535,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 16,\n",
       "   'regressor:extra_trees:min_samples_split': 2},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0180455794722024,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.8586520108194636,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.23827040785053913,\n",
       "   'feature_preprocessor:polynomial:degree': 2,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'True',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'False',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 2,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.28863258504082207,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.897100253720673,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.2871414091901358,\n",
       "   'regressor:extra_trees:bootstrap': 'False',\n",
       "   'regressor:extra_trees:criterion': 'mae',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.1329237227418703,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 19,\n",
       "   'regressor:extra_trees:min_samples_split': 3},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'feature_agglomeration',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 1115,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'uniform',\n",
       "   'feature_preprocessor:feature_agglomeration:affinity': 'euclidean',\n",
       "   'feature_preprocessor:feature_agglomeration:linkage': 'average',\n",
       "   'feature_preprocessor:feature_agglomeration:n_clusters': 168,\n",
       "   'feature_preprocessor:feature_agglomeration:pooling_func': 'median',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 10,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.019813872852303883,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.8972032234584776,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.1280817535223777,\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'False',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 8,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 13,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 15,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 24,\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 33,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'gaussian_process',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.4813623710978043,\n",
       "   'regressor:gaussian_process:alpha': 3.206930145962583e-07,\n",
       "   'regressor:gaussian_process:thetaL': 1.1565529981987449e-06,\n",
       "   'regressor:gaussian_process:thetaU': 8435.567086757135},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'gaussian_process',\n",
       "   'regressor:gaussian_process:alpha': 1.3413077444000527e-08,\n",
       "   'regressor:gaussian_process:thetaL': 9.001903126881822e-10,\n",
       "   'regressor:gaussian_process:thetaU': 2376.788108857216},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 1144,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'uniform',\n",
       "   'feature_preprocessor:pca:keep_variance': 0.5999992869650137,\n",
       "   'feature_preprocessor:pca:whiten': 'False',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 20,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.00013796288226023464,\n",
       "   'feature_preprocessor:pca:keep_variance': 0.8675731134276842,\n",
       "   'feature_preprocessor:pca:whiten': 'False',\n",
       "   'regressor:random_forest:bootstrap': 'False',\n",
       "   'regressor:random_forest:criterion': 'mae',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.8280917823458034,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 8,\n",
       "   'regressor:random_forest:min_samples_split': 15,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'True',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 9,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 19,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 6,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 44,\n",
       "   'regressor:random_forest:bootstrap': 'True',\n",
       "   'regressor:random_forest:criterion': 'mse',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.5251685295588083,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 7,\n",
       "   'regressor:random_forest:min_samples_split': 20,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'True',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 5,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 18,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 10,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 33,\n",
       "   'regressor:extra_trees:bootstrap': 'False',\n",
       "   'regressor:extra_trees:criterion': 'mse',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.4011809347747183,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 12,\n",
       "   'regressor:extra_trees:min_samples_split': 4},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0008659359897684668,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.8230042618470891,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.10921310213023767,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'exp',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 2,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'distance',\n",
       "   'feature_preprocessor:fast_ica:n_components': 565},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'feature_preprocessor:pca:keep_variance': 0.7988154665543525,\n",
       "   'feature_preprocessor:pca:whiten': 'False',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 59,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'cube',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:random_forest:bootstrap': 'True',\n",
       "   'regressor:random_forest:criterion': 'mse',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.5666145451543694,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 7,\n",
       "   'regressor:random_forest:min_samples_split': 2,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 1550},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'feature_agglomeration',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'feature_preprocessor:feature_agglomeration:affinity': 'cosine',\n",
       "   'feature_preprocessor:feature_agglomeration:linkage': 'complete',\n",
       "   'feature_preprocessor:feature_agglomeration:n_clusters': 378,\n",
       "   'feature_preprocessor:feature_agglomeration:pooling_func': 'median',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 37,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'exp',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'False',\n",
       "   'regressor:extra_trees:bootstrap': 'True',\n",
       "   'regressor:extra_trees:criterion': 'mae',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.843350429386684,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 17,\n",
       "   'regressor:extra_trees:min_samples_split': 8},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'regressor:random_forest:bootstrap': 'False',\n",
       "   'regressor:random_forest:criterion': 'mae',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.7160668600623384,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 7,\n",
       "   'regressor:random_forest:min_samples_split': 10,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0007575433512626152,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.9928212613657226,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.25185752642666553,\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'True',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 10,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 13,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 6,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 65,\n",
       "   'regressor:extra_trees:bootstrap': 'False',\n",
       "   'regressor:extra_trees:criterion': 'mse',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.1529081535176583,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 7,\n",
       "   'regressor:extra_trees:min_samples_split': 16},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'kernel_pca',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'feature_preprocessor:kernel_pca:kernel': 'poly',\n",
       "   'feature_preprocessor:kernel_pca:n_components': 1666,\n",
       "   'regressor:ridge_regression:alpha': 3274.4250105092497,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 5.772340527903332e-07,\n",
       "   'feature_preprocessor:kernel_pca:coef0': 0.10480631736353785,\n",
       "   'feature_preprocessor:kernel_pca:degree': 5,\n",
       "   'feature_preprocessor:kernel_pca:gamma': 0.08498747147500653},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'True',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 5,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 1,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 8,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 10,\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 14,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'gaussian_process',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.023953027463529022,\n",
       "   'feature_preprocessor:polynomial:degree': 3,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'False',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'False',\n",
       "   'regressor:gaussian_process:alpha': 2.868149393351456e-13,\n",
       "   'regressor:gaussian_process:thetaL': 0.0002098640411127642,\n",
       "   'regressor:gaussian_process:thetaU': 14037.07491261275},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0002063381820949854,\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 22,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0001420570513136922,\n",
       "   'feature_preprocessor:pca:keep_variance': 0.9762164035883709,\n",
       "   'feature_preprocessor:pca:whiten': 'True',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 1,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'True',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'mae',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.5820074539244974,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 4,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 5,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:extra_trees:bootstrap': 'False',\n",
       "   'regressor:extra_trees:criterion': 'mse',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.5761232074559555,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 1,\n",
       "   'regressor:extra_trees:min_samples_split': 10},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.06637252513062747,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 691,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'normal',\n",
       "   'feature_preprocessor:polynomial:degree': 3,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'False',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'True',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 1.917259113221755,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 19,\n",
       "   'regressor:decision_tree:min_samples_split': 13,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.8843830207422064,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.10109348249580129,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'False',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'mse',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.7235173501600752,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 8,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 15,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 32,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'False',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'mse',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.6556266562283924,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 12,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 9,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 1,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'distance'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'feature_agglomeration',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'feature_preprocessor:feature_agglomeration:affinity': 'euclidean',\n",
       "   'feature_preprocessor:feature_agglomeration:linkage': 'average',\n",
       "   'feature_preprocessor:feature_agglomeration:n_clusters': 143,\n",
       "   'feature_preprocessor:feature_agglomeration:pooling_func': 'max',\n",
       "   'regressor:random_forest:bootstrap': 'False',\n",
       "   'regressor:random_forest:criterion': 'friedman_mse',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.5582165495832695,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 12,\n",
       "   'regressor:random_forest:min_samples_split': 17,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'feature_agglomeration',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'feature_preprocessor:feature_agglomeration:affinity': 'manhattan',\n",
       "   'feature_preprocessor:feature_agglomeration:linkage': 'average',\n",
       "   'feature_preprocessor:feature_agglomeration:n_clusters': 60,\n",
       "   'feature_preprocessor:feature_agglomeration:pooling_func': 'mean',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 13,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.13747485305343582,\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'False',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 4,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 16,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 12,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 99,\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 28,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'gaussian_process',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 1301,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'normal',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'exp',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'False',\n",
       "   'regressor:gaussian_process:alpha': 8.340897828840255e-06,\n",
       "   'regressor:gaussian_process:thetaL': 3.4021536883449562e-06,\n",
       "   'regressor:gaussian_process:thetaU': 1.5469090679843953},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'feature_agglomeration',\n",
       "   'regressor:__choice__': 'gaussian_process',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0007633507253520759,\n",
       "   'feature_preprocessor:feature_agglomeration:affinity': 'euclidean',\n",
       "   'feature_preprocessor:feature_agglomeration:linkage': 'average',\n",
       "   'feature_preprocessor:feature_agglomeration:n_clusters': 15,\n",
       "   'feature_preprocessor:feature_agglomeration:pooling_func': 'max',\n",
       "   'regressor:gaussian_process:alpha': 6.137917094150185e-07,\n",
       "   'regressor:gaussian_process:thetaL': 6.510022300738803e-07,\n",
       "   'regressor:gaussian_process:thetaU': 14380.96003193229},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.00046356607595790734,\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 93,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'exp',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:random_forest:bootstrap': 'False',\n",
       "   'regressor:random_forest:criterion': 'mae',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.11058349489885469,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 4,\n",
       "   'regressor:random_forest:min_samples_split': 6,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 1066},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'gaussian_process',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.007354995702224433,\n",
       "   'feature_preprocessor:polynomial:degree': 2,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'False',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'True',\n",
       "   'regressor:gaussian_process:alpha': 0.0005287923931285408,\n",
       "   'regressor:gaussian_process:thetaL': 1.0281297617323337e-05,\n",
       "   'regressor:gaussian_process:thetaU': 6.05276217992108},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'gaussian_process',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.08619203130962694,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.9015835219562789,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.19091094237779277,\n",
       "   'regressor:gaussian_process:alpha': 0.20198288696375102,\n",
       "   'regressor:gaussian_process:thetaL': 0.00014306569974764348,\n",
       "   'regressor:gaussian_process:thetaU': 69.99717127946799},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.00013999336176564157,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.9253400137923409,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.25760829328798157,\n",
       "   'feature_preprocessor:pca:keep_variance': 0.5915499625765565,\n",
       "   'feature_preprocessor:pca:whiten': 'True',\n",
       "   'regressor:extra_trees:bootstrap': 'True',\n",
       "   'regressor:extra_trees:criterion': 'friedman_mse',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.2808555881374558,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 3,\n",
       "   'regressor:extra_trees:min_samples_split': 5},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.000770155102090166,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'False',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'friedman_mse',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.9603363320885359,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 13,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 10,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:extra_trees:bootstrap': 'True',\n",
       "   'regressor:extra_trees:criterion': 'mse',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.3161064016205493,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 3,\n",
       "   'regressor:extra_trees:min_samples_split': 5},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.9495886119958568,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.138650334421375,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'exp',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'False',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 32,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'True',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'mae',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.4925553560532644,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 11,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 16,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 18,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'feature_agglomeration',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'feature_preprocessor:feature_agglomeration:affinity': 'euclidean',\n",
       "   'feature_preprocessor:feature_agglomeration:linkage': 'average',\n",
       "   'feature_preprocessor:feature_agglomeration:n_clusters': 103,\n",
       "   'feature_preprocessor:feature_agglomeration:pooling_func': 'mean',\n",
       "   'regressor:ridge_regression:alpha': 137.133047187694,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 1.7246846099630385e-07},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'feature_preprocessor:pca:keep_variance': 0.8934132687184688,\n",
       "   'feature_preprocessor:pca:whiten': 'False',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.6147471031682119,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 17,\n",
       "   'regressor:decision_tree:min_samples_split': 13,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0007608753407517968,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 1,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform',\n",
       "   'feature_preprocessor:fast_ica:n_components': 1477},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0036452204756717314,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'cube',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 18,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform',\n",
       "   'feature_preprocessor:fast_ica:n_components': 173},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.08186446417051273,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'cube',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 52,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform',\n",
       "   'feature_preprocessor:fast_ica:n_components': 1678},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.994240117077666,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.03615897831860765,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'True',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'mae',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.7635639376673111,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 3,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 8,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:extra_trees:bootstrap': 'False',\n",
       "   'regressor:extra_trees:criterion': 'friedman_mse',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.8606790687270301,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 11,\n",
       "   'regressor:extra_trees:min_samples_split': 2},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.7778893534208513,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.2949072618650858,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'cube',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 16,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform',\n",
       "   'feature_preprocessor:fast_ica:n_components': 1783},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.7877811394544847,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.29436598550446663,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'exp',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:extra_trees:bootstrap': 'True',\n",
       "   'regressor:extra_trees:criterion': 'friedman_mse',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.4540925617907534,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 13,\n",
       "   'regressor:extra_trees:min_samples_split': 12,\n",
       "   'feature_preprocessor:fast_ica:n_components': 274},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'True',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'mse',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.1982530939863398,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 6,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 17,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:ridge_regression:alpha': 2428.9619427947273,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 7.424163333155804e-06},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'feature_agglomeration',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'feature_preprocessor:feature_agglomeration:affinity': 'manhattan',\n",
       "   'feature_preprocessor:feature_agglomeration:linkage': 'average',\n",
       "   'feature_preprocessor:feature_agglomeration:n_clusters': 112,\n",
       "   'feature_preprocessor:feature_agglomeration:pooling_func': 'median',\n",
       "   'regressor:random_forest:bootstrap': 'True',\n",
       "   'regressor:random_forest:criterion': 'mse',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.5822938852621277,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 14,\n",
       "   'regressor:random_forest:min_samples_split': 12,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.000150400778920533,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 1862,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'uniform',\n",
       "   'feature_preprocessor:pca:keep_variance': 0.7664678236160156,\n",
       "   'feature_preprocessor:pca:whiten': 'False',\n",
       "   'regressor:random_forest:bootstrap': 'False',\n",
       "   'regressor:random_forest:criterion': 'friedman_mse',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.6288652760379884,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 15,\n",
       "   'regressor:random_forest:min_samples_split': 16,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'feature_agglomeration',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'feature_preprocessor:feature_agglomeration:affinity': 'euclidean',\n",
       "   'feature_preprocessor:feature_agglomeration:linkage': 'average',\n",
       "   'feature_preprocessor:feature_agglomeration:n_clusters': 151,\n",
       "   'feature_preprocessor:feature_agglomeration:pooling_func': 'mean',\n",
       "   'regressor:extra_trees:bootstrap': 'False',\n",
       "   'regressor:extra_trees:criterion': 'friedman_mse',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.17054430517352986,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 15,\n",
       "   'regressor:extra_trees:min_samples_split': 9},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 32,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'distance',\n",
       "   'feature_preprocessor:fast_ica:n_components': 207},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'False',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'mse',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.5401976506289086,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 15,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 19,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:extra_trees:bootstrap': 'False',\n",
       "   'regressor:extra_trees:criterion': 'mae',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.5863044549932291,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 20,\n",
       "   'regressor:extra_trees:min_samples_split': 11},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.7488127839730384,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.27589570158837545,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'cube',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:random_forest:bootstrap': 'True',\n",
       "   'regressor:random_forest:criterion': 'mae',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.6767124013393699,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 14,\n",
       "   'regressor:random_forest:min_samples_split': 17,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 1427},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:extra_trees:bootstrap': 'False',\n",
       "   'regressor:extra_trees:criterion': 'mae',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.321013119900368,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 16,\n",
       "   'regressor:extra_trees:min_samples_split': 2,\n",
       "   'feature_preprocessor:fast_ica:n_components': 1284},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'feature_preprocessor:polynomial:degree': 3,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'True',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'True',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.8227189329764348,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 10,\n",
       "   'regressor:decision_tree:min_samples_split': 20,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'gaussian_process',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'cube',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'False',\n",
       "   'regressor:gaussian_process:alpha': 1.4279264738488698e-05,\n",
       "   'regressor:gaussian_process:thetaL': 1.8232250593656966e-09,\n",
       "   'regressor:gaussian_process:thetaU': 287.036062788838},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.010180235185225369,\n",
       "   'feature_preprocessor:polynomial:degree': 3,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'False',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'True',\n",
       "   'regressor:random_forest:bootstrap': 'True',\n",
       "   'regressor:random_forest:criterion': 'mae',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.43081057598423467,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 10,\n",
       "   'regressor:random_forest:min_samples_split': 18,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'kernel_pca',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.14592003194082992,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.9691319259445099,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.09098826374421197,\n",
       "   'feature_preprocessor:kernel_pca:kernel': 'poly',\n",
       "   'feature_preprocessor:kernel_pca:n_components': 935,\n",
       "   'regressor:ridge_regression:alpha': 111.96359127375808,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 3.6186467979736135e-05,\n",
       "   'feature_preprocessor:kernel_pca:coef0': 0.6331171932872737,\n",
       "   'feature_preprocessor:kernel_pca:degree': 3,\n",
       "   'feature_preprocessor:kernel_pca:gamma': 0.2028330668617213},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.8654827146186823,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.1980760421030535,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'False',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'mae',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.5824770881507192,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 10,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 2,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:random_forest:bootstrap': 'False',\n",
       "   'regressor:random_forest:criterion': 'mae',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.6840353038113615,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 14,\n",
       "   'regressor:random_forest:min_samples_split': 11,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.004319599169227568,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'exp',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:extra_trees:bootstrap': 'False',\n",
       "   'regressor:extra_trees:criterion': 'friedman_mse',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.5505759451077971,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 7,\n",
       "   'regressor:extra_trees:min_samples_split': 8,\n",
       "   'feature_preprocessor:fast_ica:n_components': 1514},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'gaussian_process',\n",
       "   'feature_preprocessor:polynomial:degree': 2,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'False',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'False',\n",
       "   'regressor:gaussian_process:alpha': 1.1926670400365974e-14,\n",
       "   'regressor:gaussian_process:thetaL': 0.0001898374349413664,\n",
       "   'regressor:gaussian_process:thetaU': 72.16501630751512},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.24031633400825428,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.9773821063827329,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.1794285039473189,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'False',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'mae',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.6878138877880059,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 7,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 20,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:random_forest:bootstrap': 'True',\n",
       "   'regressor:random_forest:criterion': 'mse',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.6012391102043385,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 9,\n",
       "   'regressor:random_forest:min_samples_split': 4,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'gaussian_process',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 1962,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'normal',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'False',\n",
       "   'regressor:gaussian_process:alpha': 1.8510629021887296e-13,\n",
       "   'regressor:gaussian_process:thetaL': 7.689595204401312e-09,\n",
       "   'regressor:gaussian_process:thetaU': 33.979735014371904},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'False',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'friedman_mse',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.3197320336199699,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 19,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 20,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:random_forest:bootstrap': 'True',\n",
       "   'regressor:random_forest:criterion': 'mae',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.17185442652526123,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 3,\n",
       "   'regressor:random_forest:min_samples_split': 8,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.08057940058549941,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'False',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'mae',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.7072781534595707,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 17,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 6,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:random_forest:bootstrap': 'True',\n",
       "   'regressor:random_forest:criterion': 'mae',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.4338184089599194,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 16,\n",
       "   'regressor:random_forest:min_samples_split': 7,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.02856878828343338,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.9876785539653535,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.08951494099260295,\n",
       "   'feature_preprocessor:pca:keep_variance': 0.9942512977021508,\n",
       "   'feature_preprocessor:pca:whiten': 'True',\n",
       "   'regressor:ridge_regression:alpha': 2497.9783027749017,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 2.694770119011952e-05},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'gaussian_process',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0034942135860504056,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'exp',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'False',\n",
       "   'regressor:gaussian_process:alpha': 0.20715049096123334,\n",
       "   'regressor:gaussian_process:thetaL': 5.4024371099075145e-06,\n",
       "   'regressor:gaussian_process:thetaU': 9.861965779489228},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'False',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 3,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 18,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 6,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 70,\n",
       "   'regressor:ridge_regression:alpha': 2362.068090413322,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 1.3215892368670988e-06},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'kernel_pca',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.005927799138355616,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 1541,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'normal',\n",
       "   'feature_preprocessor:kernel_pca:kernel': 'rbf',\n",
       "   'feature_preprocessor:kernel_pca:n_components': 625,\n",
       "   'regressor:ridge_regression:alpha': 6890.896757490497,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 4.623820818163569e-05,\n",
       "   'feature_preprocessor:kernel_pca:gamma': 1.4764653976914917},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'kernel_pca',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.35400005770330456,\n",
       "   'feature_preprocessor:kernel_pca:kernel': 'cosine',\n",
       "   'feature_preprocessor:kernel_pca:n_components': 239,\n",
       "   'regressor:ridge_regression:alpha': 1655.9646539384337,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 5.613153914486779e-06},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0003716964677931218,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.7699524097253767,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.23968431431354048,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'False',\n",
       "   'regressor:random_forest:bootstrap': 'True',\n",
       "   'regressor:random_forest:criterion': 'friedman_mse',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.6248392764081618,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 15,\n",
       "   'regressor:random_forest:min_samples_split': 14,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.8865711283077852,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.1646265864143412,\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'False',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 10,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 19,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 16,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 93,\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 16,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'distance'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'True',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'mse',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.22439347025025402,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 14,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 8,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:random_forest:bootstrap': 'False',\n",
       "   'regressor:random_forest:criterion': 'mse',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.5533840231512234,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 13,\n",
       "   'regressor:random_forest:min_samples_split': 4,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'True',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'friedman_mse',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.466777253255788,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 13,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 11,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 1,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'cube',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'False',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 2,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0007028517599287743,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:extra_trees:bootstrap': 'False',\n",
       "   'regressor:extra_trees:criterion': 'mse',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.7590205431845929,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 5,\n",
       "   'regressor:extra_trees:min_samples_split': 12,\n",
       "   'feature_preprocessor:fast_ica:n_components': 859},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0020262016484419504,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.9123680645131744,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.1389057583743652,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'False',\n",
       "   'regressor:extra_trees:bootstrap': 'False',\n",
       "   'regressor:extra_trees:criterion': 'mse',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.20239388741073672,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 13,\n",
       "   'regressor:extra_trees:min_samples_split': 20},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'gaussian_process',\n",
       "   'feature_preprocessor:pca:keep_variance': 0.7430342298893273,\n",
       "   'feature_preprocessor:pca:whiten': 'False',\n",
       "   'regressor:gaussian_process:alpha': 2.1367275012623696e-08,\n",
       "   'regressor:gaussian_process:thetaL': 4.2171506451482755e-05,\n",
       "   'regressor:gaussian_process:thetaU': 1.074132790363595},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.00046070159490080634,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.8419958127490841,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.21274168860520076,\n",
       "   'regressor:ridge_regression:alpha': 4971.387249216191,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 9.430935935002632e-06},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'exp',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 23,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform',\n",
       "   'feature_preprocessor:fast_ica:n_components': 193},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.010000000000000004,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.8456284235373617,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.27646556567463704,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'True',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'mse',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.5258929081478239,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 6,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 19,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:extra_trees:bootstrap': 'False',\n",
       "   'regressor:extra_trees:criterion': 'mse',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.7969024368047993,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 14,\n",
       "   'regressor:extra_trees:min_samples_split': 18},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'gaussian_process',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.007429386425622277,\n",
       "   'feature_preprocessor:pca:keep_variance': 0.502695487221814,\n",
       "   'feature_preprocessor:pca:whiten': 'False',\n",
       "   'regressor:gaussian_process:alpha': 1.390487699936202e-11,\n",
       "   'regressor:gaussian_process:thetaL': 7.703181143649476e-10,\n",
       "   'regressor:gaussian_process:thetaU': 2.9452903619926247},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'True',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 2,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 17,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 10,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 42,\n",
       "   'regressor:extra_trees:bootstrap': 'True',\n",
       "   'regressor:extra_trees:criterion': 'mse',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.4979798557239201,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 20,\n",
       "   'regressor:extra_trees:min_samples_split': 5},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:random_forest:bootstrap': 'False',\n",
       "   'regressor:random_forest:criterion': 'friedman_mse',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.26652675320482944,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 5,\n",
       "   'regressor:random_forest:min_samples_split': 18,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 1444},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0022450817024126787,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 363,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'normal',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'True',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'mse',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.46099295597435896,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 14,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 19,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 14,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'distance'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.12561018629189794,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'exp',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 29,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform',\n",
       "   'feature_preprocessor:fast_ica:n_components': 1608},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0001463764430038483,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'exp',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 16,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform',\n",
       "   'feature_preprocessor:fast_ica:n_components': 1609},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'exp',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:random_forest:bootstrap': 'True',\n",
       "   'regressor:random_forest:criterion': 'friedman_mse',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.7724990020105982,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 2,\n",
       "   'regressor:random_forest:min_samples_split': 9,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 1156},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.08157340478207341,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'exp',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:extra_trees:bootstrap': 'True',\n",
       "   'regressor:extra_trees:criterion': 'friedman_mse',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.8112840058642931,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 4,\n",
       "   'regressor:extra_trees:min_samples_split': 11,\n",
       "   'feature_preprocessor:fast_ica:n_components': 1908},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0003764164133044991,\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'False',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 4,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 3,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 12,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 55,\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 26,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.05514391375574247,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.9799969570212033,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.00269674015605084,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'exp',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'False',\n",
       "   'regressor:extra_trees:bootstrap': 'False',\n",
       "   'regressor:extra_trees:criterion': 'friedman_mse',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.13058749967482217,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 18,\n",
       "   'regressor:extra_trees:min_samples_split': 9},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'True',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'mse',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.35787438865321775,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 4,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 2,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 12,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'False',\n",
       "   'regressor:extra_trees:bootstrap': 'False',\n",
       "   'regressor:extra_trees:criterion': 'friedman_mse',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.6228569464301977,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 8,\n",
       "   'regressor:extra_trees:min_samples_split': 7},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'feature_agglomeration',\n",
       "   'regressor:__choice__': 'gaussian_process',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.7444986868057768,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.05038620684127415,\n",
       "   'feature_preprocessor:feature_agglomeration:affinity': 'cosine',\n",
       "   'feature_preprocessor:feature_agglomeration:linkage': 'complete',\n",
       "   'feature_preprocessor:feature_agglomeration:n_clusters': 20,\n",
       "   'feature_preprocessor:feature_agglomeration:pooling_func': 'median',\n",
       "   'regressor:gaussian_process:alpha': 0.006475275053987242,\n",
       "   'regressor:gaussian_process:thetaL': 1.1216212356658958e-09,\n",
       "   'regressor:gaussian_process:thetaU': 1.7041974424427613},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.4786436354310186,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:random_forest:bootstrap': 'False',\n",
       "   'regressor:random_forest:criterion': 'mse',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.3449416078131302,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 15,\n",
       "   'regressor:random_forest:min_samples_split': 20,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 1658},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'feature_agglomeration',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0020682810998537034,\n",
       "   'feature_preprocessor:feature_agglomeration:affinity': 'euclidean',\n",
       "   'feature_preprocessor:feature_agglomeration:linkage': 'ward',\n",
       "   'feature_preprocessor:feature_agglomeration:n_clusters': 365,\n",
       "   'feature_preprocessor:feature_agglomeration:pooling_func': 'median',\n",
       "   'regressor:random_forest:bootstrap': 'False',\n",
       "   'regressor:random_forest:criterion': 'mse',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.6072669614617056,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 13,\n",
       "   'regressor:random_forest:min_samples_split': 2,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:extra_trees:bootstrap': 'False',\n",
       "   'regressor:extra_trees:criterion': 'mae',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.321013119900368,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 16,\n",
       "   'regressor:extra_trees:min_samples_split': 2,\n",
       "   'feature_preprocessor:fast_ica:n_components': 1284},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'False',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 58,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.006173676939667257,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'False',\n",
       "   'regressor:extra_trees:bootstrap': 'True',\n",
       "   'regressor:extra_trees:criterion': 'mae',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.6225156808704722,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 5,\n",
       "   'regressor:extra_trees:min_samples_split': 11},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'nystroem_sampler',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'feature_preprocessor:nystroem_sampler:kernel': 'sigmoid',\n",
       "   'feature_preprocessor:nystroem_sampler:n_components': 142,\n",
       "   'regressor:ridge_regression:alpha': 245.64311422557375,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 3.813550411304487e-05,\n",
       "   'feature_preprocessor:nystroem_sampler:coef0': -0.3032067704870627,\n",
       "   'feature_preprocessor:nystroem_sampler:gamma': 6.492052790300398e-05},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.9249905869456366,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.2525850739027893,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'cube',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.8556122984280683,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 13,\n",
       "   'regressor:decision_tree:min_samples_split': 7,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 1308},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0010671792729195077,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'True',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'mae',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.8178748405936461,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 6,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 3,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 67,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'distance'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.00012091939650286628,\n",
       "   'feature_preprocessor:pca:keep_variance': 0.55813885452653,\n",
       "   'feature_preprocessor:pca:whiten': 'False',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 71,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'distance'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.06196173438148183,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.8504663111546336,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.13346266839700516,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'True',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'mae',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.6807793692839955,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 1,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 16,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 7,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'distance'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0005161305611197287,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'exp',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 14,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform',\n",
       "   'feature_preprocessor:fast_ica:n_components': 834},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.05483118632501047,\n",
       "   'feature_preprocessor:pca:keep_variance': 0.8275896013380938,\n",
       "   'feature_preprocessor:pca:whiten': 'True',\n",
       "   'regressor:ridge_regression:alpha': 5844.002574476549,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 1.5242231978076232e-06},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 354,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'uniform',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'False',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 15,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'False',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'mse',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.8393800361589034,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 7,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 5,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 6,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.43100382381130314,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.9799815835215617,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.029191592009910613,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'exp',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 17,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'distance',\n",
       "   'feature_preprocessor:fast_ica:n_components': 1326},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.007973200158774592,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'False',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'mse',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.6255465631963165,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 20,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 3,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 77,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0029591466452595395,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'True',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'mae',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.9947294831957315,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 13,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 5,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 18,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'gaussian_process',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0006988462903025105,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'True',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'friedman_mse',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.7202691278549422,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 8,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 11,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:gaussian_process:alpha': 2.4943590085523828e-14,\n",
       "   'regressor:gaussian_process:thetaL': 0.00035331328505355857,\n",
       "   'regressor:gaussian_process:thetaU': 53283.70339523912},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.10421338213740242,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.9510986742123887,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.2368763671328048,\n",
       "   'feature_preprocessor:pca:keep_variance': 0.6152267921455538,\n",
       "   'feature_preprocessor:pca:whiten': 'False',\n",
       "   'regressor:extra_trees:bootstrap': 'False',\n",
       "   'regressor:extra_trees:criterion': 'mae',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.4233082907505926,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 4,\n",
       "   'regressor:extra_trees:min_samples_split': 15},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.8596583537302948,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.2109816113358427,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'False',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'friedman_mse',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.6179330618043082,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 12,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 15,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:extra_trees:bootstrap': 'False',\n",
       "   'regressor:extra_trees:criterion': 'mae',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.7096700583343091,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 13,\n",
       "   'regressor:extra_trees:min_samples_split': 20},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 1620,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'normal',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'False',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'friedman_mse',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.753750709643032,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 17,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 13,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:random_forest:bootstrap': 'False',\n",
       "   'regressor:random_forest:criterion': 'friedman_mse',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.9760700292117067,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 13,\n",
       "   'regressor:random_forest:min_samples_split': 11,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.010000000000000004,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'exp',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 15,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'distance',\n",
       "   'feature_preprocessor:fast_ica:n_components': 941},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.00028887210695479037,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'cube',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'False',\n",
       "   'regressor:extra_trees:bootstrap': 'True',\n",
       "   'regressor:extra_trees:criterion': 'friedman_mse',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.10185296988062187,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 18,\n",
       "   'regressor:extra_trees:min_samples_split': 7},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.004476220621903362,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'True',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'friedman_mse',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.8316730926700951,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 4,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 6,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 17,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'distance'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.062121248260352965,\n",
       "   'feature_preprocessor:polynomial:degree': 3,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'False',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'False',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 3,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.009033997425806675,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'True',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'mse',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.9561629539713378,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 16,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 16,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:extra_trees:bootstrap': 'False',\n",
       "   'regressor:extra_trees:criterion': 'mse',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.7242747912368396,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 1,\n",
       "   'regressor:extra_trees:min_samples_split': 13},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.896637925108655,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.06538880065066409,\n",
       "   'feature_preprocessor:polynomial:degree': 3,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'True',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'True',\n",
       "   'regressor:random_forest:bootstrap': 'False',\n",
       "   'regressor:random_forest:criterion': 'friedman_mse',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.8840956683508758,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 19,\n",
       "   'regressor:random_forest:min_samples_split': 16,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'False',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'mse',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.78436043649581,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 3,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 13,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 69,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'distance'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'regressor:random_forest:bootstrap': 'True',\n",
       "   'regressor:random_forest:criterion': 'mse',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.6297464564951961,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 3,\n",
       "   'regressor:random_forest:min_samples_split': 13,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.00012479807854604748,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'False',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'mae',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.7167571026167089,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 12,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 3,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 43,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'distance'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 1000,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'normal',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 6,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform',\n",
       "   'feature_preprocessor:fast_ica:n_components': 76},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'nystroem_sampler',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'feature_preprocessor:nystroem_sampler:kernel': 'rbf',\n",
       "   'feature_preprocessor:nystroem_sampler:n_components': 306,\n",
       "   'regressor:ridge_regression:alpha': 4033.5551972550975,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 5.186559866196402e-07,\n",
       "   'feature_preprocessor:nystroem_sampler:gamma': 3.696700406797084e-05},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'cube',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 16,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform',\n",
       "   'feature_preprocessor:fast_ica:n_components': 1555},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0003632678247218346,\n",
       "   'feature_preprocessor:polynomial:degree': 3,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'True',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'False',\n",
       "   'regressor:ridge_regression:alpha': 114.96703551039991,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 2.8840370949989165e-06},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'False',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'friedman_mse',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.13475263368907847,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 6,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 3,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:random_forest:bootstrap': 'True',\n",
       "   'regressor:random_forest:criterion': 'friedman_mse',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.45146884844304047,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 15,\n",
       "   'regressor:random_forest:min_samples_split': 15,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'feature_agglomeration',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'feature_preprocessor:feature_agglomeration:affinity': 'euclidean',\n",
       "   'feature_preprocessor:feature_agglomeration:linkage': 'ward',\n",
       "   'feature_preprocessor:feature_agglomeration:n_clusters': 25,\n",
       "   'feature_preprocessor:feature_agglomeration:pooling_func': 'mean',\n",
       "   'regressor:random_forest:bootstrap': 'False',\n",
       "   'regressor:random_forest:criterion': 'mae',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.46655064698452375,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 12,\n",
       "   'regressor:random_forest:min_samples_split': 2,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.00019002053866005197,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'False',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'friedman_mse',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.8474628078620302,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 15,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 11,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 37,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'distance'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'regressor:ridge_regression:alpha': 2891.8912532566237,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 3.215920568676646e-05},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 1502,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'uniform',\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'False',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 7,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 12,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 20,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 43,\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 76,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'distance'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.00010715172211538464,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'False',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'friedman_mse',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.8351542476324354,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 7,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 12,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:extra_trees:bootstrap': 'False',\n",
       "   'regressor:extra_trees:criterion': 'mse',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.12478532667987306,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 7,\n",
       "   'regressor:extra_trees:min_samples_split': 20},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'cube',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 12,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform',\n",
       "   'feature_preprocessor:fast_ica:n_components': 127},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0002901645474864113,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.9043393121361277,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.2956463389533333,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'True',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'friedman_mse',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.1948076876803117,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 18,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 10,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:extra_trees:bootstrap': 'False',\n",
       "   'regressor:extra_trees:criterion': 'mae',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.4033791508373106,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 6,\n",
       "   'regressor:extra_trees:min_samples_split': 2},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'feature_agglomeration',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.10639196545783305,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.9588519272296614,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.27108951755325406,\n",
       "   'feature_preprocessor:feature_agglomeration:affinity': 'manhattan',\n",
       "   'feature_preprocessor:feature_agglomeration:linkage': 'average',\n",
       "   'feature_preprocessor:feature_agglomeration:n_clusters': 95,\n",
       "   'feature_preprocessor:feature_agglomeration:pooling_func': 'median',\n",
       "   'regressor:random_forest:bootstrap': 'False',\n",
       "   'regressor:random_forest:criterion': 'friedman_mse',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.6318845394734633,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 10,\n",
       "   'regressor:random_forest:min_samples_split': 6,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 329,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'normal',\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'True',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 9,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 17,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 2,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 28,\n",
       "   'regressor:ridge_regression:alpha': 360.7971691284488,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 1.1465466365904057e-05},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'gaussian_process',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0014909345096524203,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.8693483750824091,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.11465188136981816,\n",
       "   'feature_preprocessor:polynomial:degree': 3,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'True',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'True',\n",
       "   'regressor:gaussian_process:alpha': 1.4736016285731312e-09,\n",
       "   'regressor:gaussian_process:thetaL': 3.076604135826946e-06,\n",
       "   'regressor:gaussian_process:thetaU': 1726.5686836572502},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.025548043997448398,\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'True',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 10,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 18,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 11,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 56,\n",
       "   'regressor:extra_trees:bootstrap': 'False',\n",
       "   'regressor:extra_trees:criterion': 'mae',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.223788396300784,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 3,\n",
       "   'regressor:extra_trees:min_samples_split': 2},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.8418617159378143,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.04473369757084339,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'False',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'friedman_mse',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.4051305371937508,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 9,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 13,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:extra_trees:bootstrap': 'False',\n",
       "   'regressor:extra_trees:criterion': 'mae',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.3704691120667316,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 11,\n",
       "   'regressor:extra_trees:min_samples_split': 20},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0003716964677931218,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'False',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'friedman_mse',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.9692000454935757,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 15,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 2,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 25,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'distance'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.004047978636383022,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'False',\n",
       "   'regressor:random_forest:bootstrap': 'True',\n",
       "   'regressor:random_forest:criterion': 'friedman_mse',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.15659863368338756,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 7,\n",
       "   'regressor:random_forest:min_samples_split': 17,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.00028569994555173727,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.8880567208364974,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.07018960067771882,\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'True',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 4,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 1,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 8,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 27,\n",
       "   'regressor:extra_trees:bootstrap': 'True',\n",
       "   'regressor:extra_trees:criterion': 'friedman_mse',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.6889624293129364,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 8,\n",
       "   'regressor:extra_trees:min_samples_split': 7},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'False',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'friedman_mse',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.7505018286705717,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 13,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 9,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 37,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.008799331638525625,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.7156389413251741,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.1457519005867994,\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'False',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 4,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 18,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 15,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 66,\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 49,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'False',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'mae',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.22138131339514516,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 10,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 4,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:extra_trees:bootstrap': 'True',\n",
       "   'regressor:extra_trees:criterion': 'friedman_mse',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.35384726576715564,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 12,\n",
       "   'regressor:extra_trees:min_samples_split': 13},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'False',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'friedman_mse',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.4218137381994512,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 9,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 6,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:ridge_regression:alpha': 489.52412294125753,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 3.278394403811397e-05},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0014271516277145012,\n",
       "   'feature_preprocessor:pca:keep_variance': 0.9493631401580722,\n",
       "   'feature_preprocessor:pca:whiten': 'True',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 1,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'distance'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0011928275630544527,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.9135968550931912,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.2164753797864963,\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'True',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 3,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 18,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 18,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 54,\n",
       "   'regressor:extra_trees:bootstrap': 'True',\n",
       "   'regressor:extra_trees:criterion': 'friedman_mse',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.9729126286415507,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 2,\n",
       "   'regressor:extra_trees:min_samples_split': 7},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.021563947990760116,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.9844936301785254,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.001338107642891972,\n",
       "   'feature_preprocessor:pca:keep_variance': 0.658173373916156,\n",
       "   'feature_preprocessor:pca:whiten': 'True',\n",
       "   'regressor:extra_trees:bootstrap': 'True',\n",
       "   'regressor:extra_trees:criterion': 'friedman_mse',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.5188874225104542,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 3,\n",
       "   'regressor:extra_trees:min_samples_split': 11},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.00022146892093146694,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.817729452826626,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.08405438473721615,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'exp',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:random_forest:bootstrap': 'False',\n",
       "   'regressor:random_forest:criterion': 'mae',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.7841072759596254,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 14,\n",
       "   'regressor:random_forest:min_samples_split': 9,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 1278},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.011385771470125237,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 606,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'uniform',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'False',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'mse',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.2914600922646382,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 15,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 12,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 46,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'distance'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.03859930660423184,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'False',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'mse',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.5185015794876497,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 15,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 18,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 55,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'distance'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.09564404749750208,\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 2,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'True',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'mse',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 1.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 15,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 9,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 13,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.012638359593789946,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 1673,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'normal',\n",
       "   'regressor:extra_trees:bootstrap': 'False',\n",
       "   'regressor:extra_trees:criterion': 'mse',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.27086992568125184,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 12,\n",
       "   'regressor:extra_trees:min_samples_split': 18},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.010052223119252758,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'False',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'mse',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.7079140021841538,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 6,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 4,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:ridge_regression:alpha': 2019.0065708983461,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 3.856404664779095e-06},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'feature_agglomeration',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'feature_preprocessor:feature_agglomeration:affinity': 'manhattan',\n",
       "   'feature_preprocessor:feature_agglomeration:linkage': 'complete',\n",
       "   'feature_preprocessor:feature_agglomeration:n_clusters': 339,\n",
       "   'feature_preprocessor:feature_agglomeration:pooling_func': 'max',\n",
       "   'regressor:random_forest:bootstrap': 'True',\n",
       "   'regressor:random_forest:criterion': 'mse',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.4095154069889594,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 1,\n",
       "   'regressor:random_forest:min_samples_split': 10,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'False',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'mae',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.15564302415622855,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 13,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 14,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:random_forest:bootstrap': 'True',\n",
       "   'regressor:random_forest:criterion': 'friedman_mse',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.967452275667216,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 19,\n",
       "   'regressor:random_forest:min_samples_split': 20,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.07879610577774053,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.8903197640685494,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.2714267245752716,\n",
       "   'feature_preprocessor:pca:keep_variance': 0.944823800920894,\n",
       "   'feature_preprocessor:pca:whiten': 'False',\n",
       "   'regressor:extra_trees:bootstrap': 'False',\n",
       "   'regressor:extra_trees:criterion': 'friedman_mse',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.40097708456400205,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 2,\n",
       "   'regressor:extra_trees:min_samples_split': 3},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.10418489224578882,\n",
       "   'feature_preprocessor:polynomial:degree': 2,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'False',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'False',\n",
       "   'regressor:extra_trees:bootstrap': 'False',\n",
       "   'regressor:extra_trees:criterion': 'friedman_mse',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.5307163961487747,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 11,\n",
       "   'regressor:extra_trees:min_samples_split': 13},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'feature_preprocessor:pca:keep_variance': 0.9066579070598708,\n",
       "   'feature_preprocessor:pca:whiten': 'True',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 79,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'distance'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.49064881720542597,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 917,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'normal',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'cube',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 5,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform',\n",
       "   'feature_preprocessor:fast_ica:n_components': 298},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 60,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'uniform',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'cube',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'False',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 41,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'exp',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'False',\n",
       "   'regressor:random_forest:bootstrap': 'True',\n",
       "   'regressor:random_forest:criterion': 'mse',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.2788820576593313,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 14,\n",
       "   'regressor:random_forest:min_samples_split': 16,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'gaussian_process',\n",
       "   'regressor:gaussian_process:alpha': 5.856338335459175e-14,\n",
       "   'regressor:gaussian_process:thetaL': 5.131329164411288e-08,\n",
       "   'regressor:gaussian_process:thetaU': 7659.279743730741},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'False',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 2,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0001438613287213223,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 1000,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'normal',\n",
       "   'feature_preprocessor:pca:keep_variance': 0.6409730320728056,\n",
       "   'feature_preprocessor:pca:whiten': 'False',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 13,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'distance'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0002492442357284328,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 1040,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'normal',\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'True',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 6,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 3,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 17,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 65,\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 6,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'distance'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'gaussian_process',\n",
       "   'feature_preprocessor:pca:keep_variance': 0.5251348274254521,\n",
       "   'feature_preprocessor:pca:whiten': 'True',\n",
       "   'regressor:gaussian_process:alpha': 1.9255326460123923e-11,\n",
       "   'regressor:gaussian_process:thetaL': 7.108156610214643e-08,\n",
       "   'regressor:gaussian_process:thetaU': 56.20325012506926},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 13,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform',\n",
       "   'feature_preprocessor:fast_ica:n_components': 100},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.10421338213740242,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.75,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.25,\n",
       "   'feature_preprocessor:polynomial:degree': 2,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'True',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'False',\n",
       "   'regressor:extra_trees:bootstrap': 'False',\n",
       "   'regressor:extra_trees:criterion': 'friedman_mse',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.4233082907505926,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 4,\n",
       "   'regressor:extra_trees:min_samples_split': 2},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.004990226253109335,\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'True',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 10,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 16,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 4,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 63,\n",
       "   'regressor:extra_trees:bootstrap': 'True',\n",
       "   'regressor:extra_trees:criterion': 'mae',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.7472038306010356,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 3,\n",
       "   'regressor:extra_trees:min_samples_split': 9},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.000784435423393073,\n",
       "   'feature_preprocessor:polynomial:degree': 2,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'True',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'False',\n",
       "   'regressor:random_forest:bootstrap': 'False',\n",
       "   'regressor:random_forest:criterion': 'mse',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.4827671645747057,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 4,\n",
       "   'regressor:random_forest:min_samples_split': 10,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'feature_preprocessor:pca:keep_variance': 0.9831145000734977,\n",
       "   'feature_preprocessor:pca:whiten': 'True',\n",
       "   'regressor:extra_trees:bootstrap': 'False',\n",
       "   'regressor:extra_trees:criterion': 'mae',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.9263816993350036,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 19,\n",
       "   'regressor:extra_trees:min_samples_split': 7},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 1323,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'uniform',\n",
       "   'feature_preprocessor:polynomial:degree': 3,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'True',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'False',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 15,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'distance'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0011168522113585097,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 49,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'distance',\n",
       "   'feature_preprocessor:fast_ica:n_components': 170},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'exp',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 14,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'distance',\n",
       "   'feature_preprocessor:fast_ica:n_components': 676},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'exp',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 28,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'distance',\n",
       "   'feature_preprocessor:fast_ica:n_components': 945},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'feature_preprocessor:polynomial:degree': 2,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'True',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'False',\n",
       "   'regressor:random_forest:bootstrap': 'False',\n",
       "   'regressor:random_forest:criterion': 'mae',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.4362502350364773,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 10,\n",
       "   'regressor:random_forest:min_samples_split': 13,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'gaussian_process',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.023093832466276075,\n",
       "   'regressor:gaussian_process:alpha': 1.501108258261274e-07,\n",
       "   'regressor:gaussian_process:thetaL': 1.0676971949446703e-07,\n",
       "   'regressor:gaussian_process:thetaU': 143.75186675894298},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'feature_agglomeration',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'feature_preprocessor:feature_agglomeration:affinity': 'cosine',\n",
       "   'feature_preprocessor:feature_agglomeration:linkage': 'average',\n",
       "   'feature_preprocessor:feature_agglomeration:n_clusters': 121,\n",
       "   'feature_preprocessor:feature_agglomeration:pooling_func': 'max',\n",
       "   'regressor:extra_trees:bootstrap': 'True',\n",
       "   'regressor:extra_trees:criterion': 'mse',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.3942056895177096,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 13,\n",
       "   'regressor:extra_trees:min_samples_split': 5},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.00029370169512781967,\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'True',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 6,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 19,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 18,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 84,\n",
       "   'regressor:extra_trees:bootstrap': 'False',\n",
       "   'regressor:extra_trees:criterion': 'mae',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.5734570605733377,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 12,\n",
       "   'regressor:extra_trees:min_samples_split': 16},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'gaussian_process',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.021816031177318205,\n",
       "   'feature_preprocessor:polynomial:degree': 3,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'False',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'True',\n",
       "   'regressor:gaussian_process:alpha': 2.3859666951808862e-09,\n",
       "   'regressor:gaussian_process:thetaL': 3.3263630856712037e-07,\n",
       "   'regressor:gaussian_process:thetaU': 27628.01440383758},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 17,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.37682392740815973,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.8947099494671126,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.18100466484168512,\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'False',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 7,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 14,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 14,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 49,\n",
       "   'regressor:extra_trees:bootstrap': 'False',\n",
       "   'regressor:extra_trees:criterion': 'mae',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.9198038791962958,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 8,\n",
       "   'regressor:extra_trees:min_samples_split': 3},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.007322903535438241,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 13,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'distance',\n",
       "   'feature_preprocessor:fast_ica:n_components': 526},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.010000000000000004,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'cube',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 13,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'distance',\n",
       "   'feature_preprocessor:fast_ica:n_components': 397},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'True',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 9,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 17,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 15,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 23,\n",
       "   'regressor:ridge_regression:alpha': 184.2585782014767,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 6.916856028345069e-07},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.260129158166899,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 920,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'uniform',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 35,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'distance',\n",
       "   'feature_preprocessor:fast_ica:n_components': 1306},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'kitchen_sinks',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0003195319695087046,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 1856,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'normal',\n",
       "   'feature_preprocessor:kitchen_sinks:gamma': 5.2270102435954256e-05,\n",
       "   'feature_preprocessor:kitchen_sinks:n_components': 1231,\n",
       "   'regressor:ridge_regression:alpha': 199.586377683296,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 2.0286301547086203e-07},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.970876983419237,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.21284046835599882,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'cube',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 14,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform',\n",
       "   'feature_preprocessor:fast_ica:n_components': 1077},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.002521962058923429,\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.1473280356333253,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 1,\n",
       "   'regressor:decision_tree:min_samples_split': 16,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.012588534853704928,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'cube',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 14,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform',\n",
       "   'feature_preprocessor:fast_ica:n_components': 1303},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'feature_preprocessor:pca:keep_variance': 0.6160733797878657,\n",
       "   'feature_preprocessor:pca:whiten': 'False',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 1,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'distance'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0010630543004591941,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'exp',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 67,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'distance',\n",
       "   'feature_preprocessor:fast_ica:n_components': 1660},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'cube',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 10,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform',\n",
       "   'feature_preprocessor:fast_ica:n_components': 588},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0439086270577992,\n",
       "   'regressor:ridge_regression:alpha': 1042.2920959797164,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 5.3883436479428155e-05},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.35723264496284374,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'False',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'mse',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.21174303085797821,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 18,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 8,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 79,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'distance'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.8443605873552952,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.18621352316407067,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'True',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'mae',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.3977605879053516,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 3,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 18,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:decision_tree:criterion': 'mae',\n",
       "   'regressor:decision_tree:max_depth_factor': 1.1143893983344055,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 7,\n",
       "   'regressor:decision_tree:min_samples_split': 16,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'True',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 2,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 18,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 2,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 16,\n",
       "   'regressor:random_forest:bootstrap': 'True',\n",
       "   'regressor:random_forest:criterion': 'friedman_mse',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.4119589613072887,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 9,\n",
       "   'regressor:random_forest:min_samples_split': 4,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.00336496001864943,\n",
       "   'feature_preprocessor:polynomial:degree': 2,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'False',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'True',\n",
       "   'regressor:extra_trees:bootstrap': 'True',\n",
       "   'regressor:extra_trees:criterion': 'friedman_mse',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.5091948981127149,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 2,\n",
       "   'regressor:extra_trees:min_samples_split': 12},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.002821421944770932,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.8856440305944182,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.23561730408446413,\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'True',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 7,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 17,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 14,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 73,\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 19,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'distance'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.01544267551439805,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'cube',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 10,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'distance',\n",
       "   'feature_preprocessor:fast_ica:n_components': 1570},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'False',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'mse',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.9603196322970856,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 16,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 9,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 11,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'distance'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'True',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 2,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 5,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 13,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 20,\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 32,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'feature_agglomeration',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 708,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'normal',\n",
       "   'feature_preprocessor:feature_agglomeration:affinity': 'euclidean',\n",
       "   'feature_preprocessor:feature_agglomeration:linkage': 'ward',\n",
       "   'feature_preprocessor:feature_agglomeration:n_clusters': 65,\n",
       "   'feature_preprocessor:feature_agglomeration:pooling_func': 'median',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.40422044403763846,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 1,\n",
       "   'regressor:decision_tree:min_samples_split': 2,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'gaussian_process',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0032794633885843924,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'False',\n",
       "   'regressor:gaussian_process:alpha': 0.0012585508494078986,\n",
       "   'regressor:gaussian_process:thetaL': 1.2989432542622725e-09,\n",
       "   'regressor:gaussian_process:thetaU': 350.9176745391377},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.06366258623263053,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 632,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'normal',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'False',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'mse',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.17322770048550531,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 3,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 20,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 1,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'distance'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'feature_preprocessor:pca:keep_variance': 0.9470831460295691,\n",
       "   'feature_preprocessor:pca:whiten': 'False',\n",
       "   'regressor:extra_trees:bootstrap': 'True',\n",
       "   'regressor:extra_trees:criterion': 'friedman_mse',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.920689394063422,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 20,\n",
       "   'regressor:extra_trees:min_samples_split': 12},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'gaussian_process',\n",
       "   'feature_preprocessor:pca:keep_variance': 0.6386775426908375,\n",
       "   'feature_preprocessor:pca:whiten': 'True',\n",
       "   'regressor:gaussian_process:alpha': 6.86831255137143e-09,\n",
       "   'regressor:gaussian_process:thetaL': 3.626595883283288e-09,\n",
       "   'regressor:gaussian_process:thetaU': 7.953941151617265},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0004468765073505084,\n",
       "   'regressor:decision_tree:criterion': 'mae',\n",
       "   'regressor:decision_tree:max_depth_factor': 1.0178612159642375,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 16,\n",
       "   'regressor:decision_tree:min_samples_split': 12,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'feature_preprocessor:polynomial:degree': 2,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'False',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'False',\n",
       "   'regressor:random_forest:bootstrap': 'True',\n",
       "   'regressor:random_forest:criterion': 'mae',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.4449067756269477,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 9,\n",
       "   'regressor:random_forest:min_samples_split': 20,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.026044985375436185,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 337,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'uniform',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'exp',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'False',\n",
       "   'regressor:ridge_regression:alpha': 844.6256543262815,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 1.658048117118359e-06},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'cube',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'False',\n",
       "   'regressor:decision_tree:criterion': 'mae',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.45206851368113354,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 1,\n",
       "   'regressor:decision_tree:min_samples_split': 11,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 1,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0001718497008114841,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.8702359174824481,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.09766248073288923,\n",
       "   'feature_preprocessor:pca:keep_variance': 0.6452260121358127,\n",
       "   'feature_preprocessor:pca:whiten': 'True',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 38,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.8768323903177886,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.23496758544929316,\n",
       "   'feature_preprocessor:polynomial:degree': 2,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'False',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'True',\n",
       "   'regressor:random_forest:bootstrap': 'True',\n",
       "   'regressor:random_forest:criterion': 'mae',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.2031076366666406,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 7,\n",
       "   'regressor:random_forest:min_samples_split': 3,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'feature_agglomeration',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'feature_preprocessor:feature_agglomeration:affinity': 'euclidean',\n",
       "   'feature_preprocessor:feature_agglomeration:linkage': 'ward',\n",
       "   'feature_preprocessor:feature_agglomeration:n_clusters': 3,\n",
       "   'feature_preprocessor:feature_agglomeration:pooling_func': 'median',\n",
       "   'regressor:random_forest:bootstrap': 'False',\n",
       "   'regressor:random_forest:criterion': 'friedman_mse',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.6163711655163535,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 2,\n",
       "   'regressor:random_forest:min_samples_split': 17,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.75,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.2639147472043166,\n",
       "   'feature_preprocessor:pca:keep_variance': 0.633265204169748,\n",
       "   'feature_preprocessor:pca:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.6264769596405859,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 5,\n",
       "   'regressor:decision_tree:min_samples_split': 14,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.7077248045482851,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.04111542642208652,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 22,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform',\n",
       "   'feature_preprocessor:fast_ica:n_components': 1957},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'False',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 79,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'distance'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.012013505909777747,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'exp',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'False',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 6,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.01662874282724904,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'False',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 6,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.007853878754401786,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'False',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'friedman_mse',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 1.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 1,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 2,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 4,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.03534289330072045,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'cube',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 4,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform',\n",
       "   'feature_preprocessor:fast_ica:n_components': 1884},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'feature_preprocessor:pca:keep_variance': 0.9236362820969617,\n",
       "   'feature_preprocessor:pca:whiten': 'False',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 19,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 1189,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'normal',\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'True',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 10,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 11,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 19,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 60,\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 31,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'distance'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'gaussian_process',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.04322070056066017,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.8880083492132396,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.07719222937127905,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:gaussian_process:alpha': 0.00038340317031023135,\n",
       "   'regressor:gaussian_process:thetaL': 3.5539730669533876e-07,\n",
       "   'regressor:gaussian_process:thetaU': 59.49691617916531,\n",
       "   'feature_preprocessor:fast_ica:n_components': 802},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0020558876427027844,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 468,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'normal',\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'True',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 6,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 20,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 11,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 82,\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 26,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'distance'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'feature_agglomeration',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.07592442868373174,\n",
       "   'feature_preprocessor:feature_agglomeration:affinity': 'euclidean',\n",
       "   'feature_preprocessor:feature_agglomeration:linkage': 'complete',\n",
       "   'feature_preprocessor:feature_agglomeration:n_clusters': 269,\n",
       "   'feature_preprocessor:feature_agglomeration:pooling_func': 'mean',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 28,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'distance'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.017634785889832975,\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'False',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 2,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 20,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 8,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 52,\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 31,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.7977441289934386,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.11847909645644437,\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 18,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 3,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.7334528152177051,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 18,\n",
       "   'regressor:decision_tree:min_samples_split': 6,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.11057673813850036,\n",
       "   'feature_preprocessor:polynomial:degree': 3,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'True',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'True',\n",
       "   'regressor:extra_trees:bootstrap': 'True',\n",
       "   'regressor:extra_trees:criterion': 'mae',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.21150427041311776,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 9,\n",
       "   'regressor:extra_trees:min_samples_split': 9},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.015744149885732764,\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'True',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 4,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 19,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 11,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 23,\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 46,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.010000000000000004,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.7229401741687728,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.24567295408598494,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'False',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 11,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'gaussian_process',\n",
       "   'regressor:gaussian_process:alpha': 4.489782399598325e-14,\n",
       "   'regressor:gaussian_process:thetaL': 5.757899166303097e-07,\n",
       "   'regressor:gaussian_process:thetaU': 83522.28357984616},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'True',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'friedman_mse',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.9945144837147887,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 2,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 12,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 64,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'feature_agglomeration',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.00012174765558134549,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 36,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'uniform',\n",
       "   'feature_preprocessor:feature_agglomeration:affinity': 'manhattan',\n",
       "   'feature_preprocessor:feature_agglomeration:linkage': 'complete',\n",
       "   'feature_preprocessor:feature_agglomeration:n_clusters': 308,\n",
       "   'feature_preprocessor:feature_agglomeration:pooling_func': 'median',\n",
       "   'regressor:ridge_regression:alpha': 4990.909252011707,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 3.432643954131498e-05},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 1034,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'normal',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'exp',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.6670744301935622,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 1,\n",
       "   'regressor:decision_tree:min_samples_split': 3,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 100},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 996,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'normal',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'cube',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'False',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.673784180347461,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 1,\n",
       "   'regressor:decision_tree:min_samples_split': 11,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'gaussian_process',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.9799594655018546,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.11746286194986323,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'True',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'mae',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.6483766286391843,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 10,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 3,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:gaussian_process:alpha': 0.10703515487988764,\n",
       "   'regressor:gaussian_process:thetaL': 2.841937917947068e-05,\n",
       "   'regressor:gaussian_process:thetaU': 140.13473440084033},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 592,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'normal',\n",
       "   'feature_preprocessor:polynomial:degree': 3,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'False',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'False',\n",
       "   'regressor:random_forest:bootstrap': 'True',\n",
       "   'regressor:random_forest:criterion': 'mse',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.41831768032058114,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 16,\n",
       "   'regressor:random_forest:min_samples_split': 4,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.9323255106403481,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.2602009554669062,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'exp',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:extra_trees:bootstrap': 'False',\n",
       "   'regressor:extra_trees:criterion': 'mae',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.895236607861874,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 12,\n",
       "   'regressor:extra_trees:min_samples_split': 19,\n",
       "   'feature_preprocessor:fast_ica:n_components': 225},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'feature_preprocessor:pca:keep_variance': 0.5214651233749577,\n",
       "   'feature_preprocessor:pca:whiten': 'False',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.41687451703652556,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 2,\n",
       "   'regressor:decision_tree:min_samples_split': 16,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'True',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 7,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 19,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 12,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 61,\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 44,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'distance'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.16829727897592697,\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'True',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 7,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 19,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 13,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 92,\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 27,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0008775667452956317,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'cube',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:extra_trees:bootstrap': 'False',\n",
       "   'regressor:extra_trees:criterion': 'mse',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.49398311876699463,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 13,\n",
       "   'regressor:extra_trees:min_samples_split': 15,\n",
       "   'feature_preprocessor:fast_ica:n_components': 1797},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'feature_preprocessor:polynomial:degree': 3,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'False',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'True',\n",
       "   'regressor:extra_trees:bootstrap': 'True',\n",
       "   'regressor:extra_trees:criterion': 'mse',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.4236076131082134,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 8,\n",
       "   'regressor:extra_trees:min_samples_split': 12},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.009899104164600468,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'exp',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 6,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'distance',\n",
       "   'feature_preprocessor:fast_ica:n_components': 1825},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0006645809387556937,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 1245,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'uniform',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'False',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 31,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.7640834605671735,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.25,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'cube',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'False',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.3485692701754227,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 4,\n",
       "   'regressor:decision_tree:min_samples_split': 5,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'feature_agglomeration',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0001599712226727595,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.9507573906123465,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.26560498179971587,\n",
       "   'feature_preprocessor:feature_agglomeration:affinity': 'cosine',\n",
       "   'feature_preprocessor:feature_agglomeration:linkage': 'complete',\n",
       "   'feature_preprocessor:feature_agglomeration:n_clusters': 43,\n",
       "   'feature_preprocessor:feature_agglomeration:pooling_func': 'max',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 61,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 1954,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'normal',\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'True',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 3,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 19,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 12,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 19,\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 2,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.001273556700162062,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 1698,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'uniform',\n",
       "   'feature_preprocessor:polynomial:degree': 3,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'False',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'False',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 8,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'distance'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 8,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'distance',\n",
       "   'feature_preprocessor:fast_ica:n_components': 960},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 19,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform',\n",
       "   'feature_preprocessor:fast_ica:n_components': 354},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'feature_preprocessor:pca:keep_variance': 0.5091742494447935,\n",
       "   'feature_preprocessor:pca:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.20521565931291616,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 2,\n",
       "   'regressor:decision_tree:min_samples_split': 17,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'feature_preprocessor:polynomial:degree': 2,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'True',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'True',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 53,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.010000000000000004,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 1000,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'uniform',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'cube',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'False',\n",
       "   'regressor:decision_tree:criterion': 'friedman_mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.5426862776196556,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 2,\n",
       "   'regressor:decision_tree:min_samples_split': 20,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.010000000000000004,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 763,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'normal',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'cube',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'False',\n",
       "   'regressor:decision_tree:criterion': 'friedman_mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.31497741078178065,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 2,\n",
       "   'regressor:decision_tree:min_samples_split': 17,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.015887123013573957,\n",
       "   'feature_preprocessor:pca:keep_variance': 0.7076614616514927,\n",
       "   'feature_preprocessor:pca:whiten': 'False',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 1.3301014170986079,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 12,\n",
       "   'regressor:decision_tree:min_samples_split': 20,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'feature_preprocessor:pca:keep_variance': 0.98082715000623,\n",
       "   'feature_preprocessor:pca:whiten': 'False',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 20,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'distance'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'True',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'mse',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.5425547929408466,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 15,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 2,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:decision_tree:criterion': 'mae',\n",
       "   'regressor:decision_tree:max_depth_factor': 1.9875058230704994,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 11,\n",
       "   'regressor:decision_tree:min_samples_split': 20,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0005803029973239006,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.9459425804708814,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.24944511134256273,\n",
       "   'feature_preprocessor:pca:keep_variance': 0.8510315544494598,\n",
       "   'feature_preprocessor:pca:whiten': 'False',\n",
       "   'regressor:ridge_regression:alpha': 782.5897080133776,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 3.0128734232620158e-05},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.00036595588380562797,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.8108763652380688,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.15144273102030664,\n",
       "   'regressor:extra_trees:bootstrap': 'True',\n",
       "   'regressor:extra_trees:criterion': 'mse',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.6243979185498796,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 1,\n",
       "   'regressor:extra_trees:min_samples_split': 17},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'feature_agglomeration',\n",
       "   'regressor:__choice__': 'gaussian_process',\n",
       "   'feature_preprocessor:feature_agglomeration:affinity': 'cosine',\n",
       "   'feature_preprocessor:feature_agglomeration:linkage': 'complete',\n",
       "   'feature_preprocessor:feature_agglomeration:n_clusters': 167,\n",
       "   'feature_preprocessor:feature_agglomeration:pooling_func': 'max',\n",
       "   'regressor:gaussian_process:alpha': 1.0687203495761815e-06,\n",
       "   'regressor:gaussian_process:thetaL': 7.476972189926359e-09,\n",
       "   'regressor:gaussian_process:thetaU': 3699.76488139761},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0035592579605266865,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.8661642155759056,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.2713518522075269,\n",
       "   'feature_preprocessor:polynomial:degree': 3,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'False',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'False',\n",
       "   'regressor:ridge_regression:alpha': 1294.9622022594042,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 5.480775989038313e-07},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.020560740057632115,\n",
       "   'feature_preprocessor:polynomial:degree': 2,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'True',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'True',\n",
       "   'regressor:random_forest:bootstrap': 'False',\n",
       "   'regressor:random_forest:criterion': 'mse',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.40052074195500176,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 1,\n",
       "   'regressor:random_forest:min_samples_split': 4,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.035836609584578204,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 1585,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'normal',\n",
       "   'feature_preprocessor:polynomial:degree': 3,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'False',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'True',\n",
       "   'regressor:random_forest:bootstrap': 'True',\n",
       "   'regressor:random_forest:criterion': 'friedman_mse',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.6690339287223425,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 6,\n",
       "   'regressor:random_forest:min_samples_split': 5,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.9618990325089025,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.18511803864233914,\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 37,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 807,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'uniform',\n",
       "   'feature_preprocessor:pca:keep_variance': 0.9534053072467382,\n",
       "   'feature_preprocessor:pca:whiten': 'False',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.06506680234949211,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 1,\n",
       "   'regressor:decision_tree:min_samples_split': 16,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.010000000000000004,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 17,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'distance',\n",
       "   'feature_preprocessor:fast_ica:n_components': 1666},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.00020284734326099372,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'False',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'friedman_mse',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.1964256826075412,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 16,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 6,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:ridge_regression:alpha': 508.4982297300196,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 3.8088901515802023e-06},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'gaussian_process',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 1950,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'uniform',\n",
       "   'regressor:gaussian_process:alpha': 0.013109186590037012,\n",
       "   'regressor:gaussian_process:thetaL': 3.958884283642714e-08,\n",
       "   'regressor:gaussian_process:thetaU': 501.44421030566906},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.003060463436258844,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'cube',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'False',\n",
       "   'regressor:extra_trees:bootstrap': 'True',\n",
       "   'regressor:extra_trees:criterion': 'mse',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.526806075677887,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 19,\n",
       "   'regressor:extra_trees:min_samples_split': 13},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 427,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'normal',\n",
       "   'feature_preprocessor:polynomial:degree': 3,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'True',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'True',\n",
       "   'regressor:extra_trees:bootstrap': 'False',\n",
       "   'regressor:extra_trees:criterion': 'mse',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.7968208990371841,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 19,\n",
       "   'regressor:extra_trees:min_samples_split': 14},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0010997898561207458,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 1435,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'normal',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 82,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'distance'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.01828333906048363,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'False',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 11,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'distance'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.00016378513464383534,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 1579,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'normal',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'True',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'friedman_mse',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.7011033247317937,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 13,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 15,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:ridge_regression:alpha': 844.5613559017186,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 7.098661839784815e-05},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'False',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 3,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'distance'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'feature_preprocessor:polynomial:degree': 3,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'False',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'False',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 1.6287537851836027,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 10,\n",
       "   'regressor:decision_tree:min_samples_split': 14,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.010000000000000004,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 14,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'distance',\n",
       "   'feature_preprocessor:fast_ica:n_components': 1340},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0014176666535513913,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 1130,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'normal',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'True',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'mae',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.8733489479268874,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 12,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 14,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:random_forest:bootstrap': 'False',\n",
       "   'regressor:random_forest:criterion': 'friedman_mse',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.8506608121464116,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 10,\n",
       "   'regressor:random_forest:min_samples_split': 20,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 1698,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'normal',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 43,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.010000000000000004,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'cube',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'mae',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.11133301365645826,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 2,\n",
       "   'regressor:decision_tree:min_samples_split': 10,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 65},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 1777,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'normal',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'cube',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 14,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform',\n",
       "   'feature_preprocessor:fast_ica:n_components': 1559},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'regressor:ridge_regression:alpha': 161.60821691939609,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 8.980466030863952e-07},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0007756552564797616,\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'True',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 6,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 1,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 16,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 83,\n",
       "   'regressor:random_forest:bootstrap': 'False',\n",
       "   'regressor:random_forest:criterion': 'mse',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.764349087803526,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 20,\n",
       "   'regressor:random_forest:min_samples_split': 6,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'cube',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:random_forest:bootstrap': 'True',\n",
       "   'regressor:random_forest:criterion': 'friedman_mse',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.15428881778925685,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 2,\n",
       "   'regressor:random_forest:min_samples_split': 18,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 1271},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.01001898919504183,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 21,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'distance',\n",
       "   'feature_preprocessor:fast_ica:n_components': 1236},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 73,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform',\n",
       "   'feature_preprocessor:fast_ica:n_components': 579},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.013185624665190366,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.3063751286433084,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 1,\n",
       "   'regressor:decision_tree:min_samples_split': 6,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 286},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.014724727068666104,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.3189230967012904,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 1,\n",
       "   'regressor:decision_tree:min_samples_split': 2,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 152},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0030937694831475212,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.7412676164281848,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.0846972554564278,\n",
       "   'feature_preprocessor:pca:keep_variance': 0.7412688438997743,\n",
       "   'feature_preprocessor:pca:whiten': 'False',\n",
       "   'regressor:random_forest:bootstrap': 'False',\n",
       "   'regressor:random_forest:criterion': 'mse',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.10002285776645192,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 6,\n",
       "   'regressor:random_forest:min_samples_split': 9,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'gaussian_process',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 1887,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'normal',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'False',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'mae',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.9872503928341813,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 7,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 14,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:gaussian_process:alpha': 7.83907128831309e-05,\n",
       "   'regressor:gaussian_process:thetaL': 1.154379521747539e-07,\n",
       "   'regressor:gaussian_process:thetaU': 6059.689894225536},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.8040112525353373,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.21210556101630687,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'False',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'mae',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.8819023513601646,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 3,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 17,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:ridge_regression:alpha': 152.6621931999243,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 4.601521183474215e-06},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'feature_preprocessor:pca:keep_variance': 0.6076850600204904,\n",
       "   'feature_preprocessor:pca:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.4302462063303424,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 1,\n",
       "   'regressor:decision_tree:min_samples_split': 10,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 1035,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'uniform',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'False',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'mae',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.7312936132034784,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 7,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 11,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 11,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 66,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'distance'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'exp',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.8971165463352386,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 3,\n",
       "   'regressor:decision_tree:min_samples_split': 18,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 1170},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'feature_preprocessor:pca:keep_variance': 0.9518789807996776,\n",
       "   'feature_preprocessor:pca:whiten': 'False',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.5022101050668017,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 1,\n",
       "   'regressor:decision_tree:min_samples_split': 16,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'feature_preprocessor:pca:keep_variance': 0.992061518163893,\n",
       "   'feature_preprocessor:pca:whiten': 'False',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.5951981022730573,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 1,\n",
       "   'regressor:decision_tree:min_samples_split': 14,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.005183309725112972,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 977,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'normal',\n",
       "   'feature_preprocessor:pca:keep_variance': 0.9077677966319053,\n",
       "   'feature_preprocessor:pca:whiten': 'True',\n",
       "   'regressor:ridge_regression:alpha': 228.30725366404758,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 7.389643154429484e-05},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'False',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.3882533165651361,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 8,\n",
       "   'regressor:decision_tree:min_samples_split': 3,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.05778916008155639,\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'True',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 10,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 7,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 5,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 11,\n",
       "   'regressor:ridge_regression:alpha': 1311.9310127478552,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 1.886481815695251e-07},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.010000000000000004,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 1000,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'normal',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.2772116309998369,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 10,\n",
       "   'regressor:decision_tree:min_samples_split': 14,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 384},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.01500515679370262,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'exp',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:random_forest:bootstrap': 'True',\n",
       "   'regressor:random_forest:criterion': 'mae',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.708554329111435,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 5,\n",
       "   'regressor:random_forest:min_samples_split': 3,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 10},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.00018538820693064285,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'False',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.041366106406682694,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 6,\n",
       "   'regressor:decision_tree:min_samples_split': 18,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.04444420818955184,\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'False',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 2,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 13,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 18,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 97,\n",
       "   'regressor:random_forest:bootstrap': 'True',\n",
       "   'regressor:random_forest:criterion': 'mse',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.19758018142613398,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 5,\n",
       "   'regressor:random_forest:min_samples_split': 5,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'True',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'mse',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.9449380358323889,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 3,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 19,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:ridge_regression:alpha': 282.60408263329464,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 6.505594324130389e-05},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'feature_preprocessor:pca:keep_variance': 0.6914209725045629,\n",
       "   'feature_preprocessor:pca:whiten': 'False',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 70,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'gaussian_process',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0003343100916263923,\n",
       "   'feature_preprocessor:pca:keep_variance': 0.8582331257840531,\n",
       "   'feature_preprocessor:pca:whiten': 'True',\n",
       "   'regressor:gaussian_process:alpha': 0.00034123523500557843,\n",
       "   'regressor:gaussian_process:thetaL': 9.006442528955549e-06,\n",
       "   'regressor:gaussian_process:thetaU': 1.633668740549995},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0016948493792745027,\n",
       "   'feature_preprocessor:polynomial:degree': 3,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'True',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'True',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 1.4840181339978349,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 11,\n",
       "   'regressor:decision_tree:min_samples_split': 2,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.010000000000000004,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'exp',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'friedman_mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.2772116309998369,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 9,\n",
       "   'regressor:decision_tree:min_samples_split': 10,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 410},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'feature_agglomeration',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'feature_preprocessor:feature_agglomeration:affinity': 'cosine',\n",
       "   'feature_preprocessor:feature_agglomeration:linkage': 'complete',\n",
       "   'feature_preprocessor:feature_agglomeration:n_clusters': 266,\n",
       "   'feature_preprocessor:feature_agglomeration:pooling_func': 'mean',\n",
       "   'regressor:random_forest:bootstrap': 'False',\n",
       "   'regressor:random_forest:criterion': 'mse',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.9984314315170009,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 14,\n",
       "   'regressor:random_forest:min_samples_split': 10,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.013817696045440113,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 6,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'distance',\n",
       "   'feature_preprocessor:fast_ica:n_components': 772},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.1323908519395911,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'False',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'friedman_mse',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.8384397741169155,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 17,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 19,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:random_forest:bootstrap': 'False',\n",
       "   'regressor:random_forest:criterion': 'friedman_mse',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.9920685185832182,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 18,\n",
       "   'regressor:random_forest:min_samples_split': 20,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.025620792282258106,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 6,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform',\n",
       "   'feature_preprocessor:fast_ica:n_components': 170},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.037326390700312746,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 1000,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'normal',\n",
       "   'feature_preprocessor:pca:keep_variance': 0.9684845638567539,\n",
       "   'feature_preprocessor:pca:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.342598879600562,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 4,\n",
       "   'regressor:decision_tree:min_samples_split': 14,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.010000000000000004,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 731,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'uniform',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'True',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'mae',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.9702121847698293,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 1,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 20,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:decision_tree:criterion': 'friedman_mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.3033033714113468,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 2,\n",
       "   'regressor:decision_tree:min_samples_split': 17,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.008883058472847306,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 1961,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'uniform',\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'True',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 9,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 5,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 17,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 66,\n",
       "   'regressor:extra_trees:bootstrap': 'False',\n",
       "   'regressor:extra_trees:criterion': 'mae',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.9749677660369477,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 2,\n",
       "   'regressor:extra_trees:min_samples_split': 9},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.012323951497783044,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 6,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform',\n",
       "   'feature_preprocessor:fast_ica:n_components': 1033},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.13084232819892555,\n",
       "   'feature_preprocessor:polynomial:degree': 2,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'False',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'False',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.17926236818299313,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 3,\n",
       "   'regressor:decision_tree:min_samples_split': 19,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 1388,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'uniform',\n",
       "   'feature_preprocessor:pca:keep_variance': 0.5263138008118525,\n",
       "   'feature_preprocessor:pca:whiten': 'False',\n",
       "   'regressor:decision_tree:criterion': 'friedman_mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.16238765835827285,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 16,\n",
       "   'regressor:decision_tree:min_samples_split': 19,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.010541768693793191,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.8959795570001804,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.18316700715004977,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'True',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'mae',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.908672700090446,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 13,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 19,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:random_forest:bootstrap': 'True',\n",
       "   'regressor:random_forest:criterion': 'mae',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.9304820900184396,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 9,\n",
       "   'regressor:random_forest:min_samples_split': 19,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'False',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'mae',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.31444019903264153,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 10,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 14,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 21,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.01885219760844167,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 6,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform',\n",
       "   'feature_preprocessor:fast_ica:n_components': 152},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.9370820777316549,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.09662260257852576,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 20,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'distance',\n",
       "   'feature_preprocessor:fast_ica:n_components': 1617},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'cube',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'False',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.2693398167553451,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 2,\n",
       "   'regressor:decision_tree:min_samples_split': 20,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'gaussian_process',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.006569780631001458,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'True',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'mse',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.4320338245951909,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 17,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 13,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:gaussian_process:alpha': 1.6099330114822354e-13,\n",
       "   'regressor:gaussian_process:thetaL': 1.875511903826865e-07,\n",
       "   'regressor:gaussian_process:thetaU': 55.4752710333722},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0006343362508350629,\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'False',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 3,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 20,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 15,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 60,\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 67,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0020060258832198604,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'cube',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:ridge_regression:alpha': 1424.9390375164671,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 2.3991176556368542e-06,\n",
       "   'feature_preprocessor:fast_ica:n_components': 1980},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 501,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'normal',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:ridge_regression:alpha': 104.55457967167372,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 1.844200675625974e-05,\n",
       "   'feature_preprocessor:fast_ica:n_components': 860},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.08500052980176674,\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'False',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 4,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 20,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 19,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 86,\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 20,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.3685016664496277,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 1000,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'uniform',\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'False',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 10,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 2,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 6,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 20,\n",
       "   'regressor:decision_tree:criterion': 'mae',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.29693181660895185,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 1,\n",
       "   'regressor:decision_tree:min_samples_split': 14,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.013469646219280061,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'False',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 4,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'False',\n",
       "   'regressor:decision_tree:criterion': 'friedman_mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.2772116309998369,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 6,\n",
       "   'regressor:decision_tree:min_samples_split': 9,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 1896,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'uniform',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'exp',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'False',\n",
       "   'regressor:ridge_regression:alpha': 960.0648711417111,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 9.281298111227914e-07},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.009946753530732424,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'cube',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'friedman_mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.30597420053041924,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 1,\n",
       "   'regressor:decision_tree:min_samples_split': 4,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 93},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.010000000000000004,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'False',\n",
       "   'regressor:ridge_regression:alpha': 144.73509188167773,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 5.0269072431162524e-05},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0032473898378729232,\n",
       "   'feature_preprocessor:pca:keep_variance': 0.7389703516758297,\n",
       "   'feature_preprocessor:pca:whiten': 'False',\n",
       "   'regressor:random_forest:bootstrap': 'False',\n",
       "   'regressor:random_forest:criterion': 'mse',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.4882698185806733,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 2,\n",
       "   'regressor:random_forest:min_samples_split': 12,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'kitchen_sinks',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.8500812129314648,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.12356176740823423,\n",
       "   'feature_preprocessor:kitchen_sinks:gamma': 0.0977271993233545,\n",
       "   'feature_preprocessor:kitchen_sinks:n_components': 188,\n",
       "   'regressor:ridge_regression:alpha': 867.4331680136463,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 3.474624777203255e-05},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'cube',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'False',\n",
       "   'regressor:decision_tree:criterion': 'friedman_mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.29750631896702506,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 7,\n",
       "   'regressor:decision_tree:min_samples_split': 2,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'gaussian_process',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.06902978010803223,\n",
       "   'regressor:gaussian_process:alpha': 0.005139447210250315,\n",
       "   'regressor:gaussian_process:thetaL': 7.845424330132245e-06,\n",
       "   'regressor:gaussian_process:thetaU': 258.3078405142896},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'gaussian_process',\n",
       "   'feature_preprocessor:polynomial:degree': 2,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'False',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'True',\n",
       "   'regressor:gaussian_process:alpha': 8.199515741273387e-05,\n",
       "   'regressor:gaussian_process:thetaL': 7.327731425545816e-08,\n",
       "   'regressor:gaussian_process:thetaU': 90.95086745848563},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.1434005754234265,\n",
       "   'feature_preprocessor:pca:keep_variance': 0.9613959934122577,\n",
       "   'feature_preprocessor:pca:whiten': 'True',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 77,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'cube',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'friedman_mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.2772116309998369,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 1,\n",
       "   'regressor:decision_tree:min_samples_split': 11,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 292},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.025193100805516514,\n",
       "   'regressor:decision_tree:criterion': 'mae',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.7331941601078606,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 1,\n",
       "   'regressor:decision_tree:min_samples_split': 2,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'regressor:ridge_regression:alpha': 916.808088606391,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 4.173582626121861e-07},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 717,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'uniform',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'exp',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.44291404361237785,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 2,\n",
       "   'regressor:decision_tree:min_samples_split': 16,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 199},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.005790299266525619,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.47230724619462294,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 9,\n",
       "   'regressor:decision_tree:min_samples_split': 7,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 514},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.013805634667067931,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'True',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'mae',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.8443314032590028,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 18,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 12,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 11,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'distance'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.05390758274587074,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 1000,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'uniform',\n",
       "   'feature_preprocessor:pca:keep_variance': 0.9684845638567539,\n",
       "   'feature_preprocessor:pca:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.342598879600562,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 3,\n",
       "   'regressor:decision_tree:min_samples_split': 5,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'False',\n",
       "   'regressor:decision_tree:criterion': 'friedman_mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.28322877424532295,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 8,\n",
       "   'regressor:decision_tree:min_samples_split': 2,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:extra_trees:bootstrap': 'True',\n",
       "   'regressor:extra_trees:criterion': 'friedman_mse',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.9032863976750709,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 13,\n",
       "   'regressor:extra_trees:min_samples_split': 17,\n",
       "   'feature_preprocessor:fast_ica:n_components': 1775},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.07552250200895949,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 940,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'uniform',\n",
       "   'feature_preprocessor:pca:keep_variance': 0.9350161897617322,\n",
       "   'feature_preprocessor:pca:whiten': 'False',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 14,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'distance'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'gaussian_process',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.010355500369750041,\n",
       "   'regressor:gaussian_process:alpha': 4.030478892893677e-07,\n",
       "   'regressor:gaussian_process:thetaL': 0.000692768492712403,\n",
       "   'regressor:gaussian_process:thetaU': 119.53449768146001},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.010000000000000004,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'cube',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:ridge_regression:alpha': 141.12133312677497,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 4.859700990911062e-05,\n",
       "   'feature_preprocessor:fast_ica:n_components': 203},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.000410254772168443,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.885088887798665,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.08375407401207732,\n",
       "   'feature_preprocessor:polynomial:degree': 3,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'False',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'True',\n",
       "   'regressor:extra_trees:bootstrap': 'False',\n",
       "   'regressor:extra_trees:criterion': 'friedman_mse',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.6097176029613472,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 5,\n",
       "   'regressor:extra_trees:min_samples_split': 14},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.010000000000000004,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 1000,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'uniform',\n",
       "   'feature_preprocessor:pca:keep_variance': 0.9999,\n",
       "   'feature_preprocessor:pca:whiten': 'True',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 15,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'distance'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'gaussian_process',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.00270981961172123,\n",
       "   'regressor:gaussian_process:alpha': 0.009676148045474448,\n",
       "   'regressor:gaussian_process:thetaL': 6.01740990072471e-09,\n",
       "   'regressor:gaussian_process:thetaU': 5.263078020919164},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'exp',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'friedman_mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.30472594882091525,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 2,\n",
       "   'regressor:decision_tree:min_samples_split': 16,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 24},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'feature_agglomeration',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.004269707917048525,\n",
       "   'feature_preprocessor:feature_agglomeration:affinity': 'euclidean',\n",
       "   'feature_preprocessor:feature_agglomeration:linkage': 'average',\n",
       "   'feature_preprocessor:feature_agglomeration:n_clusters': 148,\n",
       "   'feature_preprocessor:feature_agglomeration:pooling_func': 'median',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 1,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'gaussian_process',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 1951,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'normal',\n",
       "   'feature_preprocessor:polynomial:degree': 2,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'False',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'True',\n",
       "   'regressor:gaussian_process:alpha': 7.639938824064915e-10,\n",
       "   'regressor:gaussian_process:thetaL': 2.9955022511182666e-05,\n",
       "   'regressor:gaussian_process:thetaU': 61152.407151593005},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.008398452093321887,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'False',\n",
       "   'regressor:decision_tree:criterion': 'friedman_mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.29947906255940804,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 1,\n",
       "   'regressor:decision_tree:min_samples_split': 4,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.12529210179600336,\n",
       "   'regressor:ridge_regression:alpha': 359.26891201801095,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 3.9453657269562633e-07},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.010000000000000004,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'cube',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 1.4902341289528804,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 5,\n",
       "   'regressor:decision_tree:min_samples_split': 13,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 1754},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'cube',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'False',\n",
       "   'regressor:extra_trees:bootstrap': 'False',\n",
       "   'regressor:extra_trees:criterion': 'mse',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.9571260970975939,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 7,\n",
       "   'regressor:extra_trees:min_samples_split': 2},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'exp',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'friedman_mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.3017598508074356,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 1,\n",
       "   'regressor:decision_tree:min_samples_split': 15,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 36},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.00033859749554948523,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'False',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'mse',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.41249002164304704,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 2,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 18,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:ridge_regression:alpha': 166.42313068936446,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 1.0052410477086568e-06},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.6300306739998313,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 5,\n",
       "   'regressor:decision_tree:min_samples_split': 7,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 31},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.01077968821505551,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'exp',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.774025909978848,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 14,\n",
       "   'regressor:decision_tree:min_samples_split': 7,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 95},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'False',\n",
       "   'regressor:decision_tree:criterion': 'friedman_mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.47089157723143843,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 15,\n",
       "   'regressor:decision_tree:min_samples_split': 18,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'gaussian_process',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:gaussian_process:alpha': 2.2456585225316317e-09,\n",
       "   'regressor:gaussian_process:thetaL': 9.649302082962461e-07,\n",
       "   'regressor:gaussian_process:thetaU': 100000.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 941},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.010000000000000004,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'cube',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'False',\n",
       "   'regressor:decision_tree:criterion': 'friedman_mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.13622558947169422,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 1,\n",
       "   'regressor:decision_tree:min_samples_split': 17,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 864,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'normal',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'mae',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.28001800560505163,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 1,\n",
       "   'regressor:decision_tree:min_samples_split': 14,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 40},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.02849258178585786,\n",
       "   'feature_preprocessor:polynomial:degree': 2,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'False',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'False',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.1423396276291664,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 8,\n",
       "   'regressor:decision_tree:min_samples_split': 5,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 1.5991090153294587,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 6,\n",
       "   'regressor:decision_tree:min_samples_split': 6,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 42},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.010000000000000004,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 1.1206867995157397,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 6,\n",
       "   'regressor:decision_tree:min_samples_split': 7,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 43},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'gaussian_process',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.00011756728384766398,\n",
       "   'feature_preprocessor:polynomial:degree': 3,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'True',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'True',\n",
       "   'regressor:gaussian_process:alpha': 2.3569718894257355e-14,\n",
       "   'regressor:gaussian_process:thetaL': 0.00020691992493141037,\n",
       "   'regressor:gaussian_process:thetaU': 15646.302068407242},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'True',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'mse',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.9852501648348624,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 2,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 6,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:extra_trees:bootstrap': 'False',\n",
       "   'regressor:extra_trees:criterion': 'friedman_mse',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.13888338348743784,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 20,\n",
       "   'regressor:extra_trees:min_samples_split': 16},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'exp',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'False',\n",
       "   'regressor:decision_tree:criterion': 'friedman_mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.28461777309208663,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 5,\n",
       "   'regressor:decision_tree:min_samples_split': 11,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 1026,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'normal',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'exp',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 1.6942472581217551,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 2,\n",
       "   'regressor:decision_tree:min_samples_split': 6,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 159},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 138,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'normal',\n",
       "   'feature_preprocessor:pca:keep_variance': 0.5742591165892552,\n",
       "   'feature_preprocessor:pca:whiten': 'False',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 1.2053009778696606,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 19,\n",
       "   'regressor:decision_tree:min_samples_split': 17,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'False',\n",
       "   'regressor:decision_tree:criterion': 'friedman_mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.3258069972041705,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 10,\n",
       "   'regressor:decision_tree:min_samples_split': 15,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'False',\n",
       "   'regressor:decision_tree:criterion': 'friedman_mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.3083151431301858,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 7,\n",
       "   'regressor:decision_tree:min_samples_split': 15,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 353,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'uniform',\n",
       "   'regressor:random_forest:bootstrap': 'True',\n",
       "   'regressor:random_forest:criterion': 'friedman_mse',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.7883954145320086,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 4,\n",
       "   'regressor:random_forest:min_samples_split': 4,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.02562409097925195,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:ridge_regression:alpha': 149.904331147628,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 3.1061768547376794e-06,\n",
       "   'feature_preprocessor:fast_ica:n_components': 153},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'friedman_mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.2503163596279798,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 1,\n",
       "   'regressor:decision_tree:min_samples_split': 13,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 20},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.01122733703689284,\n",
       "   'feature_preprocessor:polynomial:degree': 3,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'True',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'False',\n",
       "   'regressor:random_forest:bootstrap': 'False',\n",
       "   'regressor:random_forest:criterion': 'mae',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.5993420769135036,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 8,\n",
       "   'regressor:random_forest:min_samples_split': 19,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 1762,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'uniform',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'False',\n",
       "   'regressor:random_forest:bootstrap': 'True',\n",
       "   'regressor:random_forest:criterion': 'friedman_mse',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.7762766629997746,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 1,\n",
       "   'regressor:random_forest:min_samples_split': 20,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'nystroem_sampler',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'feature_preprocessor:nystroem_sampler:kernel': 'cosine',\n",
       "   'feature_preprocessor:nystroem_sampler:n_components': 2815,\n",
       "   'regressor:ridge_regression:alpha': 1140.261988806333,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 4.23449692061904e-06},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'cube',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'mae',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.7314529769080818,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 3,\n",
       "   'regressor:decision_tree:min_samples_split': 3,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 1014},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 10,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.010000000000000004,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'friedman_mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.2456601049541306,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 1,\n",
       "   'regressor:decision_tree:min_samples_split': 14,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 36},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.006410354061162064,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.8439525743396612,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.05847182268383268,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'cube',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'False',\n",
       "   'regressor:random_forest:bootstrap': 'False',\n",
       "   'regressor:random_forest:criterion': 'mae',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.5100230548192612,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 10,\n",
       "   'regressor:random_forest:min_samples_split': 6,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.029489164983027102,\n",
       "   'regressor:random_forest:bootstrap': 'False',\n",
       "   'regressor:random_forest:criterion': 'mse',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.46047617187561185,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 2,\n",
       "   'regressor:random_forest:min_samples_split': 8,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.7477774669138393,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.06443241127651506,\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'True',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 2,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 15,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 3,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 80,\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 41,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'distance'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'kernel_pca',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'feature_preprocessor:kernel_pca:kernel': 'cosine',\n",
       "   'feature_preprocessor:kernel_pca:n_components': 1006,\n",
       "   'regressor:ridge_regression:alpha': 573.204887498955,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 2.646001201702952e-07},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'kernel_pca',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0005265986887423441,\n",
       "   'feature_preprocessor:kernel_pca:kernel': 'poly',\n",
       "   'feature_preprocessor:kernel_pca:n_components': 1203,\n",
       "   'regressor:ridge_regression:alpha': 5622.65698277594,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 3.807167203864494e-06,\n",
       "   'feature_preprocessor:kernel_pca:coef0': 0.9603247074362007,\n",
       "   'feature_preprocessor:kernel_pca:degree': 4,\n",
       "   'feature_preprocessor:kernel_pca:gamma': 0.029405498020987582},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'exp',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'False',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.5401258021431654,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 1,\n",
       "   'regressor:decision_tree:min_samples_split': 15,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.010000000000000004,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'cube',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.30081906609023806,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 13,\n",
       "   'regressor:decision_tree:min_samples_split': 9,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 100},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'cube',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'False',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.6437655304659,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 1,\n",
       "   'regressor:decision_tree:min_samples_split': 15,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.07151935004427004,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 1,\n",
       "   'regressor:decision_tree:min_samples_split': 12,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 1608},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'gaussian_process',\n",
       "   'regressor:gaussian_process:alpha': 5.753888517288542e-12,\n",
       "   'regressor:gaussian_process:thetaL': 9.636626571609476e-10,\n",
       "   'regressor:gaussian_process:thetaU': 2082.32042948293},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.008768177166989926,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'cube',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'friedman_mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.7723644336114692,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 16,\n",
       "   'regressor:decision_tree:min_samples_split': 11,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 1196},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 1692,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'uniform',\n",
       "   'regressor:extra_trees:bootstrap': 'True',\n",
       "   'regressor:extra_trees:criterion': 'friedman_mse',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.5440566204064383,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 1,\n",
       "   'regressor:extra_trees:min_samples_split': 17},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0014848635051257285,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 1673,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'normal',\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'True',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 8,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 12,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 20,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 76,\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.4144393905175181,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 8,\n",
       "   'regressor:decision_tree:min_samples_split': 2,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.1237986482603835,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 1,\n",
       "   'regressor:decision_tree:min_samples_split': 12,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 450},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'feature_agglomeration',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 774,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'uniform',\n",
       "   'feature_preprocessor:feature_agglomeration:affinity': 'euclidean',\n",
       "   'feature_preprocessor:feature_agglomeration:linkage': 'complete',\n",
       "   'feature_preprocessor:feature_agglomeration:n_clusters': 354,\n",
       "   'feature_preprocessor:feature_agglomeration:pooling_func': 'mean',\n",
       "   'regressor:random_forest:bootstrap': 'True',\n",
       "   'regressor:random_forest:criterion': 'mse',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.5381604329049665,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 5,\n",
       "   'regressor:random_forest:min_samples_split': 6,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.7304550645476362,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.25,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'exp',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.08155818919924712,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 1,\n",
       "   'regressor:decision_tree:min_samples_split': 17,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 62},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.006550501726982547,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'exp',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.4427787719206687,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 1,\n",
       "   'regressor:decision_tree:min_samples_split': 19,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 266},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 704,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'uniform',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'exp',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 1.0009865936733635,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 1,\n",
       "   'regressor:decision_tree:min_samples_split': 14,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 100},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.7753010563913649,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.25,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.025505666468476962,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 1,\n",
       "   'regressor:decision_tree:min_samples_split': 13,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 249},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 1000,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'uniform',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.012782679872980374,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 1,\n",
       "   'regressor:decision_tree:min_samples_split': 19,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 66},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 852,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'uniform',\n",
       "   'feature_preprocessor:pca:keep_variance': 0.7804349522998837,\n",
       "   'feature_preprocessor:pca:whiten': 'False',\n",
       "   'regressor:ridge_regression:alpha': 2232.1989866753925,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 9.986288554021866e-05},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.15106317403639516,\n",
       "   'feature_preprocessor:pca:keep_variance': 0.5660771291590012,\n",
       "   'feature_preprocessor:pca:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'mae',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.6095050686448309,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 4,\n",
       "   'regressor:decision_tree:min_samples_split': 3,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.001108863558075038,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'exp',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 16,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'distance',\n",
       "   'feature_preprocessor:fast_ica:n_components': 1911},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.007846203966688501,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.902028671957767,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.06159317442198516,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 84,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform',\n",
       "   'feature_preprocessor:fast_ica:n_components': 1840},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.002938516586801615,\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'True',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 5,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 7,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 18,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 16,\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 29,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'distance'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.011275045344616848,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.9195013191720424,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.23786092308474624,\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'False',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 10,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 11,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 14,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 15,\n",
       "   'regressor:extra_trees:bootstrap': 'True',\n",
       "   'regressor:extra_trees:criterion': 'mse',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.7431650163118564,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 14,\n",
       "   'regressor:extra_trees:min_samples_split': 6},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.010000000000000004,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'exp',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 40,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform',\n",
       "   'feature_preprocessor:fast_ica:n_components': 1660},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.033685758129419895,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 1751,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'normal',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'True',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'mse',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.5719364933297839,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 12,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 3,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:decision_tree:criterion': 'mae',\n",
       "   'regressor:decision_tree:max_depth_factor': 1.1790597225310715,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 20,\n",
       "   'regressor:decision_tree:min_samples_split': 11,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.010000000000000004,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 1085,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'uniform',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.09387081716619516,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 3,\n",
       "   'regressor:decision_tree:min_samples_split': 13,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 1337},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'True',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'mae',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.7603382677740694,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 10,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 7,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 58,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'distance'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.010000000000000004,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'exp',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'mae',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.05620949601342088,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 1,\n",
       "   'regressor:decision_tree:min_samples_split': 14,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 121},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.05983964446895691,\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'True',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 3,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 4,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 8,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 99,\n",
       "   'regressor:ridge_regression:alpha': 4051.2834515766626,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 3.700485454006754e-05},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'False',\n",
       "   'regressor:ridge_regression:alpha': 662.6845697876001,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 4.861366586129698e-05},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.006027654515169864,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'friedman_mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.07564645200292093,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 1,\n",
       "   'regressor:decision_tree:min_samples_split': 16,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 484},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.05658620989752028,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 20,\n",
       "   'regressor:decision_tree:min_samples_split': 18,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 1307},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'feature_agglomeration',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'feature_preprocessor:feature_agglomeration:affinity': 'euclidean',\n",
       "   'feature_preprocessor:feature_agglomeration:linkage': 'average',\n",
       "   'feature_preprocessor:feature_agglomeration:n_clusters': 215,\n",
       "   'feature_preprocessor:feature_agglomeration:pooling_func': 'median',\n",
       "   'regressor:extra_trees:bootstrap': 'True',\n",
       "   'regressor:extra_trees:criterion': 'mae',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.10305182797327056,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 15,\n",
       "   'regressor:extra_trees:min_samples_split': 5},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'feature_agglomeration',\n",
       "   'regressor:__choice__': 'gaussian_process',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.017300374836288546,\n",
       "   'feature_preprocessor:feature_agglomeration:affinity': 'manhattan',\n",
       "   'feature_preprocessor:feature_agglomeration:linkage': 'average',\n",
       "   'feature_preprocessor:feature_agglomeration:n_clusters': 288,\n",
       "   'feature_preprocessor:feature_agglomeration:pooling_func': 'mean',\n",
       "   'regressor:gaussian_process:alpha': 5.3274564473037956e-08,\n",
       "   'regressor:gaussian_process:thetaL': 1.3896252244757856e-08,\n",
       "   'regressor:gaussian_process:thetaU': 30.163210546885768},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'cube',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'friedman_mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.009707583388910803,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 1,\n",
       "   'regressor:decision_tree:min_samples_split': 15,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 69},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'exp',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.39269210789242404,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 1,\n",
       "   'regressor:decision_tree:min_samples_split': 19,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 77},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'feature_agglomeration',\n",
       "   'regressor:__choice__': 'gaussian_process',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0018211780063896173,\n",
       "   'feature_preprocessor:feature_agglomeration:affinity': 'euclidean',\n",
       "   'feature_preprocessor:feature_agglomeration:linkage': 'complete',\n",
       "   'feature_preprocessor:feature_agglomeration:n_clusters': 274,\n",
       "   'feature_preprocessor:feature_agglomeration:pooling_func': 'max',\n",
       "   'regressor:gaussian_process:alpha': 2.854857984895263e-13,\n",
       "   'regressor:gaussian_process:thetaL': 2.9199030326937677e-05,\n",
       "   'regressor:gaussian_process:thetaU': 1.0304078746185743},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.7915149211502199,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.24594749752521305,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'cube',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'friedman_mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.014463009419814293,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 1,\n",
       "   'regressor:decision_tree:min_samples_split': 13,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 164},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.011259155658237721,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'cube',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'friedman_mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.8784829749844543,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 6,\n",
       "   'regressor:decision_tree:min_samples_split': 13,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 1998},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.010000000000000004,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'friedman_mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.25400865260654704,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 3,\n",
       "   'regressor:decision_tree:min_samples_split': 3,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 259},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.010000000000000004,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.6655630060782344,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 5,\n",
       "   'regressor:decision_tree:min_samples_split': 2,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 146},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.010000000000000004,\n",
       "   'feature_preprocessor:pca:keep_variance': 0.5133827227342168,\n",
       "   'feature_preprocessor:pca:whiten': 'False',\n",
       "   'regressor:decision_tree:criterion': 'friedman_mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.42692424567096465,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 2,\n",
       "   'regressor:decision_tree:min_samples_split': 9,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'feature_preprocessor:pca:keep_variance': 0.7876030617777108,\n",
       "   'feature_preprocessor:pca:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.3095687711304246,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 2,\n",
       "   'regressor:decision_tree:min_samples_split': 10,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.738764261831867,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.2634923656320648,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.012782679872980374,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 1,\n",
       "   'regressor:decision_tree:min_samples_split': 10,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 157},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.04445996533190901,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 1,\n",
       "   'regressor:decision_tree:min_samples_split': 18,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 665},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 1000,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'normal',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'False',\n",
       "   'regressor:decision_tree:criterion': 'friedman_mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.07181792655778518,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 7,\n",
       "   'regressor:decision_tree:min_samples_split': 13,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0027471434287859656,\n",
       "   'feature_preprocessor:polynomial:degree': 3,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'False',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'True',\n",
       "   'regressor:ridge_regression:alpha': 851.7663069328822,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 2.2543866863656948e-06},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0218733515154605,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.75,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.25,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:ridge_regression:alpha': 326.8526863010516,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 5.705489022615904e-05,\n",
       "   'feature_preprocessor:fast_ica:n_components': 215},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0018555336543965256,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 78,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'uniform',\n",
       "   'feature_preprocessor:polynomial:degree': 3,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'True',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'True',\n",
       "   'regressor:ridge_regression:alpha': 1905.8879309109736,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 2.6213061701125662e-05},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.005884733209346914,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.738764261831867,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.2503061972676905,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'exp',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'friedman_mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.012782679872980374,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 1,\n",
       "   'regressor:decision_tree:min_samples_split': 13,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 290},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'feature_preprocessor:polynomial:degree': 3,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'False',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'False',\n",
       "   'regressor:extra_trees:bootstrap': 'False',\n",
       "   'regressor:extra_trees:criterion': 'mse',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.47339366490373136,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 17,\n",
       "   'regressor:extra_trees:min_samples_split': 13},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'exp',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.0034073893099065833,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 1,\n",
       "   'regressor:decision_tree:min_samples_split': 14,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 401},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.006027654515169864,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 1000,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'uniform',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.11427519603222093,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 1,\n",
       "   'regressor:decision_tree:min_samples_split': 16,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 525},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.7746216785482053,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.2325569553199831,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'exp',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.009707583388910803,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 1,\n",
       "   'regressor:decision_tree:min_samples_split': 14,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 154},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.780343741943795,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.29589787805970086,\n",
       "   'feature_preprocessor:polynomial:degree': 2,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'False',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'True',\n",
       "   'regressor:extra_trees:bootstrap': 'True',\n",
       "   'regressor:extra_trees:criterion': 'mae',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.9438787140982665,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 17,\n",
       "   'regressor:extra_trees:min_samples_split': 13},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.00951353963865729,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'cube',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.07564645200292093,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 1,\n",
       "   'regressor:decision_tree:min_samples_split': 16,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 338},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'gaussian_process',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'False',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'mse',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.29978852999659983,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 18,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 18,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:gaussian_process:alpha': 0.0014273928813546266,\n",
       "   'regressor:gaussian_process:thetaL': 4.624236152459923e-09,\n",
       "   'regressor:gaussian_process:thetaU': 2661.716100373188},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'False',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'friedman_mse',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.31278136765815123,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 15,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 3,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:decision_tree:criterion': 'mae',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.9633105075488593,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 7,\n",
       "   'regressor:decision_tree:min_samples_split': 12,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'kitchen_sinks',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0002369084187893479,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.9098448734814497,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.06884428567887217,\n",
       "   'feature_preprocessor:kitchen_sinks:gamma': 0.030137779436914123,\n",
       "   'feature_preprocessor:kitchen_sinks:n_components': 428,\n",
       "   'regressor:ridge_regression:alpha': 396.1688126960533,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 1.3837588509465938e-06},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.2754038569213427,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 1848,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'uniform',\n",
       "   'regressor:extra_trees:bootstrap': 'False',\n",
       "   'regressor:extra_trees:criterion': 'mse',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.3833155022631176,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 16,\n",
       "   'regressor:extra_trees:min_samples_split': 20},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 1894,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'normal',\n",
       "   'feature_preprocessor:pca:keep_variance': 0.9596007225771441,\n",
       "   'feature_preprocessor:pca:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.0283458148689016,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 4,\n",
       "   'regressor:decision_tree:min_samples_split': 13,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'friedman_mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.2422156151445994,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 1,\n",
       "   'regressor:decision_tree:min_samples_split': 16,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 736},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 271,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'uniform',\n",
       "   'feature_preprocessor:polynomial:degree': 3,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'False',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'True',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 20,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'distance'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.7481878625050032,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.2748445929094955,\n",
       "   'feature_preprocessor:pca:keep_variance': 0.633265204169748,\n",
       "   'feature_preprocessor:pca:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.6588116079898395,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 3,\n",
       "   'regressor:decision_tree:min_samples_split': 2,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.01899385549390604,\n",
       "   'feature_preprocessor:pca:keep_variance': 0.727549477400778,\n",
       "   'feature_preprocessor:pca:whiten': 'False',\n",
       "   'regressor:ridge_regression:alpha': 8879.595379575447,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 9.349119476441584e-07},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'gaussian_process',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.10956192212406607,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'True',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'friedman_mse',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.9955285130457278,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 14,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 20,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:gaussian_process:alpha': 1.6993913126118065e-13,\n",
       "   'regressor:gaussian_process:thetaL': 1.009043198700696e-08,\n",
       "   'regressor:gaussian_process:thetaU': 4887.203319576199},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 99,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'distance',\n",
       "   'feature_preprocessor:fast_ica:n_components': 1080},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.2839499838493097,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 1,\n",
       "   'regressor:decision_tree:min_samples_split': 16,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 205},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.005780987281674802,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'exp',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'friedman_mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.05658620989752028,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 20,\n",
       "   'regressor:decision_tree:min_samples_split': 11,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 1307},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'False',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.036330165136707636,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 2,\n",
       "   'regressor:decision_tree:min_samples_split': 11,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.07272976847860436,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'False',\n",
       "   'regressor:random_forest:bootstrap': 'False',\n",
       "   'regressor:random_forest:criterion': 'mae',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.3247834606515138,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 11,\n",
       "   'regressor:random_forest:min_samples_split': 14,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.010000000000000004,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.7227202551678057,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.2517428397542081,\n",
       "   'feature_preprocessor:pca:keep_variance': 0.9591636344000158,\n",
       "   'feature_preprocessor:pca:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'friedman_mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.027454521527994984,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 2,\n",
       "   'regressor:decision_tree:min_samples_split': 8,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.7270790412529332,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.25,\n",
       "   'feature_preprocessor:polynomial:degree': 3,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'True',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'False',\n",
       "   'regressor:decision_tree:criterion': 'friedman_mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.01142368324134076,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 6,\n",
       "   'regressor:decision_tree:min_samples_split': 11,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.010000000000000004,\n",
       "   'feature_preprocessor:pca:keep_variance': 0.9518638608487143,\n",
       "   'feature_preprocessor:pca:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'friedman_mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.027880321355516872,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 11,\n",
       "   'regressor:decision_tree:min_samples_split': 9,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.010000000000000004,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.7304550645476362,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.23359440602297973,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'cube',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.08155818919924712,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 2,\n",
       "   'regressor:decision_tree:min_samples_split': 18,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 226},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'gaussian_process',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 1210,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'normal',\n",
       "   'regressor:gaussian_process:alpha': 1.3794594469961047e-12,\n",
       "   'regressor:gaussian_process:thetaL': 4.303827269406332e-09,\n",
       "   'regressor:gaussian_process:thetaU': 760.9875463239},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.010000000000000004,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.8087315791376788,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.24821439992656255,\n",
       "   'feature_preprocessor:pca:keep_variance': 0.9927969688560696,\n",
       "   'feature_preprocessor:pca:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'friedman_mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.5,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 2,\n",
       "   'regressor:decision_tree:min_samples_split': 10,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.1871570590663185,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'exp',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'False',\n",
       "   'regressor:ridge_regression:alpha': 816.8098301137882,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 4.7425933216451976e-07},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.7776800517641831,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.2380805039223986,\n",
       "   'feature_preprocessor:pca:keep_variance': 0.9206712156481929,\n",
       "   'feature_preprocessor:pca:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'friedman_mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.030063329230867186,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 10,\n",
       "   'regressor:decision_tree:min_samples_split': 10,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'feature_preprocessor:pca:keep_variance': 0.6641094844991201,\n",
       "   'feature_preprocessor:pca:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'friedman_mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.023076523414866434,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 2,\n",
       "   'regressor:decision_tree:min_samples_split': 8,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'gaussian_process',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.08055468923764997,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:gaussian_process:alpha': 5.247330535881833e-14,\n",
       "   'regressor:gaussian_process:thetaL': 0.00021225901674294916,\n",
       "   'regressor:gaussian_process:thetaU': 4.704672577043089,\n",
       "   'feature_preprocessor:fast_ica:n_components': 1188},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'feature_preprocessor:pca:keep_variance': 0.974089648102199,\n",
       "   'feature_preprocessor:pca:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'friedman_mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.0283458148689016,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 2,\n",
       "   'regressor:decision_tree:min_samples_split': 9,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'True',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'mae',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.949010926435308,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 6,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 19,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:decision_tree:criterion': 'friedman_mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.27387533687260635,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 19,\n",
       "   'regressor:decision_tree:min_samples_split': 12,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.7445804780442575,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.2370445792404401,\n",
       "   'feature_preprocessor:pca:keep_variance': 0.9608177505562456,\n",
       "   'feature_preprocessor:pca:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'friedman_mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.020945153506898753,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 6,\n",
       "   'regressor:decision_tree:min_samples_split': 11,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.005627475185664159,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 476,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'uniform',\n",
       "   'feature_preprocessor:polynomial:degree': 2,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'False',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'False',\n",
       "   'regressor:ridge_regression:alpha': 210.12612134175228,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 6.924583804438802e-06},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 438,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'normal',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'False',\n",
       "   'regressor:extra_trees:bootstrap': 'False',\n",
       "   'regressor:extra_trees:criterion': 'mse',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.17145536111355505,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 16,\n",
       "   'regressor:extra_trees:min_samples_split': 6},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'feature_agglomeration',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.13927016029843128,\n",
       "   'feature_preprocessor:feature_agglomeration:affinity': 'manhattan',\n",
       "   'feature_preprocessor:feature_agglomeration:linkage': 'average',\n",
       "   'feature_preprocessor:feature_agglomeration:n_clusters': 160,\n",
       "   'feature_preprocessor:feature_agglomeration:pooling_func': 'median',\n",
       "   'regressor:decision_tree:criterion': 'mae',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.8346890563517426,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 14,\n",
       "   'regressor:decision_tree:min_samples_split': 8,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'feature_agglomeration',\n",
       "   'regressor:__choice__': 'gaussian_process',\n",
       "   'feature_preprocessor:feature_agglomeration:affinity': 'cosine',\n",
       "   'feature_preprocessor:feature_agglomeration:linkage': 'complete',\n",
       "   'feature_preprocessor:feature_agglomeration:n_clusters': 293,\n",
       "   'feature_preprocessor:feature_agglomeration:pooling_func': 'max',\n",
       "   'regressor:gaussian_process:alpha': 2.6621755315843536e-06,\n",
       "   'regressor:gaussian_process:thetaL': 3.5918499907717756e-09,\n",
       "   'regressor:gaussian_process:thetaU': 2.71006160915137},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.010000000000000004,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'False',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'friedman_mse',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.9390783038414527,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 1,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 2,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:decision_tree:criterion': 'mae',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.006856919975203199,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 1,\n",
       "   'regressor:decision_tree:min_samples_split': 8,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.010000000000000004,\n",
       "   'feature_preprocessor:pca:keep_variance': 0.9536398500159087,\n",
       "   'feature_preprocessor:pca:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'friedman_mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.2901468210953769,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 1,\n",
       "   'regressor:decision_tree:min_samples_split': 5,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'feature_preprocessor:pca:keep_variance': 0.9920672626107974,\n",
       "   'feature_preprocessor:pca:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'friedman_mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.02139922100435815,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 1,\n",
       "   'regressor:decision_tree:min_samples_split': 2,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0023235548876410802,\n",
       "   'feature_preprocessor:polynomial:degree': 3,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'True',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'False',\n",
       "   'regressor:extra_trees:bootstrap': 'False',\n",
       "   'regressor:extra_trees:criterion': 'mae',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.15652763524343039,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 19,\n",
       "   'regressor:extra_trees:min_samples_split': 17},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.9116613950593239,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.1645312649691532,\n",
       "   'feature_preprocessor:pca:keep_variance': 0.5066059333362967,\n",
       "   'feature_preprocessor:pca:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 1.1967935162168963,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 9,\n",
       "   'regressor:decision_tree:min_samples_split': 5,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.7373247930071872,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.2437946409898529,\n",
       "   'feature_preprocessor:pca:keep_variance': 0.5409948570046762,\n",
       "   'feature_preprocessor:pca:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'friedman_mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.7276388443565145,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 11,\n",
       "   'regressor:decision_tree:min_samples_split': 6,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.002111526563738924,\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'True',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 9,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 9,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 4,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 85,\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 30,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0017269038673268613,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'True',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'mse',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.5443367343174802,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 11,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 18,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:random_forest:bootstrap': 'False',\n",
       "   'regressor:random_forest:criterion': 'mae',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.9646874227232262,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 18,\n",
       "   'regressor:random_forest:min_samples_split': 20,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.010000000000000004,\n",
       "   'feature_preprocessor:pca:keep_variance': 0.5237836363360714,\n",
       "   'feature_preprocessor:pca:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.6557133851142325,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 2,\n",
       "   'regressor:decision_tree:min_samples_split': 13,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'feature_preprocessor:pca:keep_variance': 0.6427454497105527,\n",
       "   'feature_preprocessor:pca:whiten': 'False',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 50,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'distance'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.010000000000000004,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'cube',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'friedman_mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.037399698990877736,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 8,\n",
       "   'regressor:decision_tree:min_samples_split': 13,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 426},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.20162193319610308,\n",
       "   'regressor:random_forest:bootstrap': 'True',\n",
       "   'regressor:random_forest:criterion': 'mae',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.914066051948872,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 20,\n",
       "   'regressor:random_forest:min_samples_split': 13,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'feature_preprocessor:pca:keep_variance': 0.9237007124085592,\n",
       "   'feature_preprocessor:pca:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'friedman_mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.29982756202051747,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 1,\n",
       "   'regressor:decision_tree:min_samples_split': 6,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.018453090836748825,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.751975962159151,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.24965639353443583,\n",
       "   'feature_preprocessor:pca:keep_variance': 0.819640076082897,\n",
       "   'feature_preprocessor:pca:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'friedman_mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.027454521527994984,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 2,\n",
       "   'regressor:decision_tree:min_samples_split': 9,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 331,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'uniform',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'False',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'mse',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.1847488285508619,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 1,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 4,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 47,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'gaussian_process',\n",
       "   'regressor:gaussian_process:alpha': 0.12734348047783078,\n",
       "   'regressor:gaussian_process:thetaL': 1.081013913544105e-10,\n",
       "   'regressor:gaussian_process:thetaU': 193.69886592696662},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'gaussian_process',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 38,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'uniform',\n",
       "   'feature_preprocessor:pca:keep_variance': 0.8507096253304692,\n",
       "   'feature_preprocessor:pca:whiten': 'True',\n",
       "   'regressor:gaussian_process:alpha': 4.9710053396599514e-08,\n",
       "   'regressor:gaussian_process:thetaL': 1.1409525521407787e-08,\n",
       "   'regressor:gaussian_process:thetaU': 57178.93557628186},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0005805623196997207,\n",
       "   'feature_preprocessor:pca:keep_variance': 0.5973034972557906,\n",
       "   'feature_preprocessor:pca:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'friedman_mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 1.422393291470937,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 17,\n",
       "   'regressor:decision_tree:min_samples_split': 9,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'cube',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'False',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.005249280268851778,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 1,\n",
       "   'regressor:decision_tree:min_samples_split': 12,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.7465470445622455,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.24854954215089795,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'exp',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.4574093655738248,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 1,\n",
       "   'regressor:decision_tree:min_samples_split': 11,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 1186},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'False',\n",
       "   'regressor:extra_trees:bootstrap': 'True',\n",
       "   'regressor:extra_trees:criterion': 'mae',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.6720490364811186,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 11,\n",
       "   'regressor:extra_trees:min_samples_split': 3},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'False',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'mae',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.13806658412576014,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 16,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 15,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:random_forest:bootstrap': 'True',\n",
       "   'regressor:random_forest:criterion': 'mse',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.31689582672198,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 13,\n",
       "   'regressor:random_forest:min_samples_split': 13,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.014118098676106361,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'exp',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'mae',\n",
       "   'regressor:decision_tree:max_depth_factor': 7.748862070796649e-05,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 1,\n",
       "   'regressor:decision_tree:min_samples_split': 4,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 165},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'regressor:extra_trees:bootstrap': 'False',\n",
       "   'regressor:extra_trees:criterion': 'mse',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.2628259338576406,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 15,\n",
       "   'regressor:extra_trees:min_samples_split': 20},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0015064661654205429,\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'True',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 10,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 15,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 19,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 10,\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 1,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'distance'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'True',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'mse',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.812764966871452,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 19,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 4,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:decision_tree:criterion': 'mae',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.7353429112195173,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 18,\n",
       "   'regressor:decision_tree:min_samples_split': 17,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'True',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 9,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 16,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 6,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 94,\n",
       "   'regressor:extra_trees:bootstrap': 'True',\n",
       "   'regressor:extra_trees:criterion': 'mse',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.4618593987709718,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 2,\n",
       "   'regressor:extra_trees:min_samples_split': 4},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0001095336956261282,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'False',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'mae',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.725747531539935,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 6,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 3,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:random_forest:bootstrap': 'False',\n",
       "   'regressor:random_forest:criterion': 'friedman_mse',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.9510671099885932,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 1,\n",
       "   'regressor:random_forest:min_samples_split': 8,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.75,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.2897766074900805,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'exp',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:ridge_regression:alpha': 157.32011808375265,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 2.091563625361077e-06,\n",
       "   'feature_preprocessor:fast_ica:n_components': 294},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.01737714353009772,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.9611096604346405,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.01049469763009523,\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'False',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 5,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 20,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 16,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 54,\n",
       "   'regressor:extra_trees:bootstrap': 'True',\n",
       "   'regressor:extra_trees:criterion': 'mae',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.7565226210490769,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 19,\n",
       "   'regressor:extra_trees:min_samples_split': 8},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 505,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'normal',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'exp',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:extra_trees:bootstrap': 'False',\n",
       "   'regressor:extra_trees:criterion': 'friedman_mse',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.31887199191372007,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 17,\n",
       "   'regressor:extra_trees:min_samples_split': 10,\n",
       "   'feature_preprocessor:fast_ica:n_components': 430},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.014319520212407266,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.8140981978481444,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.2473540043970257,\n",
       "   'feature_preprocessor:polynomial:degree': 3,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'True',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'False',\n",
       "   'regressor:decision_tree:criterion': 'friedman_mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.0035358902415415974,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 1,\n",
       "   'regressor:decision_tree:min_samples_split': 15,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.010000000000000004,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.7621792193918887,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.28613478109886054,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:ridge_regression:alpha': 150.1304855228217,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 2.967291986690146e-07,\n",
       "   'feature_preprocessor:fast_ica:n_components': 1577},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.09763474303149837,\n",
       "   'regressor:extra_trees:bootstrap': 'True',\n",
       "   'regressor:extra_trees:criterion': 'mae',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.3296887254347585,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 13,\n",
       "   'regressor:extra_trees:min_samples_split': 15},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'False',\n",
       "   'regressor:ridge_regression:alpha': 9740.67845625319,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 9.363735456979302e-06},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'gaussian_process',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.00025091188672654775,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.8167931239567504,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.07458369646781687,\n",
       "   'regressor:gaussian_process:alpha': 6.294775572977233e-08,\n",
       "   'regressor:gaussian_process:thetaL': 6.927299035697042e-10,\n",
       "   'regressor:gaussian_process:thetaU': 34.59699030438471},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'feature_preprocessor:pca:keep_variance': 0.7729101352316644,\n",
       "   'feature_preprocessor:pca:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.005884909182365528,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 5,\n",
       "   'regressor:decision_tree:min_samples_split': 2,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.7445804780442575,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.27003406445695943,\n",
       "   'feature_preprocessor:pca:keep_variance': 0.8972890527743795,\n",
       "   'feature_preprocessor:pca:whiten': 'False',\n",
       "   'regressor:decision_tree:criterion': 'friedman_mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.019348843962803862,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 2,\n",
       "   'regressor:decision_tree:min_samples_split': 7,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.18570881887925805,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 1201,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'normal',\n",
       "   'regressor:decision_tree:criterion': 'friedman_mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 1.9564838142389314,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 15,\n",
       "   'regressor:decision_tree:min_samples_split': 6,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'gaussian_process',\n",
       "   'regressor:gaussian_process:alpha': 1.0580564862095533e-13,\n",
       "   'regressor:gaussian_process:thetaL': 2.3929890642424216e-05,\n",
       "   'regressor:gaussian_process:thetaU': 22143.577738676977},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.007894244932946999,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.75,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.25,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'cube',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'friedman_mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.014040162423953251,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 5,\n",
       "   'regressor:decision_tree:min_samples_split': 17,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 601},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.75,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.25,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.46395088971522636,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 1,\n",
       "   'regressor:decision_tree:min_samples_split': 14,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 82},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'feature_preprocessor:polynomial:degree': 3,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'False',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'False',\n",
       "   'regressor:ridge_regression:alpha': 305.1381442750077,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 7.427877469158044e-07},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'feature_agglomeration',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'feature_preprocessor:feature_agglomeration:affinity': 'euclidean',\n",
       "   'feature_preprocessor:feature_agglomeration:linkage': 'ward',\n",
       "   'feature_preprocessor:feature_agglomeration:n_clusters': 184,\n",
       "   'feature_preprocessor:feature_agglomeration:pooling_func': 'median',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 86,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.00023914386522372165,\n",
       "   'feature_preprocessor:polynomial:degree': 2,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'False',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'True',\n",
       "   'regressor:decision_tree:criterion': 'friedman_mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.3791136373976369,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 3,\n",
       "   'regressor:decision_tree:min_samples_split': 3,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.004146239349465869,\n",
       "   'feature_preprocessor:polynomial:degree': 3,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'False',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'False',\n",
       "   'regressor:decision_tree:criterion': 'friedman_mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.7207110017228755,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 11,\n",
       "   'regressor:decision_tree:min_samples_split': 6,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0002204795318982361,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'cube',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'False',\n",
       "   'regressor:decision_tree:criterion': 'mae',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.4214296701839799,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 3,\n",
       "   'regressor:decision_tree:min_samples_split': 19,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'kernel_pca',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'feature_preprocessor:kernel_pca:kernel': 'rbf',\n",
       "   'feature_preprocessor:kernel_pca:n_components': 1052,\n",
       "   'regressor:ridge_regression:alpha': 1165.9513013703906,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 5.088808495610496e-07,\n",
       "   'feature_preprocessor:kernel_pca:gamma': 1.3835004231842587},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'gaussian_process',\n",
       "   'feature_preprocessor:polynomial:degree': 2,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'True',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'True',\n",
       "   'regressor:gaussian_process:alpha': 8.65808954700274e-13,\n",
       "   'regressor:gaussian_process:thetaL': 0.00020717571376174408,\n",
       "   'regressor:gaussian_process:thetaU': 3.225224216786871},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.022652974628814743,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.731326699017324,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.26479942699761055,\n",
       "   'feature_preprocessor:pca:keep_variance': 0.9795213363675142,\n",
       "   'feature_preprocessor:pca:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'friedman_mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.25257535683272153,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 2,\n",
       "   'regressor:decision_tree:min_samples_split': 12,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.010000000000000004,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 1000,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'uniform',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'exp',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'mae',\n",
       "   'regressor:decision_tree:max_depth_factor': 7.748862070796649e-05,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 1,\n",
       "   'regressor:decision_tree:min_samples_split': 2,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 152},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.821474018162524,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.047018812538811676,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'exp',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'False',\n",
       "   'regressor:extra_trees:bootstrap': 'False',\n",
       "   'regressor:extra_trees:criterion': 'mse',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.5259288215139131,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 6,\n",
       "   'regressor:extra_trees:min_samples_split': 11},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.006496772904799362,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'friedman_mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.32050011710501625,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 6,\n",
       "   'regressor:decision_tree:min_samples_split': 13,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 33},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.03944114027417628,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'True',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'friedman_mse',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.9433735749271445,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 18,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 14,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:random_forest:bootstrap': 'False',\n",
       "   'regressor:random_forest:criterion': 'friedman_mse',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.9594058559087374,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 19,\n",
       "   'regressor:random_forest:min_samples_split': 3,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'feature_agglomeration',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'feature_preprocessor:feature_agglomeration:affinity': 'cosine',\n",
       "   'feature_preprocessor:feature_agglomeration:linkage': 'average',\n",
       "   'feature_preprocessor:feature_agglomeration:n_clusters': 175,\n",
       "   'feature_preprocessor:feature_agglomeration:pooling_func': 'median',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 1,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'cube',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 10,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'distance',\n",
       "   'feature_preprocessor:fast_ica:n_components': 1882},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'feature_preprocessor:pca:keep_variance': 0.7292517193044236,\n",
       "   'feature_preprocessor:pca:whiten': 'True',\n",
       "   'regressor:extra_trees:bootstrap': 'False',\n",
       "   'regressor:extra_trees:criterion': 'mae',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.12319837869797817,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 7,\n",
       "   'regressor:extra_trees:min_samples_split': 20},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.008186319173022184,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'cube',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'False',\n",
       "   'regressor:ridge_regression:alpha': 330.56577672783214,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 7.118162510607255e-06},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'feature_preprocessor:pca:keep_variance': 0.8399801618587792,\n",
       "   'feature_preprocessor:pca:whiten': 'False',\n",
       "   'regressor:decision_tree:criterion': 'mae',\n",
       "   'regressor:decision_tree:max_depth_factor': 1.3175512402113585,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 11,\n",
       "   'regressor:decision_tree:min_samples_split': 11,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 1850,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'normal',\n",
       "   'feature_preprocessor:pca:keep_variance': 0.5754442808601555,\n",
       "   'feature_preprocessor:pca:whiten': 'True',\n",
       "   'regressor:random_forest:bootstrap': 'False',\n",
       "   'regressor:random_forest:criterion': 'mae',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.8581038474114419,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 18,\n",
       "   'regressor:random_forest:min_samples_split': 6,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.7315552302558921,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.29478033882088384,\n",
       "   'feature_preprocessor:pca:keep_variance': 0.992258635139768,\n",
       "   'feature_preprocessor:pca:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.01142368324134076,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 4,\n",
       "   'regressor:decision_tree:min_samples_split': 4,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'gaussian_process',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.26540040582896884,\n",
       "   'feature_preprocessor:polynomial:degree': 2,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'True',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'False',\n",
       "   'regressor:gaussian_process:alpha': 2.8437483828518534e-13,\n",
       "   'regressor:gaussian_process:thetaL': 2.985788902868653e-05,\n",
       "   'regressor:gaussian_process:thetaU': 1570.9445352850141},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'gaussian_process',\n",
       "   'regressor:gaussian_process:alpha': 6.781483716984294e-05,\n",
       "   'regressor:gaussian_process:thetaL': 3.1842190709956113e-09,\n",
       "   'regressor:gaussian_process:thetaU': 19.240858065626785},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.12166657203197262,\n",
       "   'regressor:decision_tree:criterion': 'mae',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.7305809724585708,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 3,\n",
       "   'regressor:decision_tree:min_samples_split': 13,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 997,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'uniform',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'exp',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'mae',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.0034073893099065833,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 1,\n",
       "   'regressor:decision_tree:min_samples_split': 2,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 149},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.006255941853967279,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.75,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.25,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'exp',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'friedman_mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.2529952061544883,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 16,\n",
       "   'regressor:decision_tree:min_samples_split': 13,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 20},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'gaussian_process',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'True',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'friedman_mse',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.2595817289489165,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 15,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 20,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:gaussian_process:alpha': 4.0431185489547685e-10,\n",
       "   'regressor:gaussian_process:thetaL': 3.106443915166316e-09,\n",
       "   'regressor:gaussian_process:thetaU': 68756.15570489835},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'False',\n",
       "   'regressor:decision_tree:criterion': 'friedman_mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.6328946138672802,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 17,\n",
       "   'regressor:decision_tree:min_samples_split': 3,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'gaussian_process',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.2989334051027104,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 320,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'normal',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:gaussian_process:alpha': 2.8608376266177268e-11,\n",
       "   'regressor:gaussian_process:thetaL': 4.031362171158257e-10,\n",
       "   'regressor:gaussian_process:thetaU': 5839.141882563115,\n",
       "   'feature_preprocessor:fast_ica:n_components': 504},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.18400903141508013,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.892502672819558,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.24626870458181452,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'cube',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 42,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'distance',\n",
       "   'feature_preprocessor:fast_ica:n_components': 1327},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0066074476363156085,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'exp',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.4179990532844446,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 16,\n",
       "   'regressor:decision_tree:min_samples_split': 2,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 455},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'kitchen_sinks',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 59,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'uniform',\n",
       "   'feature_preprocessor:kitchen_sinks:gamma': 7.586154477090036e-05,\n",
       "   'feature_preprocessor:kitchen_sinks:n_components': 3840,\n",
       "   'regressor:ridge_regression:alpha': 3712.282268294319,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 4.57324082613091e-06},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.7093188758108241,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.2399530986534859,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'friedman_mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.028782404700354036,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 8,\n",
       "   'regressor:decision_tree:min_samples_split': 7,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 154},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'True',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'mse',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.6411780478927256,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 14,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 19,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:extra_trees:bootstrap': 'False',\n",
       "   'regressor:extra_trees:criterion': 'mse',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.836670130445374,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 19,\n",
       "   'regressor:extra_trees:min_samples_split': 4},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'feature_agglomeration',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'feature_preprocessor:feature_agglomeration:affinity': 'euclidean',\n",
       "   'feature_preprocessor:feature_agglomeration:linkage': 'complete',\n",
       "   'feature_preprocessor:feature_agglomeration:n_clusters': 197,\n",
       "   'feature_preprocessor:feature_agglomeration:pooling_func': 'median',\n",
       "   'regressor:random_forest:bootstrap': 'False',\n",
       "   'regressor:random_forest:criterion': 'friedman_mse',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.9282339290479904,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 9,\n",
       "   'regressor:random_forest:min_samples_split': 15,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'feature_preprocessor:polynomial:degree': 3,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'False',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'False',\n",
       "   'regressor:random_forest:bootstrap': 'False',\n",
       "   'regressor:random_forest:criterion': 'friedman_mse',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.8301447389645674,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 12,\n",
       "   'regressor:random_forest:min_samples_split': 12,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.009742722992167333,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'cube',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'friedman_mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.4450187449257414,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 6,\n",
       "   'regressor:decision_tree:min_samples_split': 9,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 276},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.014621998251212756,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.869712378458591,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.11468176248433018,\n",
       "   'feature_preprocessor:polynomial:degree': 3,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'True',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'False',\n",
       "   'regressor:ridge_regression:alpha': 5827.437277405556,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 1.7080863088396815e-07},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'feature_agglomeration',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'feature_preprocessor:feature_agglomeration:affinity': 'manhattan',\n",
       "   'feature_preprocessor:feature_agglomeration:linkage': 'average',\n",
       "   'feature_preprocessor:feature_agglomeration:n_clusters': 25,\n",
       "   'feature_preprocessor:feature_agglomeration:pooling_func': 'mean',\n",
       "   'regressor:ridge_regression:alpha': 7318.20209082838,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 3.199868314800029e-05},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.00986946307686489,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 1103,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'normal',\n",
       "   'regressor:decision_tree:criterion': 'mae',\n",
       "   'regressor:decision_tree:max_depth_factor': 1.3679798658769482,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 8,\n",
       "   'regressor:decision_tree:min_samples_split': 10,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.00020779167165397306,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'exp',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'False',\n",
       "   'regressor:extra_trees:bootstrap': 'True',\n",
       "   'regressor:extra_trees:criterion': 'mae',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.9841098774855442,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 17,\n",
       "   'regressor:extra_trees:min_samples_split': 9},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'feature_preprocessor:polynomial:degree': 2,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'True',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'True',\n",
       "   'regressor:random_forest:bootstrap': 'True',\n",
       "   'regressor:random_forest:criterion': 'mae',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.5536660668974681,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 6,\n",
       "   'regressor:random_forest:min_samples_split': 8,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.00725999714957756,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.7311214704748964,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.25,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.007133000997188478,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 2,\n",
       "   'regressor:decision_tree:min_samples_split': 3,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 116},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 19,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'distance',\n",
       "   'feature_preprocessor:fast_ica:n_components': 1512},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.008467994796513523,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.7039736664417388,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.1765324476855333,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'cube',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'friedman_mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.4140045451742804,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 16,\n",
       "   'regressor:decision_tree:min_samples_split': 9,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 704},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'False',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 3,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 7,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 14,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 57,\n",
       "   'regressor:extra_trees:bootstrap': 'False',\n",
       "   'regressor:extra_trees:criterion': 'mse',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.6748432802286871,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 10,\n",
       "   'regressor:extra_trees:min_samples_split': 18},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0002861831418601615,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.8979119156850172,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.23185285547398382,\n",
       "   'feature_preprocessor:polynomial:degree': 2,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'False',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'False',\n",
       "   'regressor:extra_trees:bootstrap': 'True',\n",
       "   'regressor:extra_trees:criterion': 'mse',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.23706222351874937,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 18,\n",
       "   'regressor:extra_trees:min_samples_split': 11},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.1515479423796738,\n",
       "   'feature_preprocessor:polynomial:degree': 3,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'False',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'True',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 1.9836872116851265,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 2,\n",
       "   'regressor:decision_tree:min_samples_split': 17,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'kernel_pca',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0014151252818318148,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 1485,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'uniform',\n",
       "   'feature_preprocessor:kernel_pca:kernel': 'cosine',\n",
       "   'feature_preprocessor:kernel_pca:n_components': 36,\n",
       "   'regressor:ridge_regression:alpha': 607.0042628061335,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 5.118607061329419e-06},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0006003193463352382,\n",
       "   'feature_preprocessor:pca:keep_variance': 0.6853536069693176,\n",
       "   'feature_preprocessor:pca:whiten': 'False',\n",
       "   'regressor:ridge_regression:alpha': 1381.0663693169138,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 6.0843277102022e-05},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'False',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 2,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 18,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 17,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 68,\n",
       "   'regressor:extra_trees:bootstrap': 'True',\n",
       "   'regressor:extra_trees:criterion': 'mse',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.531322442364711,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 13,\n",
       "   'regressor:extra_trees:min_samples_split': 9},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.20381603805722381,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.9287261986027422,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.13346334563697515,\n",
       "   'regressor:ridge_regression:alpha': 1330.6722058194077,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 1.785420079006316e-05},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.012104360763673319,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'friedman_mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.2760884242071161,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 6,\n",
       "   'regressor:decision_tree:min_samples_split': 13,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 68},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'False',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.015997809473524215,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 5,\n",
       "   'regressor:decision_tree:min_samples_split': 14,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.018712580313950948,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'cube',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.018012557016626365,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 7,\n",
       "   'regressor:decision_tree:min_samples_split': 18,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 116},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.017249412165815,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'True',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'mae',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.3486669429976798,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 15,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 14,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:random_forest:bootstrap': 'False',\n",
       "   'regressor:random_forest:criterion': 'mae',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.36446519422956236,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 3,\n",
       "   'regressor:random_forest:min_samples_split': 19,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'exp',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.2632267309034184,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 1,\n",
       "   'regressor:decision_tree:min_samples_split': 15,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 1275},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.7380005803120351,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.2359962405286948,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'friedman_mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.014040162423953251,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 6,\n",
       "   'regressor:decision_tree:min_samples_split': 13,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 597},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'feature_preprocessor:polynomial:degree': 2,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'False',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'True',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.4987560321776505,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 5,\n",
       "   'regressor:decision_tree:min_samples_split': 5,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.014892372593959171,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'friedman_mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.3162995232558996,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 6,\n",
       "   'regressor:decision_tree:min_samples_split': 17,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 82},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.7407866239121179,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.2744406794002996,\n",
       "   'feature_preprocessor:pca:keep_variance': 0.5935627274079174,\n",
       "   'feature_preprocessor:pca:whiten': 'True',\n",
       "   'regressor:random_forest:bootstrap': 'True',\n",
       "   'regressor:random_forest:criterion': 'mae',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.4340953724510477,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 6,\n",
       "   'regressor:random_forest:min_samples_split': 3,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.014716143126183596,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'cube',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.0970591056106228,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 1,\n",
       "   'regressor:decision_tree:min_samples_split': 15,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 160},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'cube',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'False',\n",
       "   'regressor:ridge_regression:alpha': 956.1732840701477,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 2.388373616615307e-07},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0018332432953504477,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'cube',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:extra_trees:bootstrap': 'True',\n",
       "   'regressor:extra_trees:criterion': 'mae',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.7610439838828551,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 13,\n",
       "   'regressor:extra_trees:min_samples_split': 16,\n",
       "   'feature_preprocessor:fast_ica:n_components': 382},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0018289178525884517,\n",
       "   'feature_preprocessor:pca:keep_variance': 0.6268980313884196,\n",
       "   'feature_preprocessor:pca:whiten': 'False',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 35,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'distance'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'friedman_mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.07564645200292093,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 1,\n",
       "   'regressor:decision_tree:min_samples_split': 14,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 145},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.8425443861561539,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.22167823181601834,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:extra_trees:bootstrap': 'True',\n",
       "   'regressor:extra_trees:criterion': 'mse',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.9970109299919133,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 14,\n",
       "   'regressor:extra_trees:min_samples_split': 8,\n",
       "   'feature_preprocessor:fast_ica:n_components': 165},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'feature_preprocessor:polynomial:degree': 2,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'True',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'True',\n",
       "   'regressor:ridge_regression:alpha': 5710.462398311651,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 6.16876525521695e-05},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.010000000000000004,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'friedman_mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.08030301019285221,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 3,\n",
       "   'regressor:decision_tree:min_samples_split': 12,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 26},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'gaussian_process',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.003660565738180404,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.7730454986918359,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.1572124109803112,\n",
       "   'regressor:gaussian_process:alpha': 1.0895010838435026e-05,\n",
       "   'regressor:gaussian_process:thetaL': 3.5147834643896604e-08,\n",
       "   'regressor:gaussian_process:thetaU': 18.87603586150951},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.012353485693373037,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.7395519899017703,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.21840286321120986,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'friedman_mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.00887780879253533,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 6,\n",
       "   'regressor:decision_tree:min_samples_split': 13,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 11},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.75,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.29318414921294567,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.27597760286275197,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 6,\n",
       "   'regressor:decision_tree:min_samples_split': 13,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 358},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.012335662371861572,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.7379072083384061,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.27652547690629203,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'exp',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'friedman_mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.1825173096667491,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 4,\n",
       "   'regressor:decision_tree:min_samples_split': 13,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 92},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.008464172832296692,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'friedman_mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.43009879865610634,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 6,\n",
       "   'regressor:decision_tree:min_samples_split': 13,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 239},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'friedman_mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.30815087435987,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 6,\n",
       "   'regressor:decision_tree:min_samples_split': 13,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 244},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 1941,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'normal',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 1.7271354123359663,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 3,\n",
       "   'regressor:decision_tree:min_samples_split': 2,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.013804434275468664,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.7484657809567563,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.19729830160438497,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.307778845149439,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 6,\n",
       "   'regressor:decision_tree:min_samples_split': 13,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 29},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.7190818190512768,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.25620704804486827,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'friedman_mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.014040162423953251,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 6,\n",
       "   'regressor:decision_tree:min_samples_split': 13,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 601},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0050519961811117285,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.740561525385529,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.26126709646645707,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'friedman_mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.014040162423953251,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 6,\n",
       "   'regressor:decision_tree:min_samples_split': 13,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 601},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.75,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.25,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.41381457275134625,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 2,\n",
       "   'regressor:decision_tree:min_samples_split': 13,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 260},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'exp',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'False',\n",
       "   'regressor:extra_trees:bootstrap': 'True',\n",
       "   'regressor:extra_trees:criterion': 'mse',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.6310497427146985,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 13,\n",
       "   'regressor:extra_trees:min_samples_split': 15},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.012969796256549726,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.7579859599648943,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.25,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.31865307212780547,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 6,\n",
       "   'regressor:decision_tree:min_samples_split': 13,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 121},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.8760082641689639,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.032885956332748094,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'mae',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.01799117766661107,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 7,\n",
       "   'regressor:decision_tree:min_samples_split': 13,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 272},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'feature_agglomeration',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'feature_preprocessor:feature_agglomeration:affinity': 'euclidean',\n",
       "   'feature_preprocessor:feature_agglomeration:linkage': 'complete',\n",
       "   'feature_preprocessor:feature_agglomeration:n_clusters': 341,\n",
       "   'feature_preprocessor:feature_agglomeration:pooling_func': 'mean',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 46,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'gaussian_process',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.000160824991752583,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 167,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'uniform',\n",
       "   'regressor:gaussian_process:alpha': 1.0936788459153977e-12,\n",
       "   'regressor:gaussian_process:thetaL': 1.8225943684116453e-06,\n",
       "   'regressor:gaussian_process:thetaU': 3080.632484630965},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.36291870319206165,\n",
       "   'feature_preprocessor:polynomial:degree': 2,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'False',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'False',\n",
       "   'regressor:extra_trees:bootstrap': 'True',\n",
       "   'regressor:extra_trees:criterion': 'mse',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.15567210832239217,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 8,\n",
       "   'regressor:extra_trees:min_samples_split': 14},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.4524623305805776,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 1730,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'uniform',\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'False',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 8,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 6,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 12,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 95,\n",
       "   'regressor:random_forest:bootstrap': 'True',\n",
       "   'regressor:random_forest:criterion': 'mse',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.6186405491692145,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 19,\n",
       "   'regressor:random_forest:min_samples_split': 4,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'kernel_pca',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.04762953879359764,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 1048,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'uniform',\n",
       "   'feature_preprocessor:kernel_pca:kernel': 'cosine',\n",
       "   'feature_preprocessor:kernel_pca:n_components': 719,\n",
       "   'regressor:ridge_regression:alpha': 258.41799203029416,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 3.5982345483844743e-06},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.7388961881420202,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.2764460714999304,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'cube',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'friedman_mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.014040162423953251,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 6,\n",
       "   'regressor:decision_tree:min_samples_split': 13,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 260},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.7334909115371182,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.2484969422715976,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'friedman_mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.31499046358670085,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 6,\n",
       "   'regressor:decision_tree:min_samples_split': 13,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 100},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'exp',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:random_forest:bootstrap': 'False',\n",
       "   'regressor:random_forest:criterion': 'mae',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.8618498460603599,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 13,\n",
       "   'regressor:random_forest:min_samples_split': 19,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 480},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.75,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.23950663874260725,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.0020002119843226043,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 11,\n",
       "   'regressor:decision_tree:min_samples_split': 13,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 1042},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'gaussian_process',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.03723592362818503,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 1339,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'uniform',\n",
       "   'feature_preprocessor:polynomial:degree': 2,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'True',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'True',\n",
       "   'regressor:gaussian_process:alpha': 5.925423626330127e-13,\n",
       "   'regressor:gaussian_process:thetaL': 8.921919879153112e-10,\n",
       "   'regressor:gaussian_process:thetaU': 2104.9498267686313},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.008785254763629619,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'friedman_mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.30668799167995037,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 3,\n",
       "   'regressor:decision_tree:min_samples_split': 13,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 209},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.010000000000000004,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'exp',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'False',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 1.4758182519665946,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 2,\n",
       "   'regressor:decision_tree:min_samples_split': 13,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.000558480922539938,\n",
       "   'regressor:random_forest:bootstrap': 'False',\n",
       "   'regressor:random_forest:criterion': 'mse',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.5849731523914219,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 11,\n",
       "   'regressor:random_forest:min_samples_split': 20,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.008633035343640879,\n",
       "   'feature_preprocessor:pca:keep_variance': 0.9086544545895956,\n",
       "   'feature_preprocessor:pca:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.3345987731749994,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 3,\n",
       "   'regressor:decision_tree:min_samples_split': 2,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.010000000000000004,\n",
       "   'feature_preprocessor:pca:keep_variance': 0.9361459358291975,\n",
       "   'feature_preprocessor:pca:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.3340505612505132,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 2,\n",
       "   'regressor:decision_tree:min_samples_split': 2,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.1279734392045744,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'friedman_mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.3184473509602603,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 2,\n",
       "   'regressor:decision_tree:min_samples_split': 13,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 224},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.014632852475471763,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'exp',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'False',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.6627386355878896,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 2,\n",
       "   'regressor:decision_tree:min_samples_split': 13,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'feature_preprocessor:pca:keep_variance': 0.9471909377193211,\n",
       "   'feature_preprocessor:pca:whiten': 'True',\n",
       "   'regressor:extra_trees:bootstrap': 'True',\n",
       "   'regressor:extra_trees:criterion': 'friedman_mse',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.2061258766417287,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 8,\n",
       "   'regressor:extra_trees:min_samples_split': 9},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0070568383297004225,\n",
       "   'feature_preprocessor:pca:keep_variance': 0.6235374507311401,\n",
       "   'feature_preprocessor:pca:whiten': 'False',\n",
       "   'regressor:ridge_regression:alpha': 1273.8833080615482,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 2.0527377843267733e-05},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.01659481449656538,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.75,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.25,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.22850511406170573,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 6,\n",
       "   'regressor:decision_tree:min_samples_split': 12,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 100},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.00025708838772162725,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.8864341844505392,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.2391332721876289,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'mae',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.3003949600354424,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 7,\n",
       "   'regressor:decision_tree:min_samples_split': 13,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 219},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.8221040153636954,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.022044477478186646,\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'True',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 7,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 4,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 11,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 76,\n",
       "   'regressor:random_forest:bootstrap': 'True',\n",
       "   'regressor:random_forest:criterion': 'mae',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.8321866912866144,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 13,\n",
       "   'regressor:random_forest:min_samples_split': 5,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.00013253081079516495,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.7111922913491919,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.007582344663434638,\n",
       "   'feature_preprocessor:polynomial:degree': 3,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'False',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'False',\n",
       "   'regressor:decision_tree:criterion': 'friedman_mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.703110590246357,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 13,\n",
       "   'regressor:decision_tree:min_samples_split': 4,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.00019961290750915517,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'True',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'mse',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.7748800784640781,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 11,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 13,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:ridge_regression:alpha': 8719.56001909118,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 2.597079295986103e-06},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.8840669730472948,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.039948200349970535,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'False',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'friedman_mse',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.6067067503003327,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 8,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 11,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:ridge_regression:alpha': 207.6131922927399,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 2.830806149114666e-05},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'gaussian_process',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.015212025186817317,\n",
       "   'regressor:gaussian_process:alpha': 6.40829809496359e-09,\n",
       "   'regressor:gaussian_process:thetaL': 0.00037976720056226806,\n",
       "   'regressor:gaussian_process:thetaU': 49643.43694075788},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'True',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'mae',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.25665517044170066,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 20,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 19,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:ridge_regression:alpha': 1719.0195100634694,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 1.0349749299742484e-07},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'False',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'mae',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.5228947842170147,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 12,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 10,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:extra_trees:bootstrap': 'True',\n",
       "   'regressor:extra_trees:criterion': 'mae',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.10052331584891495,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 20,\n",
       "   'regressor:extra_trees:min_samples_split': 16},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'True',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'mae',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.46028716628769417,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 14,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 4,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:ridge_regression:alpha': 578.2452860928365,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 1.4017850503912311e-05},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'kernel_pca',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0016259940077042803,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 1754,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'uniform',\n",
       "   'feature_preprocessor:kernel_pca:kernel': 'sigmoid',\n",
       "   'feature_preprocessor:kernel_pca:n_components': 1259,\n",
       "   'regressor:ridge_regression:alpha': 1045.5887108971615,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 7.429124269442793e-05,\n",
       "   'feature_preprocessor:kernel_pca:coef0': 0.538444404057747},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'feature_agglomeration',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'feature_preprocessor:feature_agglomeration:affinity': 'euclidean',\n",
       "   'feature_preprocessor:feature_agglomeration:linkage': 'ward',\n",
       "   'feature_preprocessor:feature_agglomeration:n_clusters': 65,\n",
       "   'feature_preprocessor:feature_agglomeration:pooling_func': 'median',\n",
       "   'regressor:ridge_regression:alpha': 2579.712142388589,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 2.335511570780284e-05},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.010000000000000004,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.7553632809503082,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.23703619761758793,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.4463955989512708,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 1,\n",
       "   'regressor:decision_tree:min_samples_split': 15,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 36},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.7360149811711411,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.2522095207581007,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:decision_tree:criterion': 'friedman_mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.014040162423953251,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 6,\n",
       "   'regressor:decision_tree:min_samples_split': 2,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 563},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.7238063532950466,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.2398225124446806,\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'False',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 6,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 18,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 17,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 66,\n",
       "   'regressor:random_forest:bootstrap': 'False',\n",
       "   'regressor:random_forest:criterion': 'mae',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.8948565276034188,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 2,\n",
       "   'regressor:random_forest:min_samples_split': 18,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'True',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'mse',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.39662322800426497,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 9,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 3,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 29,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'distance'}],\n",
       " 'rank_test_scores': array([  1, 475, 665, 340, 430, 445, 425, 423, 395,   1,   1, 475,   1,\n",
       "        343, 424,   1,   1, 444, 475, 366, 397,   1,   1, 641, 658,   1,\n",
       "          1, 383,   1,   1, 453, 401,   1, 466,   1,   1, 704,   1,   1,\n",
       "          1, 732,   1,   1, 408, 475,   1,   1, 475,   1, 653,   1,   1,\n",
       "          1, 715, 475, 440,   1, 730, 380,   1,   1,   1, 465,   1,   1,\n",
       "          1,   1,   1, 468, 665,   1,   1,   1, 412, 665,   1,   1, 475,\n",
       "          1,   1, 475,   1,   1,   1,   1, 381,   1,   1,   1, 382,   1,\n",
       "        390, 368, 461,   1,   1, 696, 373, 475,   1, 475,   1,   1, 475,\n",
       "          1,   1, 663,   1,   1,   1,   1, 698,   1, 391,   1, 475, 475,\n",
       "          1,   1,   1,   1, 731,   1,   1,   1,   1,   1,   1, 470,   1,\n",
       "        475,   1, 709,   1, 475,   1, 743,   1, 475,   1, 475, 475,   1,\n",
       "          1, 475, 475,   1,   1,   1,   1, 369, 475, 747,   1,   1,   1,\n",
       "          1,   1, 438,   1,   1,   1,   1,   1,   1,   1, 475, 475,   1,\n",
       "        385,   1,   1, 475,   1, 475,   1,   1, 447, 475, 475, 469, 452,\n",
       "          1,   1,   1, 715, 721,   1,   1, 639, 449,   1,   1, 641,   1,\n",
       "          1,   1,   1,   1,   1,   1,   1,   1, 415,   1, 475,   1,   1,\n",
       "          1,   1,   1, 472, 475,   1,   1, 409,   1, 462,   1, 359,   1,\n",
       "          1,   1, 475,   1,   1,   1,   1,   1,   1, 656,   1,   1,   1,\n",
       "          1,   1, 646, 474,   1, 418,   1,   1,   1, 446,   1,   1, 389,\n",
       "          1,   1, 475, 475,   1,   1,   1,   1,   1,   1,   1,   1, 393,\n",
       "        709,   1,   1,   1,   1,   1, 706, 475,   1, 434,   1,   1,   1,\n",
       "          1,   1, 654,   1,   1, 475, 706, 686, 714, 639, 475,   1,   1,\n",
       "          1,   1,   1,   1,   1,   1,   1, 475,   1,   1, 475,   1,   1,\n",
       "        362, 362, 475,   1, 471,   1, 475,   1, 746,   1, 407, 422,   1,\n",
       "        665,   1,   1,   1, 364, 643,   1, 687, 475, 715,   1, 475, 665,\n",
       "          1, 414, 742, 715,   1,   1,   1, 475,   1,   1, 359, 359, 650,\n",
       "        659,   1,   1, 475,   1,   1,   1,   1, 704, 475,   1,   1, 403,\n",
       "        475,   1, 450, 687, 740, 475,   1,   1, 475,   1,   1,   1,   1,\n",
       "        404,   1, 655,   1, 720, 645, 376,   1, 475,   1, 475, 475, 475,\n",
       "          1, 665, 410,   1, 475, 371,   1,   1,   1, 475,   1, 394, 475,\n",
       "          1,   1,   1, 386, 413, 691, 475,   1,   1,   1, 722,   1, 374,\n",
       "          1,   1,   1,   1, 751, 751,   1, 475, 372, 734, 651,   1, 475,\n",
       "        475, 475, 400, 475, 475, 475,   1, 475,   1, 384,   1, 475, 475,\n",
       "        475,   1, 404,   1, 646, 475, 475,   1, 646, 475, 475,   1,   1,\n",
       "        646,   1, 475, 475,   1, 463, 432,   1, 665, 664, 357, 421, 748,\n",
       "        370,   1, 460, 475, 475, 475,   1, 748, 699, 417, 475, 475, 643,\n",
       "        660, 475,   1,   1, 475, 437,   1,   1, 475, 475, 715, 475, 734,\n",
       "        388, 378,   1, 475, 375, 689, 475, 475, 475, 475, 665, 475, 711,\n",
       "        711, 475,   1, 692, 703, 475, 475, 475,   1, 439, 751,   1,   1,\n",
       "        448, 722, 391, 475,   1,   1,   1, 433, 467, 475, 475, 475, 751,\n",
       "        475, 475,   1, 475, 751,   1, 475, 475, 475, 751, 475, 436, 340,\n",
       "          1,   1,   1,   1,   1, 665, 692,   1, 665, 416, 402, 475, 475,\n",
       "          1, 475, 475, 475, 475, 748, 694, 683, 689, 346, 346, 751, 475,\n",
       "        475, 406, 451, 429, 751,   1, 475, 475, 475,   1, 475, 475, 665,\n",
       "        456,   1, 346, 475,   1, 346, 458, 475,   1, 475, 475, 724,   1,\n",
       "        346, 657, 475, 475, 475, 724, 411, 475, 346, 475, 346, 475, 357,\n",
       "        377,   1, 665, 475, 745, 734, 734,   1, 475, 475,   1,   1, 346,\n",
       "          1, 475,   1, 734, 346,   1, 475, 475, 475, 740, 751,   1,   1,\n",
       "        751,   1, 732, 665,   1,   1, 443,   1,   1, 475, 441,   1, 459,\n",
       "        475, 343, 346, 475, 475, 475, 475, 367,   1, 345, 475, 665, 464,\n",
       "        475, 724, 699,   1, 327,   1, 743, 364,   1, 387, 665,   1, 346,\n",
       "        475, 475, 340, 699, 475, 475, 475, 475,   1, 475, 473, 475,   1,\n",
       "          1,   1, 398, 396, 455, 665,   1,   1, 739,   1, 475,   1,   1,\n",
       "        475, 435, 428,   1, 427, 327, 475, 475,   1, 475, 327, 702, 475,\n",
       "          1, 475, 420,   1,   1, 475,   1, 454, 683, 475, 327, 327, 652,\n",
       "        327, 327, 708, 327, 327, 327, 697,   1, 327, 665,   1, 475,   1,\n",
       "          1, 419, 694, 327,   1, 475, 475, 683, 724,   1, 660, 660, 724,\n",
       "        724,   1, 426, 711, 665,   1, 475, 457, 379, 475, 431,   1, 399,\n",
       "          1, 442, 475, 327,   1,   1]),\n",
       " 'status': ['Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Crash'],\n",
       " 'budgets': [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " 'param_data_preprocessing:categorical_transformer:categorical_encoding:__choice__': masked_array(data=['one_hot_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding', 'no_encoding',\n",
       "                    'no_encoding', 'one_hot_encoding', 'no_encoding',\n",
       "                    'no_encoding', 'no_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'no_encoding', 'one_hot_encoding',\n",
       "                    'no_encoding', 'no_encoding', 'no_encoding',\n",
       "                    'no_encoding', 'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'no_encoding', 'no_encoding',\n",
       "                    'no_encoding', 'no_encoding', 'one_hot_encoding',\n",
       "                    'no_encoding', 'no_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'no_encoding', 'no_encoding',\n",
       "                    'no_encoding', 'one_hot_encoding', 'no_encoding',\n",
       "                    'no_encoding', 'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding', 'no_encoding',\n",
       "                    'no_encoding', 'no_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'no_encoding', 'no_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding', 'no_encoding',\n",
       "                    'one_hot_encoding', 'no_encoding', 'no_encoding',\n",
       "                    'no_encoding', 'no_encoding', 'one_hot_encoding',\n",
       "                    'no_encoding', 'no_encoding', 'no_encoding',\n",
       "                    'no_encoding', 'no_encoding', 'no_encoding',\n",
       "                    'no_encoding', 'no_encoding', 'no_encoding',\n",
       "                    'no_encoding', 'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'no_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding', 'no_encoding',\n",
       "                    'one_hot_encoding', 'no_encoding', 'no_encoding',\n",
       "                    'no_encoding', 'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'no_encoding', 'no_encoding', 'one_hot_encoding',\n",
       "                    'no_encoding', 'no_encoding', 'no_encoding',\n",
       "                    'no_encoding', 'no_encoding', 'no_encoding',\n",
       "                    'one_hot_encoding', 'no_encoding', 'one_hot_encoding',\n",
       "                    'no_encoding', 'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'no_encoding', 'no_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'no_encoding', 'no_encoding',\n",
       "                    'no_encoding', 'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'no_encoding', 'no_encoding',\n",
       "                    'no_encoding', 'no_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding', 'no_encoding',\n",
       "                    'no_encoding', 'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'no_encoding', 'no_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding', 'no_encoding',\n",
       "                    'no_encoding', 'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'no_encoding', 'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding', 'no_encoding',\n",
       "                    'no_encoding', 'no_encoding', 'one_hot_encoding',\n",
       "                    'no_encoding', 'one_hot_encoding', 'no_encoding',\n",
       "                    'no_encoding', 'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding', 'no_encoding',\n",
       "                    'no_encoding', 'no_encoding', 'no_encoding',\n",
       "                    'no_encoding', 'no_encoding', 'no_encoding',\n",
       "                    'no_encoding', 'no_encoding', 'no_encoding',\n",
       "                    'no_encoding', 'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'no_encoding', 'no_encoding', 'one_hot_encoding',\n",
       "                    'no_encoding', 'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding', 'no_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding', 'no_encoding',\n",
       "                    'one_hot_encoding', 'no_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'no_encoding', 'no_encoding',\n",
       "                    'one_hot_encoding', 'no_encoding', 'no_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding', 'no_encoding',\n",
       "                    'one_hot_encoding', 'no_encoding', 'no_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'no_encoding', 'no_encoding',\n",
       "                    'one_hot_encoding', 'no_encoding', 'no_encoding',\n",
       "                    'one_hot_encoding', 'no_encoding', 'no_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'no_encoding', 'no_encoding',\n",
       "                    'no_encoding', 'one_hot_encoding', 'no_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'no_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'no_encoding', 'one_hot_encoding',\n",
       "                    'no_encoding', 'one_hot_encoding', 'no_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding', 'no_encoding',\n",
       "                    'one_hot_encoding', 'no_encoding', 'no_encoding',\n",
       "                    'one_hot_encoding', 'no_encoding', 'one_hot_encoding',\n",
       "                    'no_encoding', 'one_hot_encoding', 'no_encoding',\n",
       "                    'no_encoding', 'no_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding', 'no_encoding',\n",
       "                    'no_encoding', 'one_hot_encoding', 'no_encoding',\n",
       "                    'one_hot_encoding', 'no_encoding', 'no_encoding',\n",
       "                    'one_hot_encoding', 'no_encoding', 'no_encoding',\n",
       "                    'no_encoding', 'no_encoding', 'no_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding', 'no_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding', 'no_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'no_encoding', 'one_hot_encoding',\n",
       "                    'no_encoding', 'one_hot_encoding', 'no_encoding',\n",
       "                    'no_encoding', 'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'no_encoding', 'no_encoding', 'no_encoding',\n",
       "                    'no_encoding', 'no_encoding', 'no_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding', 'no_encoding',\n",
       "                    'no_encoding', 'one_hot_encoding', 'no_encoding',\n",
       "                    'no_encoding', 'one_hot_encoding', 'no_encoding',\n",
       "                    'one_hot_encoding', 'no_encoding', 'no_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding', 'no_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'no_encoding', 'one_hot_encoding',\n",
       "                    'no_encoding', 'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'no_encoding', 'no_encoding', 'one_hot_encoding',\n",
       "                    'no_encoding', 'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'no_encoding', 'one_hot_encoding', 'no_encoding',\n",
       "                    'no_encoding', 'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'no_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding', 'no_encoding',\n",
       "                    'no_encoding', 'one_hot_encoding', 'no_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'no_encoding', 'no_encoding',\n",
       "                    'no_encoding', 'one_hot_encoding', 'no_encoding',\n",
       "                    'no_encoding', 'one_hot_encoding', 'no_encoding',\n",
       "                    'no_encoding', 'no_encoding', 'no_encoding',\n",
       "                    'one_hot_encoding', 'no_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'no_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding', 'no_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding', 'no_encoding',\n",
       "                    'one_hot_encoding', 'no_encoding', 'one_hot_encoding',\n",
       "                    'no_encoding', 'no_encoding', 'no_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding', 'no_encoding',\n",
       "                    'one_hot_encoding', 'no_encoding', 'no_encoding',\n",
       "                    'no_encoding', 'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'no_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'no_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding', 'no_encoding',\n",
       "                    'one_hot_encoding', 'no_encoding', 'no_encoding',\n",
       "                    'no_encoding', 'one_hot_encoding', 'no_encoding',\n",
       "                    'one_hot_encoding', 'no_encoding', 'no_encoding',\n",
       "                    'no_encoding', 'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'no_encoding', 'no_encoding',\n",
       "                    'one_hot_encoding', 'no_encoding', 'no_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'no_encoding', 'no_encoding',\n",
       "                    'no_encoding', 'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'no_encoding', 'no_encoding', 'one_hot_encoding',\n",
       "                    'no_encoding', 'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'no_encoding', 'one_hot_encoding', 'no_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'no_encoding', 'no_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding', 'no_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding', 'no_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'no_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding', 'no_encoding',\n",
       "                    'no_encoding', 'no_encoding', 'one_hot_encoding',\n",
       "                    'no_encoding', 'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'no_encoding', 'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding', 'no_encoding',\n",
       "                    'no_encoding', 'no_encoding', 'no_encoding',\n",
       "                    'one_hot_encoding', 'no_encoding', 'no_encoding',\n",
       "                    'no_encoding', 'one_hot_encoding', 'no_encoding',\n",
       "                    'one_hot_encoding', 'no_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding', 'no_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'no_encoding', 'no_encoding',\n",
       "                    'no_encoding', 'one_hot_encoding', 'no_encoding',\n",
       "                    'no_encoding', 'no_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'no_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'no_encoding', 'no_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding', 'no_encoding',\n",
       "                    'no_encoding', 'one_hot_encoding', 'no_encoding',\n",
       "                    'one_hot_encoding', 'no_encoding', 'no_encoding',\n",
       "                    'no_encoding', 'no_encoding', 'one_hot_encoding',\n",
       "                    'no_encoding', 'one_hot_encoding', 'no_encoding',\n",
       "                    'one_hot_encoding', 'no_encoding', 'one_hot_encoding',\n",
       "                    'no_encoding', 'no_encoding', 'one_hot_encoding',\n",
       "                    'no_encoding', 'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'no_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'no_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding', 'no_encoding',\n",
       "                    'no_encoding', 'one_hot_encoding', 'no_encoding',\n",
       "                    'no_encoding', 'one_hot_encoding', 'no_encoding',\n",
       "                    'no_encoding', 'no_encoding', 'no_encoding',\n",
       "                    'no_encoding', 'no_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding', 'no_encoding',\n",
       "                    'no_encoding', 'no_encoding', 'no_encoding',\n",
       "                    'no_encoding', 'no_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'no_encoding', 'no_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding', 'no_encoding',\n",
       "                    'one_hot_encoding', 'no_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding', 'no_encoding',\n",
       "                    'no_encoding', 'no_encoding', 'one_hot_encoding',\n",
       "                    'no_encoding', 'no_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding', 'no_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'no_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'no_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'no_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'no_encoding', 'one_hot_encoding',\n",
       "                    'no_encoding', 'one_hot_encoding', 'no_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding', 'no_encoding',\n",
       "                    'one_hot_encoding', 'no_encoding', 'no_encoding',\n",
       "                    'no_encoding', 'one_hot_encoding', 'no_encoding',\n",
       "                    'one_hot_encoding', 'no_encoding', 'one_hot_encoding',\n",
       "                    'no_encoding', 'one_hot_encoding', 'no_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding', 'no_encoding',\n",
       "                    'one_hot_encoding', 'no_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding', 'no_encoding',\n",
       "                    'no_encoding', 'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'no_encoding', 'one_hot_encoding', 'no_encoding',\n",
       "                    'no_encoding', 'no_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding', 'no_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding', 'no_encoding',\n",
       "                    'one_hot_encoding', 'no_encoding', 'one_hot_encoding',\n",
       "                    'no_encoding', 'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'no_encoding', 'no_encoding', 'one_hot_encoding',\n",
       "                    'no_encoding', 'no_encoding', 'no_encoding',\n",
       "                    'no_encoding', 'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'no_encoding', 'one_hot_encoding',\n",
       "                    'no_encoding', 'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'no_encoding', 'no_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'no_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'no_encoding', 'no_encoding',\n",
       "                    'one_hot_encoding', 'no_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'no_encoding', 'no_encoding',\n",
       "                    'no_encoding', 'one_hot_encoding', 'no_encoding',\n",
       "                    'one_hot_encoding', 'no_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'no_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding', 'no_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding', 'no_encoding',\n",
       "                    'no_encoding', 'no_encoding', 'no_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'no_encoding', 'one_hot_encoding',\n",
       "                    'no_encoding', 'no_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'no_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding', 'no_encoding'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U16'),\n",
       " 'param_data_preprocessing:categorical_transformer:category_coalescence:__choice__': masked_array(data=['minority_coalescer', 'no_coalescense',\n",
       "                    'no_coalescense', 'no_coalescense', 'no_coalescense',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'no_coalescense', 'no_coalescense',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'no_coalescense', 'no_coalescense',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'no_coalescense', 'no_coalescense',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'no_coalescense', 'no_coalescense', 'no_coalescense',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'no_coalescense', 'no_coalescense', 'no_coalescense',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'no_coalescense', 'no_coalescense', 'no_coalescense',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'no_coalescense', 'no_coalescense', 'no_coalescense',\n",
       "                    'no_coalescense', 'no_coalescense', 'no_coalescense',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'no_coalescense', 'no_coalescense',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'no_coalescense', 'no_coalescense', 'no_coalescense',\n",
       "                    'no_coalescense', 'no_coalescense',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'no_coalescense', 'no_coalescense', 'no_coalescense',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'no_coalescense', 'no_coalescense', 'no_coalescense',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'no_coalescense', 'no_coalescense', 'no_coalescense',\n",
       "                    'no_coalescense', 'no_coalescense',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'no_coalescense', 'no_coalescense', 'no_coalescense',\n",
       "                    'no_coalescense', 'no_coalescense', 'no_coalescense',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'no_coalescense', 'no_coalescense',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'no_coalescense', 'no_coalescense', 'no_coalescense',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'no_coalescense', 'no_coalescense', 'no_coalescense',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'no_coalescense', 'no_coalescense',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'no_coalescense', 'no_coalescense',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'no_coalescense', 'no_coalescense', 'no_coalescense',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'no_coalescense', 'no_coalescense',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'no_coalescense', 'no_coalescense',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'no_coalescense', 'no_coalescense', 'no_coalescense',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'no_coalescense', 'no_coalescense',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'no_coalescense', 'no_coalescense', 'no_coalescense',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'no_coalescense', 'no_coalescense', 'no_coalescense',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'no_coalescense', 'no_coalescense',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'no_coalescense', 'no_coalescense', 'no_coalescense',\n",
       "                    'no_coalescense', 'no_coalescense',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'no_coalescense', 'no_coalescense',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'no_coalescense', 'no_coalescense', 'no_coalescense',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'no_coalescense', 'no_coalescense', 'no_coalescense',\n",
       "                    'no_coalescense', 'no_coalescense', 'no_coalescense',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'no_coalescense', 'no_coalescense', 'no_coalescense',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'no_coalescense', 'no_coalescense',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'no_coalescense', 'no_coalescense',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'no_coalescense', 'no_coalescense',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'no_coalescense', 'no_coalescense',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'no_coalescense', 'no_coalescense', 'no_coalescense',\n",
       "                    'no_coalescense', 'no_coalescense', 'no_coalescense',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'no_coalescense', 'no_coalescense',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'no_coalescense', 'no_coalescense',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'no_coalescense', 'no_coalescense',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'no_coalescense', 'no_coalescense',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'no_coalescense', 'no_coalescense',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'no_coalescense', 'no_coalescense', 'no_coalescense',\n",
       "                    'no_coalescense', 'no_coalescense', 'no_coalescense',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'no_coalescense', 'no_coalescense', 'no_coalescense',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'no_coalescense', 'no_coalescense', 'no_coalescense',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'no_coalescense', 'no_coalescense',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'no_coalescense', 'no_coalescense', 'no_coalescense',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'no_coalescense', 'no_coalescense',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'no_coalescense', 'no_coalescense', 'no_coalescense',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'no_coalescense', 'no_coalescense',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'no_coalescense', 'no_coalescense', 'no_coalescense',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'no_coalescense', 'no_coalescense',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'no_coalescense', 'no_coalescense',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'no_coalescense', 'no_coalescense',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'no_coalescense', 'no_coalescense',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'no_coalescense', 'no_coalescense', 'no_coalescense',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'no_coalescense', 'no_coalescense', 'no_coalescense',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'no_coalescense', 'no_coalescense',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'no_coalescense', 'no_coalescense',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'no_coalescense', 'no_coalescense', 'no_coalescense',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'no_coalescense', 'no_coalescense',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'no_coalescense', 'no_coalescense', 'no_coalescense',\n",
       "                    'no_coalescense', 'no_coalescense',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'no_coalescense', 'no_coalescense', 'no_coalescense',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'no_coalescense', 'no_coalescense', 'no_coalescense',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'no_coalescense', 'no_coalescense',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'no_coalescense', 'no_coalescense',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'no_coalescense', 'no_coalescense', 'no_coalescense',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'no_coalescense', 'no_coalescense', 'no_coalescense',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'no_coalescense', 'no_coalescense'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U18'),\n",
       " 'param_data_preprocessing:numerical_transformer:imputation:strategy': masked_array(data=['mean', 'most_frequent', 'most_frequent', 'mean',\n",
       "                    'most_frequent', 'mean', 'most_frequent',\n",
       "                    'most_frequent', 'median', 'most_frequent', 'median',\n",
       "                    'mean', 'mean', 'most_frequent', 'most_frequent',\n",
       "                    'most_frequent', 'most_frequent', 'most_frequent',\n",
       "                    'mean', 'most_frequent', 'mean', 'most_frequent',\n",
       "                    'mean', 'mean', 'mean', 'median', 'most_frequent',\n",
       "                    'median', 'median', 'most_frequent', 'median', 'mean',\n",
       "                    'median', 'median', 'median', 'most_frequent', 'mean',\n",
       "                    'mean', 'median', 'median', 'most_frequent',\n",
       "                    'most_frequent', 'most_frequent', 'median', 'median',\n",
       "                    'most_frequent', 'mean', 'median', 'most_frequent',\n",
       "                    'most_frequent', 'mean', 'mean', 'median',\n",
       "                    'most_frequent', 'mean', 'most_frequent',\n",
       "                    'most_frequent', 'mean', 'most_frequent', 'median',\n",
       "                    'most_frequent', 'median', 'median', 'median',\n",
       "                    'most_frequent', 'median', 'median', 'mean',\n",
       "                    'most_frequent', 'mean', 'median', 'most_frequent',\n",
       "                    'median', 'mean', 'mean', 'median', 'median', 'median',\n",
       "                    'most_frequent', 'most_frequent', 'mean', 'mean',\n",
       "                    'mean', 'median', 'mean', 'mean', 'median', 'median',\n",
       "                    'most_frequent', 'median', 'median', 'median',\n",
       "                    'median', 'median', 'most_frequent', 'most_frequent',\n",
       "                    'most_frequent', 'median', 'median', 'mean', 'median',\n",
       "                    'mean', 'median', 'median', 'most_frequent', 'median',\n",
       "                    'mean', 'mean', 'median', 'median', 'median',\n",
       "                    'most_frequent', 'median', 'mean', 'median', 'median',\n",
       "                    'mean', 'mean', 'median', 'most_frequent',\n",
       "                    'most_frequent', 'mean', 'most_frequent', 'median',\n",
       "                    'median', 'mean', 'most_frequent', 'median', 'mean',\n",
       "                    'mean', 'median', 'mean', 'most_frequent', 'mean',\n",
       "                    'median', 'median', 'median', 'most_frequent',\n",
       "                    'median', 'median', 'mean', 'most_frequent', 'median',\n",
       "                    'median', 'median', 'median', 'median', 'mean', 'mean',\n",
       "                    'most_frequent', 'median', 'most_frequent', 'mean',\n",
       "                    'mean', 'median', 'median', 'mean', 'median', 'mean',\n",
       "                    'most_frequent', 'mean', 'median', 'median', 'median',\n",
       "                    'mean', 'mean', 'median', 'median', 'mean', 'mean',\n",
       "                    'median', 'mean', 'most_frequent', 'median', 'mean',\n",
       "                    'mean', 'median', 'most_frequent', 'mean', 'median',\n",
       "                    'median', 'most_frequent', 'mean', 'most_frequent',\n",
       "                    'median', 'mean', 'mean', 'most_frequent', 'median',\n",
       "                    'median', 'mean', 'most_frequent', 'most_frequent',\n",
       "                    'most_frequent', 'most_frequent', 'median',\n",
       "                    'most_frequent', 'most_frequent', 'mean', 'median',\n",
       "                    'median', 'median', 'median', 'mean', 'most_frequent',\n",
       "                    'most_frequent', 'most_frequent', 'median', 'mean',\n",
       "                    'mean', 'median', 'mean', 'mean', 'median', 'median',\n",
       "                    'mean', 'most_frequent', 'most_frequent', 'mean',\n",
       "                    'median', 'most_frequent', 'median', 'mean', 'median',\n",
       "                    'median', 'most_frequent', 'most_frequent', 'mean',\n",
       "                    'mean', 'median', 'most_frequent', 'most_frequent',\n",
       "                    'most_frequent', 'mean', 'median', 'mean',\n",
       "                    'most_frequent', 'most_frequent', 'median', 'mean',\n",
       "                    'median', 'most_frequent', 'mean', 'mean', 'median',\n",
       "                    'median', 'mean', 'most_frequent', 'most_frequent',\n",
       "                    'most_frequent', 'most_frequent', 'mean', 'median',\n",
       "                    'median', 'mean', 'most_frequent', 'median',\n",
       "                    'most_frequent', 'most_frequent', 'mean', 'mean',\n",
       "                    'most_frequent', 'median', 'most_frequent',\n",
       "                    'most_frequent', 'most_frequent', 'median', 'median',\n",
       "                    'most_frequent', 'most_frequent', 'median',\n",
       "                    'most_frequent', 'most_frequent', 'most_frequent',\n",
       "                    'median', 'most_frequent', 'median', 'most_frequent',\n",
       "                    'median', 'most_frequent', 'median', 'mean', 'median',\n",
       "                    'most_frequent', 'mean', 'mean', 'most_frequent',\n",
       "                    'mean', 'most_frequent', 'most_frequent', 'mean',\n",
       "                    'mean', 'mean', 'mean', 'most_frequent', 'median',\n",
       "                    'median', 'most_frequent', 'mean', 'median', 'median',\n",
       "                    'median', 'median', 'mean', 'mean', 'median', 'mean',\n",
       "                    'most_frequent', 'mean', 'median', 'most_frequent',\n",
       "                    'median', 'mean', 'median', 'median', 'mean', 'mean',\n",
       "                    'median', 'most_frequent', 'mean', 'median',\n",
       "                    'most_frequent', 'most_frequent', 'median', 'mean',\n",
       "                    'median', 'most_frequent', 'median', 'most_frequent',\n",
       "                    'median', 'median', 'most_frequent', 'most_frequent',\n",
       "                    'most_frequent', 'most_frequent', 'median', 'mean',\n",
       "                    'median', 'median', 'most_frequent', 'most_frequent',\n",
       "                    'most_frequent', 'mean', 'most_frequent', 'mean',\n",
       "                    'mean', 'mean', 'mean', 'mean', 'most_frequent',\n",
       "                    'mean', 'median', 'median', 'median', 'most_frequent',\n",
       "                    'most_frequent', 'mean', 'most_frequent', 'mean',\n",
       "                    'mean', 'mean', 'most_frequent', 'median',\n",
       "                    'most_frequent', 'mean', 'mean', 'most_frequent',\n",
       "                    'most_frequent', 'median', 'mean', 'mean',\n",
       "                    'most_frequent', 'mean', 'mean', 'most_frequent',\n",
       "                    'most_frequent', 'most_frequent', 'most_frequent',\n",
       "                    'most_frequent', 'median', 'mean', 'median',\n",
       "                    'most_frequent', 'most_frequent', 'mean',\n",
       "                    'most_frequent', 'mean', 'most_frequent',\n",
       "                    'most_frequent', 'most_frequent', 'mean', 'median',\n",
       "                    'median', 'median', 'most_frequent', 'mean', 'mean',\n",
       "                    'median', 'median', 'mean', 'mean', 'most_frequent',\n",
       "                    'mean', 'median', 'median', 'most_frequent',\n",
       "                    'most_frequent', 'most_frequent', 'median', 'median',\n",
       "                    'most_frequent', 'mean', 'most_frequent', 'median',\n",
       "                    'most_frequent', 'most_frequent', 'most_frequent',\n",
       "                    'mean', 'median', 'mean', 'median', 'most_frequent',\n",
       "                    'most_frequent', 'mean', 'median', 'most_frequent',\n",
       "                    'mean', 'mean', 'most_frequent', 'most_frequent',\n",
       "                    'most_frequent', 'median', 'mean', 'most_frequent',\n",
       "                    'most_frequent', 'median', 'mean', 'median',\n",
       "                    'most_frequent', 'mean', 'most_frequent', 'mean',\n",
       "                    'most_frequent', 'mean', 'median', 'mean', 'median',\n",
       "                    'median', 'most_frequent', 'mean', 'mean', 'mean',\n",
       "                    'most_frequent', 'mean', 'median', 'mean', 'mean',\n",
       "                    'median', 'most_frequent', 'median', 'median',\n",
       "                    'median', 'median', 'mean', 'mean', 'median',\n",
       "                    'most_frequent', 'most_frequent', 'most_frequent',\n",
       "                    'most_frequent', 'mean', 'mean', 'mean', 'median',\n",
       "                    'median', 'most_frequent', 'mean', 'most_frequent',\n",
       "                    'median', 'mean', 'mean', 'median', 'mean', 'median',\n",
       "                    'most_frequent', 'most_frequent', 'most_frequent',\n",
       "                    'most_frequent', 'mean', 'most_frequent',\n",
       "                    'most_frequent', 'mean', 'median', 'most_frequent',\n",
       "                    'mean', 'median', 'most_frequent', 'mean',\n",
       "                    'most_frequent', 'mean', 'mean', 'mean', 'median',\n",
       "                    'median', 'most_frequent', 'mean', 'median',\n",
       "                    'most_frequent', 'most_frequent', 'median',\n",
       "                    'most_frequent', 'mean', 'median', 'median', 'median',\n",
       "                    'median', 'median', 'most_frequent', 'mean',\n",
       "                    'most_frequent', 'mean', 'most_frequent', 'mean',\n",
       "                    'most_frequent', 'most_frequent', 'most_frequent',\n",
       "                    'most_frequent', 'most_frequent', 'most_frequent',\n",
       "                    'most_frequent', 'most_frequent', 'median', 'mean',\n",
       "                    'most_frequent', 'mean', 'mean', 'mean', 'mean',\n",
       "                    'most_frequent', 'most_frequent', 'median',\n",
       "                    'most_frequent', 'median', 'most_frequent',\n",
       "                    'most_frequent', 'median', 'most_frequent',\n",
       "                    'most_frequent', 'most_frequent', 'most_frequent',\n",
       "                    'mean', 'most_frequent', 'most_frequent', 'mean',\n",
       "                    'mean', 'median', 'most_frequent', 'mean', 'median',\n",
       "                    'most_frequent', 'most_frequent', 'mean', 'mean',\n",
       "                    'most_frequent', 'mean', 'most_frequent', 'median',\n",
       "                    'median', 'most_frequent', 'median', 'most_frequent',\n",
       "                    'most_frequent', 'most_frequent', 'mean', 'mean',\n",
       "                    'median', 'mean', 'mean', 'median', 'most_frequent',\n",
       "                    'mean', 'mean', 'median', 'median', 'median', 'mean',\n",
       "                    'most_frequent', 'median', 'most_frequent', 'median',\n",
       "                    'most_frequent', 'mean', 'mean', 'mean', 'median',\n",
       "                    'mean', 'mean', 'mean', 'most_frequent',\n",
       "                    'most_frequent', 'median', 'most_frequent',\n",
       "                    'most_frequent', 'mean', 'median', 'most_frequent',\n",
       "                    'most_frequent', 'median', 'median', 'most_frequent',\n",
       "                    'mean', 'most_frequent', 'median', 'most_frequent',\n",
       "                    'mean', 'mean', 'mean', 'mean', 'median',\n",
       "                    'most_frequent', 'median', 'median', 'mean',\n",
       "                    'most_frequent', 'most_frequent', 'most_frequent',\n",
       "                    'median', 'most_frequent', 'median', 'median', 'mean',\n",
       "                    'most_frequent', 'most_frequent', 'most_frequent',\n",
       "                    'mean', 'most_frequent', 'most_frequent',\n",
       "                    'most_frequent', 'mean', 'mean', 'median', 'mean',\n",
       "                    'most_frequent', 'most_frequent', 'mean', 'mean',\n",
       "                    'median', 'mean', 'median', 'most_frequent', 'median',\n",
       "                    'most_frequent', 'most_frequent', 'most_frequent',\n",
       "                    'median', 'median', 'mean', 'median', 'mean', 'median',\n",
       "                    'mean', 'median', 'mean', 'mean', 'mean', 'mean',\n",
       "                    'most_frequent', 'median', 'median', 'most_frequent',\n",
       "                    'most_frequent', 'most_frequent', 'median',\n",
       "                    'most_frequent', 'median', 'median', 'median',\n",
       "                    'median', 'median', 'mean', 'mean', 'median',\n",
       "                    'most_frequent', 'mean', 'median', 'most_frequent',\n",
       "                    'mean', 'median', 'mean', 'mean', 'mean', 'mean',\n",
       "                    'median', 'mean', 'median', 'most_frequent', 'mean',\n",
       "                    'most_frequent', 'mean', 'most_frequent',\n",
       "                    'most_frequent', 'most_frequent', 'most_frequent',\n",
       "                    'mean', 'mean', 'most_frequent', 'mean', 'mean',\n",
       "                    'mean', 'mean', 'median', 'most_frequent', 'median',\n",
       "                    'most_frequent', 'median', 'mean', 'mean', 'median',\n",
       "                    'median', 'mean', 'median', 'most_frequent',\n",
       "                    'most_frequent', 'median', 'median', 'most_frequent',\n",
       "                    'most_frequent', 'median', 'most_frequent', 'mean',\n",
       "                    'mean', 'median', 'median', 'mean', 'mean', 'median',\n",
       "                    'mean', 'most_frequent', 'mean', 'mean', 'median',\n",
       "                    'mean', 'most_frequent', 'mean', 'median', 'mean',\n",
       "                    'mean', 'most_frequent', 'mean', 'median', 'median',\n",
       "                    'mean', 'mean', 'median', 'most_frequent', 'median',\n",
       "                    'median', 'median', 'median', 'most_frequent'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U13'),\n",
       " 'param_data_preprocessing:numerical_transformer:rescaling:__choice__': masked_array(data=['standardize', 'minmax', 'normalize',\n",
       "                    'quantile_transformer', 'robust_scaler', 'standardize',\n",
       "                    'robust_scaler', 'standardize', 'standardize',\n",
       "                    'quantile_transformer', 'robust_scaler', 'normalize',\n",
       "                    'none', 'minmax', 'robust_scaler', 'robust_scaler',\n",
       "                    'none', 'normalize', 'robust_scaler',\n",
       "                    'quantile_transformer', 'standardize', 'standardize',\n",
       "                    'robust_scaler', 'none', 'standardize', 'normalize',\n",
       "                    'minmax', 'none', 'robust_scaler', 'robust_scaler',\n",
       "                    'robust_scaler', 'normalize', 'robust_scaler',\n",
       "                    'minmax', 'none', 'none', 'standardize', 'minmax',\n",
       "                    'standardize', 'normalize', 'robust_scaler',\n",
       "                    'quantile_transformer', 'quantile_transformer',\n",
       "                    'robust_scaler', 'normalize', 'standardize', 'minmax',\n",
       "                    'normalize', 'minmax', 'robust_scaler', 'normalize',\n",
       "                    'normalize', 'standardize', 'standardize',\n",
       "                    'standardize', 'minmax', 'standardize', 'minmax',\n",
       "                    'normalize', 'normalize', 'none', 'normalize',\n",
       "                    'minmax', 'minmax', 'normalize', 'robust_scaler',\n",
       "                    'quantile_transformer', 'robust_scaler', 'minmax',\n",
       "                    'standardize', 'standardize', 'robust_scaler',\n",
       "                    'normalize', 'none', 'minmax', 'normalize', 'minmax',\n",
       "                    'quantile_transformer', 'none', 'robust_scaler',\n",
       "                    'quantile_transformer', 'robust_scaler',\n",
       "                    'robust_scaler', 'quantile_transformer',\n",
       "                    'quantile_transformer', 'robust_scaler',\n",
       "                    'robust_scaler', 'robust_scaler', 'robust_scaler',\n",
       "                    'none', 'robust_scaler', 'normalize', 'robust_scaler',\n",
       "                    'standardize', 'normalize', 'none', 'standardize',\n",
       "                    'minmax', 'none', 'robust_scaler', 'none',\n",
       "                    'robust_scaler', 'robust_scaler', 'minmax',\n",
       "                    'normalize', 'none', 'minmax', 'quantile_transformer',\n",
       "                    'minmax', 'normalize', 'standardize', 'robust_scaler',\n",
       "                    'robust_scaler', 'quantile_transformer',\n",
       "                    'robust_scaler', 'none', 'standardize',\n",
       "                    'quantile_transformer', 'none', 'normalize', 'minmax',\n",
       "                    'robust_scaler', 'standardize', 'standardize',\n",
       "                    'minmax', 'none', 'minmax', 'robust_scaler', 'minmax',\n",
       "                    'standardize', 'none', 'minmax', 'normalize',\n",
       "                    'normalize', 'quantile_transformer', 'robust_scaler',\n",
       "                    'standardize', 'standardize', 'minmax', 'standardize',\n",
       "                    'quantile_transformer', 'standardize', 'standardize',\n",
       "                    'normalize', 'none', 'robust_scaler', 'robust_scaler',\n",
       "                    'standardize', 'robust_scaler', 'none', 'normalize',\n",
       "                    'standardize', 'none', 'standardize', 'standardize',\n",
       "                    'robust_scaler', 'robust_scaler', 'robust_scaler',\n",
       "                    'none', 'none', 'quantile_transformer', 'standardize',\n",
       "                    'standardize', 'minmax', 'robust_scaler', 'minmax',\n",
       "                    'normalize', 'normalize', 'standardize',\n",
       "                    'robust_scaler', 'robust_scaler', 'normalize', 'none',\n",
       "                    'robust_scaler', 'quantile_transformer', 'normalize',\n",
       "                    'standardize', 'robust_scaler', 'normalize',\n",
       "                    'normalize', 'quantile_transformer', 'minmax',\n",
       "                    'robust_scaler', 'robust_scaler', 'none', 'normalize',\n",
       "                    'minmax', 'none', 'robust_scaler', 'standardize',\n",
       "                    'robust_scaler', 'none', 'robust_scaler', 'none',\n",
       "                    'none', 'normalize', 'quantile_transformer',\n",
       "                    'standardize', 'normalize', 'normalize', 'minmax',\n",
       "                    'minmax', 'robust_scaler', 'normalize', 'none',\n",
       "                    'robust_scaler', 'none', 'normalize', 'minmax',\n",
       "                    'standardize', 'none', 'minmax', 'robust_scaler',\n",
       "                    'minmax', 'minmax', 'robust_scaler', 'none',\n",
       "                    'normalize', 'quantile_transformer', 'none',\n",
       "                    'robust_scaler', 'none', 'normalize', 'normalize',\n",
       "                    'robust_scaler', 'robust_scaler',\n",
       "                    'quantile_transformer', 'none', 'standardize',\n",
       "                    'standardize', 'normalize', 'minmax', 'robust_scaler',\n",
       "                    'none', 'minmax', 'none', 'quantile_transformer',\n",
       "                    'normalize', 'normalize', 'none', 'none', 'none',\n",
       "                    'standardize', 'standardize', 'quantile_transformer',\n",
       "                    'none', 'none', 'robust_scaler', 'robust_scaler',\n",
       "                    'quantile_transformer', 'robust_scaler', 'standardize',\n",
       "                    'robust_scaler', 'normalize', 'none', 'robust_scaler',\n",
       "                    'standardize', 'robust_scaler', 'minmax', 'normalize',\n",
       "                    'standardize', 'robust_scaler', 'robust_scaler',\n",
       "                    'robust_scaler', 'quantile_transformer', 'standardize',\n",
       "                    'minmax', 'minmax', 'quantile_transformer', 'none',\n",
       "                    'minmax', 'none', 'robust_scaler', 'none',\n",
       "                    'standardize', 'quantile_transformer',\n",
       "                    'quantile_transformer', 'minmax', 'standardize',\n",
       "                    'normalize', 'quantile_transformer',\n",
       "                    'quantile_transformer', 'minmax', 'normalize',\n",
       "                    'robust_scaler', 'minmax', 'minmax', 'none',\n",
       "                    'quantile_transformer', 'none', 'standardize', 'none',\n",
       "                    'minmax', 'standardize', 'normalize', 'none',\n",
       "                    'standardize', 'none', 'robust_scaler', 'none', 'none',\n",
       "                    'none', 'quantile_transformer', 'quantile_transformer',\n",
       "                    'robust_scaler', 'none', 'none', 'none', 'minmax',\n",
       "                    'none', 'minmax', 'normalize', 'robust_scaler', 'none',\n",
       "                    'standardize', 'robust_scaler', 'none', 'standardize',\n",
       "                    'minmax', 'quantile_transformer', 'normalize',\n",
       "                    'quantile_transformer', 'minmax', 'standardize',\n",
       "                    'none', 'minmax', 'quantile_transformer', 'minmax',\n",
       "                    'minmax', 'robust_scaler', 'robust_scaler',\n",
       "                    'standardize', 'robust_scaler', 'robust_scaler',\n",
       "                    'normalize', 'none', 'none', 'none', 'none', 'minmax',\n",
       "                    'quantile_transformer', 'robust_scaler',\n",
       "                    'quantile_transformer', 'normalize', 'standardize',\n",
       "                    'robust_scaler', 'none', 'minmax', 'standardize',\n",
       "                    'normalize', 'robust_scaler', 'minmax', 'minmax',\n",
       "                    'quantile_transformer', 'quantile_transformer',\n",
       "                    'quantile_transformer', 'robust_scaler',\n",
       "                    'quantile_transformer', 'robust_scaler', 'none',\n",
       "                    'normalize', 'minmax', 'none', 'standardize', 'none',\n",
       "                    'quantile_transformer', 'robust_scaler',\n",
       "                    'robust_scaler', 'quantile_transformer',\n",
       "                    'quantile_transformer', 'none', 'none', 'minmax',\n",
       "                    'none', 'quantile_transformer', 'quantile_transformer',\n",
       "                    'minmax', 'minmax', 'normalize', 'robust_scaler',\n",
       "                    'robust_scaler', 'none', 'robust_scaler', 'normalize',\n",
       "                    'quantile_transformer', 'robust_scaler',\n",
       "                    'quantile_transformer', 'none', 'minmax',\n",
       "                    'quantile_transformer', 'normalize',\n",
       "                    'quantile_transformer', 'quantile_transformer', 'none',\n",
       "                    'quantile_transformer', 'normalize', 'standardize',\n",
       "                    'none', 'quantile_transformer', 'quantile_transformer',\n",
       "                    'none', 'quantile_transformer', 'minmax', 'minmax',\n",
       "                    'minmax', 'none', 'minmax', 'none', 'none',\n",
       "                    'robust_scaler', 'quantile_transformer',\n",
       "                    'robust_scaler', 'none', 'quantile_transformer',\n",
       "                    'standardize', 'normalize', 'minmax', 'none',\n",
       "                    'quantile_transformer', 'minmax', 'standardize',\n",
       "                    'quantile_transformer', 'standardize', 'standardize',\n",
       "                    'standardize', 'none', 'minmax', 'none', 'normalize',\n",
       "                    'none', 'standardize', 'none', 'standardize', 'none',\n",
       "                    'quantile_transformer', 'quantile_transformer',\n",
       "                    'quantile_transformer', 'none', 'none',\n",
       "                    'quantile_transformer', 'robust_scaler', 'minmax',\n",
       "                    'none', 'robust_scaler', 'normalize', 'normalize',\n",
       "                    'normalize', 'minmax', 'quantile_transformer', 'none',\n",
       "                    'quantile_transformer', 'normalize', 'minmax',\n",
       "                    'quantile_transformer', 'none', 'standardize',\n",
       "                    'normalize', 'robust_scaler', 'minmax', 'normalize',\n",
       "                    'minmax', 'none', 'none', 'none', 'minmax',\n",
       "                    'quantile_transformer', 'normalize', 'normalize',\n",
       "                    'quantile_transformer', 'minmax', 'normalize',\n",
       "                    'quantile_transformer', 'normalize', 'none',\n",
       "                    'robust_scaler', 'quantile_transformer', 'minmax',\n",
       "                    'minmax', 'normalize', 'quantile_transformer',\n",
       "                    'standardize', 'none', 'standardize', 'standardize',\n",
       "                    'none', 'minmax', 'none', 'none', 'none',\n",
       "                    'standardize', 'minmax', 'quantile_transformer',\n",
       "                    'minmax', 'standardize', 'standardize', 'none', 'none',\n",
       "                    'none', 'quantile_transformer', 'quantile_transformer',\n",
       "                    'none', 'none', 'quantile_transformer', 'minmax',\n",
       "                    'none', 'minmax', 'quantile_transformer',\n",
       "                    'standardize', 'normalize', 'normalize', 'none',\n",
       "                    'robust_scaler', 'normalize', 'robust_scaler',\n",
       "                    'normalize', 'none', 'minmax', 'none', 'minmax',\n",
       "                    'standardize', 'minmax', 'normalize',\n",
       "                    'quantile_transformer', 'quantile_transformer', 'none',\n",
       "                    'quantile_transformer', 'robust_scaler', 'minmax',\n",
       "                    'quantile_transformer', 'robust_scaler',\n",
       "                    'quantile_transformer', 'quantile_transformer',\n",
       "                    'normalize', 'standardize', 'robust_scaler',\n",
       "                    'normalize', 'robust_scaler', 'minmax',\n",
       "                    'quantile_transformer', 'quantile_transformer',\n",
       "                    'minmax', 'normalize', 'minmax', 'standardize', 'none',\n",
       "                    'standardize', 'none', 'normalize', 'none', 'none',\n",
       "                    'normalize', 'robust_scaler', 'none', 'minmax',\n",
       "                    'minmax', 'minmax', 'normalize', 'robust_scaler',\n",
       "                    'none', 'quantile_transformer', 'normalize',\n",
       "                    'robust_scaler', 'quantile_transformer',\n",
       "                    'robust_scaler', 'none', 'standardize',\n",
       "                    'quantile_transformer', 'robust_scaler',\n",
       "                    'robust_scaler', 'minmax', 'none', 'minmax',\n",
       "                    'robust_scaler', 'quantile_transformer',\n",
       "                    'quantile_transformer', 'none', 'quantile_transformer',\n",
       "                    'robust_scaler', 'standardize', 'none', 'none',\n",
       "                    'standardize', 'minmax', 'minmax', 'normalize',\n",
       "                    'robust_scaler', 'robust_scaler', 'minmax',\n",
       "                    'robust_scaler', 'quantile_transformer',\n",
       "                    'robust_scaler', 'none', 'robust_scaler', 'normalize',\n",
       "                    'standardize', 'normalize', 'minmax', 'robust_scaler',\n",
       "                    'quantile_transformer', 'quantile_transformer',\n",
       "                    'minmax', 'minmax', 'minmax', 'minmax', 'minmax',\n",
       "                    'standardize', 'robust_scaler', 'robust_scaler',\n",
       "                    'minmax', 'minmax', 'standardize', 'minmax', 'none',\n",
       "                    'minmax', 'minmax', 'robust_scaler',\n",
       "                    'quantile_transformer', 'normalize',\n",
       "                    'quantile_transformer', 'minmax', 'normalize',\n",
       "                    'robust_scaler', 'minmax', 'normalize', 'normalize',\n",
       "                    'minmax', 'none', 'normalize', 'minmax', 'normalize',\n",
       "                    'robust_scaler', 'robust_scaler',\n",
       "                    'quantile_transformer', 'robust_scaler',\n",
       "                    'robust_scaler', 'minmax', 'none', 'robust_scaler',\n",
       "                    'normalize', 'robust_scaler', 'quantile_transformer',\n",
       "                    'minmax', 'robust_scaler', 'robust_scaler', 'minmax',\n",
       "                    'none', 'standardize', 'none', 'normalize', 'minmax',\n",
       "                    'normalize', 'robust_scaler', 'quantile_transformer',\n",
       "                    'robust_scaler', 'normalize', 'standardize', 'none',\n",
       "                    'none', 'none', 'minmax', 'none',\n",
       "                    'quantile_transformer', 'robust_scaler', 'none',\n",
       "                    'none', 'none', 'quantile_transformer',\n",
       "                    'robust_scaler', 'minmax', 'none',\n",
       "                    'quantile_transformer', 'robust_scaler', 'standardize',\n",
       "                    'quantile_transformer', 'robust_scaler', 'minmax',\n",
       "                    'normalize', 'standardize', 'minmax', 'robust_scaler',\n",
       "                    'none', 'quantile_transformer', 'standardize', 'none',\n",
       "                    'robust_scaler', 'normalize', 'robust_scaler',\n",
       "                    'standardize', 'robust_scaler', 'normalize',\n",
       "                    'quantile_transformer', 'standardize', 'minmax',\n",
       "                    'robust_scaler', 'normalize', 'normalize',\n",
       "                    'standardize', 'standardize', 'minmax',\n",
       "                    'robust_scaler', 'none', 'normalize', 'robust_scaler',\n",
       "                    'none', 'minmax', 'minmax', 'none', 'none',\n",
       "                    'robust_scaler', 'standardize', 'normalize',\n",
       "                    'robust_scaler', 'robust_scaler', 'robust_scaler',\n",
       "                    'robust_scaler', 'normalize', 'normalize',\n",
       "                    'quantile_transformer', 'robust_scaler',\n",
       "                    'robust_scaler', 'robust_scaler', 'robust_scaler',\n",
       "                    'standardize', 'robust_scaler', 'robust_scaler',\n",
       "                    'standardize', 'quantile_transformer', 'none',\n",
       "                    'quantile_transformer', 'quantile_transformer',\n",
       "                    'robust_scaler', 'robust_scaler', 'none',\n",
       "                    'robust_scaler', 'quantile_transformer', 'normalize',\n",
       "                    'normalize', 'normalize', 'minmax', 'minmax',\n",
       "                    'normalize', 'normalize', 'minmax', 'standardize',\n",
       "                    'robust_scaler', 'robust_scaler', 'robust_scaler',\n",
       "                    'robust_scaler', 'standardize', 'robust_scaler',\n",
       "                    'standardize', 'none', 'none', 'minmax',\n",
       "                    'quantile_transformer', 'standardize', 'robust_scaler',\n",
       "                    'robust_scaler', 'robust_scaler', 'standardize'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U20'),\n",
       " 'param_feature_preprocessor:__choice__': masked_array(data=['no_preprocessing', 'random_trees_embedding',\n",
       "                    'feature_agglomeration', 'pca', 'no_preprocessing',\n",
       "                    'extra_trees_preproc_for_regression',\n",
       "                    'no_preprocessing', 'nystroem_sampler',\n",
       "                    'no_preprocessing', 'feature_agglomeration', 'pca',\n",
       "                    'polynomial', 'pca', 'pca', 'feature_agglomeration',\n",
       "                    'pca', 'no_preprocessing', 'no_preprocessing',\n",
       "                    'random_trees_embedding', 'fast_ica', 'pca',\n",
       "                    'feature_agglomeration',\n",
       "                    'extra_trees_preproc_for_regression', 'pca',\n",
       "                    'random_trees_embedding', 'pca',\n",
       "                    'feature_agglomeration', 'pca',\n",
       "                    'random_trees_embedding', 'feature_agglomeration',\n",
       "                    'no_preprocessing', 'pca', 'random_trees_embedding',\n",
       "                    'kitchen_sinks', 'polynomial', 'polynomial',\n",
       "                    'feature_agglomeration', 'random_trees_embedding',\n",
       "                    'random_trees_embedding', 'feature_agglomeration',\n",
       "                    'random_trees_embedding', 'random_trees_embedding',\n",
       "                    'fast_ica', 'no_preprocessing',\n",
       "                    'extra_trees_preproc_for_regression',\n",
       "                    'random_trees_embedding', 'pca', 'fast_ica',\n",
       "                    'random_trees_embedding', 'polynomial', 'polynomial',\n",
       "                    'extra_trees_preproc_for_regression',\n",
       "                    'extra_trees_preproc_for_regression',\n",
       "                    'extra_trees_preproc_for_regression', 'fast_ica',\n",
       "                    'extra_trees_preproc_for_regression', 'pca',\n",
       "                    'no_preprocessing', 'polynomial',\n",
       "                    'feature_agglomeration', 'random_trees_embedding',\n",
       "                    'random_trees_embedding', 'kernel_pca',\n",
       "                    'random_trees_embedding', 'random_trees_embedding',\n",
       "                    'extra_trees_preproc_for_regression', 'pca',\n",
       "                    'feature_agglomeration', 'fast_ica', 'pca',\n",
       "                    'random_trees_embedding', 'no_preprocessing',\n",
       "                    'feature_agglomeration', 'no_preprocessing', 'pca',\n",
       "                    'polynomial', 'no_preprocessing',\n",
       "                    'random_trees_embedding', 'random_trees_embedding',\n",
       "                    'polynomial', 'random_trees_embedding',\n",
       "                    'extra_trees_preproc_for_regression', 'fast_ica',\n",
       "                    'no_preprocessing', 'no_preprocessing',\n",
       "                    'random_trees_embedding', 'random_trees_embedding',\n",
       "                    'extra_trees_preproc_for_regression',\n",
       "                    'no_preprocessing', 'feature_agglomeration',\n",
       "                    'feature_agglomeration', 'kernel_pca', 'pca', 'pca',\n",
       "                    'random_trees_embedding', 'random_trees_embedding',\n",
       "                    'no_preprocessing', 'no_preprocessing',\n",
       "                    'no_preprocessing', 'fast_ica', 'polynomial',\n",
       "                    'random_trees_embedding',\n",
       "                    'extra_trees_preproc_for_regression', 'fast_ica',\n",
       "                    'random_trees_embedding', 'pca', 'polynomial',\n",
       "                    'fast_ica', 'feature_agglomeration', 'polynomial',\n",
       "                    'fast_ica', 'polynomial', 'no_preprocessing',\n",
       "                    'feature_agglomeration', 'random_trees_embedding',\n",
       "                    'no_preprocessing', 'no_preprocessing', 'pca', 'pca',\n",
       "                    'random_trees_embedding', 'random_trees_embedding',\n",
       "                    'fast_ica', 'pca', 'fast_ica', 'feature_agglomeration',\n",
       "                    'fast_ica', 'no_preprocessing',\n",
       "                    'random_trees_embedding', 'kernel_pca',\n",
       "                    'random_trees_embedding', 'polynomial',\n",
       "                    'no_preprocessing', 'pca',\n",
       "                    'extra_trees_preproc_for_regression', 'polynomial',\n",
       "                    'extra_trees_preproc_for_regression',\n",
       "                    'extra_trees_preproc_for_regression',\n",
       "                    'feature_agglomeration', 'feature_agglomeration',\n",
       "                    'random_trees_embedding', 'fast_ica',\n",
       "                    'feature_agglomeration', 'no_preprocessing',\n",
       "                    'fast_ica', 'polynomial', 'no_preprocessing', 'pca',\n",
       "                    'extra_trees_preproc_for_regression', 'fast_ica',\n",
       "                    'extra_trees_preproc_for_regression',\n",
       "                    'feature_agglomeration', 'pca', 'fast_ica', 'fast_ica',\n",
       "                    'fast_ica', 'extra_trees_preproc_for_regression',\n",
       "                    'fast_ica', 'fast_ica',\n",
       "                    'extra_trees_preproc_for_regression',\n",
       "                    'feature_agglomeration', 'pca',\n",
       "                    'feature_agglomeration', 'fast_ica',\n",
       "                    'extra_trees_preproc_for_regression', 'fast_ica',\n",
       "                    'fast_ica', 'polynomial', 'fast_ica', 'polynomial',\n",
       "                    'kernel_pca', 'extra_trees_preproc_for_regression',\n",
       "                    'fast_ica', 'polynomial',\n",
       "                    'extra_trees_preproc_for_regression', 'fast_ica',\n",
       "                    'extra_trees_preproc_for_regression',\n",
       "                    'extra_trees_preproc_for_regression', 'pca',\n",
       "                    'fast_ica', 'random_trees_embedding', 'kernel_pca',\n",
       "                    'kernel_pca', 'fast_ica', 'random_trees_embedding',\n",
       "                    'extra_trees_preproc_for_regression',\n",
       "                    'extra_trees_preproc_for_regression', 'fast_ica',\n",
       "                    'fast_ica', 'fast_ica', 'pca', 'no_preprocessing',\n",
       "                    'fast_ica', 'extra_trees_preproc_for_regression',\n",
       "                    'pca', 'random_trees_embedding', 'fast_ica',\n",
       "                    'extra_trees_preproc_for_regression', 'fast_ica',\n",
       "                    'fast_ica', 'fast_ica', 'fast_ica',\n",
       "                    'random_trees_embedding', 'fast_ica',\n",
       "                    'extra_trees_preproc_for_regression', 'fast_ica',\n",
       "                    'feature_agglomeration', 'fast_ica',\n",
       "                    'feature_agglomeration', 'fast_ica', 'fast_ica',\n",
       "                    'fast_ica', 'nystroem_sampler', 'fast_ica',\n",
       "                    'extra_trees_preproc_for_regression', 'pca',\n",
       "                    'extra_trees_preproc_for_regression', 'fast_ica',\n",
       "                    'pca', 'fast_ica',\n",
       "                    'extra_trees_preproc_for_regression', 'fast_ica',\n",
       "                    'extra_trees_preproc_for_regression',\n",
       "                    'extra_trees_preproc_for_regression',\n",
       "                    'extra_trees_preproc_for_regression', 'pca',\n",
       "                    'extra_trees_preproc_for_regression',\n",
       "                    'extra_trees_preproc_for_regression', 'fast_ica',\n",
       "                    'fast_ica', 'extra_trees_preproc_for_regression',\n",
       "                    'polynomial', 'extra_trees_preproc_for_regression',\n",
       "                    'polynomial', 'extra_trees_preproc_for_regression',\n",
       "                    'no_preprocessing',\n",
       "                    'extra_trees_preproc_for_regression', 'fast_ica',\n",
       "                    'nystroem_sampler', 'fast_ica', 'polynomial',\n",
       "                    'extra_trees_preproc_for_regression',\n",
       "                    'feature_agglomeration',\n",
       "                    'extra_trees_preproc_for_regression',\n",
       "                    'no_preprocessing', 'random_trees_embedding',\n",
       "                    'extra_trees_preproc_for_regression', 'fast_ica',\n",
       "                    'extra_trees_preproc_for_regression',\n",
       "                    'feature_agglomeration', 'random_trees_embedding',\n",
       "                    'polynomial', 'random_trees_embedding',\n",
       "                    'extra_trees_preproc_for_regression',\n",
       "                    'extra_trees_preproc_for_regression', 'fast_ica',\n",
       "                    'random_trees_embedding',\n",
       "                    'extra_trees_preproc_for_regression',\n",
       "                    'random_trees_embedding',\n",
       "                    'extra_trees_preproc_for_regression',\n",
       "                    'extra_trees_preproc_for_regression', 'pca',\n",
       "                    'random_trees_embedding', 'pca', 'fast_ica',\n",
       "                    'extra_trees_preproc_for_regression',\n",
       "                    'extra_trees_preproc_for_regression',\n",
       "                    'no_preprocessing',\n",
       "                    'extra_trees_preproc_for_regression',\n",
       "                    'no_preprocessing',\n",
       "                    'extra_trees_preproc_for_regression',\n",
       "                    'feature_agglomeration',\n",
       "                    'extra_trees_preproc_for_regression', 'pca',\n",
       "                    'polynomial', 'pca', 'fast_ica', 'fast_ica',\n",
       "                    'fast_ica', 'no_preprocessing', 'fast_ica', 'pca',\n",
       "                    'random_trees_embedding', 'pca', 'fast_ica',\n",
       "                    'polynomial', 'random_trees_embedding', 'polynomial',\n",
       "                    'pca', 'polynomial', 'fast_ica', 'fast_ica',\n",
       "                    'fast_ica', 'polynomial', 'no_preprocessing',\n",
       "                    'feature_agglomeration', 'random_trees_embedding',\n",
       "                    'polynomial', 'no_preprocessing',\n",
       "                    'random_trees_embedding', 'fast_ica', 'fast_ica',\n",
       "                    'random_trees_embedding', 'fast_ica', 'kitchen_sinks',\n",
       "                    'fast_ica', 'no_preprocessing', 'fast_ica', 'pca',\n",
       "                    'fast_ica', 'fast_ica', 'no_preprocessing',\n",
       "                    'extra_trees_preproc_for_regression',\n",
       "                    'extra_trees_preproc_for_regression',\n",
       "                    'random_trees_embedding', 'polynomial',\n",
       "                    'random_trees_embedding', 'fast_ica',\n",
       "                    'extra_trees_preproc_for_regression',\n",
       "                    'random_trees_embedding', 'feature_agglomeration',\n",
       "                    'fast_ica', 'extra_trees_preproc_for_regression',\n",
       "                    'pca', 'pca', 'no_preprocessing', 'polynomial',\n",
       "                    'fast_ica', 'fast_ica', 'no_preprocessing', 'pca',\n",
       "                    'polynomial', 'feature_agglomeration', 'pca',\n",
       "                    'fast_ica', 'fast_ica', 'fast_ica', 'fast_ica',\n",
       "                    'extra_trees_preproc_for_regression', 'fast_ica',\n",
       "                    'pca', 'random_trees_embedding', 'fast_ica',\n",
       "                    'random_trees_embedding', 'feature_agglomeration',\n",
       "                    'random_trees_embedding', 'no_preprocessing',\n",
       "                    'no_preprocessing', 'no_preprocessing', 'polynomial',\n",
       "                    'random_trees_embedding', 'fast_ica',\n",
       "                    'no_preprocessing',\n",
       "                    'extra_trees_preproc_for_regression',\n",
       "                    'feature_agglomeration', 'fast_ica', 'fast_ica',\n",
       "                    'extra_trees_preproc_for_regression', 'polynomial',\n",
       "                    'fast_ica', 'pca', 'random_trees_embedding',\n",
       "                    'random_trees_embedding', 'fast_ica', 'polynomial',\n",
       "                    'fast_ica', 'fast_ica', 'fast_ica',\n",
       "                    'feature_agglomeration', 'random_trees_embedding',\n",
       "                    'polynomial', 'fast_ica', 'fast_ica', 'pca',\n",
       "                    'polynomial', 'fast_ica', 'fast_ica', 'pca', 'pca',\n",
       "                    'extra_trees_preproc_for_regression', 'pca',\n",
       "                    'no_preprocessing', 'feature_agglomeration',\n",
       "                    'polynomial', 'polynomial', 'polynomial',\n",
       "                    'no_preprocessing', 'pca', 'fast_ica',\n",
       "                    'extra_trees_preproc_for_regression',\n",
       "                    'no_preprocessing', 'fast_ica', 'polynomial',\n",
       "                    'no_preprocessing', 'fast_ica',\n",
       "                    'extra_trees_preproc_for_regression', 'fast_ica',\n",
       "                    'polynomial', 'fast_ica',\n",
       "                    'extra_trees_preproc_for_regression',\n",
       "                    'no_preprocessing', 'fast_ica', 'fast_ica',\n",
       "                    'no_preprocessing', 'random_trees_embedding',\n",
       "                    'fast_ica', 'fast_ica', 'fast_ica', 'fast_ica',\n",
       "                    'fast_ica', 'pca',\n",
       "                    'extra_trees_preproc_for_regression',\n",
       "                    'extra_trees_preproc_for_regression', 'pca',\n",
       "                    'extra_trees_preproc_for_regression',\n",
       "                    'no_preprocessing', 'fast_ica', 'pca', 'pca', 'pca',\n",
       "                    'fast_ica', 'random_trees_embedding', 'fast_ica',\n",
       "                    'fast_ica', 'fast_ica', 'random_trees_embedding',\n",
       "                    'extra_trees_preproc_for_regression', 'pca', 'pca',\n",
       "                    'polynomial', 'fast_ica', 'feature_agglomeration',\n",
       "                    'fast_ica', 'extra_trees_preproc_for_regression',\n",
       "                    'fast_ica', 'pca',\n",
       "                    'extra_trees_preproc_for_regression',\n",
       "                    'random_trees_embedding', 'fast_ica', 'polynomial',\n",
       "                    'pca', 'extra_trees_preproc_for_regression',\n",
       "                    'extra_trees_preproc_for_regression', 'fast_ica',\n",
       "                    'fast_ica', 'fast_ica',\n",
       "                    'extra_trees_preproc_for_regression',\n",
       "                    'random_trees_embedding', 'fast_ica', 'fast_ica',\n",
       "                    'random_trees_embedding', 'random_trees_embedding',\n",
       "                    'fast_ica', 'fast_ica', 'fast_ica', 'fast_ica',\n",
       "                    'fast_ica', 'pca', 'kitchen_sinks', 'fast_ica',\n",
       "                    'no_preprocessing', 'polynomial', 'pca', 'fast_ica',\n",
       "                    'no_preprocessing', 'no_preprocessing', 'fast_ica',\n",
       "                    'fast_ica', 'extra_trees_preproc_for_regression',\n",
       "                    'pca', 'fast_ica', 'fast_ica', 'pca',\n",
       "                    'no_preprocessing', 'fast_ica', 'polynomial', 'pca',\n",
       "                    'no_preprocessing', 'fast_ica',\n",
       "                    'feature_agglomeration', 'polynomial', 'fast_ica',\n",
       "                    'no_preprocessing', 'fast_ica', 'fast_ica', 'fast_ica',\n",
       "                    'extra_trees_preproc_for_regression', 'fast_ica',\n",
       "                    'fast_ica', 'fast_ica', 'fast_ica', 'fast_ica',\n",
       "                    'fast_ica', 'polynomial', 'fast_ica', 'fast_ica',\n",
       "                    'polynomial', 'extra_trees_preproc_for_regression',\n",
       "                    'fast_ica', 'fast_ica', 'pca', 'fast_ica', 'fast_ica',\n",
       "                    'no_preprocessing', 'fast_ica', 'fast_ica',\n",
       "                    'polynomial', 'fast_ica', 'nystroem_sampler',\n",
       "                    'fast_ica', 'no_preprocessing', 'fast_ica', 'fast_ica',\n",
       "                    'no_preprocessing', 'random_trees_embedding',\n",
       "                    'kernel_pca', 'kernel_pca', 'fast_ica', 'fast_ica',\n",
       "                    'fast_ica', 'fast_ica', 'no_preprocessing', 'fast_ica',\n",
       "                    'no_preprocessing', 'random_trees_embedding',\n",
       "                    'fast_ica', 'feature_agglomeration', 'fast_ica',\n",
       "                    'fast_ica', 'fast_ica', 'fast_ica', 'fast_ica', 'pca',\n",
       "                    'pca', 'fast_ica', 'fast_ica',\n",
       "                    'random_trees_embedding', 'random_trees_embedding',\n",
       "                    'fast_ica', 'extra_trees_preproc_for_regression',\n",
       "                    'fast_ica', 'extra_trees_preproc_for_regression',\n",
       "                    'fast_ica', 'random_trees_embedding', 'fast_ica',\n",
       "                    'fast_ica', 'fast_ica', 'feature_agglomeration',\n",
       "                    'feature_agglomeration', 'fast_ica', 'fast_ica',\n",
       "                    'feature_agglomeration', 'fast_ica', 'fast_ica',\n",
       "                    'fast_ica', 'fast_ica', 'pca', 'pca', 'fast_ica',\n",
       "                    'fast_ica', 'fast_ica', 'polynomial', 'fast_ica',\n",
       "                    'polynomial', 'fast_ica', 'polynomial', 'fast_ica',\n",
       "                    'fast_ica', 'fast_ica', 'polynomial', 'fast_ica',\n",
       "                    'extra_trees_preproc_for_regression',\n",
       "                    'extra_trees_preproc_for_regression', 'kitchen_sinks',\n",
       "                    'no_preprocessing', 'pca', 'fast_ica', 'polynomial',\n",
       "                    'pca', 'pca', 'extra_trees_preproc_for_regression',\n",
       "                    'fast_ica', 'fast_ica', 'fast_ica', 'fast_ica',\n",
       "                    'fast_ica', 'pca', 'polynomial', 'pca', 'fast_ica',\n",
       "                    'no_preprocessing', 'pca', 'fast_ica', 'pca', 'pca',\n",
       "                    'fast_ica', 'pca',\n",
       "                    'extra_trees_preproc_for_regression', 'pca',\n",
       "                    'polynomial', 'fast_ica', 'feature_agglomeration',\n",
       "                    'feature_agglomeration',\n",
       "                    'extra_trees_preproc_for_regression', 'pca', 'pca',\n",
       "                    'polynomial', 'pca', 'pca', 'random_trees_embedding',\n",
       "                    'extra_trees_preproc_for_regression', 'pca', 'pca',\n",
       "                    'fast_ica', 'no_preprocessing', 'pca', 'pca',\n",
       "                    'extra_trees_preproc_for_regression',\n",
       "                    'no_preprocessing', 'pca', 'pca', 'fast_ica',\n",
       "                    'fast_ica', 'fast_ica',\n",
       "                    'extra_trees_preproc_for_regression', 'fast_ica',\n",
       "                    'no_preprocessing', 'random_trees_embedding',\n",
       "                    'extra_trees_preproc_for_regression',\n",
       "                    'random_trees_embedding',\n",
       "                    'extra_trees_preproc_for_regression', 'fast_ica',\n",
       "                    'random_trees_embedding', 'fast_ica', 'polynomial',\n",
       "                    'fast_ica', 'no_preprocessing', 'fast_ica',\n",
       "                    'no_preprocessing', 'pca', 'pca', 'no_preprocessing',\n",
       "                    'no_preprocessing', 'fast_ica', 'fast_ica',\n",
       "                    'polynomial', 'feature_agglomeration', 'polynomial',\n",
       "                    'polynomial', 'fast_ica', 'kernel_pca', 'polynomial',\n",
       "                    'pca', 'fast_ica', 'fast_ica', 'fast_ica',\n",
       "                    'extra_trees_preproc_for_regression',\n",
       "                    'feature_agglomeration', 'fast_ica', 'pca', 'fast_ica',\n",
       "                    'pca', 'pca', 'pca', 'polynomial', 'no_preprocessing',\n",
       "                    'no_preprocessing', 'fast_ica', 'fast_ica',\n",
       "                    'extra_trees_preproc_for_regression', 'fast_ica',\n",
       "                    'fast_ica', 'fast_ica', 'fast_ica', 'kitchen_sinks',\n",
       "                    'fast_ica', 'extra_trees_preproc_for_regression',\n",
       "                    'feature_agglomeration', 'polynomial', 'fast_ica',\n",
       "                    'polynomial', 'feature_agglomeration',\n",
       "                    'no_preprocessing', 'fast_ica', 'polynomial',\n",
       "                    'fast_ica', 'fast_ica', 'fast_ica',\n",
       "                    'random_trees_embedding', 'polynomial', 'polynomial',\n",
       "                    'kernel_pca', 'pca', 'random_trees_embedding',\n",
       "                    'no_preprocessing', 'fast_ica', 'fast_ica', 'fast_ica',\n",
       "                    'extra_trees_preproc_for_regression', 'fast_ica',\n",
       "                    'fast_ica', 'polynomial', 'fast_ica', 'pca',\n",
       "                    'fast_ica', 'fast_ica', 'fast_ica', 'pca', 'fast_ica',\n",
       "                    'fast_ica', 'polynomial', 'fast_ica',\n",
       "                    'no_preprocessing', 'fast_ica', 'fast_ica', 'fast_ica',\n",
       "                    'fast_ica', 'fast_ica', 'no_preprocessing', 'fast_ica',\n",
       "                    'fast_ica', 'fast_ica', 'fast_ica', 'fast_ica',\n",
       "                    'fast_ica', 'fast_ica', 'feature_agglomeration',\n",
       "                    'no_preprocessing', 'polynomial',\n",
       "                    'random_trees_embedding', 'kernel_pca', 'fast_ica',\n",
       "                    'fast_ica', 'fast_ica', 'fast_ica', 'polynomial',\n",
       "                    'fast_ica', 'fast_ica', 'no_preprocessing', 'pca',\n",
       "                    'pca', 'fast_ica', 'fast_ica', 'pca', 'pca',\n",
       "                    'fast_ica', 'fast_ica', 'random_trees_embedding',\n",
       "                    'polynomial', 'extra_trees_preproc_for_regression',\n",
       "                    'extra_trees_preproc_for_regression',\n",
       "                    'no_preprocessing',\n",
       "                    'extra_trees_preproc_for_regression',\n",
       "                    'extra_trees_preproc_for_regression',\n",
       "                    'extra_trees_preproc_for_regression', 'kernel_pca',\n",
       "                    'feature_agglomeration', 'fast_ica', 'fast_ica',\n",
       "                    'random_trees_embedding',\n",
       "                    'extra_trees_preproc_for_regression'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U34'),\n",
       " 'param_regressor:__choice__': masked_array(data=['random_forest', 'ridge_regression', 'decision_tree',\n",
       "                    'decision_tree', 'ridge_regression',\n",
       "                    'ridge_regression', 'ridge_regression',\n",
       "                    'ridge_regression', 'ridge_regression', 'extra_trees',\n",
       "                    'k_nearest_neighbors', 'decision_tree',\n",
       "                    'random_forest', 'decision_tree', 'ridge_regression',\n",
       "                    'random_forest', 'k_nearest_neighbors',\n",
       "                    'ridge_regression', 'decision_tree',\n",
       "                    'k_nearest_neighbors', 'ridge_regression',\n",
       "                    'random_forest', 'random_forest', 'gaussian_process',\n",
       "                    'k_nearest_neighbors', 'extra_trees', 'random_forest',\n",
       "                    'ridge_regression', 'random_forest', 'extra_trees',\n",
       "                    'ridge_regression', 'ridge_regression',\n",
       "                    'k_nearest_neighbors', 'ridge_regression',\n",
       "                    'random_forest', 'k_nearest_neighbors',\n",
       "                    'k_nearest_neighbors', 'random_forest',\n",
       "                    'random_forest', 'random_forest',\n",
       "                    'k_nearest_neighbors', 'k_nearest_neighbors',\n",
       "                    'random_forest', 'ridge_regression',\n",
       "                    'gaussian_process', 'k_nearest_neighbors',\n",
       "                    'random_forest', 'decision_tree', 'random_forest',\n",
       "                    'k_nearest_neighbors', 'random_forest',\n",
       "                    'random_forest', 'k_nearest_neighbors',\n",
       "                    'k_nearest_neighbors', 'gaussian_process',\n",
       "                    'ridge_regression', 'random_forest', 'decision_tree',\n",
       "                    'ridge_regression', 'k_nearest_neighbors',\n",
       "                    'k_nearest_neighbors', 'random_forest',\n",
       "                    'ridge_regression', 'k_nearest_neighbors',\n",
       "                    'k_nearest_neighbors', 'random_forest',\n",
       "                    'k_nearest_neighbors', 'random_forest',\n",
       "                    'ridge_regression', 'decision_tree',\n",
       "                    'k_nearest_neighbors', 'random_forest',\n",
       "                    'random_forest', 'ridge_regression', 'decision_tree',\n",
       "                    'k_nearest_neighbors', 'extra_trees',\n",
       "                    'k_nearest_neighbors', 'extra_trees',\n",
       "                    'k_nearest_neighbors', 'k_nearest_neighbors',\n",
       "                    'extra_trees', 'k_nearest_neighbors',\n",
       "                    'k_nearest_neighbors', 'extra_trees',\n",
       "                    'ridge_regression', 'k_nearest_neighbors',\n",
       "                    'k_nearest_neighbors', 'random_forest',\n",
       "                    'ridge_regression', 'k_nearest_neighbors',\n",
       "                    'ridge_regression', 'k_nearest_neighbors',\n",
       "                    'ridge_regression', 'random_forest', 'random_forest',\n",
       "                    'decision_tree', 'ridge_regression',\n",
       "                    'gaussian_process', 'extra_trees', 'decision_tree',\n",
       "                    'random_forest', 'extra_trees', 'decision_tree',\n",
       "                    'k_nearest_neighbors', 'k_nearest_neighbors',\n",
       "                    'k_nearest_neighbors', 'random_forest',\n",
       "                    'k_nearest_neighbors', 'random_forest', 'extra_trees',\n",
       "                    'k_nearest_neighbors', 'extra_trees',\n",
       "                    'k_nearest_neighbors', 'k_nearest_neighbors',\n",
       "                    'gaussian_process', 'gaussian_process',\n",
       "                    'k_nearest_neighbors', 'random_forest',\n",
       "                    'random_forest', 'extra_trees', 'k_nearest_neighbors',\n",
       "                    'k_nearest_neighbors', 'random_forest',\n",
       "                    'k_nearest_neighbors', 'extra_trees', 'random_forest',\n",
       "                    'extra_trees', 'ridge_regression',\n",
       "                    'k_nearest_neighbors', 'gaussian_process',\n",
       "                    'k_nearest_neighbors', 'k_nearest_neighbors',\n",
       "                    'extra_trees', 'decision_tree', 'k_nearest_neighbors',\n",
       "                    'k_nearest_neighbors', 'random_forest',\n",
       "                    'k_nearest_neighbors', 'k_nearest_neighbors',\n",
       "                    'gaussian_process', 'gaussian_process',\n",
       "                    'k_nearest_neighbors', 'random_forest',\n",
       "                    'gaussian_process', 'gaussian_process', 'extra_trees',\n",
       "                    'extra_trees', 'k_nearest_neighbors',\n",
       "                    'k_nearest_neighbors', 'ridge_regression',\n",
       "                    'decision_tree', 'k_nearest_neighbors',\n",
       "                    'k_nearest_neighbors', 'k_nearest_neighbors',\n",
       "                    'extra_trees', 'k_nearest_neighbors', 'extra_trees',\n",
       "                    'ridge_regression', 'random_forest', 'random_forest',\n",
       "                    'extra_trees', 'k_nearest_neighbors', 'extra_trees',\n",
       "                    'random_forest', 'extra_trees', 'decision_tree',\n",
       "                    'gaussian_process', 'random_forest',\n",
       "                    'ridge_regression', 'random_forest', 'extra_trees',\n",
       "                    'gaussian_process', 'random_forest',\n",
       "                    'gaussian_process', 'random_forest', 'random_forest',\n",
       "                    'ridge_regression', 'gaussian_process',\n",
       "                    'ridge_regression', 'ridge_regression',\n",
       "                    'ridge_regression', 'random_forest',\n",
       "                    'k_nearest_neighbors', 'random_forest',\n",
       "                    'k_nearest_neighbors', 'k_nearest_neighbors',\n",
       "                    'extra_trees', 'extra_trees', 'gaussian_process',\n",
       "                    'ridge_regression', 'k_nearest_neighbors',\n",
       "                    'extra_trees', 'gaussian_process', 'extra_trees',\n",
       "                    'random_forest', 'k_nearest_neighbors',\n",
       "                    'k_nearest_neighbors', 'k_nearest_neighbors',\n",
       "                    'random_forest', 'extra_trees', 'k_nearest_neighbors',\n",
       "                    'extra_trees', 'k_nearest_neighbors', 'extra_trees',\n",
       "                    'gaussian_process', 'random_forest', 'random_forest',\n",
       "                    'extra_trees', 'k_nearest_neighbors', 'extra_trees',\n",
       "                    'ridge_regression', 'decision_tree',\n",
       "                    'k_nearest_neighbors', 'k_nearest_neighbors',\n",
       "                    'k_nearest_neighbors', 'k_nearest_neighbors',\n",
       "                    'ridge_regression', 'k_nearest_neighbors',\n",
       "                    'k_nearest_neighbors', 'k_nearest_neighbors',\n",
       "                    'k_nearest_neighbors', 'k_nearest_neighbors',\n",
       "                    'gaussian_process', 'extra_trees', 'extra_trees',\n",
       "                    'random_forest', 'k_nearest_neighbors', 'extra_trees',\n",
       "                    'k_nearest_neighbors', 'k_nearest_neighbors',\n",
       "                    'extra_trees', 'random_forest', 'k_nearest_neighbors',\n",
       "                    'random_forest', 'k_nearest_neighbors',\n",
       "                    'k_nearest_neighbors', 'ridge_regression',\n",
       "                    'k_nearest_neighbors', 'ridge_regression',\n",
       "                    'random_forest', 'random_forest',\n",
       "                    'k_nearest_neighbors', 'ridge_regression',\n",
       "                    'k_nearest_neighbors', 'extra_trees',\n",
       "                    'k_nearest_neighbors', 'extra_trees', 'random_forest',\n",
       "                    'ridge_regression', 'gaussian_process', 'extra_trees',\n",
       "                    'extra_trees', 'k_nearest_neighbors', 'random_forest',\n",
       "                    'extra_trees', 'k_nearest_neighbors',\n",
       "                    'k_nearest_neighbors', 'extra_trees',\n",
       "                    'ridge_regression', 'k_nearest_neighbors',\n",
       "                    'extra_trees', 'extra_trees', 'random_forest',\n",
       "                    'k_nearest_neighbors', 'k_nearest_neighbors',\n",
       "                    'k_nearest_neighbors', 'k_nearest_neighbors',\n",
       "                    'extra_trees', 'ridge_regression', 'random_forest',\n",
       "                    'random_forest', 'extra_trees', 'extra_trees',\n",
       "                    'k_nearest_neighbors', 'k_nearest_neighbors',\n",
       "                    'k_nearest_neighbors', 'random_forest',\n",
       "                    'gaussian_process', 'k_nearest_neighbors',\n",
       "                    'k_nearest_neighbors', 'k_nearest_neighbors',\n",
       "                    'gaussian_process', 'k_nearest_neighbors',\n",
       "                    'extra_trees', 'extra_trees', 'random_forest',\n",
       "                    'extra_trees', 'k_nearest_neighbors',\n",
       "                    'k_nearest_neighbors', 'k_nearest_neighbors',\n",
       "                    'k_nearest_neighbors', 'random_forest',\n",
       "                    'gaussian_process', 'extra_trees', 'extra_trees',\n",
       "                    'gaussian_process', 'k_nearest_neighbors',\n",
       "                    'extra_trees', 'k_nearest_neighbors',\n",
       "                    'k_nearest_neighbors', 'ridge_regression',\n",
       "                    'k_nearest_neighbors', 'ridge_regression',\n",
       "                    'k_nearest_neighbors', 'decision_tree',\n",
       "                    'k_nearest_neighbors', 'k_nearest_neighbors',\n",
       "                    'k_nearest_neighbors', 'k_nearest_neighbors',\n",
       "                    'ridge_regression', 'k_nearest_neighbors',\n",
       "                    'decision_tree', 'random_forest', 'extra_trees',\n",
       "                    'k_nearest_neighbors', 'k_nearest_neighbors',\n",
       "                    'k_nearest_neighbors', 'k_nearest_neighbors',\n",
       "                    'decision_tree', 'gaussian_process',\n",
       "                    'k_nearest_neighbors', 'extra_trees',\n",
       "                    'gaussian_process', 'decision_tree', 'random_forest',\n",
       "                    'ridge_regression', 'decision_tree',\n",
       "                    'k_nearest_neighbors', 'k_nearest_neighbors',\n",
       "                    'random_forest', 'random_forest', 'decision_tree',\n",
       "                    'k_nearest_neighbors', 'k_nearest_neighbors',\n",
       "                    'k_nearest_neighbors', 'k_nearest_neighbors',\n",
       "                    'k_nearest_neighbors', 'k_nearest_neighbors',\n",
       "                    'k_nearest_neighbors', 'k_nearest_neighbors',\n",
       "                    'gaussian_process', 'k_nearest_neighbors',\n",
       "                    'k_nearest_neighbors', 'k_nearest_neighbors',\n",
       "                    'k_nearest_neighbors', 'k_nearest_neighbors',\n",
       "                    'decision_tree', 'extra_trees', 'k_nearest_neighbors',\n",
       "                    'k_nearest_neighbors', 'gaussian_process',\n",
       "                    'k_nearest_neighbors', 'ridge_regression',\n",
       "                    'decision_tree', 'decision_tree', 'gaussian_process',\n",
       "                    'random_forest', 'extra_trees', 'decision_tree',\n",
       "                    'k_nearest_neighbors', 'k_nearest_neighbors',\n",
       "                    'extra_trees', 'extra_trees', 'k_nearest_neighbors',\n",
       "                    'k_nearest_neighbors', 'decision_tree',\n",
       "                    'k_nearest_neighbors', 'k_nearest_neighbors',\n",
       "                    'k_nearest_neighbors', 'k_nearest_neighbors',\n",
       "                    'k_nearest_neighbors', 'decision_tree',\n",
       "                    'k_nearest_neighbors', 'decision_tree',\n",
       "                    'decision_tree', 'decision_tree',\n",
       "                    'k_nearest_neighbors', 'decision_tree',\n",
       "                    'ridge_regression', 'extra_trees', 'gaussian_process',\n",
       "                    'ridge_regression', 'random_forest', 'random_forest',\n",
       "                    'k_nearest_neighbors', 'decision_tree',\n",
       "                    'k_nearest_neighbors', 'ridge_regression',\n",
       "                    'gaussian_process', 'extra_trees', 'extra_trees',\n",
       "                    'k_nearest_neighbors', 'k_nearest_neighbors',\n",
       "                    'ridge_regression', 'k_nearest_neighbors',\n",
       "                    'decision_tree', 'k_nearest_neighbors',\n",
       "                    'random_forest', 'k_nearest_neighbors',\n",
       "                    'decision_tree', 'k_nearest_neighbors',\n",
       "                    'ridge_regression', 'random_forest', 'random_forest',\n",
       "                    'k_nearest_neighbors', 'k_nearest_neighbors',\n",
       "                    'decision_tree', 'decision_tree', 'random_forest',\n",
       "                    'gaussian_process', 'ridge_regression',\n",
       "                    'decision_tree', 'k_nearest_neighbors',\n",
       "                    'k_nearest_neighbors', 'decision_tree',\n",
       "                    'decision_tree', 'decision_tree', 'ridge_regression',\n",
       "                    'decision_tree', 'ridge_regression', 'decision_tree',\n",
       "                    'random_forest', 'decision_tree', 'random_forest',\n",
       "                    'ridge_regression', 'k_nearest_neighbors',\n",
       "                    'gaussian_process', 'decision_tree', 'decision_tree',\n",
       "                    'random_forest', 'k_nearest_neighbors',\n",
       "                    'random_forest', 'k_nearest_neighbors',\n",
       "                    'decision_tree', 'decision_tree', 'extra_trees',\n",
       "                    'k_nearest_neighbors', 'decision_tree',\n",
       "                    'decision_tree', 'random_forest',\n",
       "                    'k_nearest_neighbors', 'k_nearest_neighbors',\n",
       "                    'k_nearest_neighbors', 'decision_tree',\n",
       "                    'gaussian_process', 'k_nearest_neighbors',\n",
       "                    'ridge_regression', 'ridge_regression',\n",
       "                    'k_nearest_neighbors', 'decision_tree',\n",
       "                    'k_nearest_neighbors', 'decision_tree',\n",
       "                    'ridge_regression', 'decision_tree',\n",
       "                    'ridge_regression', 'random_forest',\n",
       "                    'ridge_regression', 'decision_tree',\n",
       "                    'gaussian_process', 'gaussian_process',\n",
       "                    'k_nearest_neighbors', 'decision_tree',\n",
       "                    'decision_tree', 'ridge_regression', 'decision_tree',\n",
       "                    'decision_tree', 'k_nearest_neighbors',\n",
       "                    'decision_tree', 'decision_tree', 'extra_trees',\n",
       "                    'k_nearest_neighbors', 'gaussian_process',\n",
       "                    'ridge_regression', 'extra_trees',\n",
       "                    'k_nearest_neighbors', 'gaussian_process',\n",
       "                    'decision_tree', 'k_nearest_neighbors',\n",
       "                    'gaussian_process', 'decision_tree',\n",
       "                    'ridge_regression', 'decision_tree', 'extra_trees',\n",
       "                    'decision_tree', 'ridge_regression', 'decision_tree',\n",
       "                    'decision_tree', 'decision_tree', 'gaussian_process',\n",
       "                    'decision_tree', 'decision_tree', 'decision_tree',\n",
       "                    'decision_tree', 'decision_tree', 'gaussian_process',\n",
       "                    'extra_trees', 'decision_tree', 'decision_tree',\n",
       "                    'decision_tree', 'decision_tree', 'decision_tree',\n",
       "                    'random_forest', 'ridge_regression', 'decision_tree',\n",
       "                    'random_forest', 'random_forest', 'ridge_regression',\n",
       "                    'decision_tree', 'k_nearest_neighbors',\n",
       "                    'decision_tree', 'random_forest', 'random_forest',\n",
       "                    'k_nearest_neighbors', 'ridge_regression',\n",
       "                    'ridge_regression', 'decision_tree', 'decision_tree',\n",
       "                    'decision_tree', 'decision_tree', 'gaussian_process',\n",
       "                    'decision_tree', 'extra_trees', 'decision_tree',\n",
       "                    'decision_tree', 'random_forest', 'decision_tree',\n",
       "                    'decision_tree', 'decision_tree', 'decision_tree',\n",
       "                    'decision_tree', 'ridge_regression', 'decision_tree',\n",
       "                    'k_nearest_neighbors', 'k_nearest_neighbors',\n",
       "                    'k_nearest_neighbors', 'extra_trees',\n",
       "                    'k_nearest_neighbors', 'decision_tree',\n",
       "                    'decision_tree', 'k_nearest_neighbors',\n",
       "                    'decision_tree', 'ridge_regression',\n",
       "                    'ridge_regression', 'decision_tree', 'decision_tree',\n",
       "                    'extra_trees', 'gaussian_process', 'decision_tree',\n",
       "                    'decision_tree', 'gaussian_process', 'decision_tree',\n",
       "                    'decision_tree', 'decision_tree', 'decision_tree',\n",
       "                    'decision_tree', 'decision_tree', 'decision_tree',\n",
       "                    'decision_tree', 'decision_tree', 'ridge_regression',\n",
       "                    'ridge_regression', 'ridge_regression',\n",
       "                    'decision_tree', 'extra_trees', 'decision_tree',\n",
       "                    'decision_tree', 'decision_tree', 'extra_trees',\n",
       "                    'decision_tree', 'gaussian_process', 'decision_tree',\n",
       "                    'ridge_regression', 'extra_trees', 'decision_tree',\n",
       "                    'decision_tree', 'k_nearest_neighbors',\n",
       "                    'decision_tree', 'ridge_regression',\n",
       "                    'gaussian_process', 'k_nearest_neighbors',\n",
       "                    'decision_tree', 'decision_tree', 'decision_tree',\n",
       "                    'random_forest', 'decision_tree', 'decision_tree',\n",
       "                    'decision_tree', 'decision_tree', 'gaussian_process',\n",
       "                    'decision_tree', 'ridge_regression', 'decision_tree',\n",
       "                    'decision_tree', 'gaussian_process', 'decision_tree',\n",
       "                    'decision_tree', 'decision_tree', 'ridge_regression',\n",
       "                    'extra_trees', 'decision_tree', 'gaussian_process',\n",
       "                    'decision_tree', 'decision_tree', 'decision_tree',\n",
       "                    'extra_trees', 'decision_tree', 'decision_tree',\n",
       "                    'k_nearest_neighbors', 'random_forest',\n",
       "                    'decision_tree', 'k_nearest_neighbors',\n",
       "                    'decision_tree', 'random_forest', 'decision_tree',\n",
       "                    'decision_tree', 'k_nearest_neighbors',\n",
       "                    'gaussian_process', 'gaussian_process',\n",
       "                    'decision_tree', 'decision_tree', 'decision_tree',\n",
       "                    'extra_trees', 'random_forest', 'decision_tree',\n",
       "                    'extra_trees', 'k_nearest_neighbors', 'decision_tree',\n",
       "                    'extra_trees', 'random_forest', 'ridge_regression',\n",
       "                    'extra_trees', 'extra_trees', 'decision_tree',\n",
       "                    'ridge_regression', 'extra_trees', 'ridge_regression',\n",
       "                    'gaussian_process', 'decision_tree', 'decision_tree',\n",
       "                    'decision_tree', 'gaussian_process', 'decision_tree',\n",
       "                    'decision_tree', 'ridge_regression',\n",
       "                    'k_nearest_neighbors', 'decision_tree',\n",
       "                    'decision_tree', 'decision_tree', 'ridge_regression',\n",
       "                    'gaussian_process', 'decision_tree', 'decision_tree',\n",
       "                    'extra_trees', 'decision_tree', 'random_forest',\n",
       "                    'k_nearest_neighbors', 'k_nearest_neighbors',\n",
       "                    'extra_trees', 'ridge_regression', 'decision_tree',\n",
       "                    'random_forest', 'decision_tree', 'gaussian_process',\n",
       "                    'gaussian_process', 'decision_tree', 'decision_tree',\n",
       "                    'decision_tree', 'gaussian_process', 'decision_tree',\n",
       "                    'gaussian_process', 'k_nearest_neighbors',\n",
       "                    'decision_tree', 'ridge_regression', 'decision_tree',\n",
       "                    'extra_trees', 'random_forest', 'random_forest',\n",
       "                    'decision_tree', 'ridge_regression',\n",
       "                    'ridge_regression', 'decision_tree', 'extra_trees',\n",
       "                    'random_forest', 'decision_tree',\n",
       "                    'k_nearest_neighbors', 'decision_tree', 'extra_trees',\n",
       "                    'extra_trees', 'decision_tree', 'ridge_regression',\n",
       "                    'ridge_regression', 'extra_trees', 'ridge_regression',\n",
       "                    'decision_tree', 'decision_tree', 'decision_tree',\n",
       "                    'random_forest', 'decision_tree', 'decision_tree',\n",
       "                    'decision_tree', 'decision_tree', 'random_forest',\n",
       "                    'decision_tree', 'ridge_regression', 'extra_trees',\n",
       "                    'k_nearest_neighbors', 'decision_tree', 'extra_trees',\n",
       "                    'ridge_regression', 'decision_tree',\n",
       "                    'gaussian_process', 'decision_tree', 'decision_tree',\n",
       "                    'decision_tree', 'decision_tree', 'decision_tree',\n",
       "                    'decision_tree', 'decision_tree', 'decision_tree',\n",
       "                    'decision_tree', 'decision_tree', 'extra_trees',\n",
       "                    'decision_tree', 'decision_tree',\n",
       "                    'k_nearest_neighbors', 'gaussian_process',\n",
       "                    'extra_trees', 'random_forest', 'ridge_regression',\n",
       "                    'decision_tree', 'decision_tree', 'random_forest',\n",
       "                    'decision_tree', 'gaussian_process', 'decision_tree',\n",
       "                    'decision_tree', 'random_forest', 'decision_tree',\n",
       "                    'decision_tree', 'decision_tree', 'decision_tree',\n",
       "                    'extra_trees', 'ridge_regression', 'decision_tree',\n",
       "                    'decision_tree', 'random_forest', 'decision_tree',\n",
       "                    'ridge_regression', 'ridge_regression',\n",
       "                    'gaussian_process', 'ridge_regression', 'extra_trees',\n",
       "                    'ridge_regression', 'ridge_regression',\n",
       "                    'ridge_regression', 'decision_tree', 'decision_tree',\n",
       "                    'random_forest', 'k_nearest_neighbors'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U19'),\n",
       " 'param_data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': masked_array(data=[0.01, --, --, --, --, 0.0011679258777861955, --,\n",
       "                    0.0006988218955545649, --, --, 0.005682022063001382,\n",
       "                    0.0009298748419912689, 0.00013879650933019193, --,\n",
       "                    0.00016213197545826907, 0.013363138290388014,\n",
       "                    0.1909928329387177, 0.0002967529383081362,\n",
       "                    0.00015684662078155833, 0.07390120164542405,\n",
       "                    0.09178868574434537, 0.3576171257664492, --, --,\n",
       "                    0.0966475757611034, --, --, 0.004051161203697263,\n",
       "                    0.0026723628332913215, 0.0033035980008628064,\n",
       "                    0.06168018197582326, 0.45208205650974276, --,\n",
       "                    0.0002936424716414241, --, --, 0.00011883517326313243,\n",
       "                    0.012511082513128205, --, --, 0.00026614849041013905,\n",
       "                    --, --, 0.0018426246803094804, 0.06908285889290702,\n",
       "                    0.13747485305343582, 0.010540728968686353,\n",
       "                    0.0018161796291229762, --, 0.3169504448474022,\n",
       "                    0.014289469344544552, 0.0404755789329183,\n",
       "                    0.0038073363161950126, 0.0004849060790770139,\n",
       "                    0.0027945067330199594, 0.018237795813167968, --, --,\n",
       "                    0.2327663189643284, 0.00015977807530727866,\n",
       "                    0.2545530201786845, 0.00038825387382819814, --, --,\n",
       "                    0.00014942294630736707, --, 0.010000000000000004,\n",
       "                    0.08876488298149353, --, 0.04155487164663673, --, --,\n",
       "                    0.0002145882041254209, 0.0012837019682791723, --, --,\n",
       "                    --, 0.007848244270198477, --, --,\n",
       "                    0.0055580993593109486, --, --, --,\n",
       "                    0.014554240633797177, --, 0.010000000000000004, --, --,\n",
       "                    --, --, 0.00266932594699517, 0.3548933343030698,\n",
       "                    0.006390402476840058, 0.00659498797437954,\n",
       "                    0.007689619853255995, 0.00026839176367698193,\n",
       "                    0.017152202203432405, --, --, --, --,\n",
       "                    0.06419067360160154, --, --, --, --, --, --, --, --,\n",
       "                    0.0180455794722024, 0.28863258504082207, --,\n",
       "                    0.019813872852303883, 0.4813623710978043, --, --,\n",
       "                    0.00013796288226023464, --, --, 0.0008659359897684668,\n",
       "                    --, --, --, --, --, 0.0007575433512626152, --, --,\n",
       "                    0.023953027463529022, 0.0002063381820949854,\n",
       "                    0.0001420570513136922, --, 0.06637252513062747, --, --,\n",
       "                    --, --, 0.13747485305343582, --, 0.0007633507253520759,\n",
       "                    0.00046356607595790734, --, 0.007354995702224433,\n",
       "                    0.08619203130962694, 0.00013999336176564157,\n",
       "                    0.000770155102090166, --, --, --, --,\n",
       "                    0.0007608753407517968, 0.0036452204756717314,\n",
       "                    0.08186446417051273, --, --, --, --, --,\n",
       "                    0.000150400778920533, --, --, --, --, --, --, --,\n",
       "                    0.010180235185225369, 0.14592003194082992, --,\n",
       "                    0.004319599169227568, --, 0.24031633400825428, --, --,\n",
       "                    0.08057940058549941, 0.02856878828343338,\n",
       "                    0.0034942135860504056, --, 0.005927799138355616,\n",
       "                    0.35400005770330456, 0.0003716964677931218, --, --, --,\n",
       "                    --, 0.0007028517599287743, 0.0020262016484419504, --,\n",
       "                    0.00046070159490080634, --, 0.010000000000000004,\n",
       "                    0.007429386425622277, --, --, 0.0022450817024126787,\n",
       "                    0.12561018629189794, 0.0001463764430038483, --,\n",
       "                    0.08157340478207341, 0.0003764164133044991,\n",
       "                    0.05514391375574247, --, --, --, 0.4786436354310186,\n",
       "                    0.0020682810998537034, --, --, 0.006173676939667257,\n",
       "                    --, --, 0.0010671792729195077, 0.00012091939650286628,\n",
       "                    0.06196173438148183, 0.0005161305611197287,\n",
       "                    0.05483118632501047, --, --, 0.43100382381130314,\n",
       "                    0.007973200158774592, 0.0029591466452595395,\n",
       "                    0.0006988462903025105, 0.10421338213740242, --, --,\n",
       "                    0.010000000000000004, 0.00028887210695479037,\n",
       "                    0.004476220621903362, 0.062121248260352965,\n",
       "                    0.009033997425806675, --, --, --,\n",
       "                    0.00012479807854604748, --, --, --,\n",
       "                    0.0003632678247218346, --, --, 0.00019002053866005197,\n",
       "                    --, --, 0.00010715172211538464, --,\n",
       "                    0.0002901645474864113, 0.10639196545783305, --,\n",
       "                    0.0014909345096524203, 0.025548043997448398, --,\n",
       "                    0.0003716964677931218, 0.004047978636383022,\n",
       "                    0.00028569994555173727, --, 0.008799331638525625, --,\n",
       "                    --, 0.0014271516277145012, 0.0011928275630544527,\n",
       "                    0.021563947990760116, 0.00022146892093146694,\n",
       "                    0.011385771470125237, 0.03859930660423184,\n",
       "                    0.09564404749750208, --, 0.012638359593789946,\n",
       "                    0.010052223119252758, --, --, 0.07879610577774053,\n",
       "                    0.10418489224578882, --, 0.49064881720542597, --, --,\n",
       "                    --, --, 0.0001438613287213223, 0.0002492442357284328,\n",
       "                    --, --, 0.10421338213740242, 0.004990226253109335,\n",
       "                    0.000784435423393073, --, --, 0.0011168522113585097,\n",
       "                    --, --, --, 0.023093832466276075, --,\n",
       "                    0.00029370169512781967, 0.021816031177318205, --,\n",
       "                    0.37682392740815973, 0.007322903535438241,\n",
       "                    0.010000000000000004, --, 0.260129158166899,\n",
       "                    0.0003195319695087046, --, 0.002521962058923429,\n",
       "                    0.012588534853704928, --, 0.0010630543004591941, --,\n",
       "                    0.0439086270577992, 0.35723264496284374, --, --,\n",
       "                    0.00336496001864943, 0.002821421944770932,\n",
       "                    0.01544267551439805, --, --, --, 0.0032794633885843924,\n",
       "                    0.06366258623263053, --, --, 0.0004468765073505084, --,\n",
       "                    0.026044985375436185, --, --, 0.0001718497008114841,\n",
       "                    --, --, --, --, --, 0.012013505909777747,\n",
       "                    0.01662874282724904, 0.007853878754401786,\n",
       "                    0.03534289330072045, --, --, 0.04322070056066017,\n",
       "                    0.0020558876427027844, 0.07592442868373174,\n",
       "                    0.017634785889832975, --, --, --, 0.11057673813850036,\n",
       "                    0.015744149885732764, 0.010000000000000004, --, --,\n",
       "                    0.00012174765558134549, --, --, --, --, --, --, --,\n",
       "                    0.16829727897592697, 0.0008775667452956317, --,\n",
       "                    0.009899104164600468, 0.0006645809387556937, --,\n",
       "                    0.0001599712226727595, --, 0.001273556700162062, --,\n",
       "                    --, --, --, 0.010000000000000004, 0.010000000000000004,\n",
       "                    0.015887123013573957, --, --, 0.0005803029973239006,\n",
       "                    0.00036595588380562797, --, 0.0035592579605266865,\n",
       "                    0.020560740057632115, 0.035836609584578204, --, --,\n",
       "                    0.010000000000000004, 0.00020284734326099372, --,\n",
       "                    0.003060463436258844, --, 0.0010997898561207458,\n",
       "                    0.01828333906048363, 0.00016378513464383534, --, --,\n",
       "                    0.010000000000000004, 0.0014176666535513913, --,\n",
       "                    0.010000000000000004, --, --, 0.0007756552564797616,\n",
       "                    --, 0.01001898919504183, --, 0.013185624665190366,\n",
       "                    0.014724727068666104, 0.0030937694831475212, --, --,\n",
       "                    --, --, --, --, --, --, 0.005183309725112972, --,\n",
       "                    0.05778916008155639, 0.010000000000000004,\n",
       "                    0.01500515679370262, 0.00018538820693064285,\n",
       "                    0.04444420818955184, --, --, 0.0003343100916263923,\n",
       "                    0.0016948493792745027, 0.010000000000000004, --,\n",
       "                    0.013817696045440113, 0.1323908519395911,\n",
       "                    0.025620792282258106, 0.037326390700312746,\n",
       "                    0.010000000000000004, 0.008883058472847306,\n",
       "                    0.012323951497783044, 0.13084232819892555, --,\n",
       "                    0.010541768693793191, --, 0.01885219760844167, --, --,\n",
       "                    0.006569780631001458, 0.0006343362508350629,\n",
       "                    0.0020060258832198604, --, 0.08500052980176674,\n",
       "                    0.3685016664496277, 0.013469646219280061, --, --,\n",
       "                    0.009946753530732424, 0.010000000000000004,\n",
       "                    0.0032473898378729232, --, --, 0.06902978010803223, --,\n",
       "                    0.1434005754234265, --, 0.025193100805516514, --, --,\n",
       "                    0.005790299266525619, 0.013805634667067931,\n",
       "                    0.05390758274587074, --, --, 0.07552250200895949,\n",
       "                    0.010355500369750041, 0.010000000000000004,\n",
       "                    0.000410254772168443, 0.010000000000000004,\n",
       "                    0.00270981961172123, --, 0.004269707917048525, --,\n",
       "                    0.008398452093321887, 0.12529210179600336,\n",
       "                    0.010000000000000004, --, --, 0.00033859749554948523,\n",
       "                    --, 0.01077968821505551, --, --, 0.010000000000000004,\n",
       "                    --, 0.02849258178585786, --, 0.010000000000000004,\n",
       "                    0.00011756728384766398, --, --, --, --, --, --, --,\n",
       "                    0.02562409097925195, --, 0.01122733703689284, --, --,\n",
       "                    --, --, 0.010000000000000004, 0.006410354061162064,\n",
       "                    0.029489164983027102, --, --, 0.0005265986887423441,\n",
       "                    --, 0.010000000000000004, --, --, --,\n",
       "                    0.008768177166989926, --, 0.0014848635051257285, --,\n",
       "                    --, --, 0.006550501726982547, --, --, --, --,\n",
       "                    0.15106317403639516, 0.001108863558075038,\n",
       "                    0.007846203966688501, 0.002938516586801615,\n",
       "                    0.011275045344616848, 0.010000000000000004,\n",
       "                    0.033685758129419895, 0.010000000000000004, --,\n",
       "                    0.010000000000000004, 0.05983964446895691, --,\n",
       "                    0.006027654515169864, --, --, 0.017300374836288546, --,\n",
       "                    --, 0.0018211780063896173, --, 0.011259155658237721,\n",
       "                    0.010000000000000004, 0.010000000000000004,\n",
       "                    0.010000000000000004, --, --, --, --,\n",
       "                    0.0027471434287859656, 0.0218733515154605,\n",
       "                    0.0018555336543965256, 0.005884733209346914, --, --,\n",
       "                    0.006027654515169864, --, --, 0.00951353963865729, --,\n",
       "                    --, 0.0002369084187893479, 0.2754038569213427, --, --,\n",
       "                    --, --, 0.01899385549390604, 0.10956192212406607, --,\n",
       "                    --, 0.005780987281674802, --, 0.07272976847860436,\n",
       "                    0.010000000000000004, --, 0.010000000000000004,\n",
       "                    0.010000000000000004, --, 0.010000000000000004,\n",
       "                    0.1871570590663185, --, --, 0.08055468923764997, --,\n",
       "                    --, --, 0.005627475185664159, --, 0.13927016029843128,\n",
       "                    --, 0.010000000000000004, 0.010000000000000004, --,\n",
       "                    0.0023235548876410802, --, --, 0.002111526563738924,\n",
       "                    0.0017269038673268613, 0.010000000000000004, --,\n",
       "                    0.010000000000000004, 0.20162193319610308, --,\n",
       "                    0.018453090836748825, --, --, --,\n",
       "                    0.0005805623196997207, --, --, --, --,\n",
       "                    0.014118098676106361, --, 0.0015064661654205429, --,\n",
       "                    --, 0.0001095336956261282, --, 0.01737714353009772, --,\n",
       "                    0.014319520212407266, 0.010000000000000004,\n",
       "                    0.09763474303149837, --, 0.00025091188672654775, --,\n",
       "                    --, 0.18570881887925805, --, 0.007894244932946999, --,\n",
       "                    --, --, 0.00023914386522372165, 0.004146239349465869,\n",
       "                    0.0002204795318982361, --, --, 0.022652974628814743,\n",
       "                    0.010000000000000004, --, 0.006496772904799362,\n",
       "                    0.03944114027417628, --, --, --, 0.008186319173022184,\n",
       "                    --, --, --, 0.26540040582896884, --,\n",
       "                    0.12166657203197262, --, 0.006255941853967279, --, --,\n",
       "                    0.2989334051027104, 0.18400903141508013,\n",
       "                    0.0066074476363156085, --, --, --, --, --,\n",
       "                    0.009742722992167333, 0.014621998251212756, --,\n",
       "                    0.00986946307686489, 0.00020779167165397306, --,\n",
       "                    0.00725999714957756, --, 0.008467994796513523, --,\n",
       "                    0.0002861831418601615, 0.1515479423796738,\n",
       "                    0.0014151252818318148, 0.0006003193463352382, --,\n",
       "                    0.20381603805722381, 0.012104360763673319, --,\n",
       "                    0.018712580313950948, 0.017249412165815, --, --, --,\n",
       "                    0.014892372593959171, --, 0.014716143126183596, --,\n",
       "                    0.0018332432953504477, 0.0018289178525884517, --, --,\n",
       "                    --, 0.010000000000000004, 0.003660565738180404,\n",
       "                    0.012353485693373037, --, 0.012335662371861572,\n",
       "                    0.008464172832296692, --, --, 0.013804434275468664, --,\n",
       "                    0.0050519961811117285, --, --, 0.012969796256549726,\n",
       "                    --, --, 0.000160824991752583, 0.36291870319206165,\n",
       "                    0.4524623305805776, 0.04762953879359764, --, --, --,\n",
       "                    --, 0.03723592362818503, 0.008785254763629619,\n",
       "                    0.010000000000000004, 0.000558480922539938,\n",
       "                    0.008633035343640879, 0.010000000000000004,\n",
       "                    0.1279734392045744, 0.014632852475471763, --,\n",
       "                    0.0070568383297004225, 0.01659481449656538,\n",
       "                    0.00025708838772162725, --, 0.00013253081079516495,\n",
       "                    0.00019961290750915517, --, 0.015212025186817317, --,\n",
       "                    --, --, 0.0016259940077042803, --,\n",
       "                    0.010000000000000004, --, --, --],\n",
       "              mask=[False,  True,  True,  True,  True, False,  True, False,\n",
       "                     True,  True, False, False, False,  True, False, False,\n",
       "                    False, False, False, False, False, False,  True,  True,\n",
       "                    False,  True,  True, False, False, False, False, False,\n",
       "                     True, False,  True,  True, False, False,  True,  True,\n",
       "                    False,  True,  True, False, False, False, False, False,\n",
       "                     True, False, False, False, False, False, False, False,\n",
       "                     True,  True, False, False, False, False,  True,  True,\n",
       "                    False,  True, False, False,  True, False,  True,  True,\n",
       "                    False, False,  True,  True,  True, False,  True,  True,\n",
       "                    False,  True,  True,  True, False,  True, False,  True,\n",
       "                     True,  True,  True, False, False, False, False, False,\n",
       "                    False, False,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                    False,  True, False, False,  True,  True, False,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True, False, False, False,  True, False,  True,\n",
       "                     True,  True,  True, False,  True, False, False,  True,\n",
       "                    False, False, False, False,  True,  True,  True,  True,\n",
       "                    False, False, False,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False, False,  True, False,  True, False,  True,  True,\n",
       "                    False, False, False,  True, False, False, False,  True,\n",
       "                     True,  True,  True, False, False,  True, False,  True,\n",
       "                    False, False,  True,  True, False, False, False,  True,\n",
       "                    False, False, False,  True,  True,  True, False, False,\n",
       "                     True,  True, False,  True,  True, False, False, False,\n",
       "                    False, False,  True,  True, False, False, False, False,\n",
       "                    False,  True,  True, False, False, False, False, False,\n",
       "                     True,  True,  True, False,  True,  True,  True, False,\n",
       "                     True,  True, False,  True,  True, False,  True, False,\n",
       "                    False,  True, False, False,  True, False, False, False,\n",
       "                     True, False,  True,  True, False, False, False, False,\n",
       "                    False, False, False,  True, False, False,  True,  True,\n",
       "                    False, False,  True, False,  True,  True,  True,  True,\n",
       "                    False, False,  True,  True, False, False, False,  True,\n",
       "                     True, False,  True,  True,  True, False,  True, False,\n",
       "                    False,  True, False, False, False,  True, False, False,\n",
       "                     True, False, False,  True, False,  True, False, False,\n",
       "                     True,  True, False, False, False,  True,  True,  True,\n",
       "                    False, False,  True,  True, False,  True, False,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True, False,\n",
       "                    False, False, False,  True,  True, False, False, False,\n",
       "                    False,  True,  True,  True, False, False, False,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False, False,  True, False, False,  True, False,\n",
       "                     True, False,  True,  True,  True,  True, False, False,\n",
       "                    False,  True,  True, False, False,  True, False, False,\n",
       "                    False,  True,  True, False, False,  True, False,  True,\n",
       "                    False, False, False,  True,  True, False, False,  True,\n",
       "                    False,  True,  True, False,  True, False,  True, False,\n",
       "                    False, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True, False, False, False, False,\n",
       "                    False,  True,  True, False, False, False,  True, False,\n",
       "                    False, False, False, False, False, False, False,  True,\n",
       "                    False,  True, False,  True,  True, False, False, False,\n",
       "                     True, False, False, False,  True,  True, False, False,\n",
       "                    False,  True,  True, False,  True, False,  True, False,\n",
       "                     True,  True, False, False, False,  True,  True, False,\n",
       "                    False, False, False, False, False,  True, False,  True,\n",
       "                    False, False, False,  True,  True, False,  True, False,\n",
       "                     True,  True, False,  True, False,  True, False, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True, False,  True,  True,  True,  True, False, False,\n",
       "                    False,  True,  True, False,  True, False,  True,  True,\n",
       "                     True, False,  True, False,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True, False, False, False, False,\n",
       "                    False, False, False, False,  True, False, False,  True,\n",
       "                    False,  True,  True, False,  True,  True, False,  True,\n",
       "                    False, False, False, False,  True,  True,  True,  True,\n",
       "                    False, False, False, False,  True,  True, False,  True,\n",
       "                     True, False,  True,  True, False, False,  True,  True,\n",
       "                     True,  True, False, False,  True,  True, False,  True,\n",
       "                    False, False,  True, False, False,  True, False, False,\n",
       "                     True,  True, False,  True,  True,  True, False,  True,\n",
       "                    False,  True, False, False,  True, False,  True,  True,\n",
       "                    False, False, False,  True, False, False,  True, False,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                    False,  True, False,  True,  True, False,  True, False,\n",
       "                     True, False, False, False,  True, False,  True,  True,\n",
       "                    False,  True, False,  True,  True,  True, False, False,\n",
       "                    False,  True,  True, False, False,  True, False, False,\n",
       "                     True,  True,  True, False,  True,  True,  True, False,\n",
       "                     True, False,  True, False,  True,  True, False, False,\n",
       "                    False,  True,  True,  True,  True,  True, False, False,\n",
       "                     True, False, False,  True, False,  True, False,  True,\n",
       "                    False, False, False, False,  True, False, False,  True,\n",
       "                    False, False,  True,  True,  True, False,  True, False,\n",
       "                     True, False, False,  True,  True,  True, False, False,\n",
       "                    False,  True, False, False,  True,  True, False,  True,\n",
       "                    False,  True,  True, False,  True,  True, False, False,\n",
       "                    False, False,  True,  True,  True,  True, False, False,\n",
       "                    False, False, False, False, False, False,  True, False,\n",
       "                    False, False,  True, False, False,  True, False,  True,\n",
       "                     True,  True, False,  True, False,  True,  True,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': masked_array(data=[--, --, --, 792.0, --, --, --, --, --, 563.0, --, --,\n",
       "                    --, --, --, --, --, --, --, 1167.0, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 1114.0, 1230.0, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 996.0, --, --, --, --, --, --, --, --, --, --,\n",
       "                    913.0, --, --, 1000.0, --, --, 1189.0, 1494.0, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 1824.0, --, --, --, --, --,\n",
       "                    1115.0, --, --, --, 1144.0, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 691.0, --, --, --,\n",
       "                    --, --, 1301.0, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 1862.0, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, 1962.0, --, --,\n",
       "                    --, --, --, 1541.0, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 363.0, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 354.0, --, --, --, --, --, --, --, 1620.0, --, --,\n",
       "                    --, --, --, --, --, --, --, 1000.0, --, --, --, --, --,\n",
       "                    --, --, 1502.0, --, --, --, --, 329.0, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, 606.0, --, --,\n",
       "                    --, 1673.0, --, --, --, --, --, --, 917.0, 60.0, --,\n",
       "                    --, --, 1000.0, 1040.0, --, --, --, --, --, --, 1323.0,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    920.0, 1856.0, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 708.0, --, 632.0, --, --, --, --,\n",
       "                    337.0, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 1189.0, --, 468.0, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 36.0, 1034.0, 996.0, --, 592.0, --, --, --, --,\n",
       "                    --, --, --, 1245.0, --, --, 1954.0, 1698.0, --, --, --,\n",
       "                    --, 1000.0, 763.0, --, --, --, --, --, --, --, --,\n",
       "                    1585.0, --, 807.0, --, --, 1950.0, --, 427.0, 1435.0,\n",
       "                    --, 1579.0, --, --, --, 1130.0, 1698.0, --, 1777.0, --,\n",
       "                    --, --, --, --, --, --, --, 1887.0, --, --, 1035.0, --,\n",
       "                    --, --, --, 977.0, --, --, 1000.0, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 1000.0, 731.0, 1961.0, --,\n",
       "                    --, 1388.0, --, --, --, --, --, --, --, --, 501.0, --,\n",
       "                    1000.0, --, --, 1896.0, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 717.0, --, --, 1000.0, --, --, 940.0, --,\n",
       "                    --, --, 1000.0, --, --, --, 1951.0, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 864.0, --, --, --, --, --, --,\n",
       "                    1026.0, 138.0, --, --, 353.0, --, --, --, 1762.0, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    1692.0, 1673.0, --, 774.0, --, --, 704.0, --, 1000.0,\n",
       "                    852.0, --, --, --, --, --, --, 1751.0, 1085.0, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 1000.0, --, --, 78.0, --, --, --, 1000.0,\n",
       "                    --, --, --, --, --, --, 1848.0, 1894.0, --, 271.0, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, 1210.0, --,\n",
       "                    --, --, --, --, --, --, --, 476.0, 438.0, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    331.0, --, 38.0, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 505.0, --, --, --, --, --, --, --,\n",
       "                    1201.0, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    1000.0, --, --, --, --, --, --, --, --, 1850.0, --, --,\n",
       "                    --, --, 997.0, --, --, --, 320.0, --, --, 59.0, --, --,\n",
       "                    --, --, --, --, --, 1103.0, --, --, --, --, --, --, --,\n",
       "                    --, 1485.0, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 1941.0, --, --, --, --, --, --, --, --, 167.0, --,\n",
       "                    1730.0, 1048.0, --, --, --, --, 1339.0, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 1754.0, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                    False,  True,  True, False, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True, False, False,  True,  True,  True,\n",
       "                    False, False,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True, False,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False, False, False,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                    False, False,  True,  True,  True,  True, False, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True, False,  True,  True, False,  True, False,\n",
       "                    False,  True, False,  True,  True,  True, False, False,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True, False,  True,  True,\n",
       "                     True,  True, False,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False, False, False,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True, False,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True, False,  True,  True, False,\n",
       "                     True,  True,  True, False,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True, False, False,  True,  True, False,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False, False,  True, False,  True,  True,\n",
       "                    False,  True, False, False,  True,  True,  True,  True,\n",
       "                     True,  True, False, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True, False,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True, False, False,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True, False,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                    False, False,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': masked_array(data=[--, --, --, 'normal', --, --, --, --, --, 'uniform',\n",
       "                    --, --, --, --, --, --, --, --, --, 'normal', --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 'uniform', 'uniform', --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 'uniform', --, --, --, --, --,\n",
       "                    --, --, --, --, --, 'normal', --, --, 'normal', --, --,\n",
       "                    'uniform', 'uniform', --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    'normal', --, --, --, --, --, 'uniform', --, --, --,\n",
       "                    'uniform', --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 'normal', --, --, --, --, --,\n",
       "                    'normal', --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 'uniform', --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, 'normal', --,\n",
       "                    --, --, --, --, 'normal', --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 'normal', --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 'uniform', --, --, --, --, --, --, --,\n",
       "                    'normal', --, --, --, --, --, --, --, --, --, 'normal',\n",
       "                    --, --, --, --, --, --, --, 'uniform', --, --, --, --,\n",
       "                    'normal', --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 'uniform', --, --, --, 'normal', --, --,\n",
       "                    --, --, --, --, 'normal', 'uniform', --, --, --,\n",
       "                    'normal', 'normal', --, --, --, --, --, --, 'uniform',\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    'uniform', 'normal', --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 'normal', --, 'normal', --,\n",
       "                    --, --, --, 'uniform', --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 'normal', --, 'normal', --, --, --,\n",
       "                    --, --, --, --, --, --, --, 'uniform', 'normal',\n",
       "                    'normal', --, 'normal', --, --, --, --, --, --, --,\n",
       "                    'uniform', --, --, 'normal', 'uniform', --, --, --, --,\n",
       "                    'uniform', 'normal', --, --, --, --, --, --, --, --,\n",
       "                    'normal', --, 'uniform', --, --, 'uniform', --,\n",
       "                    'normal', 'normal', --, 'normal', --, --, --, 'normal',\n",
       "                    'normal', --, 'normal', --, --, --, --, --, --, --, --,\n",
       "                    'normal', --, --, 'uniform', --, --, --, --, 'normal',\n",
       "                    --, --, 'normal', --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 'normal', 'uniform', 'uniform', --, --,\n",
       "                    'uniform', --, --, --, --, --, --, --, --, 'normal',\n",
       "                    --, 'uniform', --, --, 'uniform', --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 'uniform', --, --, 'uniform',\n",
       "                    --, --, 'uniform', --, --, --, 'uniform', --, --, --,\n",
       "                    'normal', --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    'normal', --, --, --, --, --, --, 'normal', 'normal',\n",
       "                    --, --, 'uniform', --, --, --, 'uniform', --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    'uniform', 'normal', --, 'uniform', --, --, 'uniform',\n",
       "                    --, 'uniform', 'uniform', --, --, --, --, --, --,\n",
       "                    'normal', 'uniform', --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, 'normal',\n",
       "                    --, --, 'uniform', --, --, --, 'uniform', --, --, --,\n",
       "                    --, --, --, 'uniform', 'normal', --, 'uniform', --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, 'normal', --,\n",
       "                    --, --, --, --, --, --, --, 'uniform', 'normal', --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 'uniform', --, 'uniform', --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 'normal', --, --, --, --,\n",
       "                    --, --, --, 'normal', --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 'uniform', --, --, --, --, --, --, --, --,\n",
       "                    'normal', --, --, --, --, 'uniform', --, --, --,\n",
       "                    'normal', --, --, 'uniform', --, --, --, --, --, --,\n",
       "                    --, 'normal', --, --, --, --, --, --, --, --,\n",
       "                    'uniform', --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 'normal', --, --, --, --, --, --, --, --,\n",
       "                    'uniform', --, 'uniform', 'uniform', --, --, --, --,\n",
       "                    'uniform', --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 'uniform', --, --, --,\n",
       "                    --, --],\n",
       "              mask=[ True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                    False,  True,  True, False, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True, False, False,  True,  True,  True,\n",
       "                    False, False,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True, False,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False, False, False,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                    False, False,  True,  True,  True,  True, False, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True, False,  True,  True, False,  True, False,\n",
       "                    False,  True, False,  True,  True,  True, False, False,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True, False,  True,  True,\n",
       "                     True,  True, False,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False, False, False,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True, False,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True, False,  True,  True, False,\n",
       "                     True,  True,  True, False,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True, False, False,  True,  True, False,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False, False,  True, False,  True,  True,\n",
       "                    False,  True, False, False,  True,  True,  True,  True,\n",
       "                     True,  True, False, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True, False,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True, False, False,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True, False,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                    False, False,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U32'),\n",
       " 'param_data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': masked_array(data=[--, --, --, --, 0.9922478571006341, --,\n",
       "                    0.857856422838131, --, --, --, 0.8308440801417805, --,\n",
       "                    --, --, 0.8287644412071582, 0.8122675946384508, --, --,\n",
       "                    0.8793811923717466, --, --, --, 0.7029373207705987, --,\n",
       "                    --, --, --, --, 0.8171729658747383, 0.7172523673281742,\n",
       "                    0.7417696923339766, --, 0.8972032234584776, --, --, --,\n",
       "                    --, --, --, --, 0.8610406631913199, --, --,\n",
       "                    0.8684798635168272, --, --, --, --, --,\n",
       "                    0.9665152097370466, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 0.7311257127724968, --,\n",
       "                    0.9793562442982197, --, --, --, 0.9310271164513015, --,\n",
       "                    --, --, --, --, --, --, 0.9065478212865403, --,\n",
       "                    0.9341735249977134, 0.9513880535742931, --, --,\n",
       "                    0.99389801951307, 0.7654178018743998,\n",
       "                    0.7638704337309284, 0.7311132038720384, --,\n",
       "                    0.7380069422556008, --, 0.8643024280228802, --, --, --,\n",
       "                    --, --, --, 0.9301896779725476, --, 0.7339570009058797,\n",
       "                    0.9032659210517124, --, --, --, --, --, --, --, --,\n",
       "                    0.8586520108194636, 0.897100253720673, --,\n",
       "                    0.8972032234584776, --, --, --, --, --, --,\n",
       "                    0.8230042618470891, --, --, --, --, --,\n",
       "                    0.9928212613657226, --, --, --, --, --, --, --,\n",
       "                    0.8843830207422064, --, --, --, --, --, --, --, --, --,\n",
       "                    0.9015835219562789, 0.9253400137923409, --,\n",
       "                    0.9495886119958568, --, --, --, --, --, --,\n",
       "                    0.994240117077666, 0.7778893534208513,\n",
       "                    0.7877811394544847, --, --, --, --, --, --,\n",
       "                    0.7488127839730384, --, --, --, --, 0.9691319259445099,\n",
       "                    0.8654827146186823, --, --, 0.9773821063827329, --, --,\n",
       "                    --, 0.9876785539653535, --, --, --, --,\n",
       "                    0.7699524097253767, 0.8865711283077852, --, --, --, --,\n",
       "                    0.9123680645131744, --, 0.8419958127490841, --,\n",
       "                    0.8456284235373617, --, --, --, --, --, --, --, --, --,\n",
       "                    0.9799969570212033, --, --, 0.7444986868057768, --, --,\n",
       "                    --, --, --, --, 0.9249905869456366, --, --,\n",
       "                    0.8504663111546336, --, --, --, --, 0.9799815835215617,\n",
       "                    --, --, --, 0.9510986742123887, 0.8596583537302948, --,\n",
       "                    --, --, --, --, --, 0.896637925108655, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --,\n",
       "                    0.9043393121361277, 0.9588519272296614, --,\n",
       "                    0.8693483750824091, --, 0.8418617159378143, --, --,\n",
       "                    0.8880567208364974, --, 0.7156389413251741, --, --, --,\n",
       "                    0.9135968550931912, 0.9844936301785254,\n",
       "                    0.817729452826626, --, --, --, --, --, --, --, --,\n",
       "                    0.8903197640685494, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 0.75, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 0.8947099494671126, --, --, --, --, --,\n",
       "                    0.970876983419237, --, --, --, --, --, --, --,\n",
       "                    0.8443605873552952, --, --, 0.8856440305944182, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    0.8702359174824481, 0.8768323903177886, --, 0.75,\n",
       "                    0.7077248045482851, --, --, --, --, --, --, --,\n",
       "                    0.8880083492132396, --, --, --, 0.7977441289934386, --,\n",
       "                    --, --, --, 0.7229401741687728, --, --, --, --, --,\n",
       "                    0.9799594655018546, --, 0.9323255106403481, --, --, --,\n",
       "                    --, --, --, --, 0.7640834605671735, 0.9507573906123465,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    0.9459425804708814, 0.8108763652380688, --,\n",
       "                    0.8661642155759056, --, --, 0.9618990325089025, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 0.7412676164281848, --,\n",
       "                    0.8040112525353373, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 0.8959795570001804, --, --,\n",
       "                    0.9370820777316549, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 0.8500812129314648, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    0.885088887798665, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    0.8439525743396612, --, 0.7477774669138393, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 0.7304550645476362,\n",
       "                    --, --, 0.7753010563913649, --, --, --, --,\n",
       "                    0.902028671957767, --, 0.9195013191720424, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    0.7915149211502199, --, --, --, --, --,\n",
       "                    0.738764261831867, --, --, --, 0.75, --,\n",
       "                    0.738764261831867, --, --, --, 0.7746216785482053,\n",
       "                    0.780343741943795, --, --, --, 0.9098448734814497, --,\n",
       "                    --, --, --, 0.7481878625050032, --, --, --, --, --, --,\n",
       "                    --, 0.7227202551678057, 0.7270790412529332, --,\n",
       "                    0.7304550645476362, --, 0.8087315791376788, --,\n",
       "                    0.7776800517641831, --, --, --, --, 0.7445804780442575,\n",
       "                    --, --, --, --, --, --, --, --, 0.9116613950593239,\n",
       "                    0.7373247930071872, --, --, --, --, --, --, --,\n",
       "                    0.751975962159151, --, --, --, --, --,\n",
       "                    0.7465470445622455, --, --, --, --, --, --, --, --,\n",
       "                    0.75, 0.9611096604346405, --, 0.8140981978481444,\n",
       "                    0.7621792193918887, --, --, 0.8167931239567504, --,\n",
       "                    0.7445804780442575, --, --, 0.75, 0.75, --, --, --, --,\n",
       "                    --, --, --, 0.731326699017324, --, 0.821474018162524,\n",
       "                    --, --, --, --, --, --, --, --, 0.7315552302558921, --,\n",
       "                    --, --, --, 0.75, --, --, --, 0.892502672819558, --,\n",
       "                    --, 0.7093188758108241, --, --, --, --,\n",
       "                    0.869712378458591, --, --, --, --, 0.7311214704748964,\n",
       "                    --, 0.7039736664417388, --, 0.8979119156850172, --, --,\n",
       "                    --, --, 0.9287261986027422, --, --, --, --, --,\n",
       "                    0.7380005803120351, --, --, 0.7407866239121179, --, --,\n",
       "                    --, --, --, 0.8425443861561539, --, --,\n",
       "                    0.7730454986918359, 0.7395519899017703, 0.75,\n",
       "                    0.7379072083384061, --, --, --, 0.7484657809567563,\n",
       "                    0.7190818190512768, 0.740561525385529, 0.75, --,\n",
       "                    0.7579859599648943, 0.8760082641689639, --, --, --, --,\n",
       "                    --, 0.7388961881420202, 0.7334909115371182, --, 0.75,\n",
       "                    --, --, --, --, --, --, --, --, --, --, 0.75,\n",
       "                    0.8864341844505392, 0.8221040153636954,\n",
       "                    0.7111922913491919, --, 0.8840669730472948, --, --, --,\n",
       "                    --, --, --, 0.7553632809503082, 0.7360149811711411,\n",
       "                    0.7238063532950466, --],\n",
       "              mask=[ True,  True,  True,  True, False,  True, False,  True,\n",
       "                     True,  True, False,  True,  True,  True, False, False,\n",
       "                     True,  True, False,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True, False, False, False,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True, False,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True, False, False,  True,  True, False, False, False,\n",
       "                    False,  True, False,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True, False, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                    False,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False, False,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True, False, False, False,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True, False, False,  True,  True, False,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True, False, False,\n",
       "                     True,  True,  True,  True, False,  True, False,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True, False,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                    False, False,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                    False,  True, False,  True, False,  True,  True, False,\n",
       "                     True, False,  True,  True,  True, False, False, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False, False,  True, False, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True, False,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False, False,  True, False,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True, False,  True,  True,  True,  True, False,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True, False,  True, False,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False, False,  True, False,  True, False,  True,\n",
       "                    False,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False, False,\n",
       "                     True, False, False,  True,  True, False,  True, False,\n",
       "                     True,  True, False, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True, False,\n",
       "                     True,  True, False,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True, False,  True, False,  True,\n",
       "                    False,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True, False,\n",
       "                    False, False, False,  True,  True,  True, False, False,\n",
       "                    False, False,  True, False, False,  True,  True,  True,\n",
       "                     True,  True, False, False,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False, False, False, False,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True, False, False, False,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': masked_array(data=[--, --, --, --, 0.28916478076740876, --,\n",
       "                    0.16270327064031528, --, --, --, 0.0010487218901351699,\n",
       "                    --, --, --, 0.0461766024960606, 0.15400195951322834,\n",
       "                    --, --, 0.14571265895719981, --, --, --,\n",
       "                    0.19089509441218294, --, --, --, --, --,\n",
       "                    0.17269988075066917, 0.2626282879753452,\n",
       "                    0.11908259577495996, --, 0.12071545121478301, --, --,\n",
       "                    --, --, --, --, --, 0.2823605861179491, --, --,\n",
       "                    0.12335387053501023, --, --, --, --, --,\n",
       "                    0.15515031093647985, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 0.2413907755972501, --,\n",
       "                    0.24121833094677253, --, --, --, 0.05500322145529406,\n",
       "                    --, --, --, --, --, --, --, 0.0942543401396613, --,\n",
       "                    0.03751803716434402, 0.2626839624374468, --, --,\n",
       "                    0.21619345035356985, 0.25, 0.25, 0.2910568673177784,\n",
       "                    --, 0.23384526404551378, --, 0.2487694008353517, --,\n",
       "                    --, --, --, --, --, 0.12271156833480264, --,\n",
       "                    0.14689789754639004, 0.18234068612159854, --, --, --,\n",
       "                    --, --, --, --, --, 0.23827040785053913,\n",
       "                    0.2871414091901358, --, 0.1280817535223777, --, --, --,\n",
       "                    --, --, --, 0.10921310213023767, --, --, --, --, --,\n",
       "                    0.25185752642666553, --, --, --, --, --, --, --,\n",
       "                    0.10109348249580129, --, --, --, --, --, --, --, --,\n",
       "                    --, 0.19091094237779277, 0.25760829328798157, --,\n",
       "                    0.138650334421375, --, --, --, --, --, --,\n",
       "                    0.03615897831860765, 0.2949072618650858,\n",
       "                    0.29436598550446663, --, --, --, --, --, --,\n",
       "                    0.27589570158837545, --, --, --, --,\n",
       "                    0.09098826374421197, 0.1980760421030535, --, --,\n",
       "                    0.1794285039473189, --, --, --, 0.08951494099260295,\n",
       "                    --, --, --, --, 0.23968431431354048,\n",
       "                    0.1646265864143412, --, --, --, --, 0.1389057583743652,\n",
       "                    --, 0.21274168860520076, --, 0.27646556567463704, --,\n",
       "                    --, --, --, --, --, --, --, --, 0.00269674015605084,\n",
       "                    --, --, 0.05038620684127415, --, --, --, --, --, --,\n",
       "                    0.2525850739027893, --, --, 0.13346266839700516, --,\n",
       "                    --, --, --, 0.029191592009910613, --, --, --,\n",
       "                    0.2368763671328048, 0.2109816113358427, --, --, --, --,\n",
       "                    --, --, 0.06538880065066409, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 0.2956463389533333,\n",
       "                    0.27108951755325406, --, 0.11465188136981816, --,\n",
       "                    0.04473369757084339, --, --, 0.07018960067771882, --,\n",
       "                    0.1457519005867994, --, --, --, 0.2164753797864963,\n",
       "                    0.001338107642891972, 0.08405438473721615, --, --, --,\n",
       "                    --, --, --, --, --, 0.2714267245752716, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 0.25, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 0.18100466484168512,\n",
       "                    --, --, --, --, --, 0.21284046835599882, --, --, --,\n",
       "                    --, --, --, --, 0.18621352316407067, --, --,\n",
       "                    0.23561730408446413, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 0.09766248073288923,\n",
       "                    0.23496758544929316, --, 0.2639147472043166,\n",
       "                    0.04111542642208652, --, --, --, --, --, --, --,\n",
       "                    0.07719222937127905, --, --, --, 0.11847909645644437,\n",
       "                    --, --, --, --, 0.24567295408598494, --, --, --, --,\n",
       "                    --, 0.11746286194986323, --, 0.2602009554669062, --,\n",
       "                    --, --, --, --, --, --, 0.25, 0.26560498179971587, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --,\n",
       "                    0.24944511134256273, 0.15144273102030664, --,\n",
       "                    0.2713518522075269, --, --, 0.18511803864233914, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 0.0846972554564278, --,\n",
       "                    0.21210556101630687, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 0.18316700715004977, --, --,\n",
       "                    0.09662260257852576, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 0.12356176740823423, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    0.08375407401207732, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    0.05847182268383268, --, 0.06443241127651506, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, 0.25, --, --,\n",
       "                    0.25, --, --, --, --, 0.06159317442198516, --,\n",
       "                    0.23786092308474624, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 0.24594749752521305, --, --,\n",
       "                    --, --, --, 0.2634923656320648, --, --, --, 0.25, --,\n",
       "                    0.2503061972676905, --, --, --, 0.2325569553199831,\n",
       "                    0.29589787805970086, --, --, --, 0.06884428567887217,\n",
       "                    --, --, --, --, 0.2748445929094955, --, --, --, --, --,\n",
       "                    --, --, 0.2517428397542081, 0.25, --,\n",
       "                    0.23359440602297973, --, 0.24821439992656255, --,\n",
       "                    0.2380805039223986, --, --, --, --, 0.2370445792404401,\n",
       "                    --, --, --, --, --, --, --, --, 0.1645312649691532,\n",
       "                    0.2437946409898529, --, --, --, --, --, --, --,\n",
       "                    0.24965639353443583, --, --, --, --, --,\n",
       "                    0.24854954215089795, --, --, --, --, --, --, --, --,\n",
       "                    0.2897766074900805, 0.01049469763009523, --,\n",
       "                    0.2473540043970257, 0.28613478109886054, --, --,\n",
       "                    0.07458369646781687, --, 0.27003406445695943, --, --,\n",
       "                    0.25, 0.25, --, --, --, --, --, --, --,\n",
       "                    0.26479942699761055, --, 0.047018812538811676, --, --,\n",
       "                    --, --, --, --, --, --, 0.29478033882088384, --, --,\n",
       "                    --, --, 0.25, --, --, --, 0.24626870458181452, --, --,\n",
       "                    0.2399530986534859, --, --, --, --,\n",
       "                    0.11468176248433018, --, --, --, --, 0.25, --,\n",
       "                    0.1765324476855333, --, 0.23185285547398382, --, --,\n",
       "                    --, --, 0.13346334563697515, --, --, --, --, --,\n",
       "                    0.2359962405286948, --, --, 0.2744406794002996, --, --,\n",
       "                    --, --, --, 0.22167823181601834, --, --,\n",
       "                    0.1572124109803112, 0.21840286321120986,\n",
       "                    0.29318414921294567, 0.27652547690629203, --, --, --,\n",
       "                    0.19729830160438497, 0.25620704804486827,\n",
       "                    0.26126709646645707, 0.25, --, 0.25,\n",
       "                    0.032885956332748094, --, --, --, --, --,\n",
       "                    0.2764460714999304, 0.2484969422715976, --,\n",
       "                    0.23950663874260725, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 0.25, 0.2391332721876289, 0.022044477478186646,\n",
       "                    0.007582344663434638, --, 0.039948200349970535, --, --,\n",
       "                    --, --, --, --, 0.23703619761758793,\n",
       "                    0.2522095207581007, 0.2398225124446806, --],\n",
       "              mask=[ True,  True,  True,  True, False,  True, False,  True,\n",
       "                     True,  True, False,  True,  True,  True, False, False,\n",
       "                     True,  True, False,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True, False, False, False,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True, False,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True, False, False,  True,  True, False, False, False,\n",
       "                    False,  True, False,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True, False, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                    False,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False, False,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True, False, False, False,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True, False, False,  True,  True, False,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True, False, False,\n",
       "                     True,  True,  True,  True, False,  True, False,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True, False,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                    False, False,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                    False,  True, False,  True, False,  True,  True, False,\n",
       "                     True, False,  True,  True,  True, False, False, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False, False,  True, False, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True, False,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False, False,  True, False,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True, False,  True,  True,  True,  True, False,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True, False,  True, False,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False, False,  True, False,  True, False,  True,\n",
       "                    False,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False, False,\n",
       "                     True, False, False,  True,  True, False,  True, False,\n",
       "                     True,  True, False, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True, False,\n",
       "                     True,  True, False,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True, False,  True, False,  True,\n",
       "                    False,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True, False,\n",
       "                    False, False, False,  True,  True,  True, False, False,\n",
       "                    False, False,  True, False, False,  True,  True,  True,\n",
       "                     True,  True, False, False,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False, False, False, False,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True, False, False, False,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': masked_array(data=[--, --, --, --, --, 'False', --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, 'False', --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 'False', --, --, --, --, --,\n",
       "                    --, 'True', 'True', 'True', --, 'False', --, --, --,\n",
       "                    --, --, --, --, --, --, 'True', --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 'False', --, --,\n",
       "                    --, --, --, 'True', --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 'False', --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, 'True', --,\n",
       "                    'False', 'False', --, --, --, --, --, --, --, --, --,\n",
       "                    --, 'False', --, 'True', --, --, --, --, --, 'True',\n",
       "                    --, --, 'True', --, --, --, --, 'False', --, --, --,\n",
       "                    --, --, --, 'False', --, --, 'False', --, 'False',\n",
       "                    'False', --, --, --, --, --, --, --, 'True', 'True',\n",
       "                    --, --, --, --, --, --, 'True', --, --, --, 'True', --,\n",
       "                    --, --, --, --, --, 'True', --, --, --, --, --, --, --,\n",
       "                    --, --, 'True', --, 'True', --, --, --, 'False', --,\n",
       "                    'False', 'True', 'True', --, 'False', 'False', --, --,\n",
       "                    'True', --, 'True', --, 'False', --, 'False', --, --,\n",
       "                    --, --, 'False', --, 'False', --, --, 'False', --,\n",
       "                    'True', --, --, --, --, 'False', 'False', --, --,\n",
       "                    'False', --, 'False', 'False', --, --, --, --, 'False',\n",
       "                    'False', --, 'True', --, 'False', --, 'False', --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 'False', 'True',\n",
       "                    --, --, --, --, 'False', --, --, --, 'False', --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    'False', --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 'True', --, --, --, 'True', --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 'True', --, --, --, --, --, --, --, --, --,\n",
       "                    'False', --, --, --, --, --, 'True', --, --, --,\n",
       "                    'True', --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    'False', 'False', --, 'False', --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 'True', --, --, --, --, --, --,\n",
       "                    'False', --, --, 'True', --, --, --, --, 'True',\n",
       "                    'False', --, --, --, 'True', --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 'True', --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 'False', --, --, --, --, --,\n",
       "                    --, --, --, --, --, 'True', --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 'True', --, 'True', --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    'False', 'False', --, --, --, --, --, --, --, 'True',\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 'True', --, --, --, --, --, 'False', --, --,\n",
       "                    --, --, --, --, 'True', --, --, --, --, --, --,\n",
       "                    'False', --, --, --, --, --, --, 'False', --, --, --,\n",
       "                    'True', --, 'False', --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 'True', --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 'True', --, --, --, --, --, --, 'True', --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 'True', --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 'True', 'False', --, 'True', 'False', 'True',\n",
       "                    --, --, --, --, --, 'True'],\n",
       "              mask=[ True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True, False, False, False,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True, False,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True, False,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True, False,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True, False,  True, False,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False, False,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True, False,\n",
       "                     True,  True,  True, False,  True, False, False, False,\n",
       "                     True, False, False,  True,  True, False,  True, False,\n",
       "                     True, False,  True, False,  True,  True,  True,  True,\n",
       "                    False,  True, False,  True,  True, False,  True, False,\n",
       "                     True,  True,  True,  True, False, False,  True,  True,\n",
       "                    False,  True, False, False,  True,  True,  True,  True,\n",
       "                    False, False,  True, False,  True, False,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False, False,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True, False,  True,  True,  True,  True,\n",
       "                    False, False,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True, False,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False, False,  True, False,\n",
       "                    False, False,  True,  True,  True,  True,  True, False],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U32'),\n",
       " 'param_feature_preprocessor:extra_trees_preproc_for_regression:criterion': masked_array(data=[--, --, --, --, --, 'friedman_mse', --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, 'mae', --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 'friedman_mse', --, --, --, --,\n",
       "                    --, --, 'mse', 'friedman_mse', 'mae', --, 'mse', --,\n",
       "                    --, --, --, --, --, --, --, --, 'mse', --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, 'mae', --,\n",
       "                    --, --, --, --, 'mae', --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 'friedman_mse', --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, 'mae',\n",
       "                    --, 'mse', 'mse', --, --, --, --, --, --, --, --, --,\n",
       "                    --, 'friedman_mse', --, 'mae', --, --, --, --, --,\n",
       "                    'mae', --, --, 'mse', --, --, --, --, 'mse', --, --,\n",
       "                    --, --, --, --, 'mae', --, --, 'mae', --,\n",
       "                    'friedman_mse', 'mae', --, --, --, --, --, --, --,\n",
       "                    'mse', 'friedman_mse', --, --, --, --, --, --, 'mse',\n",
       "                    --, --, --, 'mse', --, --, --, --, --, --, 'mse', --,\n",
       "                    --, --, --, --, --, --, --, --, 'mae', --, 'mae', --,\n",
       "                    --, --, 'mse', --, 'mse', 'mae', 'friedman_mse', --,\n",
       "                    'friedman_mse', 'friedman_mse', --, --, 'friedman_mse',\n",
       "                    --, 'mse', --, 'mse', --, 'mae', --, --, --, --,\n",
       "                    'friedman_mse', --, 'friedman_mse', --, --,\n",
       "                    'friedman_mse', --, 'friedman_mse', --, --, --, --,\n",
       "                    'friedman_mse', 'friedman_mse', --, --, 'friedman_mse',\n",
       "                    --, 'mae', 'friedman_mse', --, --, --, --, 'mse',\n",
       "                    'mse', --, 'mse', --, 'mse', --, 'mae', --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 'mse', 'mae', --, --, --,\n",
       "                    --, 'mse', --, --, --, 'mse', --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 'friedman_mse', --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    'friedman_mse', --, --, --, 'mae', --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 'mse', --, --, --, --, --, --, --, --, --,\n",
       "                    'friedman_mse', --, --, --, --, --, 'friedman_mse', --,\n",
       "                    --, --, 'mae', --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 'mae', 'mae', --, 'mae', --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 'mse', --, --, --, --, --, --,\n",
       "                    'friedman_mse', --, --, 'mae', --, --, --, --, 'mae',\n",
       "                    'mae', --, --, --, 'mse', --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    'mae', --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 'mse', --, --, --, --, --, --, --,\n",
       "                    --, --, --, 'mse', --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 'mse', --, 'mae', --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, 'mse',\n",
       "                    'friedman_mse', --, --, --, --, --, --, --,\n",
       "                    'friedman_mse', --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 'mae', --, --, --, --, --,\n",
       "                    'friedman_mse', --, --, --, --, --, --, 'mse', --, --,\n",
       "                    --, --, --, --, 'mse', --, --, --, --, --, --, 'mae',\n",
       "                    --, --, --, 'mse', --, 'mae', --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 'friedman_mse', --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 'friedman_mse', --, --, --,\n",
       "                    --, --, --, 'mse', --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, 'mae',\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 'mse', 'friedman_mse',\n",
       "                    --, 'mae', 'mae', 'mae', --, --, --, --, --, 'mse'],\n",
       "              mask=[ True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True, False, False, False,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True, False,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True, False,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True, False,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True, False,  True, False,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False, False,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True, False,\n",
       "                     True,  True,  True, False,  True, False, False, False,\n",
       "                     True, False, False,  True,  True, False,  True, False,\n",
       "                     True, False,  True, False,  True,  True,  True,  True,\n",
       "                    False,  True, False,  True,  True, False,  True, False,\n",
       "                     True,  True,  True,  True, False, False,  True,  True,\n",
       "                    False,  True, False, False,  True,  True,  True,  True,\n",
       "                    False, False,  True, False,  True, False,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False, False,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True, False,  True,  True,  True,  True,\n",
       "                    False, False,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True, False,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False, False,  True, False,\n",
       "                    False, False,  True,  True,  True,  True,  True, False],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U32'),\n",
       " 'param_feature_preprocessor:extra_trees_preproc_for_regression:max_depth': masked_array(data=[--, --, --, --, --, 'None', --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 'None', --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 'None', --, --, --, --, --, --, 'None',\n",
       "                    'None', 'None', --, 'None', --, --, --, --, --, --, --,\n",
       "                    --, --, 'None', --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 'None', --, --, --, --, --, 'None',\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    'None', --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 'None', --, 'None', 'None', --, --, --,\n",
       "                    --, --, --, --, --, --, --, 'None', --, 'None', --, --,\n",
       "                    --, --, --, 'None', --, --, 'None', --, --, --, --,\n",
       "                    'None', --, --, --, --, --, --, 'None', --, --, 'None',\n",
       "                    --, 'None', 'None', --, --, --, --, --, --, --, 'None',\n",
       "                    'None', --, --, --, --, --, --, 'None', --, --, --,\n",
       "                    'None', --, --, --, --, --, --, 'None', --, --, --, --,\n",
       "                    --, --, --, --, --, 'None', --, 'None', --, --, --,\n",
       "                    'None', --, 'None', 'None', 'None', --, 'None', 'None',\n",
       "                    --, --, 'None', --, 'None', --, 'None', --, 'None', --,\n",
       "                    --, --, --, 'None', --, 'None', --, --, 'None', --,\n",
       "                    'None', --, --, --, --, 'None', 'None', --, --, 'None',\n",
       "                    --, 'None', 'None', --, --, --, --, 'None', 'None', --,\n",
       "                    'None', --, 'None', --, 'None', --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 'None', 'None', --, --, --, --,\n",
       "                    'None', --, --, --, 'None', --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 'None', --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, 'None', --, --,\n",
       "                    --, 'None', --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, 'None', --, --,\n",
       "                    --, --, --, --, --, --, --, 'None', --, --, --, --, --,\n",
       "                    'None', --, --, --, 'None', --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 'None', 'None', --, 'None', --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 'None', --, --, --, --,\n",
       "                    --, --, 'None', --, --, 'None', --, --, --, --, 'None',\n",
       "                    'None', --, --, --, 'None', --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    'None', --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 'None', --, --, --, --, --, --, --,\n",
       "                    --, --, --, 'None', --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 'None', --, 'None', --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, 'None', 'None',\n",
       "                    --, --, --, --, --, --, --, 'None', --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, 'None', --,\n",
       "                    --, --, --, --, 'None', --, --, --, --, --, --, 'None',\n",
       "                    --, --, --, --, --, --, 'None', --, --, --, --, --, --,\n",
       "                    'None', --, --, --, 'None', --, 'None', --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 'None', --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 'None', --, --, --, --, --,\n",
       "                    --, 'None', --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, 'None', --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 'None', 'None', --, 'None',\n",
       "                    'None', 'None', --, --, --, --, --, 'None'],\n",
       "              mask=[ True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True, False, False, False,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True, False,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True, False,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True, False,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True, False,  True, False,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False, False,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True, False,\n",
       "                     True,  True,  True, False,  True, False, False, False,\n",
       "                     True, False, False,  True,  True, False,  True, False,\n",
       "                     True, False,  True, False,  True,  True,  True,  True,\n",
       "                    False,  True, False,  True,  True, False,  True, False,\n",
       "                     True,  True,  True,  True, False, False,  True,  True,\n",
       "                    False,  True, False, False,  True,  True,  True,  True,\n",
       "                    False, False,  True, False,  True, False,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False, False,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True, False,  True,  True,  True,  True,\n",
       "                    False, False,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True, False,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False, False,  True, False,\n",
       "                    False, False,  True,  True,  True,  True,  True, False],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U32'),\n",
       " 'param_feature_preprocessor:extra_trees_preproc_for_regression:max_features': masked_array(data=[--, --, --, --, --, 0.6031462814361489, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    0.47267049795789906, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    0.2354628613765028, --, --, --, --, --, --,\n",
       "                    0.8521314247974944, 0.5751330178298871,\n",
       "                    0.6927681645723903, --, 0.5440415317368462, --, --, --,\n",
       "                    --, --, --, --, --, --, 0.2880128328671823, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    0.23469763835846824, --, --, --, --, --,\n",
       "                    0.6165419827233979, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 0.7087732242505305, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    0.5820074539244974, --, 0.7235173501600752,\n",
       "                    0.6556266562283924, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 0.9603363320885359, --, 0.4925553560532644, --, --,\n",
       "                    --, --, --, 0.7635639376673111, --, --,\n",
       "                    0.1982530939863398, --, --, --, --, 0.5401976506289086,\n",
       "                    --, --, --, --, --, --, 0.5824770881507192, --, --,\n",
       "                    0.6878138877880059, --, 0.3197320336199699,\n",
       "                    0.7072781534595707, --, --, --, --, --, --, --,\n",
       "                    0.22439347025025402, 0.466777253255788, --, --, --, --,\n",
       "                    --, --, 0.5258929081478239, --, --, --,\n",
       "                    0.46099295597435896, --, --, --, --, --, --,\n",
       "                    0.35787438865321775, --, --, --, --, --, --, --, --,\n",
       "                    --, 0.8178748405936461, --, 0.6807793692839955, --, --,\n",
       "                    --, 0.8393800361589034, --, 0.6255465631963165,\n",
       "                    0.9947294831957315, 0.7202691278549422, --,\n",
       "                    0.6179330618043082, 0.753750709643032, --, --,\n",
       "                    0.8316730926700951, --, 0.9561629539713378, --,\n",
       "                    0.78436043649581, --, 0.7167571026167089, --, --, --,\n",
       "                    --, 0.13475263368907847, --, 0.8474628078620302, --,\n",
       "                    --, 0.8351542476324354, --, 0.1948076876803117, --, --,\n",
       "                    --, --, 0.4051305371937508, 0.9692000454935757, --, --,\n",
       "                    0.7505018286705717, --, 0.22138131339514516,\n",
       "                    0.4218137381994512, --, --, --, --, 0.2914600922646382,\n",
       "                    0.5185015794876497, --, 1.0, --, 0.7079140021841538,\n",
       "                    --, 0.15564302415622855, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 0.21174303085797821,\n",
       "                    0.3977605879053516, --, --, --, --, 0.9603196322970856,\n",
       "                    --, --, --, 0.17322770048550531, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, 1.0, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    0.9945144837147887, --, --, --, 0.6483766286391843, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 0.5425547929408466, --, --, --,\n",
       "                    --, --, --, --, --, --, 0.1964256826075412, --, --, --,\n",
       "                    --, --, 0.7011033247317937, --, --, --,\n",
       "                    0.8733489479268874, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 0.9872503928341813, 0.8819023513601646, --,\n",
       "                    0.7312936132034784, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 0.9449380358323889, --, --, --, --, --, --,\n",
       "                    0.8384397741169155, --, --, 0.9702121847698293, --, --,\n",
       "                    --, --, 0.908672700090446, 0.31444019903264153, --, --,\n",
       "                    --, 0.4320338245951909, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    0.8443314032590028, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 0.41249002164304704,\n",
       "                    --, --, --, --, --, --, --, --, --, --,\n",
       "                    0.9852501648348624, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 0.5719364933297839, --,\n",
       "                    0.7603382677740694, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 0.29978852999659983,\n",
       "                    0.31278136765815123, --, --, --, --, --, --, --,\n",
       "                    0.9955285130457278, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 0.949010926435308, --, --,\n",
       "                    --, --, --, 0.9390783038414527, --, --, --, --, --, --,\n",
       "                    0.5443367343174802, --, --, --, --, --, --,\n",
       "                    0.1847488285508619, --, --, --, --, --, --,\n",
       "                    0.13806658412576014, --, --, --, 0.812764966871452, --,\n",
       "                    0.725747531539935, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 0.9433735749271445, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 0.2595817289489165, --, --, --, --,\n",
       "                    --, --, 0.6411780478927256, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    0.3486669429976798, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    0.7748800784640781, 0.6067067503003327, --,\n",
       "                    0.25665517044170066, 0.5228947842170147,\n",
       "                    0.46028716628769417, --, --, --, --, --,\n",
       "                    0.39662322800426497],\n",
       "              mask=[ True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True, False, False, False,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True, False,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True, False,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True, False,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True, False,  True, False,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False, False,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True, False,\n",
       "                     True,  True,  True, False,  True, False, False, False,\n",
       "                     True, False, False,  True,  True, False,  True, False,\n",
       "                     True, False,  True, False,  True,  True,  True,  True,\n",
       "                    False,  True, False,  True,  True, False,  True, False,\n",
       "                     True,  True,  True,  True, False, False,  True,  True,\n",
       "                    False,  True, False, False,  True,  True,  True,  True,\n",
       "                    False, False,  True, False,  True, False,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False, False,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True, False,  True,  True,  True,  True,\n",
       "                    False, False,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True, False,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False, False,  True, False,\n",
       "                    False, False,  True,  True,  True,  True,  True, False],\n",
       "        fill_value=1e+20),\n",
       " 'param_feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': masked_array(data=[--, --, --, --, --, 'None', --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 'None', --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 'None', --, --, --, --, --, --, 'None',\n",
       "                    'None', 'None', --, 'None', --, --, --, --, --, --, --,\n",
       "                    --, --, 'None', --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 'None', --, --, --, --, --, 'None',\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    'None', --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 'None', --, 'None', 'None', --, --, --,\n",
       "                    --, --, --, --, --, --, --, 'None', --, 'None', --, --,\n",
       "                    --, --, --, 'None', --, --, 'None', --, --, --, --,\n",
       "                    'None', --, --, --, --, --, --, 'None', --, --, 'None',\n",
       "                    --, 'None', 'None', --, --, --, --, --, --, --, 'None',\n",
       "                    'None', --, --, --, --, --, --, 'None', --, --, --,\n",
       "                    'None', --, --, --, --, --, --, 'None', --, --, --, --,\n",
       "                    --, --, --, --, --, 'None', --, 'None', --, --, --,\n",
       "                    'None', --, 'None', 'None', 'None', --, 'None', 'None',\n",
       "                    --, --, 'None', --, 'None', --, 'None', --, 'None', --,\n",
       "                    --, --, --, 'None', --, 'None', --, --, 'None', --,\n",
       "                    'None', --, --, --, --, 'None', 'None', --, --, 'None',\n",
       "                    --, 'None', 'None', --, --, --, --, 'None', 'None', --,\n",
       "                    'None', --, 'None', --, 'None', --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 'None', 'None', --, --, --, --,\n",
       "                    'None', --, --, --, 'None', --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 'None', --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, 'None', --, --,\n",
       "                    --, 'None', --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, 'None', --, --,\n",
       "                    --, --, --, --, --, --, --, 'None', --, --, --, --, --,\n",
       "                    'None', --, --, --, 'None', --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 'None', 'None', --, 'None', --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 'None', --, --, --, --,\n",
       "                    --, --, 'None', --, --, 'None', --, --, --, --, 'None',\n",
       "                    'None', --, --, --, 'None', --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    'None', --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 'None', --, --, --, --, --, --, --,\n",
       "                    --, --, --, 'None', --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 'None', --, 'None', --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, 'None', 'None',\n",
       "                    --, --, --, --, --, --, --, 'None', --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, 'None', --,\n",
       "                    --, --, --, --, 'None', --, --, --, --, --, --, 'None',\n",
       "                    --, --, --, --, --, --, 'None', --, --, --, --, --, --,\n",
       "                    'None', --, --, --, 'None', --, 'None', --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 'None', --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 'None', --, --, --, --, --,\n",
       "                    --, 'None', --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, 'None', --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 'None', 'None', --, 'None',\n",
       "                    'None', 'None', --, --, --, --, --, 'None'],\n",
       "              mask=[ True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True, False, False, False,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True, False,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True, False,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True, False,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True, False,  True, False,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False, False,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True, False,\n",
       "                     True,  True,  True, False,  True, False, False, False,\n",
       "                     True, False, False,  True,  True, False,  True, False,\n",
       "                     True, False,  True, False,  True,  True,  True,  True,\n",
       "                    False,  True, False,  True,  True, False,  True, False,\n",
       "                     True,  True,  True,  True, False, False,  True,  True,\n",
       "                    False,  True, False, False,  True,  True,  True,  True,\n",
       "                    False, False,  True, False,  True, False,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False, False,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True, False,  True,  True,  True,  True,\n",
       "                    False, False,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True, False,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False, False,  True, False,\n",
       "                    False, False,  True,  True,  True,  True,  True, False],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U32'),\n",
       " 'param_feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': masked_array(data=[--, --, --, --, --, 20.0, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 11.0, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 16.0, --, --, --, --, --, --, 4.0, 6.0,\n",
       "                    20.0, --, 7.0, --, --, --, --, --, --, --, --, --, 4.0,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 8.0, --, --, --, --, --, 6.0, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 6.0, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    4.0, --, 8.0, 12.0, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 13.0, --, 11.0, --, --, --, --, --, 3.0, --, --,\n",
       "                    6.0, --, --, --, --, 15.0, --, --, --, --, --, --,\n",
       "                    10.0, --, --, 7.0, --, 19.0, 17.0, --, --, --, --, --,\n",
       "                    --, --, 14.0, 13.0, --, --, --, --, --, --, 6.0, --,\n",
       "                    --, --, 14.0, --, --, --, --, --, --, 4.0, --, --, --,\n",
       "                    --, --, --, --, --, --, 6.0, --, 1.0, --, --, --, 7.0,\n",
       "                    --, 20.0, 13.0, 8.0, --, 12.0, 17.0, --, --, 4.0, --,\n",
       "                    16.0, --, 3.0, --, 12.0, --, --, --, --, 6.0, --, 15.0,\n",
       "                    --, --, 7.0, --, 18.0, --, --, --, --, 9.0, 15.0, --,\n",
       "                    --, 13.0, --, 10.0, 9.0, --, --, --, --, 15.0, 15.0,\n",
       "                    --, 15.0, --, 6.0, --, 13.0, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 18.0, 3.0, --, --, --, --, 16.0,\n",
       "                    --, --, --, 3.0, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 1.0, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 2.0, --, --, --, 10.0,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 15.0, --, --, --, --, --,\n",
       "                    --, --, --, --, 16.0, --, --, --, --, --, 13.0, --, --,\n",
       "                    --, 12.0, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    7.0, 3.0, --, 7.0, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 3.0, --, --, --, --, --, --, 17.0, --, --, 1.0,\n",
       "                    --, --, --, --, 13.0, 10.0, --, --, --, 17.0, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 18.0, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, 2.0, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 2.0, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 12.0, --, 10.0, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    18.0, 15.0, --, --, --, --, --, --, --, 14.0, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    6.0, --, --, --, --, --, 1.0, --, --, --, --, --, --,\n",
       "                    11.0, --, --, --, --, --, --, 1.0, --, --, --, --, --,\n",
       "                    --, 16.0, --, --, --, 19.0, --, 6.0, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 18.0, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 15.0, --, --, --, --, --,\n",
       "                    --, 14.0, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, 15.0, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 11.0, 8.0, --, 20.0, 12.0,\n",
       "                    14.0, --, --, --, --, --, 9.0],\n",
       "              mask=[ True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True, False, False, False,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True, False,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True, False,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True, False,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True, False,  True, False,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False, False,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True, False,\n",
       "                     True,  True,  True, False,  True, False, False, False,\n",
       "                     True, False, False,  True,  True, False,  True, False,\n",
       "                     True, False,  True, False,  True,  True,  True,  True,\n",
       "                    False,  True, False,  True,  True, False,  True, False,\n",
       "                     True,  True,  True,  True, False, False,  True,  True,\n",
       "                    False,  True, False, False,  True,  True,  True,  True,\n",
       "                    False, False,  True, False,  True, False,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False, False,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True, False,  True,  True,  True,  True,\n",
       "                    False, False,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True, False,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False, False,  True, False,\n",
       "                    False, False,  True,  True,  True,  True,  True, False],\n",
       "        fill_value=1e+20),\n",
       " 'param_feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': masked_array(data=[--, --, --, --, --, 13.0, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 14.0, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 14.0, --, --, --, --, --, --, 8.0, 8.0,\n",
       "                    9.0, --, 18.0, --, --, --, --, --, --, --, --, --, 8.0,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 13.0, --, --, --, --, --, 17.0, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 8.0, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    5.0, --, 15.0, 9.0, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 10.0, --, 16.0, --, --, --, --, --, 8.0, --, --,\n",
       "                    17.0, --, --, --, --, 19.0, --, --, --, --, --, --,\n",
       "                    2.0, --, --, 20.0, --, 20.0, 6.0, --, --, --, --, --,\n",
       "                    --, --, 8.0, 11.0, --, --, --, --, --, --, 19.0, --,\n",
       "                    --, --, 19.0, --, --, --, --, --, --, 2.0, --, --, --,\n",
       "                    --, --, --, --, --, --, 3.0, --, 16.0, --, --, --, 5.0,\n",
       "                    --, 3.0, 5.0, 11.0, --, 15.0, 13.0, --, --, 6.0, --,\n",
       "                    16.0, --, 13.0, --, 3.0, --, --, --, --, 3.0, --, 11.0,\n",
       "                    --, --, 12.0, --, 10.0, --, --, --, --, 13.0, 2.0, --,\n",
       "                    --, 9.0, --, 4.0, 6.0, --, --, --, --, 12.0, 18.0, --,\n",
       "                    9.0, --, 4.0, --, 14.0, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 8.0, 18.0, --, --, --, --, 9.0, --, --, --,\n",
       "                    20.0, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 2.0, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 12.0, --, --, --, 3.0, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 2.0, --, --, --, --, --, --, --, --,\n",
       "                    --, 6.0, --, --, --, --, --, 15.0, --, --, --, 14.0,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, 14.0, 17.0,\n",
       "                    --, 11.0, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    19.0, --, --, --, --, --, --, 19.0, --, --, 20.0, --,\n",
       "                    --, --, --, 19.0, 14.0, --, --, --, 13.0, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 12.0, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 18.0, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 6.0, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 3.0, --, 7.0, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    18.0, 3.0, --, --, --, --, --, --, --, 20.0, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    19.0, --, --, --, --, --, 2.0, --, --, --, --, --, --,\n",
       "                    18.0, --, --, --, --, --, --, 4.0, --, --, --, --, --,\n",
       "                    --, 15.0, --, --, --, 4.0, --, 3.0, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 14.0, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 20.0, --, --, --, --, --, --,\n",
       "                    19.0, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 14.0, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 13.0, 11.0, --, 19.0, 10.0, 4.0,\n",
       "                    --, --, --, --, --, 3.0],\n",
       "              mask=[ True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True, False, False, False,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True, False,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True, False,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True, False,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True, False,  True, False,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False, False,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True, False,\n",
       "                     True,  True,  True, False,  True, False, False, False,\n",
       "                     True, False, False,  True,  True, False,  True, False,\n",
       "                     True, False,  True, False,  True,  True,  True,  True,\n",
       "                    False,  True, False,  True,  True, False,  True, False,\n",
       "                     True,  True,  True,  True, False, False,  True,  True,\n",
       "                    False,  True, False, False,  True,  True,  True,  True,\n",
       "                    False, False,  True, False,  True, False,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False, False,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True, False,  True,  True,  True,  True,\n",
       "                    False, False,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True, False,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False, False,  True, False,\n",
       "                    False, False,  True,  True,  True,  True,  True, False],\n",
       "        fill_value=1e+20),\n",
       " 'param_feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': masked_array(data=[--, --, --, --, --, 0.0, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 0.0, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 0.0, --, --, --, --, --, --, 0.0, 0.0,\n",
       "                    0.0, --, 0.0, --, --, --, --, --, --, --, --, --, 0.0,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 0.0, --, --, --, --, --, 0.0, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 0.0, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    0.0, --, 0.0, 0.0, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 0.0, --, 0.0, --, --, --, --, --, 0.0, --, --, 0.0,\n",
       "                    --, --, --, --, 0.0, --, --, --, --, --, --, 0.0, --,\n",
       "                    --, 0.0, --, 0.0, 0.0, --, --, --, --, --, --, --, 0.0,\n",
       "                    0.0, --, --, --, --, --, --, 0.0, --, --, --, 0.0, --,\n",
       "                    --, --, --, --, --, 0.0, --, --, --, --, --, --, --,\n",
       "                    --, --, 0.0, --, 0.0, --, --, --, 0.0, --, 0.0, 0.0,\n",
       "                    0.0, --, 0.0, 0.0, --, --, 0.0, --, 0.0, --, 0.0, --,\n",
       "                    0.0, --, --, --, --, 0.0, --, 0.0, --, --, 0.0, --,\n",
       "                    0.0, --, --, --, --, 0.0, 0.0, --, --, 0.0, --, 0.0,\n",
       "                    0.0, --, --, --, --, 0.0, 0.0, --, 0.0, --, 0.0, --,\n",
       "                    0.0, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    0.0, 0.0, --, --, --, --, 0.0, --, --, --, 0.0, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    0.0, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 0.0, --, --, --, 0.0, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 0.0, --, --, --, --, --, --, --, --, --, 0.0, --,\n",
       "                    --, --, --, --, 0.0, --, --, --, 0.0, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 0.0, 0.0, --, 0.0, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 0.0, --, --, --,\n",
       "                    --, --, --, 0.0, --, --, 0.0, --, --, --, --, 0.0, 0.0,\n",
       "                    --, --, --, 0.0, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, 0.0,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 0.0, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 0.0, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 0.0, --, 0.0, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 0.0, 0.0, --, --, --, --,\n",
       "                    --, --, --, 0.0, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 0.0, --, --, --, --, --,\n",
       "                    0.0, --, --, --, --, --, --, 0.0, --, --, --, --, --,\n",
       "                    --, 0.0, --, --, --, --, --, --, 0.0, --, --, --, 0.0,\n",
       "                    --, 0.0, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    0.0, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    0.0, --, --, --, --, --, --, 0.0, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 0.0, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, 0.0,\n",
       "                    0.0, --, 0.0, 0.0, 0.0, --, --, --, --, --, 0.0],\n",
       "              mask=[ True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True, False, False, False,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True, False,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True, False,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True, False,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True, False,  True, False,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False, False,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True, False,\n",
       "                     True,  True,  True, False,  True, False, False, False,\n",
       "                     True, False, False,  True,  True, False,  True, False,\n",
       "                     True, False,  True, False,  True,  True,  True,  True,\n",
       "                    False,  True, False,  True,  True, False,  True, False,\n",
       "                     True,  True,  True,  True, False, False,  True,  True,\n",
       "                    False,  True, False, False,  True,  True,  True,  True,\n",
       "                    False, False,  True, False,  True, False,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False, False,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True, False,  True,  True,  True,  True,\n",
       "                    False, False,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True, False,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False, False,  True, False,\n",
       "                    False, False,  True,  True,  True,  True,  True, False],\n",
       "        fill_value=1e+20),\n",
       " 'param_feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': masked_array(data=[--, --, --, --, --, 100.0, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 100.0, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 100.0, --, --, --, --, --, --, 100.0,\n",
       "                    100.0, 100.0, --, 100.0, --, --, --, --, --, --, --,\n",
       "                    --, --, 100.0, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 100.0, --, --, --, --, --, 100.0,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    100.0, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 100.0, --, 100.0, 100.0, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 100.0, --, 100.0, --, --,\n",
       "                    --, --, --, 100.0, --, --, 100.0, --, --, --, --,\n",
       "                    100.0, --, --, --, --, --, --, 100.0, --, --, 100.0,\n",
       "                    --, 100.0, 100.0, --, --, --, --, --, --, --, 100.0,\n",
       "                    100.0, --, --, --, --, --, --, 100.0, --, --, --,\n",
       "                    100.0, --, --, --, --, --, --, 100.0, --, --, --, --,\n",
       "                    --, --, --, --, --, 100.0, --, 100.0, --, --, --,\n",
       "                    100.0, --, 100.0, 100.0, 100.0, --, 100.0, 100.0, --,\n",
       "                    --, 100.0, --, 100.0, --, 100.0, --, 100.0, --, --, --,\n",
       "                    --, 100.0, --, 100.0, --, --, 100.0, --, 100.0, --, --,\n",
       "                    --, --, 100.0, 100.0, --, --, 100.0, --, 100.0, 100.0,\n",
       "                    --, --, --, --, 100.0, 100.0, --, 100.0, --, 100.0, --,\n",
       "                    100.0, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    100.0, 100.0, --, --, --, --, 100.0, --, --, --, 100.0,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 100.0, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 100.0, --, --, --, 100.0, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 100.0, --, --, --, --, --, --, --, --, --,\n",
       "                    100.0, --, --, --, --, --, 100.0, --, --, --, 100.0,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, 100.0,\n",
       "                    100.0, --, 100.0, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 100.0, --, --, --, --, --, --, 100.0, --, --,\n",
       "                    100.0, --, --, --, --, 100.0, 100.0, --, --, --, 100.0,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 100.0, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, 100.0,\n",
       "                    --, --, --, --, --, --, --, --, --, --, 100.0, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, 100.0, --,\n",
       "                    100.0, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 100.0, 100.0, --, --, --, --, --, --, --,\n",
       "                    100.0, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 100.0, --, --, --, --, --, 100.0, --,\n",
       "                    --, --, --, --, --, 100.0, --, --, --, --, --, --,\n",
       "                    100.0, --, --, --, --, --, --, 100.0, --, --, --,\n",
       "                    100.0, --, 100.0, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 100.0, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 100.0, --, --, --, --, --, --, 100.0, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 100.0, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 100.0, 100.0, --, 100.0, 100.0, 100.0, --, --, --,\n",
       "                    --, --, 100.0],\n",
       "              mask=[ True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True, False, False, False,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True, False,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True, False,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True, False,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True, False,  True, False,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False, False,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True, False,\n",
       "                     True,  True,  True, False,  True, False, False, False,\n",
       "                     True, False, False,  True,  True, False,  True, False,\n",
       "                     True, False,  True, False,  True,  True,  True,  True,\n",
       "                    False,  True, False,  True,  True, False,  True, False,\n",
       "                     True,  True,  True,  True, False, False,  True,  True,\n",
       "                    False,  True, False, False,  True,  True,  True,  True,\n",
       "                    False, False,  True, False,  True, False,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False, False,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True, False,  True,  True,  True,  True,\n",
       "                    False, False,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True, False,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False, False,  True, False,\n",
       "                    False, False,  True,  True,  True,  True,  True, False],\n",
       "        fill_value=1e+20),\n",
       " 'param_feature_preprocessor:fast_ica:algorithm': masked_array(data=[--, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 'parallel', --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 'deflation', --, --, --, --, 'parallel', --,\n",
       "                    --, --, --, --, --, 'deflation', --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 'parallel', --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, 'deflation',\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 'deflation', --, --, --, 'deflation', --, --,\n",
       "                    --, 'parallel', --, --, 'parallel', --, --, --, --, --,\n",
       "                    --, --, --, --, --, 'deflation', --, 'deflation', --,\n",
       "                    'parallel', --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 'deflation', --, --, 'parallel', --, --,\n",
       "                    --, --, 'deflation', --, --, --, 'parallel',\n",
       "                    'parallel', 'parallel', --, 'parallel', 'parallel', --,\n",
       "                    --, --, --, 'parallel', --, 'deflation', 'deflation',\n",
       "                    --, 'parallel', --, --, --, 'deflation', --, --,\n",
       "                    'deflation', --, --, --, 'deflation', --, --, --,\n",
       "                    'deflation', --, --, --, 'parallel', 'parallel',\n",
       "                    'deflation', --, --, 'parallel', --, --, --,\n",
       "                    'parallel', --, 'parallel', 'deflation', 'deflation',\n",
       "                    'deflation', --, 'deflation', --, 'parallel', --,\n",
       "                    'deflation', --, 'deflation', 'parallel', 'parallel',\n",
       "                    --, 'deflation', --, --, --, 'parallel', --,\n",
       "                    'parallel', --, 'parallel', --, --, --, --, --, --,\n",
       "                    'deflation', 'deflation', --, --, --, --, --, --, --,\n",
       "                    'deflation', --, 'deflation', --, --, --, --, --, --,\n",
       "                    --, 'deflation', --, --, --, --, --, --, --,\n",
       "                    'parallel', --, --, --, --, --, --, --, --,\n",
       "                    'deflation', --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 'deflation', 'parallel', 'deflation', --,\n",
       "                    'deflation', --, --, --, 'deflation', --, --, --, --,\n",
       "                    --, 'parallel', 'deflation', 'deflation', --, --, --,\n",
       "                    --, --, --, --, 'deflation', 'deflation', --,\n",
       "                    'parallel', --, 'deflation', --, 'deflation', --,\n",
       "                    'deflation', 'parallel', --, --, --, --, --, --,\n",
       "                    'deflation', --, --, --, 'deflation', --, --, --, --,\n",
       "                    --, 'parallel', 'parallel', --, --, --, --, --,\n",
       "                    'deflation', 'deflation', 'parallel', 'parallel', --,\n",
       "                    'parallel', --, --, 'parallel', --, --, --, --, --, --,\n",
       "                    --, --, 'parallel', --, --, --, 'parallel', 'parallel',\n",
       "                    --, --, 'deflation', --, --, --, 'parallel', --,\n",
       "                    'deflation', 'parallel', 'parallel', --, --, --,\n",
       "                    'parallel', 'parallel', --, --, 'deflation',\n",
       "                    'deflation', --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 'deflation', --, --, 'parallel', --, --,\n",
       "                    'parallel', --, 'parallel', --, 'parallel', --, --,\n",
       "                    'parallel', 'parallel', --, --, 'deflation',\n",
       "                    'deflation', 'parallel', 'deflation', 'deflation', --,\n",
       "                    --, --, --, --, --, 'deflation', --, --, --,\n",
       "                    'deflation', --, 'parallel', 'parallel', 'deflation',\n",
       "                    --, --, --, --, --, 'deflation', --, 'deflation', --,\n",
       "                    'parallel', --, --, --, 'deflation', --, --, --, --,\n",
       "                    'parallel', 'parallel', 'parallel', --, --, 'parallel',\n",
       "                    'deflation', --, --, 'parallel', 'deflation',\n",
       "                    'parallel', 'deflation', 'parallel', --, --,\n",
       "                    'deflation', --, --, --, 'deflation', --, --,\n",
       "                    'deflation', 'deflation', --, --, 'deflation',\n",
       "                    'parallel', --, --, 'deflation', --, --, --,\n",
       "                    'deflation', --, --, 'deflation', --, 'parallel',\n",
       "                    'parallel', 'parallel', --, 'deflation', 'deflation',\n",
       "                    'deflation', 'deflation', 'deflation', 'parallel', --,\n",
       "                    'parallel', 'parallel', --, --, 'deflation',\n",
       "                    'parallel', --, 'parallel', 'parallel', --, 'parallel',\n",
       "                    'parallel', --, 'parallel', --, 'parallel', --,\n",
       "                    'parallel', 'deflation', --, --, --, --, 'deflation',\n",
       "                    'deflation', 'deflation', 'deflation', --, 'deflation',\n",
       "                    --, --, 'parallel', --, 'deflation', 'deflation',\n",
       "                    'deflation', 'deflation', 'parallel', --, --,\n",
       "                    'deflation', 'deflation', --, --, 'parallel', --,\n",
       "                    'parallel', --, 'deflation', --, 'parallel',\n",
       "                    'parallel', 'parallel', --, --, 'parallel',\n",
       "                    'deflation', --, 'deflation', 'deflation', 'deflation',\n",
       "                    'deflation', --, --, 'deflation', 'deflation',\n",
       "                    'deflation', --, 'deflation', --, 'deflation', --,\n",
       "                    'parallel', 'parallel', 'deflation', --, 'deflation',\n",
       "                    --, --, --, --, --, 'parallel', --, --, --, --,\n",
       "                    'parallel', 'parallel', 'deflation', 'deflation',\n",
       "                    'deflation', --, --, --, 'deflation', --, --,\n",
       "                    'deflation', --, --, 'parallel', --, --, --, --,\n",
       "                    'parallel', --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 'deflation', --, --, --, --, --, --, --,\n",
       "                    'parallel', 'deflation', 'parallel', --, 'deflation',\n",
       "                    --, --, --, --, --, 'deflation', --, 'parallel', --,\n",
       "                    'deflation', --, 'parallel', --, --, --, --, --,\n",
       "                    'deflation', 'deflation', --, --, --, --, 'deflation',\n",
       "                    --, --, --, 'parallel', 'parallel', 'deflation', --,\n",
       "                    --, 'deflation', --, 'deflation', --, --, --, --, --,\n",
       "                    --, 'parallel', 'parallel', --, 'parallel', 'parallel',\n",
       "                    'parallel', 'deflation', --, 'deflation', --, --, --,\n",
       "                    'parallel', --, --, --, 'parallel', --, 'parallel',\n",
       "                    'deflation', 'parallel', --, --, --, --, --, --, --,\n",
       "                    'deflation', 'deflation', 'deflation', --, 'deflation',\n",
       "                    'deflation', --, 'deflation', --, 'parallel',\n",
       "                    'parallel', 'deflation', --, 'deflation', 'parallel',\n",
       "                    --, 'deflation', --, 'deflation', 'deflation',\n",
       "                    'deflation', 'deflation', 'deflation', --, 'deflation',\n",
       "                    'deflation', 'deflation', 'deflation', 'parallel',\n",
       "                    'deflation', 'deflation', --, --, --, --, --,\n",
       "                    'deflation', 'deflation', 'deflation', 'deflation', --,\n",
       "                    'deflation', 'deflation', --, --, --, 'deflation',\n",
       "                    'deflation', --, --, 'parallel', 'deflation', --, --,\n",
       "                    --, --, --, --, --, --, --, --, 'deflation',\n",
       "                    'deflation', --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True, False,\n",
       "                     True,  True,  True, False,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True, False,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True, False,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                    False, False, False,  True, False, False,  True,  True,\n",
       "                     True,  True, False,  True, False, False,  True, False,\n",
       "                     True,  True,  True, False,  True,  True, False,  True,\n",
       "                     True,  True, False,  True,  True,  True, False,  True,\n",
       "                     True,  True, False, False, False,  True,  True, False,\n",
       "                     True,  True,  True, False,  True, False, False, False,\n",
       "                    False,  True, False,  True, False,  True, False,  True,\n",
       "                    False, False, False,  True, False,  True,  True,  True,\n",
       "                    False,  True, False,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True, False, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False, False, False,  True, False,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True, False, False, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False, False,  True, False,  True,\n",
       "                    False,  True, False,  True, False, False,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True, False, False,\n",
       "                     True,  True,  True,  True,  True, False, False, False,\n",
       "                    False,  True, False,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True, False, False,  True,  True, False,  True,\n",
       "                     True,  True, False,  True, False, False, False,  True,\n",
       "                     True,  True, False, False,  True,  True, False, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True, False,  True,\n",
       "                     True, False,  True, False,  True, False,  True,  True,\n",
       "                    False, False,  True,  True, False, False, False, False,\n",
       "                    False,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True, False,  True, False, False, False,\n",
       "                     True,  True,  True,  True,  True, False,  True, False,\n",
       "                     True, False,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True, False, False, False,  True,  True, False,\n",
       "                    False,  True,  True, False, False, False, False, False,\n",
       "                     True,  True, False,  True,  True,  True, False,  True,\n",
       "                     True, False, False,  True,  True, False, False,  True,\n",
       "                     True, False,  True,  True,  True, False,  True,  True,\n",
       "                    False,  True, False, False, False,  True, False, False,\n",
       "                    False, False, False, False,  True, False, False,  True,\n",
       "                     True, False, False,  True, False, False,  True, False,\n",
       "                    False,  True, False,  True, False,  True, False, False,\n",
       "                     True,  True,  True,  True, False, False, False, False,\n",
       "                     True, False,  True,  True, False,  True, False, False,\n",
       "                    False, False, False,  True,  True, False, False,  True,\n",
       "                     True, False,  True, False,  True, False,  True, False,\n",
       "                    False, False,  True,  True, False, False,  True, False,\n",
       "                    False, False, False,  True,  True, False, False, False,\n",
       "                     True, False,  True, False,  True, False, False, False,\n",
       "                     True, False,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True, False, False, False, False,\n",
       "                    False,  True,  True,  True, False,  True,  True, False,\n",
       "                     True,  True, False,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False, False, False,  True,\n",
       "                    False,  True,  True,  True,  True,  True, False,  True,\n",
       "                    False,  True, False,  True, False,  True,  True,  True,\n",
       "                     True,  True, False, False,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True, False, False, False,  True,\n",
       "                     True, False,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True, False, False,  True, False, False, False,\n",
       "                    False,  True, False,  True,  True,  True, False,  True,\n",
       "                     True,  True, False,  True, False, False, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False, False,\n",
       "                    False,  True, False, False,  True, False,  True, False,\n",
       "                    False, False,  True, False, False,  True, False,  True,\n",
       "                    False, False, False, False, False,  True, False, False,\n",
       "                    False, False, False, False, False,  True,  True,  True,\n",
       "                     True,  True, False, False, False, False,  True, False,\n",
       "                    False,  True,  True,  True, False, False,  True,  True,\n",
       "                    False, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False, False,  True,  True],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U32'),\n",
       " 'param_feature_preprocessor:fast_ica:fun': masked_array(data=[--, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 'logcosh', --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 'exp', --, --, --, --, 'exp', --, --, --, --,\n",
       "                    --, --, 'cube', --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 'cube', --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 'cube', --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 'cube', --, --, --,\n",
       "                    'cube', --, --, --, 'cube', --, --, 'exp', --, --, --,\n",
       "                    --, --, --, --, --, --, --, 'exp', --, 'cube', --,\n",
       "                    'exp', --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 'exp', --, --, 'exp', --, --, --, --, 'exp',\n",
       "                    --, --, --, 'logcosh', 'cube', 'cube', --, 'cube',\n",
       "                    'exp', --, --, --, --, 'logcosh', --, 'cube',\n",
       "                    'logcosh', --, 'cube', --, --, --, 'exp', --, --,\n",
       "                    'logcosh', --, --, --, 'exp', --, --, --, 'logcosh',\n",
       "                    --, --, --, 'cube', 'logcosh', 'logcosh', --, --,\n",
       "                    'exp', --, --, --, 'logcosh', --, 'exp', 'exp', 'exp',\n",
       "                    'exp', --, 'exp', --, 'logcosh', --, 'logcosh', --,\n",
       "                    'logcosh', 'logcosh', 'logcosh', --, 'cube', --, --,\n",
       "                    --, 'exp', --, 'logcosh', --, 'exp', --, --, --, --,\n",
       "                    --, --, 'exp', 'cube', --, --, --, --, --, --, --,\n",
       "                    'logcosh', --, 'cube', --, --, --, --, --, --, --,\n",
       "                    'cube', --, --, --, --, --, --, --, 'logcosh', --, --,\n",
       "                    --, --, --, --, --, --, 'exp', --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 'cube', 'cube', 'exp', --,\n",
       "                    'logcosh', --, --, --, 'logcosh', --, --, --, --, --,\n",
       "                    'logcosh', 'exp', 'exp', --, --, --, --, --, --, --,\n",
       "                    'logcosh', 'cube', --, 'logcosh', --, 'cube', --,\n",
       "                    'cube', --, 'exp', 'cube', --, --, --, --, --, --,\n",
       "                    'cube', --, --, --, 'logcosh', --, --, --, --, --,\n",
       "                    'exp', 'cube', --, --, --, --, --, 'logcosh',\n",
       "                    'logcosh', 'exp', 'logcosh', --, 'cube', --, --,\n",
       "                    'logcosh', --, --, --, --, --, --, --, --, 'logcosh',\n",
       "                    --, --, --, 'exp', 'cube', --, --, 'exp', --, --, --,\n",
       "                    'cube', --, 'exp', 'logcosh', 'cube', --, --, --,\n",
       "                    'logcosh', 'logcosh', --, --, 'cube', 'cube', --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 'logcosh', --, --,\n",
       "                    'cube', --, --, 'logcosh', --, 'logcosh', --,\n",
       "                    'logcosh', --, --, 'cube', 'cube', --, --, 'cube',\n",
       "                    'logcosh', 'logcosh', 'logcosh', 'logcosh', --, --, --,\n",
       "                    --, --, --, 'exp', --, --, --, 'logcosh', --,\n",
       "                    'logcosh', 'exp', 'logcosh', --, --, --, --, --, 'exp',\n",
       "                    --, 'logcosh', --, 'logcosh', --, --, --, 'logcosh',\n",
       "                    --, --, --, --, 'logcosh', 'logcosh', 'cube', --, --,\n",
       "                    'cube', 'logcosh', --, --, 'logcosh', 'logcosh', 'exp',\n",
       "                    'cube', 'logcosh', --, --, 'cube', --, --, --, 'cube',\n",
       "                    --, --, 'exp', 'logcosh', --, --, 'logcosh', 'logcosh',\n",
       "                    --, --, 'cube', --, --, --, 'exp', --, --, 'logcosh',\n",
       "                    --, 'cube', 'cube', 'exp', --, 'logcosh', 'exp',\n",
       "                    'logcosh', 'logcosh', 'cube', 'logcosh', --, 'logcosh',\n",
       "                    'logcosh', --, --, 'exp', 'exp', --, 'logcosh',\n",
       "                    'logcosh', --, 'logcosh', 'logcosh', --, 'logcosh', --,\n",
       "                    'cube', --, 'logcosh', 'cube', --, --, --, --, 'exp',\n",
       "                    'cube', 'cube', 'logcosh', --, 'cube', --, --,\n",
       "                    'logcosh', --, 'exp', 'exp', 'exp', 'logcosh',\n",
       "                    'logcosh', --, --, 'exp', 'logcosh', --, --, 'exp', --,\n",
       "                    'logcosh', --, 'exp', --, 'logcosh', 'logcosh',\n",
       "                    'logcosh', --, --, 'cube', 'exp', --, 'cube', 'cube',\n",
       "                    'logcosh', 'logcosh', --, --, 'logcosh', 'logcosh',\n",
       "                    'logcosh', --, 'logcosh', --, 'exp', --, 'exp',\n",
       "                    'logcosh', 'exp', --, 'cube', --, --, --, --, --,\n",
       "                    'logcosh', --, --, --, --, 'logcosh', 'logcosh', 'exp',\n",
       "                    'logcosh', 'logcosh', --, --, --, 'cube', --, --,\n",
       "                    'exp', --, --, 'logcosh', --, --, --, --, 'logcosh',\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, 'cube',\n",
       "                    --, --, --, --, --, --, --, 'cube', 'exp', 'logcosh',\n",
       "                    --, 'exp', --, --, --, --, --, 'exp', --, 'exp', --,\n",
       "                    'logcosh', --, 'logcosh', --, --, --, --, --, 'cube',\n",
       "                    'logcosh', --, --, --, --, 'cube', --, --, --, 'exp',\n",
       "                    'exp', 'logcosh', --, --, 'cube', --, 'cube', --, --,\n",
       "                    --, --, --, --, 'exp', 'exp', --, 'logcosh', 'logcosh',\n",
       "                    'cube', 'exp', --, 'logcosh', --, --, --, 'cube', --,\n",
       "                    --, --, 'exp', --, 'logcosh', 'logcosh', 'cube', --,\n",
       "                    --, --, --, --, --, --, 'logcosh', 'logcosh', 'cube',\n",
       "                    --, 'exp', 'logcosh', --, 'logcosh', --, 'cube',\n",
       "                    'cube', 'cube', --, 'logcosh', 'logcosh', --,\n",
       "                    'logcosh', --, 'logcosh', 'logcosh', 'exp', 'logcosh',\n",
       "                    'logcosh', --, 'logcosh', 'logcosh', 'logcosh',\n",
       "                    'logcosh', 'exp', 'logcosh', 'logcosh', --, --, --, --,\n",
       "                    --, 'cube', 'logcosh', 'exp', 'logcosh', --, 'logcosh',\n",
       "                    'exp', --, --, --, 'logcosh', 'exp', --, --, 'logcosh',\n",
       "                    'logcosh', --, --, --, --, --, --, --, --, --, --,\n",
       "                    'logcosh', 'logcosh', --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True, False,\n",
       "                     True,  True,  True, False,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True, False,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True, False,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                    False, False, False,  True, False, False,  True,  True,\n",
       "                     True,  True, False,  True, False, False,  True, False,\n",
       "                     True,  True,  True, False,  True,  True, False,  True,\n",
       "                     True,  True, False,  True,  True,  True, False,  True,\n",
       "                     True,  True, False, False, False,  True,  True, False,\n",
       "                     True,  True,  True, False,  True, False, False, False,\n",
       "                    False,  True, False,  True, False,  True, False,  True,\n",
       "                    False, False, False,  True, False,  True,  True,  True,\n",
       "                    False,  True, False,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True, False, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False, False, False,  True, False,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True, False, False, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False, False,  True, False,  True,\n",
       "                    False,  True, False,  True, False, False,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True, False, False,\n",
       "                     True,  True,  True,  True,  True, False, False, False,\n",
       "                    False,  True, False,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True, False, False,  True,  True, False,  True,\n",
       "                     True,  True, False,  True, False, False, False,  True,\n",
       "                     True,  True, False, False,  True,  True, False, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True, False,  True,\n",
       "                     True, False,  True, False,  True, False,  True,  True,\n",
       "                    False, False,  True,  True, False, False, False, False,\n",
       "                    False,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True, False,  True, False, False, False,\n",
       "                     True,  True,  True,  True,  True, False,  True, False,\n",
       "                     True, False,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True, False, False, False,  True,  True, False,\n",
       "                    False,  True,  True, False, False, False, False, False,\n",
       "                     True,  True, False,  True,  True,  True, False,  True,\n",
       "                     True, False, False,  True,  True, False, False,  True,\n",
       "                     True, False,  True,  True,  True, False,  True,  True,\n",
       "                    False,  True, False, False, False,  True, False, False,\n",
       "                    False, False, False, False,  True, False, False,  True,\n",
       "                     True, False, False,  True, False, False,  True, False,\n",
       "                    False,  True, False,  True, False,  True, False, False,\n",
       "                     True,  True,  True,  True, False, False, False, False,\n",
       "                     True, False,  True,  True, False,  True, False, False,\n",
       "                    False, False, False,  True,  True, False, False,  True,\n",
       "                     True, False,  True, False,  True, False,  True, False,\n",
       "                    False, False,  True,  True, False, False,  True, False,\n",
       "                    False, False, False,  True,  True, False, False, False,\n",
       "                     True, False,  True, False,  True, False, False, False,\n",
       "                     True, False,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True, False, False, False, False,\n",
       "                    False,  True,  True,  True, False,  True,  True, False,\n",
       "                     True,  True, False,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False, False, False,  True,\n",
       "                    False,  True,  True,  True,  True,  True, False,  True,\n",
       "                    False,  True, False,  True, False,  True,  True,  True,\n",
       "                     True,  True, False, False,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True, False, False, False,  True,\n",
       "                     True, False,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True, False, False,  True, False, False, False,\n",
       "                    False,  True, False,  True,  True,  True, False,  True,\n",
       "                     True,  True, False,  True, False, False, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False, False,\n",
       "                    False,  True, False, False,  True, False,  True, False,\n",
       "                    False, False,  True, False, False,  True, False,  True,\n",
       "                    False, False, False, False, False,  True, False, False,\n",
       "                    False, False, False, False, False,  True,  True,  True,\n",
       "                     True,  True, False, False, False, False,  True, False,\n",
       "                    False,  True,  True,  True, False, False,  True,  True,\n",
       "                    False, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False, False,  True,  True],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U32'),\n",
       " 'param_feature_preprocessor:fast_ica:whiten': masked_array(data=[--, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 'True', --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 'False', --, --, --, --, 'False', --, --, --, --,\n",
       "                    --, --, 'False', --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 'True', --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 'False', --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, 'True', --, --,\n",
       "                    --, 'True', --, --, --, 'True', --, --, 'False', --,\n",
       "                    --, --, --, --, --, --, --, --, --, 'True', --, 'True',\n",
       "                    --, 'False', --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 'False', --, --, 'True', --, --, --,\n",
       "                    --, 'False', --, --, --, 'True', 'True', 'True', --,\n",
       "                    'True', 'True', --, --, --, --, 'True', --, 'True',\n",
       "                    'True', --, 'False', --, --, --, 'True', --, --,\n",
       "                    'False', --, --, --, 'False', --, --, --, 'False', --,\n",
       "                    --, --, 'False', 'True', 'False', --, --, 'True', --,\n",
       "                    --, --, 'True', --, 'True', 'True', 'True', 'True', --,\n",
       "                    'False', --, 'False', --, 'True', --, 'True', 'False',\n",
       "                    'False', --, 'True', --, --, --, 'True', --, 'False',\n",
       "                    --, 'True', --, --, --, --, --, --, 'True', 'False',\n",
       "                    --, --, --, --, --, --, --, 'True', --, 'True', --, --,\n",
       "                    --, --, --, --, --, 'True', --, --, --, --, --, --, --,\n",
       "                    'False', --, --, --, --, --, --, --, --, 'True', --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, 'True',\n",
       "                    'False', 'False', --, 'False', --, --, --, 'True', --,\n",
       "                    --, --, --, --, 'True', 'True', 'True', --, --, --, --,\n",
       "                    --, --, --, 'True', 'True', --, 'True', --, 'True', --,\n",
       "                    'True', --, 'True', 'True', --, --, --, --, --, --,\n",
       "                    'True', --, --, --, 'False', --, --, --, --, --,\n",
       "                    'False', 'False', --, --, --, --, --, 'True', 'False',\n",
       "                    'False', 'False', --, 'True', --, --, 'True', --, --,\n",
       "                    --, --, --, --, --, --, 'False', --, --, --, 'True',\n",
       "                    'False', --, --, 'True', --, --, --, 'True', --,\n",
       "                    'True', 'False', 'False', --, --, --, 'True', 'True',\n",
       "                    --, --, 'False', 'False', --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 'True', --, --, 'False', --, --,\n",
       "                    'False', --, 'False', --, 'True', --, --, 'True',\n",
       "                    'True', --, --, 'True', 'True', 'True', 'True', 'True',\n",
       "                    --, --, --, --, --, --, 'True', --, --, --, 'False',\n",
       "                    --, 'True', 'True', 'False', --, --, --, --, --,\n",
       "                    'True', --, 'True', --, 'True', --, --, --, 'True', --,\n",
       "                    --, --, --, 'True', 'True', 'False', --, --, 'True',\n",
       "                    'True', --, --, 'False', 'False', 'False', 'True',\n",
       "                    'False', --, --, 'False', --, --, --, 'True', --, --,\n",
       "                    'True', 'True', --, --, 'False', 'True', --, --,\n",
       "                    'True', --, --, --, 'True', --, --, 'False', --,\n",
       "                    'True', 'False', 'True', --, 'True', 'True', 'False',\n",
       "                    'True', 'False', 'True', --, 'True', 'True', --, --,\n",
       "                    'False', 'True', --, 'False', 'False', --, 'True',\n",
       "                    'True', --, 'False', --, 'True', --, 'True', 'False',\n",
       "                    --, --, --, --, 'False', 'True', 'False', 'True', --,\n",
       "                    'True', --, --, 'True', --, 'True', 'True', 'True',\n",
       "                    'True', 'True', --, --, 'True', 'True', --, --, 'True',\n",
       "                    --, 'True', --, 'True', --, 'False', 'True', 'True',\n",
       "                    --, --, 'True', 'True', --, 'True', 'True', 'True',\n",
       "                    'True', --, --, 'True', 'True', 'False', --, 'True',\n",
       "                    --, 'True', --, 'True', 'True', 'True', --, 'True', --,\n",
       "                    --, --, --, --, 'True', --, --, --, --, 'True', 'True',\n",
       "                    'True', 'False', 'False', --, --, --, 'True', --, --,\n",
       "                    'False', --, --, 'True', --, --, --, --, 'False', --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, 'True', --,\n",
       "                    --, --, --, --, --, --, 'False', 'True', 'False', --,\n",
       "                    'True', --, --, --, --, --, 'True', --, 'True', --,\n",
       "                    'True', --, 'False', --, --, --, --, --, 'True',\n",
       "                    'True', --, --, --, --, 'False', --, --, --, 'True',\n",
       "                    'False', 'True', --, --, 'True', --, 'False', --, --,\n",
       "                    --, --, --, --, 'True', 'True', --, 'False', 'True',\n",
       "                    'True', 'True', --, 'True', --, --, --, 'True', --, --,\n",
       "                    --, 'False', --, 'True', 'True', 'True', --, --, --,\n",
       "                    --, --, --, --, 'True', 'False', 'True', --, 'True',\n",
       "                    'True', --, 'True', --, 'True', 'False', 'True', --,\n",
       "                    'True', 'True', --, 'True', --, 'True', 'True', 'True',\n",
       "                    'True', 'True', --, 'True', 'True', 'True', 'True',\n",
       "                    'False', 'True', 'True', --, --, --, --, --, 'True',\n",
       "                    'True', 'True', 'True', --, 'True', 'False', --, --,\n",
       "                    --, 'True', 'False', --, --, 'True', 'True', --, --,\n",
       "                    --, --, --, --, --, --, --, --, 'True', 'True', --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True, False,\n",
       "                     True,  True,  True, False,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True, False,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True, False,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                    False, False, False,  True, False, False,  True,  True,\n",
       "                     True,  True, False,  True, False, False,  True, False,\n",
       "                     True,  True,  True, False,  True,  True, False,  True,\n",
       "                     True,  True, False,  True,  True,  True, False,  True,\n",
       "                     True,  True, False, False, False,  True,  True, False,\n",
       "                     True,  True,  True, False,  True, False, False, False,\n",
       "                    False,  True, False,  True, False,  True, False,  True,\n",
       "                    False, False, False,  True, False,  True,  True,  True,\n",
       "                    False,  True, False,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True, False, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False, False, False,  True, False,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True, False, False, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False, False,  True, False,  True,\n",
       "                    False,  True, False,  True, False, False,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True, False, False,\n",
       "                     True,  True,  True,  True,  True, False, False, False,\n",
       "                    False,  True, False,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True, False, False,  True,  True, False,  True,\n",
       "                     True,  True, False,  True, False, False, False,  True,\n",
       "                     True,  True, False, False,  True,  True, False, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True, False,  True,\n",
       "                     True, False,  True, False,  True, False,  True,  True,\n",
       "                    False, False,  True,  True, False, False, False, False,\n",
       "                    False,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True, False,  True, False, False, False,\n",
       "                     True,  True,  True,  True,  True, False,  True, False,\n",
       "                     True, False,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True, False, False, False,  True,  True, False,\n",
       "                    False,  True,  True, False, False, False, False, False,\n",
       "                     True,  True, False,  True,  True,  True, False,  True,\n",
       "                     True, False, False,  True,  True, False, False,  True,\n",
       "                     True, False,  True,  True,  True, False,  True,  True,\n",
       "                    False,  True, False, False, False,  True, False, False,\n",
       "                    False, False, False, False,  True, False, False,  True,\n",
       "                     True, False, False,  True, False, False,  True, False,\n",
       "                    False,  True, False,  True, False,  True, False, False,\n",
       "                     True,  True,  True,  True, False, False, False, False,\n",
       "                     True, False,  True,  True, False,  True, False, False,\n",
       "                    False, False, False,  True,  True, False, False,  True,\n",
       "                     True, False,  True, False,  True, False,  True, False,\n",
       "                    False, False,  True,  True, False, False,  True, False,\n",
       "                    False, False, False,  True,  True, False, False, False,\n",
       "                     True, False,  True, False,  True, False, False, False,\n",
       "                     True, False,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True, False, False, False, False,\n",
       "                    False,  True,  True,  True, False,  True,  True, False,\n",
       "                     True,  True, False,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False, False, False,  True,\n",
       "                    False,  True,  True,  True,  True,  True, False,  True,\n",
       "                    False,  True, False,  True, False,  True,  True,  True,\n",
       "                     True,  True, False, False,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True, False, False, False,  True,\n",
       "                     True, False,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True, False, False,  True, False, False, False,\n",
       "                    False,  True, False,  True,  True,  True, False,  True,\n",
       "                     True,  True, False,  True, False, False, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False, False,\n",
       "                    False,  True, False, False,  True, False,  True, False,\n",
       "                    False, False,  True, False, False,  True, False,  True,\n",
       "                    False, False, False, False, False,  True, False, False,\n",
       "                    False, False, False, False, False,  True,  True,  True,\n",
       "                     True,  True, False, False, False, False,  True, False,\n",
       "                    False,  True,  True,  True, False, False,  True,  True,\n",
       "                    False, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False, False,  True,  True],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U32'),\n",
       " 'param_feature_preprocessor:feature_agglomeration:affinity': masked_array(data=[--, --, 'cosine', --, --, --, --, --, --, 'euclidean',\n",
       "                    --, --, --, --, 'manhattan', --, --, --, --, --, --,\n",
       "                    'manhattan', --, --, --, --, 'euclidean', --, --,\n",
       "                    'manhattan', --, --, --, --, --, --, 'euclidean', --,\n",
       "                    --, 'euclidean', --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, 'manhattan',\n",
       "                    --, --, --, --, --, --, --, 'euclidean', --, --, --,\n",
       "                    --, 'manhattan', --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 'euclidean', 'euclidean',\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 'manhattan', --, --, --, --, 'euclidean',\n",
       "                    --, --, --, --, --, --, --, --, --, --, 'cosine', --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    'euclidean', 'manhattan', --, --, 'euclidean', --, --,\n",
       "                    --, --, --, --, --, --, 'euclidean', --, --, --, --,\n",
       "                    --, --, --, --, 'manhattan', --, 'euclidean', --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    'cosine', --, 'euclidean', --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    'euclidean', --, --, --, --, --, --, 'manhattan', --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 'manhattan', --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 'cosine', --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 'euclidean', --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 'euclidean', --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 'euclidean', --, --, --, --,\n",
       "                    --, --, --, --, --, 'manhattan', --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 'cosine', --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, 'cosine', --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 'cosine', --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    'euclidean', --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 'euclidean', --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 'euclidean', 'manhattan', --, --,\n",
       "                    'euclidean', --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    'manhattan', 'cosine', --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 'euclidean', --, --, --,\n",
       "                    --, --, --, --, --, --, --, 'cosine', --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 'euclidean', --, --, --, 'manhattan', --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    'euclidean', --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 'euclidean', --, --, --, --],\n",
       "              mask=[ True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True, False,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False, False,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False, False,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U32'),\n",
       " 'param_feature_preprocessor:feature_agglomeration:linkage': masked_array(data=[--, --, 'complete', --, --, --, --, --, --, 'ward', --,\n",
       "                    --, --, --, 'average', --, --, --, --, --, --,\n",
       "                    'complete', --, --, --, --, 'average', --, --,\n",
       "                    'complete', --, --, --, --, --, --, 'complete', --, --,\n",
       "                    'ward', --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 'complete', --, --, --, --,\n",
       "                    --, --, --, 'complete', --, --, --, --, 'average', --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 'average', 'average', --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, 'average', --,\n",
       "                    --, --, --, 'average', --, --, --, --, --, --, --, --,\n",
       "                    --, --, 'complete', --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 'average', 'average', --, --, 'average',\n",
       "                    --, --, --, --, --, --, --, --, 'average', --, --, --,\n",
       "                    --, --, --, --, --, 'average', --, 'average', --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    'complete', --, 'ward', --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, 'ward', --,\n",
       "                    --, --, --, --, --, 'average', --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 'complete', --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    'average', --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    'ward', --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    'ward', --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    'complete', --, --, --, --, --, --, --, --, --,\n",
       "                    'complete', --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 'complete', --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 'complete', --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    'complete', --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 'average', --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 'complete', --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, 'average',\n",
       "                    'average', --, --, 'complete', --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 'average', 'complete', --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 'ward', --, --, --, --,\n",
       "                    --, --, --, --, --, --, 'average', --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    'complete', --, --, --, 'average', --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, 'complete',\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 'ward', --, --, --, --],\n",
       "              mask=[ True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True, False,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False, False,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False, False,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U32'),\n",
       " 'param_feature_preprocessor:feature_agglomeration:n_clusters': masked_array(data=[--, --, 398.0, --, --, --, --, --, --, 4.0, --, --, --,\n",
       "                    --, 188.0, --, --, --, --, --, --, 317.0, --, --, --,\n",
       "                    --, 123.0, --, --, 134.0, --, --, --, --, --, --, 90.0,\n",
       "                    --, --, 47.0, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 244.0, --, --, --,\n",
       "                    --, --, --, --, 234.0, --, --, --, --, 400.0, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    15.0, 74.0, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 149.0, --, --, --, --, 168.0,\n",
       "                    --, --, --, --, --, --, --, --, --, --, 378.0, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, 143.0, 60.0,\n",
       "                    --, --, 15.0, --, --, --, --, --, --, --, --, 103.0,\n",
       "                    --, --, --, --, --, --, --, --, 112.0, --, 151.0, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    20.0, --, 365.0, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, 25.0, --, --,\n",
       "                    --, --, --, --, 95.0, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    339.0, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, 121.0, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 65.0, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 3.0, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 269.0, --, --, --, --, --,\n",
       "                    --, --, --, --, 308.0, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 43.0, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 167.0, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    266.0, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 148.0, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    354.0, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 215.0, 288.0, --, --,\n",
       "                    274.0, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 160.0, 293.0, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    184.0, --, --, --, --, --, --, --, --, --, --, 175.0,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 197.0, --, --, --, 25.0, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    341.0, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 65.0, --, --, --, --],\n",
       "              mask=[ True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True, False,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False, False,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False, False,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_feature_preprocessor:feature_agglomeration:pooling_func': masked_array(data=[--, --, 'mean', --, --, --, --, --, --, 'median', --,\n",
       "                    --, --, --, 'max', --, --, --, --, --, --, 'max', --,\n",
       "                    --, --, --, 'max', --, --, 'mean', --, --, --, --, --,\n",
       "                    --, 'mean', --, --, 'max', --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, 'mean',\n",
       "                    --, --, --, --, --, --, --, 'max', --, --, --, --,\n",
       "                    'mean', --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 'max', 'mean', --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, 'median',\n",
       "                    --, --, --, --, 'median', --, --, --, --, --, --, --,\n",
       "                    --, --, --, 'median', --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 'max', 'mean', --, --, 'max', --, --,\n",
       "                    --, --, --, --, --, --, 'mean', --, --, --, --, --, --,\n",
       "                    --, --, 'median', --, 'mean', --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 'median', --,\n",
       "                    'median', --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 'mean', --, --, --, --,\n",
       "                    --, --, 'median', --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, 'max',\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 'max', --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 'median', --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 'median', --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 'mean', --, --, --, --, --,\n",
       "                    --, --, --, --, 'median', --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 'max', --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 'max', --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 'mean', --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 'median', --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 'mean', --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 'median', 'mean',\n",
       "                    --, --, 'max', --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, 'median',\n",
       "                    'max', --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 'median', --, --, --, --, --, --, --, --,\n",
       "                    --, --, 'median', --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, 'median', --,\n",
       "                    --, --, 'mean', --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 'mean', --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 'median', --, --,\n",
       "                    --, --],\n",
       "              mask=[ True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True, False,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False, False,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False, False,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U32'),\n",
       " 'param_feature_preprocessor:kernel_pca:kernel': masked_array(data=[--, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 'rbf', --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 'cosine', --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 'poly', --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 'poly', --, --, --, --, --, --, --,\n",
       "                    --, --, --, 'rbf', 'cosine', --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 'cosine', 'poly', --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 'rbf', --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 'cosine', --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 'cosine', --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    'sigmoid', --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U32'),\n",
       " 'param_feature_preprocessor:kernel_pca:n_components': masked_array(data=[--, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 565.0, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 1445.0, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 1666.0, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 935.0, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 625.0, 239.0, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 1006.0, 1203.0, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    1052.0, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    36.0, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, 719.0,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, 1259.0, --, --,\n",
       "                    --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_feature_preprocessor:kitchen_sinks:gamma': masked_array(data=[--, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 0.49992769333482023, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    5.2270102435954256e-05, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 0.0977271993233545, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    0.030137779436914123, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 7.586154477090036e-05,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_feature_preprocessor:kitchen_sinks:n_components': masked_array(data=[--, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 185.0, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, 1231.0, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, 188.0, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 428.0, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 3840.0, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_feature_preprocessor:nystroem_sampler:kernel': masked_array(data=[--, --, --, --, --, --, --, 'cosine', --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 'sigmoid', --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 'rbf', --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 'cosine', --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U32'),\n",
       " 'param_feature_preprocessor:nystroem_sampler:n_components': masked_array(data=[--, --, --, --, --, --, --, 7194.0, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 142.0, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 306.0, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 2815.0, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_feature_preprocessor:pca:keep_variance': masked_array(data=[--, --, --, 0.5150397929969202, --, --, --, --, --, --,\n",
       "                    0.5783606461422713, --, 0.9097752246818678,\n",
       "                    0.6102908450519211, --, 0.9671377476120258, --, --, --,\n",
       "                    --, 0.9344482753632339, --, --, 0.6883498821937447, --,\n",
       "                    0.8608936859645954, --, 0.9661723340966253, --, --, --,\n",
       "                    0.9566043734590466, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 0.6167438010763403, --, --, --, --,\n",
       "                    --, --, --, --, --, 0.8425952962565404, --, --, --, --,\n",
       "                    --, --, --, --, --, 0.9999, --, --, 0.7751815548232117,\n",
       "                    --, --, --, --, 0.5834574753485161, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    0.8503409103322925, 0.6233090897331361, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 0.5603296801927988, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 0.5999992869650137,\n",
       "                    0.8675731134276842, --, --, --, 0.7988154665543525, --,\n",
       "                    --, --, --, --, --, --, --, --, 0.9762164035883709, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    0.5915499625765565, --, --, --, --, 0.8934132687184688,\n",
       "                    --, --, --, --, --, --, --, --, 0.7664678236160156, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 0.9942512977021508, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 0.7430342298893273, --, --, --,\n",
       "                    0.502695487221814, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    0.55813885452653, --, --, 0.8275896013380938, --, --,\n",
       "                    --, --, --, --, 0.6152267921455538, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 0.9493631401580722, --, 0.658173373916156, --,\n",
       "                    --, --, --, --, --, --, --, --, 0.944823800920894, --,\n",
       "                    0.9066579070598708, --, --, --, --, --,\n",
       "                    0.6409730320728056, --, 0.5251348274254521, --, --, --,\n",
       "                    --, 0.9831145000734977, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    0.6160733797878657, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 0.9470831460295691,\n",
       "                    0.6386775426908375, --, --, --, --, --,\n",
       "                    0.6452260121358127, --, --, 0.633265204169748, --, --,\n",
       "                    --, --, --, --, 0.9236362820969617, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    0.5214651233749577, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 0.5091742494447935, --, --, --,\n",
       "                    0.7076614616514927, 0.98082715000623, --,\n",
       "                    0.8510315544494598, --, --, --, --, --, --,\n",
       "                    0.9534053072467382, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    0.7412688438997743, --, --, 0.6076850600204904, --, --,\n",
       "                    --, 0.9518789807996776, 0.992061518163893,\n",
       "                    0.9077677966319053, --, --, --, --, --, --, --,\n",
       "                    0.6914209725045629, 0.8582331257840531, --, --, --, --,\n",
       "                    --, --, 0.9684845638567539, --, --, --, --,\n",
       "                    0.5263138008118525, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 0.7389703516758297, --, --,\n",
       "                    --, --, 0.9613959934122577, --, --, --, --, --, --,\n",
       "                    0.9684845638567539, --, --, 0.9350161897617322, --, --,\n",
       "                    --, 0.9999, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    0.5742591165892552, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 0.7804349522998837,\n",
       "                    0.5660771291590012, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    0.5133827227342168, 0.7876030617777108, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    0.9596007225771441, --, --, 0.633265204169748,\n",
       "                    0.727549477400778, --, --, --, --, --, --,\n",
       "                    0.9591636344000158, --, 0.9518638608487143, --, --,\n",
       "                    0.9927969688560696, --, 0.9206712156481929,\n",
       "                    0.6641094844991201, --, 0.974089648102199, --,\n",
       "                    0.9608177505562456, --, --, --, --, --,\n",
       "                    0.9536398500159087, 0.9920672626107974, --,\n",
       "                    0.5066059333362967, 0.5409948570046762, --, --,\n",
       "                    0.5237836363360714, 0.6427454497105527, --, --,\n",
       "                    0.9237007124085592, 0.819640076082897, --, --,\n",
       "                    0.8507096253304692, 0.5973034972557906, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    0.7729101352316644, 0.8972890527743795, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 0.9795213363675142, --, --,\n",
       "                    --, --, --, --, 0.7292517193044236, --,\n",
       "                    0.8399801618587792, 0.5754442808601555,\n",
       "                    0.992258635139768, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 0.6853536069693176, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 0.5935627274079174, --, --, --,\n",
       "                    0.6268980313884196, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 0.9086544545895956,\n",
       "                    0.9361459358291975, --, --, 0.9471909377193211,\n",
       "                    0.6235374507311401, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True, False, False,  True, False,\n",
       "                     True,  True,  True,  True, False,  True,  True, False,\n",
       "                     True, False,  True, False,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True, False,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False, False,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True, False,  True,  True,  True,  True,  True,\n",
       "                    False,  True, False,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False, False,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                    False, False,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True, False,  True,  True,  True,\n",
       "                    False, False, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False, False,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True, False,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True, False, False,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True, False,  True,  True, False,  True,\n",
       "                    False, False,  True, False,  True, False,  True,  True,\n",
       "                     True,  True,  True, False, False,  True, False, False,\n",
       "                     True,  True, False, False,  True,  True, False, False,\n",
       "                     True,  True, False, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True, False, False, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False, False,  True,  True, False, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_feature_preprocessor:pca:whiten': masked_array(data=[--, --, --, 'False', --, --, --, --, --, --, 'False',\n",
       "                    --, 'False', 'True', --, 'False', --, --, --, --,\n",
       "                    'False', --, --, 'True', --, 'True', --, 'True', --,\n",
       "                    --, --, 'True', --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 'True', --, --, --, --, --, --, --, --,\n",
       "                    --, 'True', --, --, --, --, --, --, --, --, --,\n",
       "                    'False', --, --, 'True', --, --, --, --, 'False', --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 'False', 'True', --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 'True', --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 'False', 'False', --, --, --, 'False', --,\n",
       "                    --, --, --, --, --, --, --, --, 'True', --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 'True', --, --, --,\n",
       "                    --, 'False', --, --, --, --, --, --, --, --, 'False',\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 'True', --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 'False', --, --, --, 'False', --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 'False', --, --, 'True', --, --, --, --, --, --,\n",
       "                    'False', --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, 'True', --,\n",
       "                    'True', --, --, --, --, --, --, --, --, --, 'False',\n",
       "                    --, 'True', --, --, --, --, --, 'False', --, 'True',\n",
       "                    --, --, --, --, 'True', --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, 'False',\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    'False', 'True', --, --, --, --, --, 'True', --, --,\n",
       "                    'True', --, --, --, --, --, --, 'False', --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 'False', --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 'True', --, --, --, 'False', 'False', --,\n",
       "                    'False', --, --, --, --, --, --, 'False', --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 'False', --, --, 'True', --, --,\n",
       "                    --, 'False', 'False', 'True', --, --, --, --, --, --,\n",
       "                    --, 'False', 'True', --, --, --, --, --, --, 'True',\n",
       "                    --, --, --, --, 'False', --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 'False', --, --,\n",
       "                    --, --, 'True', --, --, --, --, --, --, 'True', --, --,\n",
       "                    'False', --, --, --, 'True', --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 'False', --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 'False', 'True',\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 'False', 'True', --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 'True', --, --, 'True', 'False', --, --, --,\n",
       "                    --, --, --, 'True', --, 'True', --, --, 'True', --,\n",
       "                    'True', 'True', --, 'True', --, 'True', --, --, --, --,\n",
       "                    --, 'True', 'True', --, 'True', 'True', --, --, 'True',\n",
       "                    'False', --, --, 'True', 'True', --, --, 'True',\n",
       "                    'True', --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 'True', 'False', --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 'True', --, --, --, --,\n",
       "                    --, --, 'True', --, 'False', 'True', 'True', --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    'False', --, --, --, --, --, --, --, --, --, --,\n",
       "                    'True', --, --, --, 'False', --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, 'True',\n",
       "                    'True', --, --, 'True', 'False', --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True, False, False,  True, False,\n",
       "                     True,  True,  True,  True, False,  True,  True, False,\n",
       "                     True, False,  True, False,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True, False,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False, False,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True, False,  True,  True,  True,  True,  True,\n",
       "                    False,  True, False,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False, False,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                    False, False,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True, False,  True,  True,  True,\n",
       "                    False, False, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False, False,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True, False,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True, False, False,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True, False,  True,  True, False,  True,\n",
       "                    False, False,  True, False,  True, False,  True,  True,\n",
       "                     True,  True,  True, False, False,  True, False, False,\n",
       "                     True,  True, False, False,  True,  True, False, False,\n",
       "                     True,  True, False, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True, False, False, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False, False,  True,  True, False, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U32'),\n",
       " 'param_feature_preprocessor:polynomial:degree': masked_array(data=[--, --, --, --, --, --, --, --, --, --, --, 2.0, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 3.0, 2.0, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 3.0, 2.0, --, --,\n",
       "                    --, --, --, --, --, 3.0, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 2.0, --, --, --,\n",
       "                    2.0, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 3.0, --, --, --, --,\n",
       "                    --, 2.0, --, --, 2.0, --, 2.0, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, 3.0,\n",
       "                    --, --, --, 3.0, --, --, --, --, --, --, --, --, --,\n",
       "                    2.0, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 3.0, --, 3.0, --,\n",
       "                    --, --, 2.0, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 3.0, --, 3.0, --, --, --, --, --,\n",
       "                    --, 3.0, --, --, --, --, --, --, --, --, --, --, 3.0,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 2.0, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 2.0, --, 2.0, --, 3.0, --, --,\n",
       "                    --, 2.0, --, --, --, 3.0, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, 2.0, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 2.0, --, --, --, --,\n",
       "                    2.0, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 3.0, --, --, --, --, --, --, --,\n",
       "                    --, 3.0, --, --, --, --, --, 3.0, --, --, --, --, --,\n",
       "                    3.0, --, --, --, 2.0, --, --, --, --, --, --, --, --,\n",
       "                    3.0, 2.0, 3.0, --, --, --, --, --, --, 3.0, --, --, --,\n",
       "                    --, 3.0, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 3.0, --, --, --, --, --, --,\n",
       "                    --, --, --, 2.0, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, 2.0,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    3.0, --, --, --, --, 2.0, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 2.0, --, --, 3.0, --, --, --, --,\n",
       "                    --, --, --, --, --, 3.0, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 3.0, --, 3.0, --, 3.0, --, --, --,\n",
       "                    2.0, --, --, --, --, --, --, --, 3.0, --, --, --, --,\n",
       "                    --, --, --, --, --, 3.0, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 2.0, --, --, --, --, --, --, 3.0, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, 3.0,\n",
       "                    --, --, --, --, --, --, --, --, --, --, 3.0, --, 2.0,\n",
       "                    3.0, --, --, 2.0, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 2.0, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 3.0, --, 3.0, --, --, --, 2.0, --, --,\n",
       "                    --, --, 2.0, 3.0, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 2.0, --, --, --, --, --, --, --, --, 2.0, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 2.0, --, --, --, --, --, --, 2.0, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 3.0, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True, False,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                    False,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True, False,  True,\n",
       "                    False,  True,  True,  True, False,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False, False,\n",
       "                    False,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True, False,  True, False,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True, False, False,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True, False,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                    False, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_feature_preprocessor:polynomial:include_bias': masked_array(data=[--, --, --, --, --, --, --, --, --, --, --, 'False',\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 'True', 'False', --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    'False', 'False', --, --, --, --, --, --, --, 'False',\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 'True', --, --, --, 'False', --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 'False', --, --, --, --, --, 'False', --, --,\n",
       "                    'True', --, 'True', --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 'False', --, --,\n",
       "                    --, 'False', --, --, --, --, --, --, --, --, --,\n",
       "                    'False', --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, 'True', --,\n",
       "                    'False', --, --, --, 'False', --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 'False', --,\n",
       "                    'True', --, --, --, --, --, --, 'True', --, --, --, --,\n",
       "                    --, --, --, --, --, --, 'True', --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 'False', --, --, --, --, --, --, --, --, --,\n",
       "                    --, 'True', --, 'True', --, 'True', --, --, --, 'True',\n",
       "                    --, --, --, 'False', --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 'False', --, --,\n",
       "                    --, --, --, --, --, --, --, --, 'False', --, --, --,\n",
       "                    --, 'False', --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 'True', --, --, --, --, --,\n",
       "                    --, --, --, 'False', --, --, --, --, --, 'False', --,\n",
       "                    --, --, --, --, 'False', --, --, --, 'True', --, --,\n",
       "                    --, --, --, --, --, --, 'False', 'True', 'False', --,\n",
       "                    --, --, --, --, --, 'True', --, --, --, --, 'False',\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 'True', --, --, --, --, --, --, --, --, --,\n",
       "                    'False', --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, 'False', --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    'False', --, --, --, --, 'False', --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 'False', --, --, 'True',\n",
       "                    --, --, --, --, --, --, --, --, --, 'True', --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 'False', --,\n",
       "                    'True', --, 'False', --, --, --, 'False', --, --, --,\n",
       "                    --, --, --, --, 'False', --, --, --, --, --, --, --,\n",
       "                    --, --, 'True', --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 'False', --, --, --, --, --, --, 'True', --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, 'True', --,\n",
       "                    --, --, --, --, --, --, --, --, --, 'False', --,\n",
       "                    'False', 'False', --, --, 'True', --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 'True', --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 'False', --, 'True',\n",
       "                    --, --, --, 'True', --, --, --, --, 'False', 'False',\n",
       "                    --, --, --, --, --, --, --, --, --, --, 'False', --,\n",
       "                    --, --, --, --, --, --, --, 'True', --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    'False', --, --, --, --, --, --, 'True', --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 'False', --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True, False,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                    False,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True, False,  True,\n",
       "                    False,  True,  True,  True, False,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False, False,\n",
       "                    False,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True, False,  True, False,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True, False, False,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True, False,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                    False, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U32'),\n",
       " 'param_feature_preprocessor:polynomial:interaction_only': masked_array(data=[--, --, --, --, --, --, --, --, --, --, --, 'True', --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 'False', 'True', --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, 'False',\n",
       "                    'False', --, --, --, --, --, --, --, 'False', --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    'False', --, --, --, 'False', --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    'False', --, --, --, --, --, 'False', --, --, 'True',\n",
       "                    --, 'False', --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 'False', --, --, --,\n",
       "                    'True', --, --, --, --, --, --, --, --, --, 'True', --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 'True', --, 'True', --, --, --,\n",
       "                    'False', --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 'False', --, 'True', --, --, --, --,\n",
       "                    --, --, 'False', --, --, --, --, --, --, --, --, --,\n",
       "                    --, 'True', --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, 'False',\n",
       "                    --, --, --, --, --, --, --, --, --, --, 'False', --,\n",
       "                    'False', --, 'False', --, --, --, 'False', --, --, --,\n",
       "                    'True', --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 'True', --, --, --, --, --, --, --,\n",
       "                    --, --, --, 'False', --, --, --, --, 'True', --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 'True', --, --, --, --, --, --, --, --, 'False',\n",
       "                    --, --, --, --, --, 'True', --, --, --, --, --,\n",
       "                    'False', --, --, --, 'True', --, --, --, --, --, --,\n",
       "                    --, --, 'False', 'True', 'True', --, --, --, --, --,\n",
       "                    --, 'True', --, --, --, --, 'False', --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    'True', --, --, --, --, --, --, --, --, --, 'False',\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 'True', --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 'True', --, --, --, --,\n",
       "                    'True', --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    'False', --, --, 'True', --, --, --, --, --, --, --,\n",
       "                    --, --, 'False', --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 'True', --, 'True', --, 'False', --, --,\n",
       "                    --, 'True', --, --, --, --, --, --, --, 'True', --, --,\n",
       "                    --, --, --, --, --, --, --, 'False', --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 'False', --, --, --, --,\n",
       "                    --, --, 'False', --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 'False', --, --, --, --, --, --, --,\n",
       "                    --, --, --, 'False', --, 'True', 'False', --, --,\n",
       "                    'True', --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    'False', --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 'False', --, 'False', --, --, --, 'True', --,\n",
       "                    --, --, --, 'False', 'True', --, --, --, --, --, --,\n",
       "                    --, --, --, --, 'True', --, --, --, --, --, --, --, --,\n",
       "                    'True', --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 'False', --, --, --, --, --, --,\n",
       "                    'True', --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    'False', --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True, False,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                    False,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True, False,  True,\n",
       "                    False,  True,  True,  True, False,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False, False,\n",
       "                    False,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True, False,  True, False,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True, False, False,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True, False,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                    False, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U32'),\n",
       " 'param_feature_preprocessor:random_trees_embedding:bootstrap': masked_array(data=[--, 'False', --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 'False', --, --, --, --, --,\n",
       "                    'True', --, --, --, 'False', --, --, --, 'False', --,\n",
       "                    --, --, --, 'False', 'False', --, 'False', 'True', --,\n",
       "                    --, --, 'False', --, --, 'True', --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 'True', 'True', --, 'True',\n",
       "                    'True', --, --, --, --, --, 'False', --, --, --, --,\n",
       "                    --, --, 'True', 'False', --, 'False', --, --, --, --,\n",
       "                    'False', 'False', --, --, --, --, --, --, --, 'True',\n",
       "                    'False', --, --, --, --, --, 'False', --, --, 'False',\n",
       "                    --, --, --, --, --, --, --, --, --, 'False', --, --,\n",
       "                    --, --, 'True', 'True', --, --, --, --, --, --, 'True',\n",
       "                    --, 'True', --, --, --, --, --, --, --, --, --,\n",
       "                    'False', --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    'False', --, --, --, 'False', --, --, --, --, --, --,\n",
       "                    --, --, --, --, 'True', --, --, --, --, --, --,\n",
       "                    'False', --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 'False', --, --, --, --, 'True', --,\n",
       "                    'True', --, --, --, 'True', --, 'False', --, --, --,\n",
       "                    'True', --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 'True', --, --, --, 'True',\n",
       "                    --, --, --, --, --, --, --, --, --, 'True', --, --,\n",
       "                    'False', --, --, 'True', --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 'True', --, 'True', --, --, 'True', --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 'True', --, 'True', --,\n",
       "                    'False', --, --, --, --, 'True', --, --, --, --, --,\n",
       "                    --, --, --, --, --, 'True', 'True', --, --, --, --, --,\n",
       "                    --, 'True', --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 'True', --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    'True', --, --, --, 'False', --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 'True', --, --, --, --, --, --, --,\n",
       "                    --, --, 'False', --, --, 'False', 'False', --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 'True', --, --, --, --, --, --, --, --, --,\n",
       "                    'True', --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    'True', 'False', --, --, --, --, --, 'True', --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 'True', --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, 'True',\n",
       "                    --, 'True', --, --, 'False', --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 'False', --, --, --, --,\n",
       "                    'False', --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, 'False', --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 'True', --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 'False', --],\n",
       "              mask=[ True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True, False,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True, False, False,  True,\n",
       "                    False, False,  True,  True,  True, False,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False, False,  True, False,\n",
       "                    False,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True, False, False,  True,\n",
       "                    False,  True,  True,  True,  True, False, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False, False,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True, False,  True, False,  True,  True,  True, False,\n",
       "                     True, False,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True, False,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True, False,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True, False,  True,\n",
       "                    False,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False, False,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True, False, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True, False,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U32'),\n",
       " 'param_feature_preprocessor:random_trees_embedding:max_depth': masked_array(data=[--, 8.0, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 9.0, --, --, --, --, --, 2.0, --,\n",
       "                    --, --, 7.0, --, --, --, 8.0, --, --, --, --, 10.0,\n",
       "                    9.0, --, 5.0, 5.0, --, --, --, 4.0, --, --, 4.0, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, 4.0, 10.0, --,\n",
       "                    9.0, 3.0, --, --, --, --, --, 5.0, --, --, --, --, --,\n",
       "                    --, 8.0, 10.0, --, 9.0, --, --, --, --, 9.0, 4.0, --,\n",
       "                    --, --, --, --, --, --, 2.0, 10.0, --, --, --, --, --,\n",
       "                    4.0, --, --, 6.0, --, --, --, --, --, --, --, --, --,\n",
       "                    8.0, --, --, --, --, 9.0, 5.0, --, --, --, --, --, --,\n",
       "                    10.0, --, 5.0, --, --, --, --, --, --, --, --, --, 4.0,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, 3.0, --,\n",
       "                    --, --, 10.0, --, --, --, --, --, --, --, --, --, --,\n",
       "                    2.0, --, --, --, --, --, --, 4.0, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 7.0, --, --, --,\n",
       "                    --, 9.0, --, 10.0, --, --, --, 4.0, --, 4.0, --, --,\n",
       "                    --, 3.0, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 6.0, --, --, --, 10.0,\n",
       "                    --, --, --, --, --, --, --, --, --, 6.0, --, --, 7.0,\n",
       "                    --, --, 9.0, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 2.0, --, 7.0, --, --, 2.0, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 10.0, --, 6.0, --, 2.0, --, --, --, --, 4.0, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 7.0, 7.0, --, --,\n",
       "                    --, --, --, --, 3.0, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, 6.0,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 10.0, --, --, --, 2.0, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 9.0, --, --, --, --, --, --, --,\n",
       "                    --, --, 3.0, --, --, 4.0, 10.0, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    2.0, --, --, --, --, --, --, --, --, --, 8.0, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 5.0, 10.0, --, --,\n",
       "                    --, --, --, 3.0, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    9.0, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 10.0, --, 9.0, --, --, 5.0, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, 3.0, --,\n",
       "                    --, --, --, 2.0, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, 8.0,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 7.0, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 6.0, --],\n",
       "              mask=[ True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True, False,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True, False, False,  True,\n",
       "                    False, False,  True,  True,  True, False,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False, False,  True, False,\n",
       "                    False,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True, False, False,  True,\n",
       "                    False,  True,  True,  True,  True, False, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False, False,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True, False,  True, False,  True,  True,  True, False,\n",
       "                     True, False,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True, False,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True, False,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True, False,  True,\n",
       "                    False,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False, False,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True, False, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True, False,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_feature_preprocessor:random_trees_embedding:max_leaf_nodes': masked_array(data=[--, 'None', --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 'None', --, --, --, --, --, 'None',\n",
       "                    --, --, --, 'None', --, --, --, 'None', --, --, --, --,\n",
       "                    'None', 'None', --, 'None', 'None', --, --, --, 'None',\n",
       "                    --, --, 'None', --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 'None', 'None', --, 'None', 'None', --, --, --, --,\n",
       "                    --, 'None', --, --, --, --, --, --, 'None', 'None', --,\n",
       "                    'None', --, --, --, --, 'None', 'None', --, --, --, --,\n",
       "                    --, --, --, 'None', 'None', --, --, --, --, --, 'None',\n",
       "                    --, --, 'None', --, --, --, --, --, --, --, --, --,\n",
       "                    'None', --, --, --, --, 'None', 'None', --, --, --, --,\n",
       "                    --, --, 'None', --, 'None', --, --, --, --, --, --, --,\n",
       "                    --, --, 'None', --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 'None', --, --, --, 'None', --, --, --, --, --, --,\n",
       "                    --, --, --, --, 'None', --, --, --, --, --, --, 'None',\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    'None', --, --, --, --, 'None', --, 'None', --, --, --,\n",
       "                    'None', --, 'None', --, --, --, 'None', --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 'None', --, --, --, 'None', --, --, --, --, --, --,\n",
       "                    --, --, --, 'None', --, --, 'None', --, --, 'None', --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, 'None', --,\n",
       "                    'None', --, --, 'None', --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    'None', --, 'None', --, 'None', --, --, --, --, 'None',\n",
       "                    --, --, --, --, --, --, --, --, --, --, 'None', 'None',\n",
       "                    --, --, --, --, --, --, 'None', --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    'None', --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 'None', --, --, --, 'None', --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 'None', --, --, --, --,\n",
       "                    --, --, --, --, --, 'None', --, --, 'None', 'None', --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 'None', --, --, --, --, --, --, --,\n",
       "                    --, --, 'None', --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 'None', 'None', --, --, --, --, --, 'None', --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 'None', --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, 'None',\n",
       "                    --, 'None', --, --, 'None', --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 'None', --, --, --, --, 'None',\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 'None', --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, 'None',\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, 'None', --],\n",
       "              mask=[ True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True, False,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True, False, False,  True,\n",
       "                    False, False,  True,  True,  True, False,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False, False,  True, False,\n",
       "                    False,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True, False, False,  True,\n",
       "                    False,  True,  True,  True,  True, False, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False, False,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True, False,  True, False,  True,  True,  True, False,\n",
       "                     True, False,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True, False,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True, False,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True, False,  True,\n",
       "                    False,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False, False,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True, False, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True, False,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U32'),\n",
       " 'param_feature_preprocessor:random_trees_embedding:min_samples_leaf': masked_array(data=[--, 16.0, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 3.0, --, --, --, --, --, 17.0, --,\n",
       "                    --, --, 18.0, --, --, --, 13.0, --, --, --, --, 15.0,\n",
       "                    16.0, --, 19.0, 2.0, --, --, --, 16.0, --, --, 6.0, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, 18.0, 1.0, --,\n",
       "                    10.0, 1.0, --, --, --, --, --, 9.0, --, --, --, --, --,\n",
       "                    --, 12.0, 4.0, --, 15.0, --, --, --, --, 2.0, 17.0, --,\n",
       "                    --, --, --, --, --, --, 17.0, 17.0, --, --, --, --, --,\n",
       "                    17.0, --, --, 7.0, --, --, --, --, --, --, --, --, --,\n",
       "                    13.0, --, --, --, --, 19.0, 18.0, --, --, --, --, --,\n",
       "                    --, 13.0, --, 1.0, --, --, --, --, --, --, --, --, --,\n",
       "                    16.0, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    18.0, --, --, --, 19.0, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 17.0, --, --, --, --, --, --, 3.0, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, 12.0, --,\n",
       "                    --, --, --, 17.0, --, 18.0, --, --, --, 1.0, --, 18.0,\n",
       "                    --, --, --, 18.0, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, 3.0, --, --,\n",
       "                    --, 16.0, --, --, --, --, --, --, --, --, --, 19.0, --,\n",
       "                    --, 14.0, --, --, 17.0, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 18.0, --, 17.0, --, --, 5.0, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 11.0, --, 20.0, --, 20.0, --, --, --,\n",
       "                    --, 19.0, --, --, --, --, --, --, --, --, --, --, 19.0,\n",
       "                    19.0, --, --, --, --, --, --, 19.0, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 1.0, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 7.0, --, --, --, 13.0, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 5.0, --, --, --, --,\n",
       "                    --, --, --, --, --, 20.0, --, --, 20.0, 2.0, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 15.0, --, --, --, --, --, --, --, --,\n",
       "                    --, 12.0, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    7.0, 11.0, --, --, --, --, --, 4.0, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 9.0, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 15.0, --, 16.0, --,\n",
       "                    --, 20.0, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 7.0, --, --, --, --, 18.0, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 6.0, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 4.0, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 18.0, --],\n",
       "              mask=[ True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True, False,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True, False, False,  True,\n",
       "                    False, False,  True,  True,  True, False,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False, False,  True, False,\n",
       "                    False,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True, False, False,  True,\n",
       "                    False,  True,  True,  True,  True, False, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False, False,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True, False,  True, False,  True,  True,  True, False,\n",
       "                     True, False,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True, False,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True, False,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True, False,  True,\n",
       "                    False,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False, False,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True, False, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True, False,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_feature_preprocessor:random_trees_embedding:min_samples_split': masked_array(data=[--, 5.0, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 11.0, --, --, --, --, --, 3.0, --,\n",
       "                    --, --, 3.0, --, --, --, 15.0, --, --, --, --, 14.0,\n",
       "                    5.0, --, 15.0, 20.0, --, --, --, 12.0, --, --, 18.0,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, 17.0, 15.0,\n",
       "                    --, 2.0, 9.0, --, --, --, --, --, 14.0, --, --, --, --,\n",
       "                    --, --, 7.0, 14.0, --, 8.0, --, --, --, --, 7.0, 17.0,\n",
       "                    --, --, --, --, --, --, --, 18.0, 6.0, --, --, --, --,\n",
       "                    --, 3.0, --, --, 15.0, --, --, --, --, --, --, --, --,\n",
       "                    --, 15.0, --, --, --, --, 6.0, 10.0, --, --, --, --,\n",
       "                    --, --, 6.0, --, 8.0, --, --, --, --, --, --, --, --,\n",
       "                    --, 12.0, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    6.0, --, --, --, 16.0, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 10.0, --, --, --, --, --, --, 12.0, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, 20.0, --,\n",
       "                    --, --, --, 2.0, --, 11.0, --, --, --, 8.0, --, 15.0,\n",
       "                    --, --, --, 18.0, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, 17.0, --, --,\n",
       "                    --, 4.0, --, --, --, --, --, --, --, --, --, 18.0, --,\n",
       "                    --, 14.0, --, --, 15.0, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 2.0, --, 14.0, --, --, 13.0, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 19.0, --, 11.0, --, 8.0, --, --, --,\n",
       "                    --, 11.0, --, --, --, --, --, --, --, --, --, --, 12.0,\n",
       "                    13.0, --, --, --, --, --, --, 12.0, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 16.0, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 5.0, --, --, --, 18.0, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 17.0, --, --, --, --,\n",
       "                    --, --, --, --, --, 15.0, --, --, 19.0, 6.0, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 3.0, --, --, --, --, --, --, --, --,\n",
       "                    --, 20.0, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    18.0, 14.0, --, --, --, --, --, 8.0, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 4.0, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, 19.0, --, 6.0,\n",
       "                    --, --, 16.0, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 14.0, --, --, --, --, 17.0, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 12.0, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 11.0, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 17.0, --],\n",
       "              mask=[ True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True, False,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True, False, False,  True,\n",
       "                    False, False,  True,  True,  True, False,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False, False,  True, False,\n",
       "                    False,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True, False, False,  True,\n",
       "                    False,  True,  True,  True,  True, False, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False, False,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True, False,  True, False,  True,  True,  True, False,\n",
       "                     True, False,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True, False,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True, False,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True, False,  True,\n",
       "                    False,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False, False,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True, False, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True, False,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': masked_array(data=[--, 1.0, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 1.0, --, --, --, --, --, 1.0, --,\n",
       "                    --, --, 1.0, --, --, --, 1.0, --, --, --, --, 1.0, 1.0,\n",
       "                    --, 1.0, 1.0, --, --, --, 1.0, --, --, 1.0, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 1.0, 1.0, --, 1.0, 1.0,\n",
       "                    --, --, --, --, --, 1.0, --, --, --, --, --, --, 1.0,\n",
       "                    1.0, --, 1.0, --, --, --, --, 1.0, 1.0, --, --, --, --,\n",
       "                    --, --, --, 1.0, 1.0, --, --, --, --, --, 1.0, --, --,\n",
       "                    1.0, --, --, --, --, --, --, --, --, --, 1.0, --, --,\n",
       "                    --, --, 1.0, 1.0, --, --, --, --, --, --, 1.0, --, 1.0,\n",
       "                    --, --, --, --, --, --, --, --, --, 1.0, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 1.0, --, --, --, 1.0,\n",
       "                    --, --, --, --, --, --, --, --, --, --, 1.0, --, --,\n",
       "                    --, --, --, --, 1.0, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 1.0, --, --, --, --, 1.0, --,\n",
       "                    1.0, --, --, --, 1.0, --, 1.0, --, --, --, 1.0, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 1.0, --, --, --, 1.0, --, --, --, --, --,\n",
       "                    --, --, --, --, 1.0, --, --, 1.0, --, --, 1.0, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 1.0, --, 1.0, --,\n",
       "                    --, 1.0, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, 1.0, --, 1.0,\n",
       "                    --, 1.0, --, --, --, --, 1.0, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 1.0, 1.0, --, --, --, --, --, --, 1.0,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 1.0, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, 1.0, --, --,\n",
       "                    --, 1.0, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    1.0, --, --, --, --, --, --, --, --, --, 1.0, --, --,\n",
       "                    1.0, 1.0, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 1.0, --, --, --,\n",
       "                    --, --, --, --, --, --, 1.0, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 1.0, 1.0, --, --, --, --, --, 1.0,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 1.0, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    1.0, --, 1.0, --, --, 1.0, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 1.0, --, --, --, --, 1.0, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 1.0, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, 1.0, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, 1.0, --],\n",
       "              mask=[ True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True, False,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True, False, False,  True,\n",
       "                    False, False,  True,  True,  True, False,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False, False,  True, False,\n",
       "                    False,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True, False, False,  True,\n",
       "                    False,  True,  True,  True,  True, False, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False, False,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True, False,  True, False,  True,  True,  True, False,\n",
       "                     True, False,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True, False,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True, False,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True, False,  True,\n",
       "                    False,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False, False,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True, False, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True, False,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_feature_preprocessor:random_trees_embedding:n_estimators': masked_array(data=[--, 37.0, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 33.0, --, --, --, --, --, 69.0, --,\n",
       "                    --, --, 43.0, --, --, --, 24.0, --, --, --, --, 23.0,\n",
       "                    41.0, --, 71.0, 17.0, --, --, --, 99.0, --, --, 50.0,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, 23.0, 15.0,\n",
       "                    --, 78.0, 86.0, --, --, --, --, --, 27.0, --, --, --,\n",
       "                    --, --, --, 42.0, 37.0, --, 91.0, --, --, --, --, 54.0,\n",
       "                    17.0, --, --, --, --, --, --, --, 91.0, 16.0, --, --,\n",
       "                    --, --, --, 12.0, --, --, 37.0, --, --, --, --, --, --,\n",
       "                    --, --, --, 24.0, --, --, --, --, 44.0, 33.0, --, --,\n",
       "                    --, --, --, --, 65.0, --, 10.0, --, --, --, --, --, --,\n",
       "                    --, --, --, 99.0, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 70.0, --, --, --, 93.0, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 42.0, --, --, --, --, --, --, 55.0, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    43.0, --, --, --, --, 28.0, --, 56.0, --, --, --, 27.0,\n",
       "                    --, 66.0, --, --, --, 54.0, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, 65.0,\n",
       "                    --, --, --, 63.0, --, --, --, --, --, --, --, --, --,\n",
       "                    84.0, --, --, 49.0, --, --, 23.0, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 16.0, --, 73.0, --, --, 20.0,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 60.0, --, 82.0, --, 52.0,\n",
       "                    --, --, --, --, 23.0, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 61.0, 92.0, --, --, --, --, --, --, 19.0, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 83.0, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 11.0, --, --, --,\n",
       "                    97.0, --, --, --, --, --, --, --, --, --, --, --, 66.0,\n",
       "                    --, --, --, --, --, --, --, --, --, 60.0, --, --, 86.0,\n",
       "                    20.0, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 80.0, --, --, --, --,\n",
       "                    --, --, --, --, --, 76.0, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 16.0, 15.0, --, --, --, --, --, 99.0,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 85.0, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    10.0, --, 94.0, --, --, 54.0, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 57.0, --, --, --, --, 68.0,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 95.0, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, 76.0,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, 66.0, --],\n",
       "              mask=[ True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True, False,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True, False, False,  True,\n",
       "                    False, False,  True,  True,  True, False,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False, False,  True, False,\n",
       "                    False,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True, False, False,  True,\n",
       "                    False,  True,  True,  True,  True, False, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False, False,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True, False,  True, False,  True,  True,  True, False,\n",
       "                     True, False,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True, False,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True, False,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True, False,  True,\n",
       "                    False,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False, False,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True, False, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True, False,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_regressor:decision_tree:criterion': masked_array(data=[--, --, 'mae', 'mae', --, --, --, --, --, --, --,\n",
       "                    'friedman_mse', --, 'mse', --, --, --, --, 'mse', --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    'friedman_mse', --, --, --, --, --, --, --, --, --,\n",
       "                    'friedman_mse', --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 'mae', --, --, --, --, 'mae', --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 'mae', --, --, --, 'friedman_mse', --, --,\n",
       "                    'mse', --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 'mse', --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 'mse', --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, 'mse', --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 'mse', --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, 'mse', --,\n",
       "                    --, --, --, --, --, 'mae', --, --, --, --, --, --,\n",
       "                    'mse', --, --, --, --, 'mae', --, --, 'mae', --, --,\n",
       "                    --, --, 'mse', --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 'mse', --, --, --, --, --, --, 'mse',\n",
       "                    'mse', --, --, --, 'mse', --, --, --, --, --, --,\n",
       "                    'mse', --, --, --, --, --, 'mse', --, 'friedman_mse',\n",
       "                    'friedman_mse', 'mse', --, 'mae', --, --, --, --, --,\n",
       "                    --, --, 'mse', --, --, --, --, --, --, --, --, --,\n",
       "                    'mse', --, --, --, 'mae', --, --, --, --, --, --,\n",
       "                    'mse', 'mse', --, --, --, 'mse', --, --, 'mse', 'mse',\n",
       "                    'mse', --, 'mse', --, 'mse', --, 'mse', --, --, --, --,\n",
       "                    'mse', 'friedman_mse', --, --, --, --, 'mse',\n",
       "                    'friedman_mse', --, --, 'mse', 'friedman_mse', --, --,\n",
       "                    --, --, 'mse', --, --, --, --, --, 'mae', --,\n",
       "                    'friedman_mse', --, 'friedman_mse', --, --, --,\n",
       "                    'friedman_mse', --, --, --, 'friedman_mse', 'mae', --,\n",
       "                    'mse', 'mse', --, 'mse', 'friedman_mse', --, --, --,\n",
       "                    --, --, --, --, 'friedman_mse', --, --, 'friedman_mse',\n",
       "                    --, 'mse', --, 'friedman_mse', --, 'mse', 'mse',\n",
       "                    'friedman_mse', --, 'friedman_mse', 'mae', 'mse',\n",
       "                    'mse', 'mse', --, --, 'friedman_mse', 'mse', 'mse',\n",
       "                    'friedman_mse', 'friedman_mse', --, --, 'friedman_mse',\n",
       "                    --, --, --, 'mae', --, 'friedman_mse', --, --, --, --,\n",
       "                    --, 'mse', 'mse', 'mse', 'mse', --, 'friedman_mse', --,\n",
       "                    'mse', 'mse', --, 'mse', 'mse', 'mse', 'mse', 'mse',\n",
       "                    --, 'mae', --, --, --, --, --, 'mae', 'mse', --, 'mae',\n",
       "                    --, --, 'friedman_mse', 'mse', --, --, 'friedman_mse',\n",
       "                    'mse', --, 'friedman_mse', 'friedman_mse',\n",
       "                    'friedman_mse', 'mse', 'friedman_mse', 'mse', 'mse',\n",
       "                    'mse', 'friedman_mse', --, --, --, 'friedman_mse', --,\n",
       "                    'mse', 'mse', 'mse', --, 'mse', --, 'mae', --, --,\n",
       "                    'mse', 'friedman_mse', --, 'mse', --, --, --, 'mse',\n",
       "                    'friedman_mse', 'mse', --, 'friedman_mse',\n",
       "                    'friedman_mse', 'friedman_mse', 'mse', --,\n",
       "                    'friedman_mse', --, 'friedman_mse', 'friedman_mse', --,\n",
       "                    'friedman_mse', 'friedman_mse', 'friedman_mse', --, --,\n",
       "                    'mae', --, 'mae', 'friedman_mse', 'friedman_mse', --,\n",
       "                    'mse', 'friedman_mse', --, --, 'mse', --,\n",
       "                    'friedman_mse', --, 'friedman_mse', 'friedman_mse', --,\n",
       "                    --, --, 'friedman_mse', 'mse', 'mse', --, --, 'mae',\n",
       "                    --, --, 'mae', --, --, --, --, --, 'friedman_mse', --,\n",
       "                    --, --, --, 'mse', 'friedman_mse', 'friedman_mse', --,\n",
       "                    'friedman_mse', 'mse', --, --, 'friedman_mse',\n",
       "                    'friedman_mse', 'mae', --, --, 'friedman_mse', 'mae',\n",
       "                    --, 'friedman_mse', --, --, --, --, --, 'mae', --,\n",
       "                    'mse', --, --, 'mae', 'mae', 'friedman_mse', --,\n",
       "                    'friedman_mse', --, --, 'mse', --, 'friedman_mse', --,\n",
       "                    --, --, 'friedman_mse', --, --, 'mae', --, --, 'mse',\n",
       "                    --, 'friedman_mse', --, --, 'mse', --, --, --, --,\n",
       "                    'friedman_mse', 'mse', 'mse', --, 'mse',\n",
       "                    'friedman_mse', 'mse', 'friedman_mse', --, 'mse', --,\n",
       "                    --, --, 'friedman_mse', --, --, 'friedman_mse', --,\n",
       "                    'friedman_mse', 'mse', 'friedman_mse', 'friedman_mse',\n",
       "                    'friedman_mse', 'mse', 'mse', 'friedman_mse',\n",
       "                    'friedman_mse', 'mse', --, 'mse', 'mae', --, --, --,\n",
       "                    --, --, 'friedman_mse', 'friedman_mse', --, 'mse', --,\n",
       "                    'friedman_mse', 'mse', --, 'mse', 'mse',\n",
       "                    'friedman_mse', 'mse', --, --, 'mse', 'mae', --,\n",
       "                    'friedman_mse', --, --, --, --, --, --, --, --, 'mse',\n",
       "                    'friedman_mse', --, --],\n",
       "              mask=[ True,  True, False, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True, False,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True, False,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True, False,  True,  True, False,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True, False, False,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True, False,  True, False, False,\n",
       "                    False,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True, False,  True,  True, False,\n",
       "                    False, False,  True, False,  True, False,  True, False,\n",
       "                     True,  True,  True,  True, False, False,  True,  True,\n",
       "                     True,  True, False, False,  True,  True, False, False,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True, False,  True, False,  True, False,  True,\n",
       "                     True,  True, False,  True,  True,  True, False, False,\n",
       "                     True, False, False,  True, False, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                    False,  True, False,  True, False,  True, False, False,\n",
       "                    False,  True, False, False, False, False, False,  True,\n",
       "                     True, False, False, False, False, False,  True,  True,\n",
       "                    False,  True,  True,  True, False,  True, False,  True,\n",
       "                     True,  True,  True,  True, False, False, False, False,\n",
       "                     True, False,  True, False, False,  True, False, False,\n",
       "                    False, False, False,  True, False,  True,  True,  True,\n",
       "                     True,  True, False, False,  True, False,  True,  True,\n",
       "                    False, False,  True,  True, False, False,  True, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                     True,  True,  True, False,  True, False, False, False,\n",
       "                     True, False,  True, False,  True,  True, False, False,\n",
       "                     True, False,  True,  True,  True, False, False, False,\n",
       "                     True, False, False, False, False,  True, False,  True,\n",
       "                    False, False,  True, False, False, False,  True,  True,\n",
       "                    False,  True, False, False, False,  True, False, False,\n",
       "                     True,  True, False,  True, False,  True, False, False,\n",
       "                     True,  True,  True, False, False, False,  True,  True,\n",
       "                    False,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True, False, False,\n",
       "                    False,  True, False, False,  True,  True, False, False,\n",
       "                    False,  True,  True, False, False,  True, False,  True,\n",
       "                     True,  True,  True,  True, False,  True, False,  True,\n",
       "                     True, False, False, False,  True, False,  True,  True,\n",
       "                    False,  True, False,  True,  True,  True, False,  True,\n",
       "                     True, False,  True,  True, False,  True, False,  True,\n",
       "                     True, False,  True,  True,  True,  True, False, False,\n",
       "                    False,  True, False, False, False, False,  True, False,\n",
       "                     True,  True,  True, False,  True,  True, False,  True,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False,  True, False, False,  True,  True,  True,\n",
       "                     True,  True, False, False,  True, False,  True, False,\n",
       "                    False,  True, False, False, False, False,  True,  True,\n",
       "                    False, False,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False, False,  True,  True],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U32'),\n",
       " 'param_regressor:decision_tree:max_depth_factor': masked_array(data=[--, --, 1.0055563958082605, 0.30043377411209327, --,\n",
       "                    --, --, --, --, --, --, 0.3674271434444325, --,\n",
       "                    0.800195617625348, --, --, --, --, 0.03153163250803037,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    0.6738734972905724, --, --, --, --, --, --, --, --, --,\n",
       "                    0.7178331182723261, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 0.9669651761509541, --, --, --, --,\n",
       "                    0.2158669126632733, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    1.442639486324955, --, --, --, 0.520735227961066, --,\n",
       "                    --, 1.0392881611506182, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 1.917259113221755, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 0.6147471031682119, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 0.8227189329764348, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    0.8556122984280683, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    0.1473280356333253, --, --, --, --, --, --,\n",
       "                    1.1143893983344055, --, --, --, --, --, --,\n",
       "                    0.40422044403763846, --, --, --, --,\n",
       "                    1.0178612159642375, --, --, 0.45206851368113354, --,\n",
       "                    --, --, --, 0.6264769596405859, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 0.7334528152177051, --,\n",
       "                    --, --, --, --, --, 0.6670744301935622,\n",
       "                    0.673784180347461, --, --, --, 0.41687451703652556, --,\n",
       "                    --, --, --, --, --, 0.3485692701754227, --, --, --, --,\n",
       "                    --, 0.20521565931291616, --, 0.5426862776196556,\n",
       "                    0.31497741078178065, 1.3301014170986079, --,\n",
       "                    1.9875058230704994, --, --, --, --, --, --, --,\n",
       "                    0.06506680234949211, --, --, --, --, --, --, --, --,\n",
       "                    --, 1.6287537851836027, --, --, --,\n",
       "                    0.11133301365645826, --, --, --, --, --, --,\n",
       "                    0.3063751286433084, 0.3189230967012904, --, --, --,\n",
       "                    0.4302462063303424, --, --, 0.8971165463352386,\n",
       "                    0.5022101050668017, 0.5951981022730573, --,\n",
       "                    0.3882533165651361, --, 0.2772116309998369, --,\n",
       "                    0.041366106406682694, --, --, --, --,\n",
       "                    1.4840181339978349, 0.2772116309998369, --, --, --, --,\n",
       "                    0.342598879600562, 0.3033033714113468, --, --,\n",
       "                    0.17926236818299313, 0.16238765835827285, --, --, --,\n",
       "                    --, 0.2693398167553451, --, --, --, --, --,\n",
       "                    0.29693181660895185, --, 0.2772116309998369, --,\n",
       "                    0.30597420053041924, --, --, --, 0.29750631896702506,\n",
       "                    --, --, --, 0.2772116309998369, 0.7331941601078606, --,\n",
       "                    0.44291404361237785, 0.47230724619462294, --,\n",
       "                    0.342598879600562, 0.28322877424532295, --, --, --, --,\n",
       "                    --, --, --, 0.30472594882091525, --, --,\n",
       "                    0.29947906255940804, --, 1.4902341289528804, --,\n",
       "                    0.3017598508074356, --, 0.6300306739998313,\n",
       "                    0.774025909978848, 0.47089157723143843, --,\n",
       "                    0.13622558947169422, 0.28001800560505163,\n",
       "                    0.1423396276291664, 1.5991090153294587,\n",
       "                    1.1206867995157397, --, --, 0.28461777309208663,\n",
       "                    1.6942472581217551, 1.2053009778696606,\n",
       "                    0.3258069972041705, 0.3083151431301858, --, --,\n",
       "                    0.2503163596279798, --, --, --, 0.7314529769080818, --,\n",
       "                    0.2456601049541306, --, --, --, --, --,\n",
       "                    0.5401258021431654, 0.30081906609023806,\n",
       "                    0.6437655304659, 0.07151935004427004, --,\n",
       "                    0.7723644336114692, --, 0.4144393905175181,\n",
       "                    0.1237986482603835, --, 0.08155818919924712,\n",
       "                    0.4427787719206687, 1.0009865936733635,\n",
       "                    0.025505666468476962, 0.012782679872980374, --,\n",
       "                    0.6095050686448309, --, --, --, --, --,\n",
       "                    1.1790597225310715, 0.09387081716619516, --,\n",
       "                    0.05620949601342088, --, --, 0.07564645200292093,\n",
       "                    0.05658620989752028, --, --, 0.009707583388910803,\n",
       "                    0.39269210789242404, --, 0.014463009419814293,\n",
       "                    0.8784829749844543, 0.25400865260654704,\n",
       "                    0.6655630060782344, 0.42692424567096465,\n",
       "                    0.3095687711304246, 0.012782679872980374,\n",
       "                    0.04445996533190901, 0.07181792655778518, --, --, --,\n",
       "                    0.012782679872980374, --, 0.0034073893099065833,\n",
       "                    0.11427519603222093, 0.009707583388910803, --,\n",
       "                    0.07564645200292093, --, 0.9633105075488593, --, --,\n",
       "                    0.0283458148689016, 0.2422156151445994, --,\n",
       "                    0.6588116079898395, --, --, --, 0.2839499838493097,\n",
       "                    0.05658620989752028, 0.036330165136707636, --,\n",
       "                    0.027454521527994984, 0.01142368324134076,\n",
       "                    0.027880321355516872, 0.08155818919924712, --, 0.5, --,\n",
       "                    0.030063329230867186, 0.023076523414866434, --,\n",
       "                    0.0283458148689016, 0.27387533687260635,\n",
       "                    0.020945153506898753, --, --, 0.8346890563517426, --,\n",
       "                    0.006856919975203199, 0.2901468210953769,\n",
       "                    0.02139922100435815, --, 1.1967935162168963,\n",
       "                    0.7276388443565145, --, --, 0.6557133851142325, --,\n",
       "                    0.037399698990877736, --, 0.29982756202051747,\n",
       "                    0.027454521527994984, --, --, --, 1.422393291470937,\n",
       "                    0.005249280268851778, 0.4574093655738248, --, --,\n",
       "                    7.748862070796649e-05, --, --, 0.7353429112195173, --,\n",
       "                    --, --, --, --, 0.0035358902415415974, --, --, --, --,\n",
       "                    0.005884909182365528, 0.019348843962803862,\n",
       "                    1.9564838142389314, --, 0.014040162423953251,\n",
       "                    0.46395088971522636, --, --, 0.3791136373976369,\n",
       "                    0.7207110017228755, 0.4214296701839799, --, --,\n",
       "                    0.25257535683272153, 7.748862070796649e-05, --,\n",
       "                    0.32050011710501625, --, --, --, --, --,\n",
       "                    1.3175512402113585, --, 0.01142368324134076, --, --,\n",
       "                    0.7305809724585708, 0.0034073893099065833,\n",
       "                    0.2529952061544883, --, 0.6328946138672802, --, --,\n",
       "                    0.4179990532844446, --, 0.028782404700354036, --, --,\n",
       "                    --, 0.4450187449257414, --, --, 1.3679798658769482, --,\n",
       "                    --, 0.007133000997188478, --, 0.4140045451742804, --,\n",
       "                    --, 1.9836872116851265, --, --, --, --,\n",
       "                    0.2760884242071161, 0.015997809473524215,\n",
       "                    0.018012557016626365, --, 0.2632267309034184,\n",
       "                    0.014040162423953251, 0.4987560321776505,\n",
       "                    0.3162995232558996, --, 0.0970591056106228, --, --, --,\n",
       "                    0.07564645200292093, --, --, 0.08030301019285221, --,\n",
       "                    0.00887780879253533, 0.27597760286275197,\n",
       "                    0.1825173096667491, 0.43009879865610634,\n",
       "                    0.30815087435987, 1.7271354123359663,\n",
       "                    0.307778845149439, 0.014040162423953251,\n",
       "                    0.014040162423953251, 0.41381457275134625, --,\n",
       "                    0.31865307212780547, 0.01799117766661107, --, --, --,\n",
       "                    --, --, 0.014040162423953251, 0.31499046358670085, --,\n",
       "                    0.0020002119843226043, --, 0.30668799167995037,\n",
       "                    1.4758182519665946, --, 0.3345987731749994,\n",
       "                    0.3340505612505132, 0.3184473509602603,\n",
       "                    0.6627386355878896, --, --, 0.22850511406170573,\n",
       "                    0.3003949600354424, --, 0.703110590246357, --, --, --,\n",
       "                    --, --, --, --, --, 0.4463955989512708,\n",
       "                    0.014040162423953251, --, --],\n",
       "              mask=[ True,  True, False, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True, False,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True, False,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True, False,  True,  True, False,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True, False, False,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True, False,  True, False, False,\n",
       "                    False,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True, False,  True,  True, False,\n",
       "                    False, False,  True, False,  True, False,  True, False,\n",
       "                     True,  True,  True,  True, False, False,  True,  True,\n",
       "                     True,  True, False, False,  True,  True, False, False,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True, False,  True, False,  True, False,  True,\n",
       "                     True,  True, False,  True,  True,  True, False, False,\n",
       "                     True, False, False,  True, False, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                    False,  True, False,  True, False,  True, False, False,\n",
       "                    False,  True, False, False, False, False, False,  True,\n",
       "                     True, False, False, False, False, False,  True,  True,\n",
       "                    False,  True,  True,  True, False,  True, False,  True,\n",
       "                     True,  True,  True,  True, False, False, False, False,\n",
       "                     True, False,  True, False, False,  True, False, False,\n",
       "                    False, False, False,  True, False,  True,  True,  True,\n",
       "                     True,  True, False, False,  True, False,  True,  True,\n",
       "                    False, False,  True,  True, False, False,  True, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                     True,  True,  True, False,  True, False, False, False,\n",
       "                     True, False,  True, False,  True,  True, False, False,\n",
       "                     True, False,  True,  True,  True, False, False, False,\n",
       "                     True, False, False, False, False,  True, False,  True,\n",
       "                    False, False,  True, False, False, False,  True,  True,\n",
       "                    False,  True, False, False, False,  True, False, False,\n",
       "                     True,  True, False,  True, False,  True, False, False,\n",
       "                     True,  True,  True, False, False, False,  True,  True,\n",
       "                    False,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True, False, False,\n",
       "                    False,  True, False, False,  True,  True, False, False,\n",
       "                    False,  True,  True, False, False,  True, False,  True,\n",
       "                     True,  True,  True,  True, False,  True, False,  True,\n",
       "                     True, False, False, False,  True, False,  True,  True,\n",
       "                    False,  True, False,  True,  True,  True, False,  True,\n",
       "                     True, False,  True,  True, False,  True, False,  True,\n",
       "                     True, False,  True,  True,  True,  True, False, False,\n",
       "                    False,  True, False, False, False, False,  True, False,\n",
       "                     True,  True,  True, False,  True,  True, False,  True,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False,  True, False, False,  True,  True,  True,\n",
       "                     True,  True, False, False,  True, False,  True, False,\n",
       "                    False,  True, False, False, False, False,  True,  True,\n",
       "                    False, False,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False, False,  True,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_regressor:decision_tree:max_features': masked_array(data=[--, --, 1.0, 1.0, --, --, --, --, --, --, --, 1.0, --,\n",
       "                    1.0, --, --, --, --, 1.0, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 1.0, --, --, --, --, --,\n",
       "                    --, --, --, --, 1.0, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 1.0, --, --, --, --, 1.0, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 1.0, --, --, --, 1.0, --, --, 1.0, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    1.0, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 1.0, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 1.0, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, 1.0, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 1.0, --, --, --, --, --,\n",
       "                    --, 1.0, --, --, --, --, --, --, 1.0, --, --, --, --,\n",
       "                    1.0, --, --, 1.0, --, --, --, --, 1.0, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, 1.0, --, --,\n",
       "                    --, --, --, --, 1.0, 1.0, --, --, --, 1.0, --, --, --,\n",
       "                    --, --, --, 1.0, --, --, --, --, --, 1.0, --, 1.0, 1.0,\n",
       "                    1.0, --, 1.0, --, --, --, --, --, --, --, 1.0, --, --,\n",
       "                    --, --, --, --, --, --, --, 1.0, --, --, --, 1.0, --,\n",
       "                    --, --, --, --, --, 1.0, 1.0, --, --, --, 1.0, --, --,\n",
       "                    1.0, 1.0, 1.0, --, 1.0, --, 1.0, --, 1.0, --, --, --,\n",
       "                    --, 1.0, 1.0, --, --, --, --, 1.0, 1.0, --, --, 1.0,\n",
       "                    1.0, --, --, --, --, 1.0, --, --, --, --, --, 1.0, --,\n",
       "                    1.0, --, 1.0, --, --, --, 1.0, --, --, --, 1.0, 1.0,\n",
       "                    --, 1.0, 1.0, --, 1.0, 1.0, --, --, --, --, --, --, --,\n",
       "                    1.0, --, --, 1.0, --, 1.0, --, 1.0, --, 1.0, 1.0, 1.0,\n",
       "                    --, 1.0, 1.0, 1.0, 1.0, 1.0, --, --, 1.0, 1.0, 1.0,\n",
       "                    1.0, 1.0, --, --, 1.0, --, --, --, 1.0, --, 1.0, --,\n",
       "                    --, --, --, --, 1.0, 1.0, 1.0, 1.0, --, 1.0, --, 1.0,\n",
       "                    1.0, --, 1.0, 1.0, 1.0, 1.0, 1.0, --, 1.0, --, --, --,\n",
       "                    --, --, 1.0, 1.0, --, 1.0, --, --, 1.0, 1.0, --, --,\n",
       "                    1.0, 1.0, --, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,\n",
       "                    1.0, --, --, --, 1.0, --, 1.0, 1.0, 1.0, --, 1.0, --,\n",
       "                    1.0, --, --, 1.0, 1.0, --, 1.0, --, --, --, 1.0, 1.0,\n",
       "                    1.0, --, 1.0, 1.0, 1.0, 1.0, --, 1.0, --, 1.0, 1.0, --,\n",
       "                    1.0, 1.0, 1.0, --, --, 1.0, --, 1.0, 1.0, 1.0, --, 1.0,\n",
       "                    1.0, --, --, 1.0, --, 1.0, --, 1.0, 1.0, --, --, --,\n",
       "                    1.0, 1.0, 1.0, --, --, 1.0, --, --, 1.0, --, --, --,\n",
       "                    --, --, 1.0, --, --, --, --, 1.0, 1.0, 1.0, --, 1.0,\n",
       "                    1.0, --, --, 1.0, 1.0, 1.0, --, --, 1.0, 1.0, --, 1.0,\n",
       "                    --, --, --, --, --, 1.0, --, 1.0, --, --, 1.0, 1.0,\n",
       "                    1.0, --, 1.0, --, --, 1.0, --, 1.0, --, --, --, 1.0,\n",
       "                    --, --, 1.0, --, --, 1.0, --, 1.0, --, --, 1.0, --, --,\n",
       "                    --, --, 1.0, 1.0, 1.0, --, 1.0, 1.0, 1.0, 1.0, --, 1.0,\n",
       "                    --, --, --, 1.0, --, --, 1.0, --, 1.0, 1.0, 1.0, 1.0,\n",
       "                    1.0, 1.0, 1.0, 1.0, 1.0, 1.0, --, 1.0, 1.0, --, --, --,\n",
       "                    --, --, 1.0, 1.0, --, 1.0, --, 1.0, 1.0, --, 1.0, 1.0,\n",
       "                    1.0, 1.0, --, --, 1.0, 1.0, --, 1.0, --, --, --, --,\n",
       "                    --, --, --, --, 1.0, 1.0, --, --],\n",
       "              mask=[ True,  True, False, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True, False,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True, False,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True, False,  True,  True, False,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True, False, False,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True, False,  True, False, False,\n",
       "                    False,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True, False,  True,  True, False,\n",
       "                    False, False,  True, False,  True, False,  True, False,\n",
       "                     True,  True,  True,  True, False, False,  True,  True,\n",
       "                     True,  True, False, False,  True,  True, False, False,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True, False,  True, False,  True, False,  True,\n",
       "                     True,  True, False,  True,  True,  True, False, False,\n",
       "                     True, False, False,  True, False, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                    False,  True, False,  True, False,  True, False, False,\n",
       "                    False,  True, False, False, False, False, False,  True,\n",
       "                     True, False, False, False, False, False,  True,  True,\n",
       "                    False,  True,  True,  True, False,  True, False,  True,\n",
       "                     True,  True,  True,  True, False, False, False, False,\n",
       "                     True, False,  True, False, False,  True, False, False,\n",
       "                    False, False, False,  True, False,  True,  True,  True,\n",
       "                     True,  True, False, False,  True, False,  True,  True,\n",
       "                    False, False,  True,  True, False, False,  True, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                     True,  True,  True, False,  True, False, False, False,\n",
       "                     True, False,  True, False,  True,  True, False, False,\n",
       "                     True, False,  True,  True,  True, False, False, False,\n",
       "                     True, False, False, False, False,  True, False,  True,\n",
       "                    False, False,  True, False, False, False,  True,  True,\n",
       "                    False,  True, False, False, False,  True, False, False,\n",
       "                     True,  True, False,  True, False,  True, False, False,\n",
       "                     True,  True,  True, False, False, False,  True,  True,\n",
       "                    False,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True, False, False,\n",
       "                    False,  True, False, False,  True,  True, False, False,\n",
       "                    False,  True,  True, False, False,  True, False,  True,\n",
       "                     True,  True,  True,  True, False,  True, False,  True,\n",
       "                     True, False, False, False,  True, False,  True,  True,\n",
       "                    False,  True, False,  True,  True,  True, False,  True,\n",
       "                     True, False,  True,  True, False,  True, False,  True,\n",
       "                     True, False,  True,  True,  True,  True, False, False,\n",
       "                    False,  True, False, False, False, False,  True, False,\n",
       "                     True,  True,  True, False,  True,  True, False,  True,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False,  True, False, False,  True,  True,  True,\n",
       "                     True,  True, False, False,  True, False,  True, False,\n",
       "                    False,  True, False, False, False, False,  True,  True,\n",
       "                    False, False,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False, False,  True,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_regressor:decision_tree:max_leaf_nodes': masked_array(data=[--, --, 'None', 'None', --, --, --, --, --, --, --,\n",
       "                    'None', --, 'None', --, --, --, --, 'None', --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, 'None', --,\n",
       "                    --, --, --, --, --, --, --, --, 'None', --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 'None', --, --, --, --,\n",
       "                    'None', --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 'None', --, --, --,\n",
       "                    'None', --, --, 'None', --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 'None', --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, 'None',\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    'None', --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 'None', --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 'None', --, --, --, --, --, --, 'None', --, --, --,\n",
       "                    --, --, --, 'None', --, --, --, --, 'None', --, --,\n",
       "                    'None', --, --, --, --, 'None', --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 'None', --, --, --, --,\n",
       "                    --, --, 'None', 'None', --, --, --, 'None', --, --, --,\n",
       "                    --, --, --, 'None', --, --, --, --, --, 'None', --,\n",
       "                    'None', 'None', 'None', --, 'None', --, --, --, --, --,\n",
       "                    --, --, 'None', --, --, --, --, --, --, --, --, --,\n",
       "                    'None', --, --, --, 'None', --, --, --, --, --, --,\n",
       "                    'None', 'None', --, --, --, 'None', --, --, 'None',\n",
       "                    'None', 'None', --, 'None', --, 'None', --, 'None', --,\n",
       "                    --, --, --, 'None', 'None', --, --, --, --, 'None',\n",
       "                    'None', --, --, 'None', 'None', --, --, --, --, 'None',\n",
       "                    --, --, --, --, --, 'None', --, 'None', --, 'None', --,\n",
       "                    --, --, 'None', --, --, --, 'None', 'None', --, 'None',\n",
       "                    'None', --, 'None', 'None', --, --, --, --, --, --, --,\n",
       "                    'None', --, --, 'None', --, 'None', --, 'None', --,\n",
       "                    'None', 'None', 'None', --, 'None', 'None', 'None',\n",
       "                    'None', 'None', --, --, 'None', 'None', 'None', 'None',\n",
       "                    'None', --, --, 'None', --, --, --, 'None', --, 'None',\n",
       "                    --, --, --, --, --, 'None', 'None', 'None', 'None', --,\n",
       "                    'None', --, 'None', 'None', --, 'None', 'None', 'None',\n",
       "                    'None', 'None', --, 'None', --, --, --, --, --, 'None',\n",
       "                    'None', --, 'None', --, --, 'None', 'None', --, --,\n",
       "                    'None', 'None', --, 'None', 'None', 'None', 'None',\n",
       "                    'None', 'None', 'None', 'None', 'None', --, --, --,\n",
       "                    'None', --, 'None', 'None', 'None', --, 'None', --,\n",
       "                    'None', --, --, 'None', 'None', --, 'None', --, --, --,\n",
       "                    'None', 'None', 'None', --, 'None', 'None', 'None',\n",
       "                    'None', --, 'None', --, 'None', 'None', --, 'None',\n",
       "                    'None', 'None', --, --, 'None', --, 'None', 'None',\n",
       "                    'None', --, 'None', 'None', --, --, 'None', --, 'None',\n",
       "                    --, 'None', 'None', --, --, --, 'None', 'None', 'None',\n",
       "                    --, --, 'None', --, --, 'None', --, --, --, --, --,\n",
       "                    'None', --, --, --, --, 'None', 'None', 'None', --,\n",
       "                    'None', 'None', --, --, 'None', 'None', 'None', --, --,\n",
       "                    'None', 'None', --, 'None', --, --, --, --, --, 'None',\n",
       "                    --, 'None', --, --, 'None', 'None', 'None', --, 'None',\n",
       "                    --, --, 'None', --, 'None', --, --, --, 'None', --, --,\n",
       "                    'None', --, --, 'None', --, 'None', --, --, 'None', --,\n",
       "                    --, --, --, 'None', 'None', 'None', --, 'None', 'None',\n",
       "                    'None', 'None', --, 'None', --, --, --, 'None', --, --,\n",
       "                    'None', --, 'None', 'None', 'None', 'None', 'None',\n",
       "                    'None', 'None', 'None', 'None', 'None', --, 'None',\n",
       "                    'None', --, --, --, --, --, 'None', 'None', --, 'None',\n",
       "                    --, 'None', 'None', --, 'None', 'None', 'None', 'None',\n",
       "                    --, --, 'None', 'None', --, 'None', --, --, --, --, --,\n",
       "                    --, --, --, 'None', 'None', --, --],\n",
       "              mask=[ True,  True, False, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True, False,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True, False,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True, False,  True,  True, False,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True, False, False,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True, False,  True, False, False,\n",
       "                    False,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True, False,  True,  True, False,\n",
       "                    False, False,  True, False,  True, False,  True, False,\n",
       "                     True,  True,  True,  True, False, False,  True,  True,\n",
       "                     True,  True, False, False,  True,  True, False, False,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True, False,  True, False,  True, False,  True,\n",
       "                     True,  True, False,  True,  True,  True, False, False,\n",
       "                     True, False, False,  True, False, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                    False,  True, False,  True, False,  True, False, False,\n",
       "                    False,  True, False, False, False, False, False,  True,\n",
       "                     True, False, False, False, False, False,  True,  True,\n",
       "                    False,  True,  True,  True, False,  True, False,  True,\n",
       "                     True,  True,  True,  True, False, False, False, False,\n",
       "                     True, False,  True, False, False,  True, False, False,\n",
       "                    False, False, False,  True, False,  True,  True,  True,\n",
       "                     True,  True, False, False,  True, False,  True,  True,\n",
       "                    False, False,  True,  True, False, False,  True, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                     True,  True,  True, False,  True, False, False, False,\n",
       "                     True, False,  True, False,  True,  True, False, False,\n",
       "                     True, False,  True,  True,  True, False, False, False,\n",
       "                     True, False, False, False, False,  True, False,  True,\n",
       "                    False, False,  True, False, False, False,  True,  True,\n",
       "                    False,  True, False, False, False,  True, False, False,\n",
       "                     True,  True, False,  True, False,  True, False, False,\n",
       "                     True,  True,  True, False, False, False,  True,  True,\n",
       "                    False,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True, False, False,\n",
       "                    False,  True, False, False,  True,  True, False, False,\n",
       "                    False,  True,  True, False, False,  True, False,  True,\n",
       "                     True,  True,  True,  True, False,  True, False,  True,\n",
       "                     True, False, False, False,  True, False,  True,  True,\n",
       "                    False,  True, False,  True,  True,  True, False,  True,\n",
       "                     True, False,  True,  True, False,  True, False,  True,\n",
       "                     True, False,  True,  True,  True,  True, False, False,\n",
       "                    False,  True, False, False, False, False,  True, False,\n",
       "                     True,  True,  True, False,  True,  True, False,  True,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False,  True, False, False,  True,  True,  True,\n",
       "                     True,  True, False, False,  True, False,  True, False,\n",
       "                    False,  True, False, False, False, False,  True,  True,\n",
       "                    False, False,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False, False,  True,  True],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U32'),\n",
       " 'param_regressor:decision_tree:min_impurity_decrease': masked_array(data=[--, --, 0.0, 0.0, --, --, --, --, --, --, --, 0.0, --,\n",
       "                    0.0, --, --, --, --, 0.0, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 0.0, --, --, --, --, --,\n",
       "                    --, --, --, --, 0.0, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 0.0, --, --, --, --, 0.0, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 0.0, --, --, --, 0.0, --, --, 0.0, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    0.0, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 0.0, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 0.0, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, 0.0, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 0.0, --, --, --, --, --,\n",
       "                    --, 0.0, --, --, --, --, --, --, 0.0, --, --, --, --,\n",
       "                    0.0, --, --, 0.0, --, --, --, --, 0.0, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, 0.0, --, --,\n",
       "                    --, --, --, --, 0.0, 0.0, --, --, --, 0.0, --, --, --,\n",
       "                    --, --, --, 0.0, --, --, --, --, --, 0.0, --, 0.0, 0.0,\n",
       "                    0.0, --, 0.0, --, --, --, --, --, --, --, 0.0, --, --,\n",
       "                    --, --, --, --, --, --, --, 0.0, --, --, --, 0.0, --,\n",
       "                    --, --, --, --, --, 0.0, 0.0, --, --, --, 0.0, --, --,\n",
       "                    0.0, 0.0, 0.0, --, 0.0, --, 0.0, --, 0.0, --, --, --,\n",
       "                    --, 0.0, 0.0, --, --, --, --, 0.0, 0.0, --, --, 0.0,\n",
       "                    0.0, --, --, --, --, 0.0, --, --, --, --, --, 0.0, --,\n",
       "                    0.0, --, 0.0, --, --, --, 0.0, --, --, --, 0.0, 0.0,\n",
       "                    --, 0.0, 0.0, --, 0.0, 0.0, --, --, --, --, --, --, --,\n",
       "                    0.0, --, --, 0.0, --, 0.0, --, 0.0, --, 0.0, 0.0, 0.0,\n",
       "                    --, 0.0, 0.0, 0.0, 0.0, 0.0, --, --, 0.0, 0.0, 0.0,\n",
       "                    0.0, 0.0, --, --, 0.0, --, --, --, 0.0, --, 0.0, --,\n",
       "                    --, --, --, --, 0.0, 0.0, 0.0, 0.0, --, 0.0, --, 0.0,\n",
       "                    0.0, --, 0.0, 0.0, 0.0, 0.0, 0.0, --, 0.0, --, --, --,\n",
       "                    --, --, 0.0, 0.0, --, 0.0, --, --, 0.0, 0.0, --, --,\n",
       "                    0.0, 0.0, --, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "                    0.0, --, --, --, 0.0, --, 0.0, 0.0, 0.0, --, 0.0, --,\n",
       "                    0.0, --, --, 0.0, 0.0, --, 0.0, --, --, --, 0.0, 0.0,\n",
       "                    0.0, --, 0.0, 0.0, 0.0, 0.0, --, 0.0, --, 0.0, 0.0, --,\n",
       "                    0.0, 0.0, 0.0, --, --, 0.0, --, 0.0, 0.0, 0.0, --, 0.0,\n",
       "                    0.0, --, --, 0.0, --, 0.0, --, 0.0, 0.0, --, --, --,\n",
       "                    0.0, 0.0, 0.0, --, --, 0.0, --, --, 0.0, --, --, --,\n",
       "                    --, --, 0.0, --, --, --, --, 0.0, 0.0, 0.0, --, 0.0,\n",
       "                    0.0, --, --, 0.0, 0.0, 0.0, --, --, 0.0, 0.0, --, 0.0,\n",
       "                    --, --, --, --, --, 0.0, --, 0.0, --, --, 0.0, 0.0,\n",
       "                    0.0, --, 0.0, --, --, 0.0, --, 0.0, --, --, --, 0.0,\n",
       "                    --, --, 0.0, --, --, 0.0, --, 0.0, --, --, 0.0, --, --,\n",
       "                    --, --, 0.0, 0.0, 0.0, --, 0.0, 0.0, 0.0, 0.0, --, 0.0,\n",
       "                    --, --, --, 0.0, --, --, 0.0, --, 0.0, 0.0, 0.0, 0.0,\n",
       "                    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, --, 0.0, 0.0, --, --, --,\n",
       "                    --, --, 0.0, 0.0, --, 0.0, --, 0.0, 0.0, --, 0.0, 0.0,\n",
       "                    0.0, 0.0, --, --, 0.0, 0.0, --, 0.0, --, --, --, --,\n",
       "                    --, --, --, --, 0.0, 0.0, --, --],\n",
       "              mask=[ True,  True, False, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True, False,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True, False,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True, False,  True,  True, False,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True, False, False,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True, False,  True, False, False,\n",
       "                    False,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True, False,  True,  True, False,\n",
       "                    False, False,  True, False,  True, False,  True, False,\n",
       "                     True,  True,  True,  True, False, False,  True,  True,\n",
       "                     True,  True, False, False,  True,  True, False, False,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True, False,  True, False,  True, False,  True,\n",
       "                     True,  True, False,  True,  True,  True, False, False,\n",
       "                     True, False, False,  True, False, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                    False,  True, False,  True, False,  True, False, False,\n",
       "                    False,  True, False, False, False, False, False,  True,\n",
       "                     True, False, False, False, False, False,  True,  True,\n",
       "                    False,  True,  True,  True, False,  True, False,  True,\n",
       "                     True,  True,  True,  True, False, False, False, False,\n",
       "                     True, False,  True, False, False,  True, False, False,\n",
       "                    False, False, False,  True, False,  True,  True,  True,\n",
       "                     True,  True, False, False,  True, False,  True,  True,\n",
       "                    False, False,  True,  True, False, False,  True, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                     True,  True,  True, False,  True, False, False, False,\n",
       "                     True, False,  True, False,  True,  True, False, False,\n",
       "                     True, False,  True,  True,  True, False, False, False,\n",
       "                     True, False, False, False, False,  True, False,  True,\n",
       "                    False, False,  True, False, False, False,  True,  True,\n",
       "                    False,  True, False, False, False,  True, False, False,\n",
       "                     True,  True, False,  True, False,  True, False, False,\n",
       "                     True,  True,  True, False, False, False,  True,  True,\n",
       "                    False,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True, False, False,\n",
       "                    False,  True, False, False,  True,  True, False, False,\n",
       "                    False,  True,  True, False, False,  True, False,  True,\n",
       "                     True,  True,  True,  True, False,  True, False,  True,\n",
       "                     True, False, False, False,  True, False,  True,  True,\n",
       "                    False,  True, False,  True,  True,  True, False,  True,\n",
       "                     True, False,  True,  True, False,  True, False,  True,\n",
       "                     True, False,  True,  True,  True,  True, False, False,\n",
       "                    False,  True, False, False, False, False,  True, False,\n",
       "                     True,  True,  True, False,  True,  True, False,  True,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False,  True, False, False,  True,  True,  True,\n",
       "                     True,  True, False, False,  True, False,  True, False,\n",
       "                    False,  True, False, False, False, False,  True,  True,\n",
       "                    False, False,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False, False,  True,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_regressor:decision_tree:min_samples_leaf': masked_array(data=[--, --, 8.0, 2.0, --, --, --, --, --, --, --, 13.0, --,\n",
       "                    5.0, --, --, --, --, 16.0, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 19.0, --, --, --, --, --,\n",
       "                    --, --, --, --, 2.0, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 10.0, --, --, --, --, 20.0, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 1.0, --, --, --, 20.0, --, --, 19.0, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 19.0, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 17.0, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 10.0, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, 13.0,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 1.0, --, --, --, --,\n",
       "                    --, --, 7.0, --, --, --, --, --, --, 1.0, --, --, --,\n",
       "                    --, 16.0, --, --, 1.0, --, --, --, --, 5.0, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, 18.0, --,\n",
       "                    --, --, --, --, --, 1.0, 1.0, --, --, --, 2.0, --, --,\n",
       "                    --, --, --, --, 4.0, --, --, --, --, --, 2.0, --, 2.0,\n",
       "                    2.0, 12.0, --, 11.0, --, --, --, --, --, --, --, 1.0,\n",
       "                    --, --, --, --, --, --, --, --, --, 10.0, --, --, --,\n",
       "                    2.0, --, --, --, --, --, --, 1.0, 1.0, --, --, --, 1.0,\n",
       "                    --, --, 3.0, 1.0, 1.0, --, 8.0, --, 10.0, --, 6.0, --,\n",
       "                    --, --, --, 11.0, 9.0, --, --, --, --, 4.0, 2.0, --,\n",
       "                    --, 3.0, 16.0, --, --, --, --, 2.0, --, --, --, --, --,\n",
       "                    1.0, --, 6.0, --, 1.0, --, --, --, 7.0, --, --, --,\n",
       "                    1.0, 1.0, --, 2.0, 9.0, --, 3.0, 8.0, --, --, --, --,\n",
       "                    --, --, --, 2.0, --, --, 1.0, --, 5.0, --, 1.0, --,\n",
       "                    5.0, 14.0, 15.0, --, 1.0, 1.0, 8.0, 6.0, 6.0, --, --,\n",
       "                    5.0, 2.0, 19.0, 10.0, 7.0, --, --, 1.0, --, --, --,\n",
       "                    3.0, --, 1.0, --, --, --, --, --, 1.0, 13.0, 1.0, 1.0,\n",
       "                    --, 16.0, --, 8.0, 1.0, --, 1.0, 1.0, 1.0, 1.0, 1.0,\n",
       "                    --, 4.0, --, --, --, --, --, 20.0, 3.0, --, 1.0, --,\n",
       "                    --, 1.0, 20.0, --, --, 1.0, 1.0, --, 1.0, 6.0, 3.0,\n",
       "                    5.0, 2.0, 2.0, 1.0, 1.0, 7.0, --, --, --, 1.0, --, 1.0,\n",
       "                    1.0, 1.0, --, 1.0, --, 7.0, --, --, 4.0, 1.0, --, 3.0,\n",
       "                    --, --, --, 1.0, 20.0, 2.0, --, 2.0, 6.0, 11.0, 2.0,\n",
       "                    --, 2.0, --, 10.0, 2.0, --, 2.0, 19.0, 6.0, --, --,\n",
       "                    14.0, --, 1.0, 1.0, 1.0, --, 9.0, 11.0, --, --, 2.0,\n",
       "                    --, 8.0, --, 1.0, 2.0, --, --, --, 17.0, 1.0, 1.0, --,\n",
       "                    --, 1.0, --, --, 18.0, --, --, --, --, --, 1.0, --, --,\n",
       "                    --, --, 5.0, 2.0, 15.0, --, 5.0, 1.0, --, --, 3.0,\n",
       "                    11.0, 3.0, --, --, 2.0, 1.0, --, 6.0, --, --, --, --,\n",
       "                    --, 11.0, --, 4.0, --, --, 3.0, 1.0, 16.0, --, 17.0,\n",
       "                    --, --, 16.0, --, 8.0, --, --, --, 6.0, --, --, 8.0,\n",
       "                    --, --, 2.0, --, 16.0, --, --, 2.0, --, --, --, --,\n",
       "                    6.0, 5.0, 7.0, --, 1.0, 6.0, 5.0, 6.0, --, 1.0, --, --,\n",
       "                    --, 1.0, --, --, 3.0, --, 6.0, 6.0, 4.0, 6.0, 6.0, 3.0,\n",
       "                    6.0, 6.0, 6.0, 2.0, --, 6.0, 7.0, --, --, --, --, --,\n",
       "                    6.0, 6.0, --, 11.0, --, 3.0, 2.0, --, 3.0, 2.0, 2.0,\n",
       "                    2.0, --, --, 6.0, 7.0, --, 13.0, --, --, --, --, --,\n",
       "                    --, --, --, 1.0, 6.0, --, --],\n",
       "              mask=[ True,  True, False, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True, False,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True, False,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True, False,  True,  True, False,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True, False, False,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True, False,  True, False, False,\n",
       "                    False,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True, False,  True,  True, False,\n",
       "                    False, False,  True, False,  True, False,  True, False,\n",
       "                     True,  True,  True,  True, False, False,  True,  True,\n",
       "                     True,  True, False, False,  True,  True, False, False,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True, False,  True, False,  True, False,  True,\n",
       "                     True,  True, False,  True,  True,  True, False, False,\n",
       "                     True, False, False,  True, False, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                    False,  True, False,  True, False,  True, False, False,\n",
       "                    False,  True, False, False, False, False, False,  True,\n",
       "                     True, False, False, False, False, False,  True,  True,\n",
       "                    False,  True,  True,  True, False,  True, False,  True,\n",
       "                     True,  True,  True,  True, False, False, False, False,\n",
       "                     True, False,  True, False, False,  True, False, False,\n",
       "                    False, False, False,  True, False,  True,  True,  True,\n",
       "                     True,  True, False, False,  True, False,  True,  True,\n",
       "                    False, False,  True,  True, False, False,  True, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                     True,  True,  True, False,  True, False, False, False,\n",
       "                     True, False,  True, False,  True,  True, False, False,\n",
       "                     True, False,  True,  True,  True, False, False, False,\n",
       "                     True, False, False, False, False,  True, False,  True,\n",
       "                    False, False,  True, False, False, False,  True,  True,\n",
       "                    False,  True, False, False, False,  True, False, False,\n",
       "                     True,  True, False,  True, False,  True, False, False,\n",
       "                     True,  True,  True, False, False, False,  True,  True,\n",
       "                    False,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True, False, False,\n",
       "                    False,  True, False, False,  True,  True, False, False,\n",
       "                    False,  True,  True, False, False,  True, False,  True,\n",
       "                     True,  True,  True,  True, False,  True, False,  True,\n",
       "                     True, False, False, False,  True, False,  True,  True,\n",
       "                    False,  True, False,  True,  True,  True, False,  True,\n",
       "                     True, False,  True,  True, False,  True, False,  True,\n",
       "                     True, False,  True,  True,  True,  True, False, False,\n",
       "                    False,  True, False, False, False, False,  True, False,\n",
       "                     True,  True,  True, False,  True,  True, False,  True,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False,  True, False, False,  True,  True,  True,\n",
       "                     True,  True, False, False,  True, False,  True, False,\n",
       "                    False,  True, False, False, False, False,  True,  True,\n",
       "                    False, False,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False, False,  True,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_regressor:decision_tree:min_samples_split': masked_array(data=[--, --, 4.0, 13.0, --, --, --, --, --, --, --, 7.0, --,\n",
       "                    6.0, --, --, --, --, 18.0, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 8.0, --, --, --, --, --,\n",
       "                    --, --, --, --, 7.0, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 18.0, --, --, --, --, 6.0, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 8.0, --, --, --, 10.0, --, --, 9.0, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    13.0, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 13.0, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 20.0, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, 7.0, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 16.0, --, --, --, --, --,\n",
       "                    --, 16.0, --, --, --, --, --, --, 2.0, --, --, --, --,\n",
       "                    12.0, --, --, 11.0, --, --, --, --, 14.0, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, 6.0, --,\n",
       "                    --, --, --, --, --, 3.0, 11.0, --, --, --, 16.0, --,\n",
       "                    --, --, --, --, --, 5.0, --, --, --, --, --, 17.0, --,\n",
       "                    20.0, 17.0, 20.0, --, 20.0, --, --, --, --, --, --, --,\n",
       "                    16.0, --, --, --, --, --, --, --, --, --, 14.0, --, --,\n",
       "                    --, 10.0, --, --, --, --, --, --, 6.0, 2.0, --, --, --,\n",
       "                    10.0, --, --, 18.0, 16.0, 14.0, --, 3.0, --, 14.0, --,\n",
       "                    18.0, --, --, --, --, 2.0, 10.0, --, --, --, --, 14.0,\n",
       "                    17.0, --, --, 19.0, 19.0, --, --, --, --, 20.0, --, --,\n",
       "                    --, --, --, 14.0, --, 9.0, --, 4.0, --, --, --, 2.0,\n",
       "                    --, --, --, 11.0, 2.0, --, 16.0, 7.0, --, 5.0, 2.0, --,\n",
       "                    --, --, --, --, --, --, 16.0, --, --, 4.0, --, 13.0,\n",
       "                    --, 15.0, --, 7.0, 7.0, 18.0, --, 17.0, 14.0, 5.0, 6.0,\n",
       "                    7.0, --, --, 11.0, 6.0, 17.0, 15.0, 15.0, --, --, 13.0,\n",
       "                    --, --, --, 3.0, --, 14.0, --, --, --, --, --, 15.0,\n",
       "                    9.0, 15.0, 12.0, --, 11.0, --, 2.0, 12.0, --, 17.0,\n",
       "                    19.0, 14.0, 13.0, 19.0, --, 3.0, --, --, --, --, --,\n",
       "                    11.0, 13.0, --, 14.0, --, --, 16.0, 18.0, --, --, 15.0,\n",
       "                    19.0, --, 13.0, 13.0, 3.0, 2.0, 9.0, 10.0, 10.0, 18.0,\n",
       "                    13.0, --, --, --, 13.0, --, 14.0, 16.0, 14.0, --, 16.0,\n",
       "                    --, 12.0, --, --, 13.0, 16.0, --, 2.0, --, --, --,\n",
       "                    16.0, 11.0, 11.0, --, 8.0, 11.0, 9.0, 18.0, --, 10.0,\n",
       "                    --, 10.0, 8.0, --, 9.0, 12.0, 11.0, --, --, 8.0, --,\n",
       "                    8.0, 5.0, 2.0, --, 5.0, 6.0, --, --, 13.0, --, 13.0,\n",
       "                    --, 6.0, 9.0, --, --, --, 9.0, 12.0, 11.0, --, --, 4.0,\n",
       "                    --, --, 17.0, --, --, --, --, --, 15.0, --, --, --, --,\n",
       "                    2.0, 7.0, 6.0, --, 17.0, 14.0, --, --, 3.0, 6.0, 19.0,\n",
       "                    --, --, 12.0, 2.0, --, 13.0, --, --, --, --, --, 11.0,\n",
       "                    --, 4.0, --, --, 13.0, 2.0, 13.0, --, 3.0, --, --, 2.0,\n",
       "                    --, 7.0, --, --, --, 9.0, --, --, 10.0, --, --, 3.0,\n",
       "                    --, 9.0, --, --, 17.0, --, --, --, --, 13.0, 14.0,\n",
       "                    18.0, --, 15.0, 13.0, 5.0, 17.0, --, 15.0, --, --, --,\n",
       "                    14.0, --, --, 12.0, --, 13.0, 13.0, 13.0, 13.0, 13.0,\n",
       "                    2.0, 13.0, 13.0, 13.0, 13.0, --, 13.0, 13.0, --, --,\n",
       "                    --, --, --, 13.0, 13.0, --, 13.0, --, 13.0, 13.0, --,\n",
       "                    2.0, 2.0, 13.0, 13.0, --, --, 12.0, 13.0, --, 4.0, --,\n",
       "                    --, --, --, --, --, --, --, 15.0, 2.0, --, --],\n",
       "              mask=[ True,  True, False, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True, False,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True, False,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True, False,  True,  True, False,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True, False, False,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True, False,  True, False, False,\n",
       "                    False,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True, False,  True,  True, False,\n",
       "                    False, False,  True, False,  True, False,  True, False,\n",
       "                     True,  True,  True,  True, False, False,  True,  True,\n",
       "                     True,  True, False, False,  True,  True, False, False,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True, False,  True, False,  True, False,  True,\n",
       "                     True,  True, False,  True,  True,  True, False, False,\n",
       "                     True, False, False,  True, False, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                    False,  True, False,  True, False,  True, False, False,\n",
       "                    False,  True, False, False, False, False, False,  True,\n",
       "                     True, False, False, False, False, False,  True,  True,\n",
       "                    False,  True,  True,  True, False,  True, False,  True,\n",
       "                     True,  True,  True,  True, False, False, False, False,\n",
       "                     True, False,  True, False, False,  True, False, False,\n",
       "                    False, False, False,  True, False,  True,  True,  True,\n",
       "                     True,  True, False, False,  True, False,  True,  True,\n",
       "                    False, False,  True,  True, False, False,  True, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                     True,  True,  True, False,  True, False, False, False,\n",
       "                     True, False,  True, False,  True,  True, False, False,\n",
       "                     True, False,  True,  True,  True, False, False, False,\n",
       "                     True, False, False, False, False,  True, False,  True,\n",
       "                    False, False,  True, False, False, False,  True,  True,\n",
       "                    False,  True, False, False, False,  True, False, False,\n",
       "                     True,  True, False,  True, False,  True, False, False,\n",
       "                     True,  True,  True, False, False, False,  True,  True,\n",
       "                    False,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True, False, False,\n",
       "                    False,  True, False, False,  True,  True, False, False,\n",
       "                    False,  True,  True, False, False,  True, False,  True,\n",
       "                     True,  True,  True,  True, False,  True, False,  True,\n",
       "                     True, False, False, False,  True, False,  True,  True,\n",
       "                    False,  True, False,  True,  True,  True, False,  True,\n",
       "                     True, False,  True,  True, False,  True, False,  True,\n",
       "                     True, False,  True,  True,  True,  True, False, False,\n",
       "                    False,  True, False, False, False, False,  True, False,\n",
       "                     True,  True,  True, False,  True,  True, False,  True,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False,  True, False, False,  True,  True,  True,\n",
       "                     True,  True, False, False,  True, False,  True, False,\n",
       "                    False,  True, False, False, False, False,  True,  True,\n",
       "                    False, False,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False, False,  True,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_regressor:decision_tree:min_weight_fraction_leaf': masked_array(data=[--, --, 0.0, 0.0, --, --, --, --, --, --, --, 0.0, --,\n",
       "                    0.0, --, --, --, --, 0.0, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 0.0, --, --, --, --, --,\n",
       "                    --, --, --, --, 0.0, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 0.0, --, --, --, --, 0.0, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 0.0, --, --, --, 0.0, --, --, 0.0, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    0.0, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 0.0, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 0.0, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, 0.0, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 0.0, --, --, --, --, --,\n",
       "                    --, 0.0, --, --, --, --, --, --, 0.0, --, --, --, --,\n",
       "                    0.0, --, --, 0.0, --, --, --, --, 0.0, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, 0.0, --, --,\n",
       "                    --, --, --, --, 0.0, 0.0, --, --, --, 0.0, --, --, --,\n",
       "                    --, --, --, 0.0, --, --, --, --, --, 0.0, --, 0.0, 0.0,\n",
       "                    0.0, --, 0.0, --, --, --, --, --, --, --, 0.0, --, --,\n",
       "                    --, --, --, --, --, --, --, 0.0, --, --, --, 0.0, --,\n",
       "                    --, --, --, --, --, 0.0, 0.0, --, --, --, 0.0, --, --,\n",
       "                    0.0, 0.0, 0.0, --, 0.0, --, 0.0, --, 0.0, --, --, --,\n",
       "                    --, 0.0, 0.0, --, --, --, --, 0.0, 0.0, --, --, 0.0,\n",
       "                    0.0, --, --, --, --, 0.0, --, --, --, --, --, 0.0, --,\n",
       "                    0.0, --, 0.0, --, --, --, 0.0, --, --, --, 0.0, 0.0,\n",
       "                    --, 0.0, 0.0, --, 0.0, 0.0, --, --, --, --, --, --, --,\n",
       "                    0.0, --, --, 0.0, --, 0.0, --, 0.0, --, 0.0, 0.0, 0.0,\n",
       "                    --, 0.0, 0.0, 0.0, 0.0, 0.0, --, --, 0.0, 0.0, 0.0,\n",
       "                    0.0, 0.0, --, --, 0.0, --, --, --, 0.0, --, 0.0, --,\n",
       "                    --, --, --, --, 0.0, 0.0, 0.0, 0.0, --, 0.0, --, 0.0,\n",
       "                    0.0, --, 0.0, 0.0, 0.0, 0.0, 0.0, --, 0.0, --, --, --,\n",
       "                    --, --, 0.0, 0.0, --, 0.0, --, --, 0.0, 0.0, --, --,\n",
       "                    0.0, 0.0, --, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "                    0.0, --, --, --, 0.0, --, 0.0, 0.0, 0.0, --, 0.0, --,\n",
       "                    0.0, --, --, 0.0, 0.0, --, 0.0, --, --, --, 0.0, 0.0,\n",
       "                    0.0, --, 0.0, 0.0, 0.0, 0.0, --, 0.0, --, 0.0, 0.0, --,\n",
       "                    0.0, 0.0, 0.0, --, --, 0.0, --, 0.0, 0.0, 0.0, --, 0.0,\n",
       "                    0.0, --, --, 0.0, --, 0.0, --, 0.0, 0.0, --, --, --,\n",
       "                    0.0, 0.0, 0.0, --, --, 0.0, --, --, 0.0, --, --, --,\n",
       "                    --, --, 0.0, --, --, --, --, 0.0, 0.0, 0.0, --, 0.0,\n",
       "                    0.0, --, --, 0.0, 0.0, 0.0, --, --, 0.0, 0.0, --, 0.0,\n",
       "                    --, --, --, --, --, 0.0, --, 0.0, --, --, 0.0, 0.0,\n",
       "                    0.0, --, 0.0, --, --, 0.0, --, 0.0, --, --, --, 0.0,\n",
       "                    --, --, 0.0, --, --, 0.0, --, 0.0, --, --, 0.0, --, --,\n",
       "                    --, --, 0.0, 0.0, 0.0, --, 0.0, 0.0, 0.0, 0.0, --, 0.0,\n",
       "                    --, --, --, 0.0, --, --, 0.0, --, 0.0, 0.0, 0.0, 0.0,\n",
       "                    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, --, 0.0, 0.0, --, --, --,\n",
       "                    --, --, 0.0, 0.0, --, 0.0, --, 0.0, 0.0, --, 0.0, 0.0,\n",
       "                    0.0, 0.0, --, --, 0.0, 0.0, --, 0.0, --, --, --, --,\n",
       "                    --, --, --, --, 0.0, 0.0, --, --],\n",
       "              mask=[ True,  True, False, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True, False,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True, False,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True, False,  True,  True, False,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True, False, False,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True, False,  True, False, False,\n",
       "                    False,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True, False,  True,  True, False,\n",
       "                    False, False,  True, False,  True, False,  True, False,\n",
       "                     True,  True,  True,  True, False, False,  True,  True,\n",
       "                     True,  True, False, False,  True,  True, False, False,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True, False,  True, False,  True, False,  True,\n",
       "                     True,  True, False,  True,  True,  True, False, False,\n",
       "                     True, False, False,  True, False, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                    False,  True, False,  True, False,  True, False, False,\n",
       "                    False,  True, False, False, False, False, False,  True,\n",
       "                     True, False, False, False, False, False,  True,  True,\n",
       "                    False,  True,  True,  True, False,  True, False,  True,\n",
       "                     True,  True,  True,  True, False, False, False, False,\n",
       "                     True, False,  True, False, False,  True, False, False,\n",
       "                    False, False, False,  True, False,  True,  True,  True,\n",
       "                     True,  True, False, False,  True, False,  True,  True,\n",
       "                    False, False,  True,  True, False, False,  True, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                     True,  True,  True, False,  True, False, False, False,\n",
       "                     True, False,  True, False,  True,  True, False, False,\n",
       "                     True, False,  True,  True,  True, False, False, False,\n",
       "                     True, False, False, False, False,  True, False,  True,\n",
       "                    False, False,  True, False, False, False,  True,  True,\n",
       "                    False,  True, False, False, False,  True, False, False,\n",
       "                     True,  True, False,  True, False,  True, False, False,\n",
       "                     True,  True,  True, False, False, False,  True,  True,\n",
       "                    False,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True, False, False,\n",
       "                    False,  True, False, False,  True,  True, False, False,\n",
       "                    False,  True,  True, False, False,  True, False,  True,\n",
       "                     True,  True,  True,  True, False,  True, False,  True,\n",
       "                     True, False, False, False,  True, False,  True,  True,\n",
       "                    False,  True, False,  True,  True,  True, False,  True,\n",
       "                     True, False,  True,  True, False,  True, False,  True,\n",
       "                     True, False,  True,  True,  True,  True, False, False,\n",
       "                    False,  True, False, False, False, False,  True, False,\n",
       "                     True,  True,  True, False,  True,  True, False,  True,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False,  True, False, False,  True,  True,  True,\n",
       "                     True,  True, False, False,  True, False,  True, False,\n",
       "                    False,  True, False, False, False, False,  True,  True,\n",
       "                    False, False,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False, False,  True,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_regressor:extra_trees:bootstrap': masked_array(data=[--, --, --, --, --, --, --, --, --, 'False', --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    'True', --, --, --, 'False', --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, 'True',\n",
       "                    --, 'True', --, --, 'True', --, --, 'False', --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, 'True',\n",
       "                    --, --, 'True', --, --, --, --, --, --, --, 'True', --,\n",
       "                    'False', --, --, --, --, --, --, --, 'False', --, --,\n",
       "                    --, --, 'True', --, 'False', --, --, --, --, --,\n",
       "                    'False', --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 'True', 'True', --, --, --, --, --, --, --,\n",
       "                    'False', --, 'True', --, --, --, 'False', --, 'False',\n",
       "                    --, 'False', --, --, --, --, --, 'False', --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    'False', 'False', --, --, --, 'False', --, 'True', --,\n",
       "                    --, --, --, --, 'True', --, 'False', --, 'False', --,\n",
       "                    --, --, 'False', --, 'True', --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 'False', 'False', --, --,\n",
       "                    'True', --, --, 'False', --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 'False', --, 'False', --, --,\n",
       "                    --, 'False', 'False', --, --, 'True', --, --, 'True',\n",
       "                    --, --, 'True', 'True', --, --, --, --, --, 'False',\n",
       "                    --, --, --, 'False', 'False', --, --, --, --, --, --,\n",
       "                    --, --, --, --, 'False', 'True', --, 'False', --, --,\n",
       "                    --, --, --, --, 'True', 'False', --, --, 'False', --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    'True', --, --, --, --, --, --, --, 'True', --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 'True', --, --, --, --,\n",
       "                    --, --, --, --, --, 'False', --, --, --, 'False',\n",
       "                    'True', --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 'True', --, --, --, --, --, --, --, --,\n",
       "                    --, 'True', 'False', --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 'False', --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 'True', --, --, --, 'False', --, --, --, --,\n",
       "                    --, --, --, --, 'False', --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 'False', --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 'True', --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 'True', --, --, --, --, --, --,\n",
       "                    --, --, --, 'True', --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 'False', --, --, --,\n",
       "                    'True', --, --, --, --, 'False', --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 'False', --, --, --, --, --,\n",
       "                    'False', --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 'True', --, --, 'False', --, --,\n",
       "                    'True', --, --, 'True', 'False', --, --, 'True', --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 'False', --, --, --, --, 'False', --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    'False', --, --, --, --, --, --, 'True', --, --, --,\n",
       "                    --, 'False', 'True', --, --, --, 'True', --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 'True', --, --,\n",
       "                    'True', --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 'True', --, --, --, --, 'True', --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 'True', --, --, --,\n",
       "                    --, --, --, --, --, --, 'True', --, --, --, --, --, --,\n",
       "                    --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True, False,  True,\n",
       "                     True, False,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True, False,  True, False,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True, False,  True,  True,\n",
       "                     True, False,  True, False,  True, False,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False, False,  True,  True,  True,\n",
       "                    False,  True, False,  True,  True,  True,  True,  True,\n",
       "                    False,  True, False,  True, False,  True,  True,  True,\n",
       "                    False,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False, False,  True,  True, False,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True, False,\n",
       "                     True,  True,  True, False, False,  True,  True, False,\n",
       "                     True,  True, False,  True,  True, False, False,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                    False, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False, False,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True, False, False,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True, False, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True, False,  True,  True, False,  True,  True, False,\n",
       "                    False,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U32'),\n",
       " 'param_regressor:extra_trees:criterion': masked_array(data=[--, --, --, --, --, --, --, --, --, 'mae', --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, 'mae',\n",
       "                    --, --, --, 'mae', --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 'mse', --,\n",
       "                    'friedman_mse', --, --, 'friedman_mse', --, --, 'mse',\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    'friedman_mse', --, --, 'friedman_mse', --, --, --, --,\n",
       "                    --, --, --, 'mse', --, 'mae', --, --, --, --, --, --,\n",
       "                    --, 'mse', --, --, --, --, 'mae', --, 'mse', --, --,\n",
       "                    --, --, --, 'mse', --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 'friedman_mse', 'mse', --, --, --, --, --,\n",
       "                    --, --, 'friedman_mse', --, 'friedman_mse', --, --, --,\n",
       "                    'friedman_mse', --, 'mae', --, 'mae', --, --, --, --,\n",
       "                    --, 'friedman_mse', --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 'mse', 'mse', --, --, --,\n",
       "                    'mse', --, 'mse', --, --, --, --, --, 'friedman_mse',\n",
       "                    --, 'friedman_mse', --, 'friedman_mse', --, --, --,\n",
       "                    'mae', --, 'mae', --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 'mae', 'mae', --, --, 'friedman_mse',\n",
       "                    --, --, 'mse', --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 'mse', --, 'mae', --, --, --, 'mae', 'mae',\n",
       "                    --, --, 'friedman_mse', --, --, 'friedman_mse', --, --,\n",
       "                    'friedman_mse', 'friedman_mse', --, --, --, --, --,\n",
       "                    'mse', --, --, --, 'friedman_mse', 'friedman_mse', --,\n",
       "                    --, --, --, --, --, --, --, --, --, 'friedman_mse',\n",
       "                    'mae', --, 'mae', --, --, --, --, --, --, 'mse', 'mae',\n",
       "                    --, --, 'mae', --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 'friedman_mse', --, --, --, --, --,\n",
       "                    --, --, 'friedman_mse', --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 'mae', --, --, --, --, --, --, --, --, --,\n",
       "                    'mae', --, --, --, 'mse', 'mse', --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, 'mse', --,\n",
       "                    --, --, --, --, --, --, --, --, 'mse', 'mse', --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    'mae', --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 'friedman_mse', --, --, --,\n",
       "                    'friedman_mse', --, --, --, --, --, --, --, --, 'mse',\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    'friedman_mse', --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 'friedman_mse', --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 'mse', --, --, --, --, --, --, --, --,\n",
       "                    --, 'mae', --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 'mse', --, --, --, 'mae', --,\n",
       "                    --, --, --, 'mse', --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 'mse', --, --, --, --, --, 'mae', --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    'mae', --, --, 'mse', --, --, 'mse', --, --, 'mae',\n",
       "                    'friedman_mse', --, --, 'mae', --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, 'mse', --,\n",
       "                    --, --, --, 'mae', --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 'mse', --, --, --, --, --,\n",
       "                    --, 'mae', --, --, --, --, 'mse', 'mse', --, --, --,\n",
       "                    'mse', --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    'mae', --, --, 'mse', --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 'mse', --, --, --, --, 'mse', --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    'friedman_mse', --, --, --, --, --, --, --, --, --,\n",
       "                    'mae', --, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True, False,  True,\n",
       "                     True, False,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True, False,  True, False,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True, False,  True,  True,\n",
       "                     True, False,  True, False,  True, False,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False, False,  True,  True,  True,\n",
       "                    False,  True, False,  True,  True,  True,  True,  True,\n",
       "                    False,  True, False,  True, False,  True,  True,  True,\n",
       "                    False,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False, False,  True,  True, False,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True, False,\n",
       "                     True,  True,  True, False, False,  True,  True, False,\n",
       "                     True,  True, False,  True,  True, False, False,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                    False, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False, False,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True, False, False,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True, False, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True, False,  True,  True, False,  True,  True, False,\n",
       "                    False,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U32'),\n",
       " 'param_regressor:extra_trees:max_depth': masked_array(data=[--, --, --, --, --, --, --, --, --, 'None', --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, 'None',\n",
       "                    --, --, --, 'None', --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 'None', --, 'None',\n",
       "                    --, --, 'None', --, --, 'None', --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 'None', --, --, 'None',\n",
       "                    --, --, --, --, --, --, --, 'None', --, 'None', --, --,\n",
       "                    --, --, --, --, --, 'None', --, --, --, --, 'None', --,\n",
       "                    'None', --, --, --, --, --, 'None', --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 'None', 'None', --, --, --,\n",
       "                    --, --, --, --, 'None', --, 'None', --, --, --, 'None',\n",
       "                    --, 'None', --, 'None', --, --, --, --, --, 'None', --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    'None', 'None', --, --, --, 'None', --, 'None', --, --,\n",
       "                    --, --, --, 'None', --, 'None', --, 'None', --, --, --,\n",
       "                    'None', --, 'None', --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 'None', 'None', --, --, 'None', --, --,\n",
       "                    'None', --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 'None', --, 'None', --, --, --, 'None', 'None', --,\n",
       "                    --, 'None', --, --, 'None', --, --, 'None', 'None', --,\n",
       "                    --, --, --, --, 'None', --, --, --, 'None', 'None', --,\n",
       "                    --, --, --, --, --, --, --, --, --, 'None', 'None', --,\n",
       "                    'None', --, --, --, --, --, --, 'None', 'None', --, --,\n",
       "                    'None', --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 'None', --, --, --, --, --, --, --, 'None',\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, 'None', --,\n",
       "                    --, --, --, --, --, --, --, --, 'None', --, --, --,\n",
       "                    'None', 'None', --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 'None', --, --, --, --, --, --,\n",
       "                    --, --, --, 'None', 'None', --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 'None', --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 'None', --, --, --, 'None', --, --, --, --, --,\n",
       "                    --, --, --, 'None', --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 'None', --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 'None', --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 'None', --, --, --, --, --, --, --, --, --,\n",
       "                    'None', --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 'None', --, --, --, 'None', --, --,\n",
       "                    --, --, 'None', --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 'None', --, --, --, --, --, 'None', --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, 'None',\n",
       "                    --, --, 'None', --, --, 'None', --, --, 'None', 'None',\n",
       "                    --, --, 'None', --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 'None', --, --, --, --,\n",
       "                    'None', --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 'None', --, --, --, --, --, --, 'None',\n",
       "                    --, --, --, --, 'None', 'None', --, --, --, 'None', --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, 'None', --,\n",
       "                    --, 'None', --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 'None', --, --, --, --, 'None', --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, 'None', --, --,\n",
       "                    --, --, --, --, --, --, --, 'None', --, --, --, --, --,\n",
       "                    --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True, False,  True,\n",
       "                     True, False,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True, False,  True, False,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True, False,  True,  True,\n",
       "                     True, False,  True, False,  True, False,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False, False,  True,  True,  True,\n",
       "                    False,  True, False,  True,  True,  True,  True,  True,\n",
       "                    False,  True, False,  True, False,  True,  True,  True,\n",
       "                    False,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False, False,  True,  True, False,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True, False,\n",
       "                     True,  True,  True, False, False,  True,  True, False,\n",
       "                     True,  True, False,  True,  True, False, False,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                    False, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False, False,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True, False, False,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True, False, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True, False,  True,  True, False,  True,  True, False,\n",
       "                    False,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U32'),\n",
       " 'param_regressor:extra_trees:max_features': masked_array(data=[--, --, --, --, --, --, --, --, --,\n",
       "                    0.15174026608915236, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 0.44443335354819347, --,\n",
       "                    --, --, 0.7684696840084816, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    0.6204801914419285, --, 0.4318708528781241, --, --,\n",
       "                    0.4328992384838738, --, --, 0.7753733361833163, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    0.2372816182585037, --, --, 0.39548844400302974, --,\n",
       "                    --, --, --, --, --, --, 0.23277331416962535, --,\n",
       "                    0.1329237227418703, --, --, --, --, --, --, --,\n",
       "                    0.4011809347747183, --, --, --, --, 0.843350429386684,\n",
       "                    --, 0.1529081535176583, --, --, --, --, --,\n",
       "                    0.5761232074559555, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 0.2808555881374558, 0.3161064016205493, --,\n",
       "                    --, --, --, --, --, --, 0.8606790687270301, --,\n",
       "                    0.4540925617907534, --, --, --, 0.17054430517352986,\n",
       "                    --, 0.5863044549932291, --, 0.321013119900368, --, --,\n",
       "                    --, --, --, 0.5505759451077971, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 0.7590205431845929,\n",
       "                    0.20239388741073672, --, --, --, 0.7969024368047993,\n",
       "                    --, 0.4979798557239201, --, --, --, --, --,\n",
       "                    0.8112840058642931, --, 0.13058749967482217, --,\n",
       "                    0.6228569464301977, --, --, --, 0.321013119900368, --,\n",
       "                    0.6225156808704722, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 0.4233082907505926, 0.7096700583343091,\n",
       "                    --, --, 0.10185296988062187, --, --,\n",
       "                    0.7242747912368396, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 0.12478532667987306, --,\n",
       "                    0.4033791508373106, --, --, --, 0.223788396300784,\n",
       "                    0.3704691120667316, --, --, 0.6889624293129364, --, --,\n",
       "                    0.35384726576715564, --, --, 0.9729126286415507,\n",
       "                    0.5188874225104542, --, --, --, --, --,\n",
       "                    0.27086992568125184, --, --, --, 0.40097708456400205,\n",
       "                    0.5307163961487747, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 0.4233082907505926, 0.7472038306010356, --,\n",
       "                    0.9263816993350036, --, --, --, --, --, --,\n",
       "                    0.3942056895177096, 0.5734570605733377, --, --,\n",
       "                    0.9198038791962958, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 0.5091948981127149, --, --, --,\n",
       "                    --, --, --, --, 0.920689394063422, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 0.21150427041311776, --, --,\n",
       "                    --, --, --, --, --, --, --, 0.895236607861874, --, --,\n",
       "                    --, 0.49398311876699463, 0.4236076131082134, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    0.6243979185498796, --, --, --, --, --, --, --, --, --,\n",
       "                    0.526806075677887, 0.7968208990371841, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    0.9749677660369477, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --,\n",
       "                    0.9032863976750709, --, --, --, 0.6097176029613472, --,\n",
       "                    --, --, --, --, --, --, --, 0.9571260970975939, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --,\n",
       "                    0.13888338348743784, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 0.5440566204064383, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 0.7431650163118564, --, --,\n",
       "                    --, --, --, --, --, --, --, 0.10305182797327056, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 0.47339366490373136, --, --, --,\n",
       "                    0.9438787140982665, --, --, --, --, 0.3833155022631176,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    0.17145536111355505, --, --, --, --, --,\n",
       "                    0.15652763524343039, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 0.6720490364811186, --,\n",
       "                    --, 0.2628259338576406, --, --, 0.4618593987709718, --,\n",
       "                    --, 0.7565226210490769, 0.31887199191372007, --, --,\n",
       "                    0.3296887254347585, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 0.5259288215139131, --,\n",
       "                    --, --, --, 0.12319837869797817, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    0.836670130445374, --, --, --, --, --, --,\n",
       "                    0.9841098774855442, --, --, --, --, 0.6748432802286871,\n",
       "                    0.23706222351874937, --, --, --, 0.531322442364711, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    0.7610439838828551, --, --, 0.9970109299919133, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    0.6310497427146985, --, --, --, --,\n",
       "                    0.15567210832239217, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 0.2061258766417287, --, --, --,\n",
       "                    --, --, --, --, --, --, 0.10052331584891495, --, --,\n",
       "                    --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True, False,  True,\n",
       "                     True, False,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True, False,  True, False,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True, False,  True,  True,\n",
       "                     True, False,  True, False,  True, False,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False, False,  True,  True,  True,\n",
       "                    False,  True, False,  True,  True,  True,  True,  True,\n",
       "                    False,  True, False,  True, False,  True,  True,  True,\n",
       "                    False,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False, False,  True,  True, False,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True, False,\n",
       "                     True,  True,  True, False, False,  True,  True, False,\n",
       "                     True,  True, False,  True,  True, False, False,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                    False, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False, False,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True, False, False,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True, False, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True, False,  True,  True, False,  True,  True, False,\n",
       "                    False,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_regressor:extra_trees:max_leaf_nodes': masked_array(data=[--, --, --, --, --, --, --, --, --, 'None', --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, 'None',\n",
       "                    --, --, --, 'None', --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 'None', --, 'None',\n",
       "                    --, --, 'None', --, --, 'None', --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 'None', --, --, 'None',\n",
       "                    --, --, --, --, --, --, --, 'None', --, 'None', --, --,\n",
       "                    --, --, --, --, --, 'None', --, --, --, --, 'None', --,\n",
       "                    'None', --, --, --, --, --, 'None', --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 'None', 'None', --, --, --,\n",
       "                    --, --, --, --, 'None', --, 'None', --, --, --, 'None',\n",
       "                    --, 'None', --, 'None', --, --, --, --, --, 'None', --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    'None', 'None', --, --, --, 'None', --, 'None', --, --,\n",
       "                    --, --, --, 'None', --, 'None', --, 'None', --, --, --,\n",
       "                    'None', --, 'None', --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 'None', 'None', --, --, 'None', --, --,\n",
       "                    'None', --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 'None', --, 'None', --, --, --, 'None', 'None', --,\n",
       "                    --, 'None', --, --, 'None', --, --, 'None', 'None', --,\n",
       "                    --, --, --, --, 'None', --, --, --, 'None', 'None', --,\n",
       "                    --, --, --, --, --, --, --, --, --, 'None', 'None', --,\n",
       "                    'None', --, --, --, --, --, --, 'None', 'None', --, --,\n",
       "                    'None', --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 'None', --, --, --, --, --, --, --, 'None',\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, 'None', --,\n",
       "                    --, --, --, --, --, --, --, --, 'None', --, --, --,\n",
       "                    'None', 'None', --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 'None', --, --, --, --, --, --,\n",
       "                    --, --, --, 'None', 'None', --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 'None', --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 'None', --, --, --, 'None', --, --, --, --, --,\n",
       "                    --, --, --, 'None', --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 'None', --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 'None', --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 'None', --, --, --, --, --, --, --, --, --,\n",
       "                    'None', --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 'None', --, --, --, 'None', --, --,\n",
       "                    --, --, 'None', --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 'None', --, --, --, --, --, 'None', --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, 'None',\n",
       "                    --, --, 'None', --, --, 'None', --, --, 'None', 'None',\n",
       "                    --, --, 'None', --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 'None', --, --, --, --,\n",
       "                    'None', --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 'None', --, --, --, --, --, --, 'None',\n",
       "                    --, --, --, --, 'None', 'None', --, --, --, 'None', --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, 'None', --,\n",
       "                    --, 'None', --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 'None', --, --, --, --, 'None', --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, 'None', --, --,\n",
       "                    --, --, --, --, --, --, --, 'None', --, --, --, --, --,\n",
       "                    --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True, False,  True,\n",
       "                     True, False,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True, False,  True, False,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True, False,  True,  True,\n",
       "                     True, False,  True, False,  True, False,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False, False,  True,  True,  True,\n",
       "                    False,  True, False,  True,  True,  True,  True,  True,\n",
       "                    False,  True, False,  True, False,  True,  True,  True,\n",
       "                    False,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False, False,  True,  True, False,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True, False,\n",
       "                     True,  True,  True, False, False,  True,  True, False,\n",
       "                     True,  True, False,  True,  True, False, False,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                    False, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False, False,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True, False, False,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True, False, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True, False,  True,  True, False,  True,  True, False,\n",
       "                    False,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U32'),\n",
       " 'param_regressor:extra_trees:min_impurity_decrease': masked_array(data=[--, --, --, --, --, --, --, --, --, 0.0, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, 0.0,\n",
       "                    --, --, --, 0.0, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 0.0, --, 0.0, --,\n",
       "                    --, 0.0, --, --, 0.0, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 0.0, --, --, 0.0, --, --, --,\n",
       "                    --, --, --, --, 0.0, --, 0.0, --, --, --, --, --, --,\n",
       "                    --, 0.0, --, --, --, --, 0.0, --, 0.0, --, --, --, --,\n",
       "                    --, 0.0, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 0.0, 0.0, --, --, --, --, --, --, --, 0.0, --, 0.0,\n",
       "                    --, --, --, 0.0, --, 0.0, --, 0.0, --, --, --, --, --,\n",
       "                    0.0, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 0.0, 0.0, --, --, --, 0.0, --, 0.0, --, --,\n",
       "                    --, --, --, 0.0, --, 0.0, --, 0.0, --, --, --, 0.0, --,\n",
       "                    0.0, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 0.0, 0.0, --, --, 0.0, --, --, 0.0, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 0.0, --, 0.0, --,\n",
       "                    --, --, 0.0, 0.0, --, --, 0.0, --, --, 0.0, --, --,\n",
       "                    0.0, 0.0, --, --, --, --, --, 0.0, --, --, --, 0.0,\n",
       "                    0.0, --, --, --, --, --, --, --, --, --, --, 0.0, 0.0,\n",
       "                    --, 0.0, --, --, --, --, --, --, 0.0, 0.0, --, --, 0.0,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 0.0, --, --, --, --, --, --, --, 0.0, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 0.0, --, --, --, --,\n",
       "                    --, --, --, --, --, 0.0, --, --, --, 0.0, 0.0, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    0.0, --, --, --, --, --, --, --, --, --, 0.0, 0.0, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 0.0, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 0.0, --, --, --, 0.0,\n",
       "                    --, --, --, --, --, --, --, --, 0.0, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 0.0, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 0.0, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 0.0, --, --, --, --,\n",
       "                    --, --, --, --, --, 0.0, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, 0.0, --, --,\n",
       "                    --, 0.0, --, --, --, --, 0.0, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 0.0, --, --, --, --, --, 0.0, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 0.0, --, --, 0.0, --, --, 0.0, --, --, 0.0, 0.0,\n",
       "                    --, --, 0.0, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 0.0, --, --, --, --, 0.0,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 0.0, --, --, --, --, --, --, 0.0, --, --, --,\n",
       "                    --, 0.0, 0.0, --, --, --, 0.0, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 0.0, --, --, 0.0, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, 0.0, --, --,\n",
       "                    --, --, 0.0, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 0.0, --, --, --, --, --, --, --, --,\n",
       "                    --, 0.0, --, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True, False,  True,\n",
       "                     True, False,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True, False,  True, False,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True, False,  True,  True,\n",
       "                     True, False,  True, False,  True, False,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False, False,  True,  True,  True,\n",
       "                    False,  True, False,  True,  True,  True,  True,  True,\n",
       "                    False,  True, False,  True, False,  True,  True,  True,\n",
       "                    False,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False, False,  True,  True, False,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True, False,\n",
       "                     True,  True,  True, False, False,  True,  True, False,\n",
       "                     True,  True, False,  True,  True, False, False,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                    False, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False, False,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True, False, False,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True, False, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True, False,  True,  True, False,  True,  True, False,\n",
       "                    False,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_regressor:extra_trees:min_samples_leaf': masked_array(data=[--, --, --, --, --, --, --, --, --, 15.0, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, 5.0,\n",
       "                    --, --, --, 7.0, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 5.0, --, 12.0, --,\n",
       "                    --, 1.0, --, --, 3.0, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 20.0, --, --, 7.0, --, --, --,\n",
       "                    --, --, --, --, 16.0, --, 19.0, --, --, --, --, --, --,\n",
       "                    --, 12.0, --, --, --, --, 17.0, --, 7.0, --, --, --,\n",
       "                    --, --, 1.0, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 3.0, 3.0, --, --, --, --, --, --, --, 11.0, --,\n",
       "                    13.0, --, --, --, 15.0, --, 20.0, --, 16.0, --, --, --,\n",
       "                    --, --, 7.0, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 5.0, 13.0, --, --, --, 14.0, --,\n",
       "                    20.0, --, --, --, --, --, 4.0, --, 18.0, --, 8.0, --,\n",
       "                    --, --, 16.0, --, 5.0, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 4.0, 13.0, --, --, 18.0, --, --,\n",
       "                    1.0, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 7.0, --, 6.0, --, --, --, 3.0, 11.0, --, --, 8.0,\n",
       "                    --, --, 12.0, --, --, 2.0, 3.0, --, --, --, --, --,\n",
       "                    12.0, --, --, --, 2.0, 11.0, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 4.0, 3.0, --, 19.0, --, --, --, --, --,\n",
       "                    --, 13.0, 12.0, --, --, 8.0, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 2.0, --, --, --,\n",
       "                    --, --, --, --, 20.0, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 9.0, --, --, --, --, --, --, --, --, --,\n",
       "                    12.0, --, --, --, 13.0, 8.0, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, 1.0, --, --,\n",
       "                    --, --, --, --, --, --, --, 19.0, 19.0, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, 2.0,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 13.0, --, --, --, 5.0, --, --, --,\n",
       "                    --, --, --, --, --, 7.0, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 20.0, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 1.0, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 14.0, --, --, --, --, --, --, --,\n",
       "                    --, --, 15.0, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 17.0, --, --, --, 17.0, --,\n",
       "                    --, --, --, 16.0, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 16.0, --, --, --, --, --, 19.0, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, 11.0,\n",
       "                    --, --, 15.0, --, --, 2.0, --, --, 19.0, 17.0, --, --,\n",
       "                    13.0, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 6.0, --, --, --, --, 7.0, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    19.0, --, --, --, --, --, --, 17.0, --, --, --, --,\n",
       "                    10.0, 18.0, --, --, --, 13.0, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 13.0, --, --, 14.0, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, 13.0, --, --,\n",
       "                    --, --, 8.0, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 8.0, --, --, --, --, --, --, --, --,\n",
       "                    --, 20.0, --, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True, False,  True,\n",
       "                     True, False,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True, False,  True, False,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True, False,  True,  True,\n",
       "                     True, False,  True, False,  True, False,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False, False,  True,  True,  True,\n",
       "                    False,  True, False,  True,  True,  True,  True,  True,\n",
       "                    False,  True, False,  True, False,  True,  True,  True,\n",
       "                    False,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False, False,  True,  True, False,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True, False,\n",
       "                     True,  True,  True, False, False,  True,  True, False,\n",
       "                     True,  True, False,  True,  True, False, False,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                    False, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False, False,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True, False, False,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True, False, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True, False,  True,  True, False,  True,  True, False,\n",
       "                    False,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_regressor:extra_trees:min_samples_split': masked_array(data=[--, --, --, --, --, --, --, --, --, 3.0, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, 7.0,\n",
       "                    --, --, --, 18.0, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 17.0, --, 8.0, --,\n",
       "                    --, 13.0, --, --, 8.0, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 18.0, --, --, 5.0, --, --, --,\n",
       "                    --, --, --, --, 2.0, --, 3.0, --, --, --, --, --, --,\n",
       "                    --, 4.0, --, --, --, --, 8.0, --, 16.0, --, --, --, --,\n",
       "                    --, 10.0, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 5.0, 5.0, --, --, --, --, --, --, --, 2.0, --,\n",
       "                    12.0, --, --, --, 9.0, --, 11.0, --, 2.0, --, --, --,\n",
       "                    --, --, 8.0, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 12.0, 20.0, --, --, --, 18.0, --,\n",
       "                    5.0, --, --, --, --, --, 11.0, --, 9.0, --, 7.0, --,\n",
       "                    --, --, 2.0, --, 11.0, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 15.0, 20.0, --, --, 7.0, --, --,\n",
       "                    13.0, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 20.0, --, 2.0, --, --, --, 2.0, 20.0, --, --, 7.0,\n",
       "                    --, --, 13.0, --, --, 7.0, 11.0, --, --, --, --, --,\n",
       "                    18.0, --, --, --, 3.0, 13.0, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 2.0, 9.0, --, 7.0, --, --, --, --, --,\n",
       "                    --, 5.0, 16.0, --, --, 3.0, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 12.0, --, --, --, --,\n",
       "                    --, --, --, 12.0, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 9.0, --, --, --, --, --, --, --, --, --, 19.0,\n",
       "                    --, --, --, 15.0, 12.0, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 17.0, --, --, --, --,\n",
       "                    --, --, --, --, --, 13.0, 14.0, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, 9.0, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 17.0, --, --, --, 14.0, --, --, --, --, --,\n",
       "                    --, --, --, 2.0, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 16.0, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 17.0, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 6.0, --, --, --, --, --, --, --, --, --,\n",
       "                    5.0, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 13.0, --, --, --, 13.0, --, --, --,\n",
       "                    --, 20.0, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    6.0, --, --, --, --, --, 17.0, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, 3.0, --, --,\n",
       "                    20.0, --, --, 4.0, --, --, 8.0, 10.0, --, --, 15.0, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 11.0, --, --, --, --, 20.0, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, 4.0, --,\n",
       "                    --, --, --, --, --, 9.0, --, --, --, --, 18.0, 11.0,\n",
       "                    --, --, --, 9.0, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 16.0, --, --, 8.0, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 15.0, --, --, --, --, 14.0,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    9.0, --, --, --, --, --, --, --, --, --, 16.0, --, --,\n",
       "                    --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True, False,  True,\n",
       "                     True, False,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True, False,  True, False,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True, False,  True,  True,\n",
       "                     True, False,  True, False,  True, False,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False, False,  True,  True,  True,\n",
       "                    False,  True, False,  True,  True,  True,  True,  True,\n",
       "                    False,  True, False,  True, False,  True,  True,  True,\n",
       "                    False,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False, False,  True,  True, False,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True, False,\n",
       "                     True,  True,  True, False, False,  True,  True, False,\n",
       "                     True,  True, False,  True,  True, False, False,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                    False, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False, False,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True, False, False,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True, False, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True, False,  True,  True, False,  True,  True, False,\n",
       "                    False,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_regressor:gaussian_process:alpha': masked_array(data=[--, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --,\n",
       "                    1.4163529997253153e-08, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    3.3573835588699042e-06, --, --, --, --, --, --, --, --,\n",
       "                    --, 5.485290306051494e-05, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 4.1791499313470473e-05,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 3.206930145962583e-07, 1.3413077444000527e-08,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    2.868149393351456e-13, --, --, --, --, --, --, --, --,\n",
       "                    --, 8.340897828840255e-06, 6.137917094150185e-07, --,\n",
       "                    --, 0.0005287923931285408, 0.20198288696375102, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 1.4279264738488698e-05, --, --, --,\n",
       "                    --, 1.1926670400365974e-14, --, 1.8510629021887296e-13,\n",
       "                    --, --, --, 0.20715049096123334, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 2.1367275012623696e-08, --, --, --,\n",
       "                    1.390487699936202e-11, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 0.006475275053987242, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    2.4943590085523828e-14, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 1.4736016285731312e-09, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --,\n",
       "                    5.856338335459175e-14, --, --, --,\n",
       "                    1.9255326460123923e-11, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 1.501108258261274e-07, --, --,\n",
       "                    2.3859666951808862e-09, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 0.0012585508494078986, --, --,\n",
       "                    6.86831255137143e-09, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --,\n",
       "                    0.00038340317031023135, --, --, --, --, --, --, --, --,\n",
       "                    --, 4.489782399598325e-14, --, --, --, --,\n",
       "                    0.10703515487988764, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 1.0687203495761815e-06, --, --, --, --, --, --,\n",
       "                    --, 0.013109186590037012, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    7.83907128831309e-05, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 0.00034123523500557843,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 1.6099330114822354e-13, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 0.005139447210250315,\n",
       "                    8.199515741273387e-05, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 4.030478892893677e-07, --, --, --,\n",
       "                    0.009676148045474448, --, --, 7.639938824064915e-10,\n",
       "                    --, --, --, --, --, --, --, --, --,\n",
       "                    2.2456585225316317e-09, --, --, --, --, --,\n",
       "                    2.3569718894257355e-14, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 5.753888517288542e-12, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 5.3274564473037956e-08, --, --,\n",
       "                    2.854857984895263e-13, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    0.0014273928813546266, --, --, --, --, --, --, --, --,\n",
       "                    1.6993913126118065e-13, --, --, --, --, --, --, --, --,\n",
       "                    --, 1.3794594469961047e-12, --, --, --, --,\n",
       "                    5.247330535881833e-14, --, --, --, --, --, --,\n",
       "                    2.6621755315843536e-06, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 0.12734348047783078,\n",
       "                    4.9710053396599514e-08, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --,\n",
       "                    6.294775572977233e-08, --, --, --,\n",
       "                    1.0580564862095533e-13, --, --, --, --, --, --, --, --,\n",
       "                    8.65808954700274e-13, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 2.8437483828518534e-13,\n",
       "                    6.781483716984294e-05, --, --, --,\n",
       "                    4.0431185489547685e-10, --, 2.8608376266177268e-11, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    1.0895010838435026e-05, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 1.0936788459153977e-12, --, --,\n",
       "                    --, --, --, --, --, 5.925423626330127e-13, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    6.40829809496359e-09, --, --, --, --, --, --, --, --,\n",
       "                    --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False, False,  True,  True,\n",
       "                    False, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True, False,  True, False,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True, False,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True, False,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_regressor:gaussian_process:thetaL': masked_array(data=[--, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --,\n",
       "                    2.019075896160975e-07, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    6.9114845976782165e-06, --, --, --, --, --, --, --, --,\n",
       "                    --, 4.6032669578907194e-05, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 1.6389034578508525e-07,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 1.1565529981987449e-06, 9.001903126881822e-10,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    0.0002098640411127642, --, --, --, --, --, --, --, --,\n",
       "                    --, 3.4021536883449562e-06, 6.510022300738803e-07, --,\n",
       "                    --, 1.0281297617323337e-05, 0.00014306569974764348, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 1.8232250593656966e-09, --, --,\n",
       "                    --, --, 0.0001898374349413664, --,\n",
       "                    7.689595204401312e-09, --, --, --,\n",
       "                    5.4024371099075145e-06, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 4.2171506451482755e-05, --, --, --,\n",
       "                    7.703181143649476e-10, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 1.1216212356658958e-09, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    0.00035331328505355857, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 3.076604135826946e-06, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --,\n",
       "                    5.131329164411288e-08, --, --, --,\n",
       "                    7.108156610214643e-08, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 1.0676971949446703e-07, --, --,\n",
       "                    3.3263630856712037e-07, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 1.2989432542622725e-09, --, --,\n",
       "                    3.626595883283288e-09, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --,\n",
       "                    3.5539730669533876e-07, --, --, --, --, --, --, --, --,\n",
       "                    --, 5.757899166303097e-07, --, --, --, --,\n",
       "                    2.841937917947068e-05, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 7.476972189926359e-09, --, --, --, --, --, --,\n",
       "                    --, 3.958884283642714e-08, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    1.154379521747539e-07, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 9.006442528955549e-06,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 1.875511903826865e-07, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 7.845424330132245e-06,\n",
       "                    7.327731425545816e-08, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 0.000692768492712403, --, --, --,\n",
       "                    6.01740990072471e-09, --, --, 2.9955022511182666e-05,\n",
       "                    --, --, --, --, --, --, --, --, --,\n",
       "                    9.649302082962461e-07, --, --, --, --, --,\n",
       "                    0.00020691992493141037, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 9.636626571609476e-10, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 1.3896252244757856e-08, --, --,\n",
       "                    2.9199030326937677e-05, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    4.624236152459923e-09, --, --, --, --, --, --, --, --,\n",
       "                    1.009043198700696e-08, --, --, --, --, --, --, --, --,\n",
       "                    --, 4.303827269406332e-09, --, --, --, --,\n",
       "                    0.00021225901674294916, --, --, --, --, --, --,\n",
       "                    3.5918499907717756e-09, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 1.081013913544105e-10,\n",
       "                    1.1409525521407787e-08, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --,\n",
       "                    6.927299035697042e-10, --, --, --,\n",
       "                    2.3929890642424216e-05, --, --, --, --, --, --, --, --,\n",
       "                    0.00020717571376174408, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 2.985788902868653e-05,\n",
       "                    3.1842190709956113e-09, --, --, --,\n",
       "                    3.106443915166316e-09, --, 4.031362171158257e-10, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    3.5147834643896604e-08, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 1.8225943684116453e-06, --, --,\n",
       "                    --, --, --, --, --, 8.921919879153112e-10, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    0.00037976720056226806, --, --, --, --, --, --, --, --,\n",
       "                    --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False, False,  True,  True,\n",
       "                    False, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True, False,  True, False,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True, False,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True, False,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_regressor:gaussian_process:thetaU': masked_array(data=[--, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 2422.9473854075172,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 7155.3735232242225, --, --, --,\n",
       "                    --, --, --, --, --, --, 3461.111573380696, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    2.0590948997394065, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 8435.567086757135,\n",
       "                    2376.788108857216, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 14037.07491261275, --, --, --, --, --,\n",
       "                    --, --, --, --, 1.5469090679843953, 14380.96003193229,\n",
       "                    --, --, 6.05276217992108, 69.99717127946799, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 287.036062788838, --, --, --, --,\n",
       "                    72.16501630751512, --, 33.979735014371904, --, --, --,\n",
       "                    9.861965779489228, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 1.074132790363595, --, --, --, 2.9452903619926247,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    1.7041974424427613, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 53283.70339523912, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    1726.5686836572502, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 7659.279743730741, --, --, --,\n",
       "                    56.20325012506926, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 143.75186675894298, --, --, 27628.01440383758, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 350.9176745391377, --,\n",
       "                    --, 7.953941151617265, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 59.49691617916531,\n",
       "                    --, --, --, --, --, --, --, --, --, 83522.28357984616,\n",
       "                    --, --, --, --, 140.13473440084033, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 3699.76488139761, --, --, --, --,\n",
       "                    --, --, --, 501.44421030566906, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    6059.689894225536, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 1.633668740549995, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 55.4752710333722, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 258.3078405142896,\n",
       "                    90.95086745848563, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 119.53449768146001, --, --, --,\n",
       "                    5.263078020919164, --, --, 61152.407151593005, --, --,\n",
       "                    --, --, --, --, --, --, --, 100000.0, --, --, --, --,\n",
       "                    --, 15646.302068407242, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 2082.32042948293, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 30.163210546885768, --, --,\n",
       "                    1.0304078746185743, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --,\n",
       "                    2661.716100373188, --, --, --, --, --, --, --, --,\n",
       "                    4887.203319576199, --, --, --, --, --, --, --, --, --,\n",
       "                    760.9875463239, --, --, --, --, 4.704672577043089, --,\n",
       "                    --, --, --, --, --, 2.71006160915137, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    193.69886592696662, 57178.93557628186, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    34.59699030438471, --, --, --, 22143.577738676977, --,\n",
       "                    --, --, --, --, --, --, --, 3.225224216786871, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --,\n",
       "                    1570.9445352850141, 19.240858065626785, --, --, --,\n",
       "                    68756.15570489835, --, 5839.141882563115, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 18.87603586150951,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    3080.632484630965, --, --, --, --, --, --, --,\n",
       "                    2104.9498267686313, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 49643.43694075788, --, --, --,\n",
       "                    --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False, False,  True,  True,\n",
       "                    False, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True, False,  True, False,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True, False,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True, False,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_regressor:k_nearest_neighbors:n_neighbors': masked_array(data=[--, --, --, --, --, --, --, --, --, --, 50.0, --, --,\n",
       "                    --, --, --, 87.0, --, --, 11.0, --, --, --, --, 3.0,\n",
       "                    --, --, --, --, --, --, --, 28.0, --, --, 66.0, 3.0,\n",
       "                    --, --, --, 1.0, 17.0, --, --, --, 28.0, --, --, --,\n",
       "                    10.0, --, --, 90.0, 1.0, --, --, --, --, --, 84.0,\n",
       "                    15.0, --, --, 83.0, 33.0, --, 15.0, --, --, --, 14.0,\n",
       "                    --, --, --, --, 18.0, --, 13.0, --, 21.0, 13.0, --,\n",
       "                    27.0, 17.0, --, --, 17.0, 90.0, --, --, 14.0, --, 9.0,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, 16.0, 14.0,\n",
       "                    4.0, --, 67.0, --, --, 2.0, --, 10.0, 33.0, --, --,\n",
       "                    20.0, --, --, --, 2.0, 59.0, --, 37.0, --, --, --, --,\n",
       "                    14.0, --, 22.0, 1.0, --, --, 32.0, 1.0, --, 13.0, 28.0,\n",
       "                    --, --, 93.0, --, --, --, --, --, 32.0, 18.0, --, --,\n",
       "                    1.0, 18.0, 52.0, --, 16.0, --, --, --, --, --, 32.0,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 16.0, --, 1.0, 2.0, --, --, --,\n",
       "                    --, 23.0, --, --, --, --, 14.0, 29.0, 16.0, --, --,\n",
       "                    26.0, --, 12.0, --, --, --, --, --, 58.0, --, --, --,\n",
       "                    67.0, 71.0, 7.0, 14.0, --, 15.0, 6.0, 17.0, 77.0, 18.0,\n",
       "                    --, --, --, --, 15.0, --, 17.0, 3.0, --, --, 69.0, --,\n",
       "                    43.0, 6.0, --, 16.0, --, --, --, 37.0, --, 76.0, --,\n",
       "                    12.0, --, --, --, --, --, --, 25.0, --, --, 37.0, 49.0,\n",
       "                    --, --, 1.0, --, --, --, 46.0, 55.0, 2.0, 13.0, --, --,\n",
       "                    --, --, --, --, 79.0, 5.0, 41.0, --, --, 2.0, 13.0,\n",
       "                    6.0, --, 13.0, --, --, --, --, 15.0, 49.0, 14.0, 28.0,\n",
       "                    --, --, --, --, --, 17.0, --, 13.0, 13.0, --, 35.0, --,\n",
       "                    14.0, --, 14.0, 1.0, 67.0, 10.0, --, 79.0, --, --, --,\n",
       "                    19.0, 10.0, 11.0, 32.0, --, --, 1.0, --, --, --, --,\n",
       "                    --, --, 1.0, 38.0, --, --, --, 22.0, 79.0, 6.0, 6.0,\n",
       "                    4.0, 4.0, 19.0, 31.0, --, 26.0, 28.0, 31.0, 18.0, 3.0,\n",
       "                    --, --, 46.0, 11.0, --, 64.0, --, --, --, --, --, --,\n",
       "                    --, 44.0, 27.0, --, --, 6.0, 31.0, --, 61.0, 2.0, 8.0,\n",
       "                    8.0, 19.0, --, 53.0, --, --, --, 20.0, --, --, --, --,\n",
       "                    --, --, --, 37.0, --, 17.0, --, --, --, --, 82.0, 11.0,\n",
       "                    --, 3.0, --, 14.0, --, 43.0, --, 14.0, --, --, --,\n",
       "                    21.0, 73.0, --, --, --, --, --, --, 11.0, 66.0, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 70.0, --, --, --,\n",
       "                    --, 6.0, --, 6.0, --, --, --, 6.0, --, --, --, 21.0,\n",
       "                    6.0, 20.0, --, --, 67.0, --, --, 20.0, --, 4.0, --, --,\n",
       "                    --, --, --, --, --, --, --, 77.0, --, --, --, --, --,\n",
       "                    11.0, --, --, --, 14.0, --, --, --, 15.0, --, --, 1.0,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 10.0, --, --, --, 41.0, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    16.0, 84.0, 29.0, --, 40.0, --, --, 58.0, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 20.0, --, --, --, 99.0, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 30.0, --, --, 50.0,\n",
       "                    --, --, --, --, 47.0, --, --, --, --, --, --, --, --,\n",
       "                    --, 1.0, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 86.0, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 1.0, 10.0, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 42.0, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 19.0, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 35.0, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 46.0, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 29.0],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True, False,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True, False, False,  True,  True,  True,\n",
       "                    False, False,  True,  True,  True, False,  True,  True,\n",
       "                     True, False,  True,  True, False, False,  True,  True,\n",
       "                     True,  True,  True, False, False,  True,  True, False,\n",
       "                    False,  True, False,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True, False,  True, False,  True, False,\n",
       "                    False,  True, False, False,  True,  True, False, False,\n",
       "                     True,  True, False,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False, False, False,  True, False,  True,  True, False,\n",
       "                     True, False, False,  True,  True, False,  True,  True,\n",
       "                     True, False, False,  True, False,  True,  True,  True,\n",
       "                     True, False,  True, False, False,  True,  True, False,\n",
       "                    False,  True, False, False,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True, False, False,  True,  True,\n",
       "                    False, False, False,  True, False,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True, False, False,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True, False, False, False,  True,\n",
       "                     True, False,  True, False,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True, False, False, False,\n",
       "                    False,  True, False, False, False, False, False,  True,\n",
       "                     True,  True,  True, False,  True, False, False,  True,\n",
       "                     True, False,  True, False, False,  True, False,  True,\n",
       "                     True,  True, False,  True, False,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                    False, False,  True,  True, False,  True,  True,  True,\n",
       "                    False, False, False, False,  True,  True,  True,  True,\n",
       "                     True,  True, False, False, False,  True,  True, False,\n",
       "                    False, False,  True, False,  True,  True,  True,  True,\n",
       "                    False, False, False, False,  True,  True,  True,  True,\n",
       "                     True, False,  True, False, False,  True, False,  True,\n",
       "                    False,  True, False, False, False, False,  True, False,\n",
       "                     True,  True,  True, False, False, False, False,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                    False, False,  True,  True,  True, False, False, False,\n",
       "                    False, False, False, False, False,  True, False, False,\n",
       "                    False, False, False,  True,  True, False, False,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False, False,  True,  True, False, False,  True, False,\n",
       "                    False, False, False, False,  True, False,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True, False,  True,  True,  True,  True,\n",
       "                    False, False,  True, False,  True, False,  True, False,\n",
       "                     True, False,  True,  True,  True, False, False,  True,\n",
       "                     True,  True,  True,  True,  True, False, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True, False,\n",
       "                     True, False,  True,  True,  True, False,  True,  True,\n",
       "                     True, False, False, False,  True,  True, False,  True,\n",
       "                     True, False,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True, False,\n",
       "                     True,  True,  True, False,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False, False, False,\n",
       "                     True, False,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True, False,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False],\n",
       "        fill_value=1e+20),\n",
       " 'param_regressor:k_nearest_neighbors:p': masked_array(data=[--, --, --, --, --, --, --, --, --, --, 1.0, --, --,\n",
       "                    --, --, --, 1.0, --, --, 2.0, --, --, --, --, 1.0, --,\n",
       "                    --, --, --, --, --, --, 1.0, --, --, 2.0, 2.0, --, --,\n",
       "                    --, 1.0, 1.0, --, --, --, 1.0, --, --, --, 1.0, --, --,\n",
       "                    1.0, 1.0, --, --, --, --, --, 1.0, 2.0, --, --, 2.0,\n",
       "                    1.0, --, 1.0, --, --, --, 1.0, --, --, --, --, 1.0, --,\n",
       "                    2.0, --, 1.0, 2.0, --, 1.0, 1.0, --, --, 1.0, 1.0, --,\n",
       "                    --, 1.0, --, 2.0, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 1.0, 1.0, 1.0, --, 1.0, --, --, 2.0, --, 1.0,\n",
       "                    1.0, --, --, 2.0, --, --, --, 2.0, 1.0, --, 2.0, --,\n",
       "                    --, --, --, 1.0, --, 2.0, 1.0, --, --, 1.0, 2.0, --,\n",
       "                    1.0, 1.0, --, --, 2.0, --, --, --, --, --, 1.0, 1.0,\n",
       "                    --, --, 1.0, 1.0, 1.0, --, 2.0, --, --, --, --, --,\n",
       "                    2.0, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 2.0, --, 1.0, 1.0, --,\n",
       "                    --, --, --, 2.0, --, --, --, --, 2.0, 2.0, 1.0, --, --,\n",
       "                    2.0, --, 1.0, --, --, --, --, --, 2.0, --, --, --, 1.0,\n",
       "                    2.0, 1.0, 1.0, --, 2.0, 2.0, 1.0, 1.0, 1.0, --, --, --,\n",
       "                    --, 1.0, --, 2.0, 2.0, --, --, 2.0, --, 1.0, 2.0, --,\n",
       "                    2.0, --, --, --, 1.0, --, 1.0, --, 2.0, --, --, --, --,\n",
       "                    --, --, 1.0, --, --, 2.0, 1.0, --, --, 1.0, --, --, --,\n",
       "                    2.0, 2.0, 2.0, 2.0, --, --, --, --, --, --, 1.0, 2.0,\n",
       "                    2.0, --, --, 2.0, 2.0, 2.0, --, 1.0, --, --, --, --,\n",
       "                    2.0, 1.0, 2.0, 2.0, --, --, --, --, --, 1.0, --, 2.0,\n",
       "                    2.0, --, 1.0, --, 2.0, --, 2.0, 2.0, 2.0, 2.0, --, 2.0,\n",
       "                    --, --, --, 2.0, 2.0, 2.0, 1.0, --, --, 1.0, --, --,\n",
       "                    --, --, --, --, 1.0, 2.0, --, --, --, 1.0, 1.0, 2.0,\n",
       "                    2.0, 2.0, 2.0, 2.0, 1.0, --, 2.0, 2.0, 1.0, 1.0, 2.0,\n",
       "                    --, --, 1.0, 1.0, --, 2.0, --, --, --, --, --, --, --,\n",
       "                    1.0, 1.0, --, --, 2.0, 2.0, --, 1.0, 2.0, 1.0, 2.0,\n",
       "                    2.0, --, 2.0, --, --, --, 1.0, --, --, --, --, --, --,\n",
       "                    --, 2.0, --, 1.0, --, --, --, --, 2.0, 1.0, --, 1.0,\n",
       "                    --, 1.0, --, 2.0, --, 2.0, --, --, --, 2.0, 1.0, --,\n",
       "                    --, --, --, --, --, 1.0, 2.0, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 2.0, --, --, --, --, 2.0, --, 2.0,\n",
       "                    --, --, --, 2.0, --, --, --, 1.0, 2.0, 1.0, --, --,\n",
       "                    1.0, --, --, 1.0, --, 2.0, --, --, --, --, --, --, --,\n",
       "                    --, --, 2.0, --, --, --, --, --, 2.0, --, --, --, 1.0,\n",
       "                    --, --, --, 1.0, --, --, 1.0, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, 1.0, --, --,\n",
       "                    --, 1.0, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 2.0, 1.0, 2.0, --, 2.0,\n",
       "                    --, --, 2.0, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, 2.0, --,\n",
       "                    --, --, 1.0, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 1.0, --, --, 1.0, --, --, --, --, 2.0, --,\n",
       "                    --, --, --, --, --, --, --, --, 2.0, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    1.0, --, --, --, --, --, --, --, --, --, --, 2.0, 2.0,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    1.0, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 2.0, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 2.0, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 1.0, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 2.0],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True, False,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True, False, False,  True,  True,  True,\n",
       "                    False, False,  True,  True,  True, False,  True,  True,\n",
       "                     True, False,  True,  True, False, False,  True,  True,\n",
       "                     True,  True,  True, False, False,  True,  True, False,\n",
       "                    False,  True, False,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True, False,  True, False,  True, False,\n",
       "                    False,  True, False, False,  True,  True, False, False,\n",
       "                     True,  True, False,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False, False, False,  True, False,  True,  True, False,\n",
       "                     True, False, False,  True,  True, False,  True,  True,\n",
       "                     True, False, False,  True, False,  True,  True,  True,\n",
       "                     True, False,  True, False, False,  True,  True, False,\n",
       "                    False,  True, False, False,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True, False, False,  True,  True,\n",
       "                    False, False, False,  True, False,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True, False, False,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True, False, False, False,  True,\n",
       "                     True, False,  True, False,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True, False, False, False,\n",
       "                    False,  True, False, False, False, False, False,  True,\n",
       "                     True,  True,  True, False,  True, False, False,  True,\n",
       "                     True, False,  True, False, False,  True, False,  True,\n",
       "                     True,  True, False,  True, False,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                    False, False,  True,  True, False,  True,  True,  True,\n",
       "                    False, False, False, False,  True,  True,  True,  True,\n",
       "                     True,  True, False, False, False,  True,  True, False,\n",
       "                    False, False,  True, False,  True,  True,  True,  True,\n",
       "                    False, False, False, False,  True,  True,  True,  True,\n",
       "                     True, False,  True, False, False,  True, False,  True,\n",
       "                    False,  True, False, False, False, False,  True, False,\n",
       "                     True,  True,  True, False, False, False, False,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                    False, False,  True,  True,  True, False, False, False,\n",
       "                    False, False, False, False, False,  True, False, False,\n",
       "                    False, False, False,  True,  True, False, False,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False, False,  True,  True, False, False,  True, False,\n",
       "                    False, False, False, False,  True, False,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True, False,  True,  True,  True,  True,\n",
       "                    False, False,  True, False,  True, False,  True, False,\n",
       "                     True, False,  True,  True,  True, False, False,  True,\n",
       "                     True,  True,  True,  True,  True, False, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True, False,\n",
       "                     True, False,  True,  True,  True, False,  True,  True,\n",
       "                     True, False, False, False,  True,  True, False,  True,\n",
       "                     True, False,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True, False,\n",
       "                     True,  True,  True, False,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False, False, False,\n",
       "                     True, False,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True, False,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False],\n",
       "        fill_value=1e+20),\n",
       " 'param_regressor:k_nearest_neighbors:weights': masked_array(data=[--, --, --, --, --, --, --, --, --, --, 'distance', --,\n",
       "                    --, --, --, --, 'uniform', --, --, 'distance', --, --,\n",
       "                    --, --, 'distance', --, --, --, --, --, --, --,\n",
       "                    'uniform', --, --, 'uniform', 'uniform', --, --, --,\n",
       "                    'distance', 'distance', --, --, --, 'uniform', --, --,\n",
       "                    --, 'distance', --, --, 'distance', 'distance', --, --,\n",
       "                    --, --, --, 'uniform', 'uniform', --, --, 'uniform',\n",
       "                    'uniform', --, 'uniform', --, --, --, 'uniform', --,\n",
       "                    --, --, --, 'uniform', --, 'uniform', --, 'uniform',\n",
       "                    'uniform', --, 'uniform', 'uniform', --, --,\n",
       "                    'distance', 'distance', --, --, 'uniform', --,\n",
       "                    'uniform', --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    'uniform', 'uniform', 'distance', --, 'distance', --,\n",
       "                    --, 'uniform', --, 'uniform', 'uniform', --, --,\n",
       "                    'uniform', --, --, --, 'distance', 'uniform', --,\n",
       "                    'uniform', --, --, --, --, 'uniform', --, 'uniform',\n",
       "                    'uniform', --, --, 'uniform', 'distance', --,\n",
       "                    'uniform', 'uniform', --, --, 'uniform', --, --, --,\n",
       "                    --, --, 'uniform', 'uniform', --, --, 'uniform',\n",
       "                    'uniform', 'uniform', --, 'uniform', --, --, --, --,\n",
       "                    --, 'distance', --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, 'distance', --,\n",
       "                    'uniform', 'uniform', --, --, --, --, 'uniform', --,\n",
       "                    --, --, --, 'distance', 'uniform', 'uniform', --, --,\n",
       "                    'uniform', --, 'uniform', --, --, --, --, --,\n",
       "                    'uniform', --, --, --, 'distance', 'distance',\n",
       "                    'distance', 'uniform', --, 'uniform', 'uniform',\n",
       "                    'distance', 'uniform', 'uniform', --, --, --, --,\n",
       "                    'distance', --, 'distance', 'uniform', --, --,\n",
       "                    'distance', --, 'distance', 'uniform', --, 'uniform',\n",
       "                    --, --, --, 'distance', --, 'distance', --, 'uniform',\n",
       "                    --, --, --, --, --, --, 'distance', --, --, 'uniform',\n",
       "                    'uniform', --, --, 'distance', --, --, --, 'distance',\n",
       "                    'distance', 'uniform', 'uniform', --, --, --, --, --,\n",
       "                    --, 'distance', 'uniform', 'uniform', --, --,\n",
       "                    'uniform', 'distance', 'distance', --, 'uniform', --,\n",
       "                    --, --, --, 'distance', 'distance', 'distance',\n",
       "                    'distance', --, --, --, --, --, 'uniform', --,\n",
       "                    'distance', 'distance', --, 'distance', --, 'uniform',\n",
       "                    --, 'uniform', 'distance', 'distance', 'uniform', --,\n",
       "                    'distance', --, --, --, 'distance', 'distance',\n",
       "                    'distance', 'uniform', --, --, 'distance', --, --, --,\n",
       "                    --, --, --, 'uniform', 'uniform', --, --, --,\n",
       "                    'uniform', 'distance', 'uniform', 'uniform', 'uniform',\n",
       "                    'uniform', 'uniform', 'distance', --, 'distance',\n",
       "                    'distance', 'uniform', 'uniform', 'uniform', --, --,\n",
       "                    'uniform', 'uniform', --, 'uniform', --, --, --, --,\n",
       "                    --, --, --, 'distance', 'uniform', --, --, 'distance',\n",
       "                    'uniform', --, 'uniform', 'uniform', 'distance',\n",
       "                    'distance', 'uniform', --, 'uniform', --, --, --,\n",
       "                    'distance', --, --, --, --, --, --, --, 'uniform', --,\n",
       "                    'distance', --, --, --, --, 'distance', 'distance', --,\n",
       "                    'distance', --, 'distance', --, 'uniform', --,\n",
       "                    'uniform', --, --, --, 'distance', 'uniform', --, --,\n",
       "                    --, --, --, --, 'uniform', 'distance', --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 'uniform', --, --, --, --,\n",
       "                    'distance', --, 'uniform', --, --, --, 'uniform', --,\n",
       "                    --, --, 'uniform', 'uniform', 'distance', --, --,\n",
       "                    'uniform', --, --, 'uniform', --, 'uniform', --, --,\n",
       "                    --, --, --, --, --, --, --, 'uniform', --, --, --, --,\n",
       "                    --, 'distance', --, --, --, 'distance', --, --, --,\n",
       "                    'distance', --, --, 'uniform', --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, 'uniform', --,\n",
       "                    --, --, 'distance', --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, 'distance',\n",
       "                    'uniform', 'distance', --, 'uniform', --, --,\n",
       "                    'distance', --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, 'distance', --,\n",
       "                    --, --, 'distance', --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 'uniform', --, --, 'distance', --, --,\n",
       "                    --, --, 'uniform', --, --, --, --, --, --, --, --, --,\n",
       "                    'distance', --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 'uniform', --, --, --, --,\n",
       "                    --, --, --, --, --, --, 'uniform', 'distance', --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, 'distance',\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    'distance', --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 'distance', --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 'uniform', --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, 'distance'],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True, False,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True, False, False,  True,  True,  True,\n",
       "                    False, False,  True,  True,  True, False,  True,  True,\n",
       "                     True, False,  True,  True, False, False,  True,  True,\n",
       "                     True,  True,  True, False, False,  True,  True, False,\n",
       "                    False,  True, False,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True, False,  True, False,  True, False,\n",
       "                    False,  True, False, False,  True,  True, False, False,\n",
       "                     True,  True, False,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False, False, False,  True, False,  True,  True, False,\n",
       "                     True, False, False,  True,  True, False,  True,  True,\n",
       "                     True, False, False,  True, False,  True,  True,  True,\n",
       "                     True, False,  True, False, False,  True,  True, False,\n",
       "                    False,  True, False, False,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True, False, False,  True,  True,\n",
       "                    False, False, False,  True, False,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True, False, False,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True, False, False, False,  True,\n",
       "                     True, False,  True, False,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True, False, False, False,\n",
       "                    False,  True, False, False, False, False, False,  True,\n",
       "                     True,  True,  True, False,  True, False, False,  True,\n",
       "                     True, False,  True, False, False,  True, False,  True,\n",
       "                     True,  True, False,  True, False,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                    False, False,  True,  True, False,  True,  True,  True,\n",
       "                    False, False, False, False,  True,  True,  True,  True,\n",
       "                     True,  True, False, False, False,  True,  True, False,\n",
       "                    False, False,  True, False,  True,  True,  True,  True,\n",
       "                    False, False, False, False,  True,  True,  True,  True,\n",
       "                     True, False,  True, False, False,  True, False,  True,\n",
       "                    False,  True, False, False, False, False,  True, False,\n",
       "                     True,  True,  True, False, False, False, False,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                    False, False,  True,  True,  True, False, False, False,\n",
       "                    False, False, False, False, False,  True, False, False,\n",
       "                    False, False, False,  True,  True, False, False,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False, False,  True,  True, False, False,  True, False,\n",
       "                    False, False, False, False,  True, False,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True, False,  True,  True,  True,  True,\n",
       "                    False, False,  True, False,  True, False,  True, False,\n",
       "                     True, False,  True,  True,  True, False, False,  True,\n",
       "                     True,  True,  True,  True,  True, False, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True, False,\n",
       "                     True, False,  True,  True,  True, False,  True,  True,\n",
       "                     True, False, False, False,  True,  True, False,  True,\n",
       "                     True, False,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True, False,\n",
       "                     True,  True,  True, False,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False, False, False,\n",
       "                     True, False,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True, False,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U32'),\n",
       " 'param_regressor:random_forest:bootstrap': masked_array(data=['True', --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    'True', --, --, 'False', --, --, --, --, --, 'True',\n",
       "                    'False', --, --, --, 'True', --, 'True', --, --, --,\n",
       "                    --, --, 'False', --, --, 'False', 'False', 'True', --,\n",
       "                    --, 'True', --, --, --, 'True', --, 'True', --,\n",
       "                    'False', 'False', --, --, --, --, 'True', --, --, --,\n",
       "                    --, 'False', --, --, --, 'True', --, 'True', --, --,\n",
       "                    --, 'False', 'True', --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 'False', --, --, --, --,\n",
       "                    --, 'False', 'False', --, --, --, --, --, 'False', --,\n",
       "                    --, --, --, --, 'True', --, 'False', --, --, --, --,\n",
       "                    --, --, --, --, 'False', 'True', --, --, --, 'True',\n",
       "                    --, --, 'False', --, --, --, --, --, --, --, --, --,\n",
       "                    --, 'False', --, --, --, --, --, 'False', --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, 'True',\n",
       "                    'False', --, --, --, 'True', --, --, --, 'True', --,\n",
       "                    'False', --, --, 'True', --, 'True', 'True', --, --,\n",
       "                    --, --, --, 'True', --, 'False', --, --, --, --, --,\n",
       "                    --, --, --, --, --, 'False', --, --, --, 'True', --,\n",
       "                    --, --, --, --, --, 'False', 'False', --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    'False', --, --, --, --, --, 'False', --, 'True', --,\n",
       "                    --, --, --, --, 'True', 'False', --, --, --, --, --,\n",
       "                    --, 'False', --, --, --, --, --, 'True', --, --, --,\n",
       "                    --, --, --, --, --, 'False', --, --, --, --, --, --,\n",
       "                    'True', 'True', --, --, --, --, --, 'True', --, --, --,\n",
       "                    --, --, --, --, --, 'False', --, --, --, --, --,\n",
       "                    'False', --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 'True', --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 'True', --, --, --, --,\n",
       "                    'True', 'False', --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 'True', --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 'False', 'True', --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 'False', --, --, --, --, 'False',\n",
       "                    'True', --, --, --, --, 'False', --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 'True', --, 'True', --, --,\n",
       "                    --, --, --, 'False', --, 'False', --, --, --, --, --,\n",
       "                    --, --, 'True', --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 'False', --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, 'True', --,\n",
       "                    --, 'False', 'True', --, --, --, --, 'False', 'False',\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, 'True',\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 'False', --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 'False', --, --, --, 'True', --, --, --, --, --,\n",
       "                    --, --, --, --, 'True', --, --, --, --, --, 'False',\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, 'False',\n",
       "                    --, --, --, --, --, 'False', --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 'False', 'False', --,\n",
       "                    --, --, --, --, 'True', --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 'False', --, --, --, --, 'True',\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, 'True', --,\n",
       "                    --, --, 'False', --, --, --, --, 'False', --, --, --,\n",
       "                    --, --, --, --, --, 'True', --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 'False', --],\n",
       "              mask=[False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True, False, False,  True,\n",
       "                     True,  True, False,  True, False,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True, False, False, False,\n",
       "                     True,  True, False,  True,  True,  True, False,  True,\n",
       "                    False,  True, False, False,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True, False,  True, False,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True, False, False,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True, False,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False, False,\n",
       "                     True,  True,  True, False,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True, False,  True,  True,  True,\n",
       "                    False,  True, False,  True,  True, False,  True, False,\n",
       "                    False,  True,  True,  True,  True,  True, False,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True, False, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                    False,  True, False,  True,  True,  True,  True,  True,\n",
       "                    False, False,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True, False, False,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True, False, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True, False, False,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                    False,  True,  True,  True,  True,  True, False,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True, False, False,  True,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False, False,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U5'),\n",
       " 'param_regressor:random_forest:criterion': masked_array(data=['mse', --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    'mse', --, --, 'mae', --, --, --, --, --,\n",
       "                    'friedman_mse', 'mae', --, --, --, 'friedman_mse', --,\n",
       "                    'mse', --, --, --, --, --, 'friedman_mse', --, --,\n",
       "                    'friedman_mse', 'mse', 'mae', --, --, 'friedman_mse',\n",
       "                    --, --, --, 'mae', --, 'mse', --, 'friedman_mse',\n",
       "                    'mse', --, --, --, --, 'mse', --, --, --, --, 'mae',\n",
       "                    --, --, --, 'mae', --, 'friedman_mse', --, --, --,\n",
       "                    'mae', 'mae', --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 'mae', --, --, --, --, --, 'mae',\n",
       "                    'mae', --, --, --, --, --, 'mse', --, --, --, --, --,\n",
       "                    'friedman_mse', --, 'mae', --, --, --, --, --, --, --,\n",
       "                    --, 'mae', 'mse', --, --, --, 'mse', --, --, 'mae', --,\n",
       "                    --, --, --, --, --, --, --, --, --, 'friedman_mse', --,\n",
       "                    --, --, --, --, 'mae', --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 'mse', 'friedman_mse', --,\n",
       "                    --, --, 'mae', --, --, --, 'mae', --, 'mae', --, --,\n",
       "                    'mse', --, 'mae', 'mae', --, --, --, --, --,\n",
       "                    'friedman_mse', --, 'mse', --, --, --, --, --, --, --,\n",
       "                    --, --, --, 'friedman_mse', --, --, --, 'friedman_mse',\n",
       "                    --, --, --, --, --, --, 'mse', 'mse', --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    'friedman_mse', --, --, --, --, --, 'friedman_mse', --,\n",
       "                    'mse', --, --, --, --, --, 'friedman_mse', 'mae', --,\n",
       "                    --, --, --, --, --, 'friedman_mse', --, --, --, --, --,\n",
       "                    'friedman_mse', --, --, --, --, --, --, --, --, 'mae',\n",
       "                    --, --, --, --, --, --, 'mse', 'friedman_mse', --, --,\n",
       "                    --, --, --, 'mse', --, --, --, --, --, --, --, --,\n",
       "                    'mse', --, --, --, --, --, 'mae', --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 'friedman_mse', --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 'mae', --, --, --, --, 'mae', 'friedman_mse',\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, 'mse', --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, 'mse',\n",
       "                    'friedman_mse', --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 'friedman_mse', --, --, --, --, 'mse',\n",
       "                    'friedman_mse', --, --, --, --, 'mse', --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 'mae', --, 'mse', --,\n",
       "                    --, --, --, --, 'mse', --, 'friedman_mse', --, --, --,\n",
       "                    --, --, --, --, 'mae', --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 'mse', --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    'friedman_mse', --, --, 'mae', 'friedman_mse', --, --,\n",
       "                    --, --, 'mae', 'mse', --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 'mse', --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 'mae', --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 'mae', --, --, --, 'mae', --,\n",
       "                    --, --, --, --, --, --, --, --, 'mse', --, --, --, --,\n",
       "                    --, 'friedman_mse', --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 'friedman_mse', --, --, --, --, --, 'mae', --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    'friedman_mse', 'friedman_mse', --, --, --, --, --,\n",
       "                    'mae', --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 'mae', --, --, --, --, 'mae', --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 'mse', --, --, --, 'mae', --,\n",
       "                    --, --, --, 'mse', --, --, --, --, --, --, --, --,\n",
       "                    'mae', --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    'mae', --],\n",
       "              mask=[False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True, False, False,  True,\n",
       "                     True,  True, False,  True, False,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True, False, False, False,\n",
       "                     True,  True, False,  True,  True,  True, False,  True,\n",
       "                    False,  True, False, False,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True, False,  True, False,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True, False, False,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True, False,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False, False,\n",
       "                     True,  True,  True, False,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True, False,  True,  True,  True,\n",
       "                    False,  True, False,  True,  True, False,  True, False,\n",
       "                    False,  True,  True,  True,  True,  True, False,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True, False, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                    False,  True, False,  True,  True,  True,  True,  True,\n",
       "                    False, False,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True, False, False,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True, False, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True, False, False,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                    False,  True,  True,  True,  True,  True, False,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True, False, False,  True,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False, False,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U12'),\n",
       " 'param_regressor:random_forest:max_depth': masked_array(data=['None', --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    'None', --, --, 'None', --, --, --, --, --, 'None',\n",
       "                    'None', --, --, --, 'None', --, 'None', --, --, --, --,\n",
       "                    --, 'None', --, --, 'None', 'None', 'None', --, --,\n",
       "                    'None', --, --, --, 'None', --, 'None', --, 'None',\n",
       "                    'None', --, --, --, --, 'None', --, --, --, --, 'None',\n",
       "                    --, --, --, 'None', --, 'None', --, --, --, 'None',\n",
       "                    'None', --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 'None', --, --, --, --, --, 'None', 'None',\n",
       "                    --, --, --, --, --, 'None', --, --, --, --, --, 'None',\n",
       "                    --, 'None', --, --, --, --, --, --, --, --, 'None',\n",
       "                    'None', --, --, --, 'None', --, --, 'None', --, --, --,\n",
       "                    --, --, --, --, --, --, --, 'None', --, --, --, --, --,\n",
       "                    'None', --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 'None', 'None', --, --, --, 'None', --, --,\n",
       "                    --, 'None', --, 'None', --, --, 'None', --, 'None',\n",
       "                    'None', --, --, --, --, --, 'None', --, 'None', --, --,\n",
       "                    --, --, --, --, --, --, --, --, 'None', --, --, --,\n",
       "                    'None', --, --, --, --, --, --, 'None', 'None', --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 'None', --, --, --, --, --, 'None', --, 'None',\n",
       "                    --, --, --, --, --, 'None', 'None', --, --, --, --, --,\n",
       "                    --, 'None', --, --, --, --, --, 'None', --, --, --, --,\n",
       "                    --, --, --, --, 'None', --, --, --, --, --, --, 'None',\n",
       "                    'None', --, --, --, --, --, 'None', --, --, --, --, --,\n",
       "                    --, --, --, 'None', --, --, --, --, --, 'None', --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 'None', --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 'None', --, --, --, --, 'None', 'None', --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, 'None', --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 'None', 'None', --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, 'None',\n",
       "                    --, --, --, --, 'None', 'None', --, --, --, --, 'None',\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, 'None',\n",
       "                    --, 'None', --, --, --, --, --, 'None', --, 'None', --,\n",
       "                    --, --, --, --, --, --, 'None', --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 'None', --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    'None', --, --, 'None', 'None', --, --, --, --, 'None',\n",
       "                    'None', --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    'None', --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 'None', --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 'None', --, --, --, 'None', --, --, --, --, --,\n",
       "                    --, --, --, --, 'None', --, --, --, --, --, 'None', --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, 'None', --, --,\n",
       "                    --, --, --, 'None', --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 'None', 'None', --, --, --, --, --,\n",
       "                    'None', --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 'None', --, --, --, --, 'None', --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 'None', --, --, --, 'None', --,\n",
       "                    --, --, --, 'None', --, --, --, --, --, --, --, --,\n",
       "                    'None', --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    'None', --],\n",
       "              mask=[False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True, False, False,  True,\n",
       "                     True,  True, False,  True, False,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True, False, False, False,\n",
       "                     True,  True, False,  True,  True,  True, False,  True,\n",
       "                    False,  True, False, False,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True, False,  True, False,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True, False, False,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True, False,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False, False,\n",
       "                     True,  True,  True, False,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True, False,  True,  True,  True,\n",
       "                    False,  True, False,  True,  True, False,  True, False,\n",
       "                    False,  True,  True,  True,  True,  True, False,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True, False, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                    False,  True, False,  True,  True,  True,  True,  True,\n",
       "                    False, False,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True, False, False,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True, False, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True, False, False,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                    False,  True,  True,  True,  True,  True, False,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True, False, False,  True,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False, False,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U4'),\n",
       " 'param_regressor:random_forest:max_features': masked_array(data=[1.0, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    0.17361565672710066, --, --, 0.37138576468393947, --,\n",
       "                    --, --, --, --, 0.6250525905667202,\n",
       "                    0.12451623391967058, --, --, --, 0.10152147514845246,\n",
       "                    --, 0.1451565735468404, --, --, --, --, --,\n",
       "                    0.6275601704575671, --, --, 0.7575181816657064,\n",
       "                    0.16151937910417372, 0.9289300348279892, --, --,\n",
       "                    0.8121254819968173, --, --, --, 0.282206585929519, --,\n",
       "                    0.7135553614375547, --, 0.3023993424587932,\n",
       "                    0.7835289444936782, --, --, --, --,\n",
       "                    0.10262589064142413, --, --, --, --,\n",
       "                    0.9549830588935443, --, --, --, 0.36843174101550646,\n",
       "                    --, 0.14738059468868145, --, --, --, 0.858313402538514,\n",
       "                    0.8340287905055578, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 0.6068399649684288, --, --, --,\n",
       "                    --, --, 0.23637037945782638, 0.2829540799311099, --,\n",
       "                    --, --, --, --, 0.44355733378940587, --, --, --, --,\n",
       "                    --, 0.8813317559529642, --, 0.8803951188555903, --, --,\n",
       "                    --, --, --, --, --, --, 0.8280917823458034,\n",
       "                    0.5251685295588083, --, --, --, 0.5666145451543694, --,\n",
       "                    --, 0.7160668600623384, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 0.5582165495832695, --, --, --, --, --,\n",
       "                    0.11058349489885469, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 0.5822938852621277,\n",
       "                    0.6288652760379884, --, --, --, 0.6767124013393699, --,\n",
       "                    --, --, 0.43081057598423467, --, 0.6840353038113615,\n",
       "                    --, --, 0.6012391102043385, --, 0.17185442652526123,\n",
       "                    0.4338184089599194, --, --, --, --, --,\n",
       "                    0.6248392764081618, --, 0.5533840231512234, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 0.26652675320482944, --,\n",
       "                    --, --, 0.7724990020105982, --, --, --, --, --, --,\n",
       "                    0.3449416078131302, 0.6072669614617056, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    0.9760700292117067, --, --, --, --, --,\n",
       "                    0.8840956683508758, --, 0.6297464564951961, --, --, --,\n",
       "                    --, --, 0.45146884844304047, 0.46655064698452375, --,\n",
       "                    --, --, --, --, --, 0.6318845394734633, --, --, --, --,\n",
       "                    --, 0.15659863368338756, --, --, --, --, --, --, --,\n",
       "                    --, 0.7841072759596254, --, --, --, --, --, --,\n",
       "                    0.4095154069889594, 0.967452275667216, --, --, --, --,\n",
       "                    --, 0.2788820576593313, --, --, --, --, --, --, --, --,\n",
       "                    0.4827671645747057, --, --, --, --, --,\n",
       "                    0.4362502350364773, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    0.4119589613072887, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 0.4449067756269477, --, --, --, --,\n",
       "                    0.2031076366666406, 0.6163711655163535, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 0.41831768032058114, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --,\n",
       "                    0.40052074195500176, 0.6690339287223425, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --,\n",
       "                    0.8506608121464116, --, --, --, --, 0.764349087803526,\n",
       "                    0.15428881778925685, --, --, --, --,\n",
       "                    0.10002285776645192, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 0.708554329111435, --,\n",
       "                    0.19758018142613398, --, --, --, --, --,\n",
       "                    0.9984314315170009, --, 0.9920685185832182, --, --, --,\n",
       "                    --, --, --, --, 0.9304820900184396, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --,\n",
       "                    0.4882698185806733, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 0.7883954145320086, --,\n",
       "                    --, 0.5993420769135036, 0.7762766629997746, --, --, --,\n",
       "                    --, 0.5100230548192612, 0.46047617187561185, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --,\n",
       "                    0.5381604329049665, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 0.3247834606515138, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 0.9646874227232262, --,\n",
       "                    --, --, 0.914066051948872, --, --, --, --, --, --, --,\n",
       "                    --, --, 0.31689582672198, --, --, --, --, --,\n",
       "                    0.9510671099885932, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 0.9594058559087374, --, --, --, --, --,\n",
       "                    0.8581038474114419, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 0.9282339290479904,\n",
       "                    0.8301447389645674, --, --, --, --, --,\n",
       "                    0.5536660668974681, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 0.36446519422956236, --, --, --, --,\n",
       "                    0.4340953724510477, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 0.6186405491692145, --, --, --,\n",
       "                    0.8618498460603599, --, --, --, --, 0.5849731523914219,\n",
       "                    --, --, --, --, --, --, --, --, 0.8321866912866144, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --,\n",
       "                    0.8948565276034188, --],\n",
       "              mask=[False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True, False, False,  True,\n",
       "                     True,  True, False,  True, False,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True, False, False, False,\n",
       "                     True,  True, False,  True,  True,  True, False,  True,\n",
       "                    False,  True, False, False,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True, False,  True, False,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True, False, False,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True, False,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False, False,\n",
       "                     True,  True,  True, False,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True, False,  True,  True,  True,\n",
       "                    False,  True, False,  True,  True, False,  True, False,\n",
       "                    False,  True,  True,  True,  True,  True, False,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True, False, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                    False,  True, False,  True,  True,  True,  True,  True,\n",
       "                    False, False,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True, False, False,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True, False, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True, False, False,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                    False,  True,  True,  True,  True,  True, False,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True, False, False,  True,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False, False,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_regressor:random_forest:max_leaf_nodes': masked_array(data=['None', --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    'None', --, --, 'None', --, --, --, --, --, 'None',\n",
       "                    'None', --, --, --, 'None', --, 'None', --, --, --, --,\n",
       "                    --, 'None', --, --, 'None', 'None', 'None', --, --,\n",
       "                    'None', --, --, --, 'None', --, 'None', --, 'None',\n",
       "                    'None', --, --, --, --, 'None', --, --, --, --, 'None',\n",
       "                    --, --, --, 'None', --, 'None', --, --, --, 'None',\n",
       "                    'None', --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 'None', --, --, --, --, --, 'None', 'None',\n",
       "                    --, --, --, --, --, 'None', --, --, --, --, --, 'None',\n",
       "                    --, 'None', --, --, --, --, --, --, --, --, 'None',\n",
       "                    'None', --, --, --, 'None', --, --, 'None', --, --, --,\n",
       "                    --, --, --, --, --, --, --, 'None', --, --, --, --, --,\n",
       "                    'None', --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 'None', 'None', --, --, --, 'None', --, --,\n",
       "                    --, 'None', --, 'None', --, --, 'None', --, 'None',\n",
       "                    'None', --, --, --, --, --, 'None', --, 'None', --, --,\n",
       "                    --, --, --, --, --, --, --, --, 'None', --, --, --,\n",
       "                    'None', --, --, --, --, --, --, 'None', 'None', --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 'None', --, --, --, --, --, 'None', --, 'None',\n",
       "                    --, --, --, --, --, 'None', 'None', --, --, --, --, --,\n",
       "                    --, 'None', --, --, --, --, --, 'None', --, --, --, --,\n",
       "                    --, --, --, --, 'None', --, --, --, --, --, --, 'None',\n",
       "                    'None', --, --, --, --, --, 'None', --, --, --, --, --,\n",
       "                    --, --, --, 'None', --, --, --, --, --, 'None', --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 'None', --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 'None', --, --, --, --, 'None', 'None', --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, 'None', --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 'None', 'None', --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, 'None',\n",
       "                    --, --, --, --, 'None', 'None', --, --, --, --, 'None',\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, 'None',\n",
       "                    --, 'None', --, --, --, --, --, 'None', --, 'None', --,\n",
       "                    --, --, --, --, --, --, 'None', --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 'None', --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    'None', --, --, 'None', 'None', --, --, --, --, 'None',\n",
       "                    'None', --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    'None', --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 'None', --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 'None', --, --, --, 'None', --, --, --, --, --,\n",
       "                    --, --, --, --, 'None', --, --, --, --, --, 'None', --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, 'None', --, --,\n",
       "                    --, --, --, 'None', --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 'None', 'None', --, --, --, --, --,\n",
       "                    'None', --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 'None', --, --, --, --, 'None', --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 'None', --, --, --, 'None', --,\n",
       "                    --, --, --, 'None', --, --, --, --, --, --, --, --,\n",
       "                    'None', --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    'None', --],\n",
       "              mask=[False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True, False, False,  True,\n",
       "                     True,  True, False,  True, False,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True, False, False, False,\n",
       "                     True,  True, False,  True,  True,  True, False,  True,\n",
       "                    False,  True, False, False,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True, False,  True, False,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True, False, False,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True, False,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False, False,\n",
       "                     True,  True,  True, False,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True, False,  True,  True,  True,\n",
       "                    False,  True, False,  True,  True, False,  True, False,\n",
       "                    False,  True,  True,  True,  True,  True, False,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True, False, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                    False,  True, False,  True,  True,  True,  True,  True,\n",
       "                    False, False,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True, False, False,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True, False, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True, False, False,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                    False,  True,  True,  True,  True,  True, False,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True, False, False,  True,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False, False,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U4'),\n",
       " 'param_regressor:random_forest:min_impurity_decrease': masked_array(data=[0.0, --, --, --, --, --, --, --, --, --, --, --, 0.0,\n",
       "                    --, --, 0.0, --, --, --, --, --, 0.0, 0.0, --, --, --,\n",
       "                    0.0, --, 0.0, --, --, --, --, --, 0.0, --, --, 0.0,\n",
       "                    0.0, 0.0, --, --, 0.0, --, --, --, 0.0, --, 0.0, --,\n",
       "                    0.0, 0.0, --, --, --, --, 0.0, --, --, --, --, 0.0, --,\n",
       "                    --, --, 0.0, --, 0.0, --, --, --, 0.0, 0.0, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, 0.0,\n",
       "                    --, --, --, --, --, 0.0, 0.0, --, --, --, --, --, 0.0,\n",
       "                    --, --, --, --, --, 0.0, --, 0.0, --, --, --, --, --,\n",
       "                    --, --, --, 0.0, 0.0, --, --, --, 0.0, --, --, 0.0, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 0.0, --, --, --,\n",
       "                    --, --, 0.0, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 0.0, 0.0, --, --, --, 0.0, --, --,\n",
       "                    --, 0.0, --, 0.0, --, --, 0.0, --, 0.0, 0.0, --, --,\n",
       "                    --, --, --, 0.0, --, 0.0, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 0.0, --, --, --, 0.0, --, --, --, --, --,\n",
       "                    --, 0.0, 0.0, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 0.0, --, --, --, --,\n",
       "                    --, 0.0, --, 0.0, --, --, --, --, --, 0.0, 0.0, --, --,\n",
       "                    --, --, --, --, 0.0, --, --, --, --, --, 0.0, --, --,\n",
       "                    --, --, --, --, --, --, 0.0, --, --, --, --, --, --,\n",
       "                    0.0, 0.0, --, --, --, --, --, 0.0, --, --, --, --, --,\n",
       "                    --, --, --, 0.0, --, --, --, --, --, 0.0, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 0.0, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 0.0, --, --, --, --, 0.0, 0.0, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 0.0, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 0.0, 0.0, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 0.0, --, --, --, --,\n",
       "                    0.0, 0.0, --, --, --, --, 0.0, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 0.0, --, 0.0, --, --, --, --,\n",
       "                    --, 0.0, --, 0.0, --, --, --, --, --, --, --, 0.0, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    0.0, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 0.0, --, --, 0.0, 0.0, --, --, --,\n",
       "                    --, 0.0, 0.0, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 0.0, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 0.0, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 0.0, --, --, --, 0.0, --, --, --, --,\n",
       "                    --, --, --, --, --, 0.0, --, --, --, --, --, 0.0, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, 0.0, --, --,\n",
       "                    --, --, --, 0.0, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 0.0, 0.0, --, --, --, --, --, 0.0,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    0.0, --, --, --, --, 0.0, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 0.0, --, --, --, 0.0, --, --, --, --,\n",
       "                    0.0, --, --, --, --, --, --, --, --, 0.0, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 0.0, --],\n",
       "              mask=[False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True, False, False,  True,\n",
       "                     True,  True, False,  True, False,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True, False, False, False,\n",
       "                     True,  True, False,  True,  True,  True, False,  True,\n",
       "                    False,  True, False, False,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True, False,  True, False,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True, False, False,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True, False,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False, False,\n",
       "                     True,  True,  True, False,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True, False,  True,  True,  True,\n",
       "                    False,  True, False,  True,  True, False,  True, False,\n",
       "                    False,  True,  True,  True,  True,  True, False,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True, False, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                    False,  True, False,  True,  True,  True,  True,  True,\n",
       "                    False, False,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True, False, False,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True, False, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True, False, False,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                    False,  True,  True,  True,  True,  True, False,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True, False, False,  True,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False, False,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_regressor:random_forest:min_samples_leaf': masked_array(data=[1.0, --, --, --, --, --, --, --, --, --, --, --, 12.0,\n",
       "                    --, --, 15.0, --, --, --, --, --, 15.0, 11.0, --, --,\n",
       "                    --, 3.0, --, 1.0, --, --, --, --, --, 4.0, --, --,\n",
       "                    15.0, 7.0, 6.0, --, --, 3.0, --, --, --, 18.0, --,\n",
       "                    18.0, --, 2.0, 2.0, --, --, --, --, 16.0, --, --, --,\n",
       "                    --, 16.0, --, --, --, 2.0, --, 15.0, --, --, --, 9.0,\n",
       "                    17.0, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 8.0, --, --, --, --, --, 13.0, 8.0, --, --,\n",
       "                    --, --, --, 9.0, --, --, --, --, --, 13.0, --, 9.0, --,\n",
       "                    --, --, --, --, --, --, --, 8.0, 7.0, --, --, --, 7.0,\n",
       "                    --, --, 7.0, --, --, --, --, --, --, --, --, --, --,\n",
       "                    12.0, --, --, --, --, --, 4.0, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 14.0, 15.0, --, --,\n",
       "                    --, 14.0, --, --, --, 10.0, --, 14.0, --, --, 9.0, --,\n",
       "                    3.0, 16.0, --, --, --, --, --, 15.0, --, 13.0, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 5.0, --, --, --, 2.0,\n",
       "                    --, --, --, --, --, --, 15.0, 13.0, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    13.0, --, --, --, --, --, 19.0, --, 3.0, --, --, --,\n",
       "                    --, --, 15.0, 12.0, --, --, --, --, --, --, 10.0, --,\n",
       "                    --, --, --, --, 7.0, --, --, --, --, --, --, --, --,\n",
       "                    14.0, --, --, --, --, --, --, 1.0, 19.0, --, --, --,\n",
       "                    --, --, 14.0, --, --, --, --, --, --, --, --, 4.0, --,\n",
       "                    --, --, --, --, 10.0, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, 9.0,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, 9.0, --,\n",
       "                    --, --, --, 7.0, 2.0, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 16.0, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 1.0, 6.0, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 10.0, --, --, --, --, 20.0, 2.0, --,\n",
       "                    --, --, --, 6.0, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 5.0, --, 5.0, --, --, --, --, --, 14.0, --,\n",
       "                    18.0, --, --, --, --, --, --, --, 9.0, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, 2.0, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 4.0, --, --, 8.0, 1.0, --, --, --, --, 10.0,\n",
       "                    2.0, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    5.0, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 11.0, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 18.0, --, --, --, 20.0, --, --, --, --, --, --,\n",
       "                    --, --, --, 13.0, --, --, --, --, --, 1.0, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 19.0, --, --, --, --,\n",
       "                    --, 18.0, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 9.0, 12.0, --, --, --, --, --, 6.0, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, 3.0, --,\n",
       "                    --, --, --, 6.0, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 19.0, --, --, --, 13.0, --, --, --, --, 11.0,\n",
       "                    --, --, --, --, --, --, --, --, 13.0, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 2.0, --],\n",
       "              mask=[False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True, False, False,  True,\n",
       "                     True,  True, False,  True, False,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True, False, False, False,\n",
       "                     True,  True, False,  True,  True,  True, False,  True,\n",
       "                    False,  True, False, False,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True, False,  True, False,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True, False, False,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True, False,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False, False,\n",
       "                     True,  True,  True, False,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True, False,  True,  True,  True,\n",
       "                    False,  True, False,  True,  True, False,  True, False,\n",
       "                    False,  True,  True,  True,  True,  True, False,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True, False, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                    False,  True, False,  True,  True,  True,  True,  True,\n",
       "                    False, False,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True, False, False,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True, False, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True, False, False,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                    False,  True,  True,  True,  True,  True, False,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True, False, False,  True,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False, False,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_regressor:random_forest:min_samples_split': masked_array(data=[2.0, --, --, --, --, --, --, --, --, --, --, --, 16.0,\n",
       "                    --, --, 6.0, --, --, --, --, --, 19.0, 14.0, --, --,\n",
       "                    --, 15.0, --, 13.0, --, --, --, --, --, 15.0, --, --,\n",
       "                    10.0, 12.0, 3.0, --, --, 19.0, --, --, --, 5.0, --,\n",
       "                    15.0, --, 11.0, 17.0, --, --, --, --, 9.0, --, --, --,\n",
       "                    --, 10.0, --, --, --, 14.0, --, 20.0, --, --, --, 17.0,\n",
       "                    11.0, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 15.0, --, --, --, --, --, 18.0, 12.0, --,\n",
       "                    --, --, --, --, 20.0, --, --, --, --, --, 17.0, --,\n",
       "                    8.0, --, --, --, --, --, --, --, --, 15.0, 20.0, --,\n",
       "                    --, --, 2.0, --, --, 10.0, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 17.0, --, --, --, --, --, 6.0, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, 12.0,\n",
       "                    16.0, --, --, --, 17.0, --, --, --, 18.0, --, 11.0, --,\n",
       "                    --, 4.0, --, 8.0, 7.0, --, --, --, --, --, 14.0, --,\n",
       "                    4.0, --, --, --, --, --, --, --, --, --, --, 18.0, --,\n",
       "                    --, --, 9.0, --, --, --, --, --, --, 20.0, 2.0, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 11.0, --, --, --, --, --, 16.0, --, 13.0, --,\n",
       "                    --, --, --, --, 15.0, 2.0, --, --, --, --, --, --, 6.0,\n",
       "                    --, --, --, --, --, 17.0, --, --, --, --, --, --, --,\n",
       "                    --, 9.0, --, --, --, --, --, --, 10.0, 20.0, --, --,\n",
       "                    --, --, --, 16.0, --, --, --, --, --, --, --, --, 10.0,\n",
       "                    --, --, --, --, --, 13.0, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    4.0, --, --, --, --, --, --, --, --, --, --, --, 20.0,\n",
       "                    --, --, --, --, 3.0, 17.0, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 4.0, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 4.0, 5.0, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 20.0, --, --, --, --, 6.0, 18.0,\n",
       "                    --, --, --, --, 9.0, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 3.0, --, 5.0, --, --, --, --, --, 10.0,\n",
       "                    --, 20.0, --, --, --, --, --, --, --, 19.0, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, 12.0,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 4.0, --, --, 19.0, 20.0, --, --, --, --,\n",
       "                    6.0, 8.0, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 6.0, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 14.0, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 20.0, --, --, --, 13.0, --, --, --, --, --,\n",
       "                    --, --, --, --, 13.0, --, --, --, --, --, 8.0, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 3.0, --, --, --,\n",
       "                    --, --, 6.0, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 15.0, 12.0, --, --, --, --, --, 8.0,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    19.0, --, --, --, --, 3.0, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 4.0, --, --, --, 19.0, --, --, --, --,\n",
       "                    20.0, --, --, --, --, --, --, --, --, 5.0, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 18.0, --],\n",
       "              mask=[False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True, False, False,  True,\n",
       "                     True,  True, False,  True, False,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True, False, False, False,\n",
       "                     True,  True, False,  True,  True,  True, False,  True,\n",
       "                    False,  True, False, False,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True, False,  True, False,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True, False, False,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True, False,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False, False,\n",
       "                     True,  True,  True, False,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True, False,  True,  True,  True,\n",
       "                    False,  True, False,  True,  True, False,  True, False,\n",
       "                    False,  True,  True,  True,  True,  True, False,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True, False, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                    False,  True, False,  True,  True,  True,  True,  True,\n",
       "                    False, False,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True, False, False,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True, False, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True, False, False,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                    False,  True,  True,  True,  True,  True, False,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True, False, False,  True,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False, False,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_regressor:random_forest:min_weight_fraction_leaf': masked_array(data=[0.0, --, --, --, --, --, --, --, --, --, --, --, 0.0,\n",
       "                    --, --, 0.0, --, --, --, --, --, 0.0, 0.0, --, --, --,\n",
       "                    0.0, --, 0.0, --, --, --, --, --, 0.0, --, --, 0.0,\n",
       "                    0.0, 0.0, --, --, 0.0, --, --, --, 0.0, --, 0.0, --,\n",
       "                    0.0, 0.0, --, --, --, --, 0.0, --, --, --, --, 0.0, --,\n",
       "                    --, --, 0.0, --, 0.0, --, --, --, 0.0, 0.0, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, 0.0,\n",
       "                    --, --, --, --, --, 0.0, 0.0, --, --, --, --, --, 0.0,\n",
       "                    --, --, --, --, --, 0.0, --, 0.0, --, --, --, --, --,\n",
       "                    --, --, --, 0.0, 0.0, --, --, --, 0.0, --, --, 0.0, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 0.0, --, --, --,\n",
       "                    --, --, 0.0, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 0.0, 0.0, --, --, --, 0.0, --, --,\n",
       "                    --, 0.0, --, 0.0, --, --, 0.0, --, 0.0, 0.0, --, --,\n",
       "                    --, --, --, 0.0, --, 0.0, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 0.0, --, --, --, 0.0, --, --, --, --, --,\n",
       "                    --, 0.0, 0.0, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 0.0, --, --, --, --,\n",
       "                    --, 0.0, --, 0.0, --, --, --, --, --, 0.0, 0.0, --, --,\n",
       "                    --, --, --, --, 0.0, --, --, --, --, --, 0.0, --, --,\n",
       "                    --, --, --, --, --, --, 0.0, --, --, --, --, --, --,\n",
       "                    0.0, 0.0, --, --, --, --, --, 0.0, --, --, --, --, --,\n",
       "                    --, --, --, 0.0, --, --, --, --, --, 0.0, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 0.0, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 0.0, --, --, --, --, 0.0, 0.0, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 0.0, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 0.0, 0.0, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 0.0, --, --, --, --,\n",
       "                    0.0, 0.0, --, --, --, --, 0.0, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 0.0, --, 0.0, --, --, --, --,\n",
       "                    --, 0.0, --, 0.0, --, --, --, --, --, --, --, 0.0, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    0.0, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 0.0, --, --, 0.0, 0.0, --, --, --,\n",
       "                    --, 0.0, 0.0, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 0.0, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 0.0, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 0.0, --, --, --, 0.0, --, --, --, --,\n",
       "                    --, --, --, --, --, 0.0, --, --, --, --, --, 0.0, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, 0.0, --, --,\n",
       "                    --, --, --, 0.0, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 0.0, 0.0, --, --, --, --, --, 0.0,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    0.0, --, --, --, --, 0.0, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 0.0, --, --, --, 0.0, --, --, --, --,\n",
       "                    0.0, --, --, --, --, --, --, --, --, 0.0, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 0.0, --],\n",
       "              mask=[False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True, False, False,  True,\n",
       "                     True,  True, False,  True, False,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True, False, False, False,\n",
       "                     True,  True, False,  True,  True,  True, False,  True,\n",
       "                    False,  True, False, False,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True, False,  True, False,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True, False, False,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True, False,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False, False,\n",
       "                     True,  True,  True, False,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True, False,  True,  True,  True,\n",
       "                    False,  True, False,  True,  True, False,  True, False,\n",
       "                    False,  True,  True,  True,  True,  True, False,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True, False, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                    False,  True, False,  True,  True,  True,  True,  True,\n",
       "                    False, False,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True, False, False,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True, False, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True, False, False,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                    False,  True,  True,  True,  True,  True, False,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True, False, False,  True,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False, False,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_regressor:ridge_regression:alpha': masked_array(data=[--, 173.52078030595007, --, --, 1629.8131509973832,\n",
       "                    2801.8018189555287, 1265.454796122566,\n",
       "                    314.9876956524643, 516.588967642959, --, --, --, --,\n",
       "                    --, 1183.594096216625, --, --, 2772.6003277693567, --,\n",
       "                    --, 507.4744030912921, --, --, --, --, --, --,\n",
       "                    102.35574469304287, --, --, 6707.71030571148,\n",
       "                    232.38582725627515, --, 3185.2199191698483, --, --, --,\n",
       "                    --, --, --, --, --, --, 776.4407618884782, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 2565.116198863405, --,\n",
       "                    --, 2016.395342809712, --, --, --, 2935.44400869741,\n",
       "                    --, --, --, --, --, 3834.883710176195, --, --, --, --,\n",
       "                    819.3527158367367, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 269.2269900098719, --, --, --,\n",
       "                    246.57639111008808, --, 109.98669387729639, --,\n",
       "                    4926.239793036449, --, --, --, 159.32764558288181, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 3274.4250105092497, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    137.133047187694, --, --, --, --, --, --, --,\n",
       "                    2428.9619427947273, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 111.96359127375808, --, --, --, --, --, --, --,\n",
       "                    2497.9783027749017, --, 2362.068090413322,\n",
       "                    6890.896757490497, 1655.9646539384337, --, --, --, --,\n",
       "                    --, --, --, --, 4971.387249216191, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 245.64311422557375, --, --, --, --, --,\n",
       "                    5844.002574476549, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --,\n",
       "                    4033.5551972550975, --, 114.96703551039991, --, --, --,\n",
       "                    2891.8912532566237, --, --, --, --, --,\n",
       "                    360.7971691284488, --, --, --, --, --, --, --, --, --,\n",
       "                    489.52412294125753, --, --, --, --, --, --, --, --, --,\n",
       "                    2019.0065708983461, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 184.2585782014767, --,\n",
       "                    199.586377683296, --, --, --, --, --, --,\n",
       "                    1042.2920959797164, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 844.6256543262815, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 4990.909252011707,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    782.5897080133776, --, --, 1294.9622022594042, --, --,\n",
       "                    --, --, --, 508.4982297300196, --, --, --, --, --,\n",
       "                    844.5613559017186, --, --, --, --, --, --, --,\n",
       "                    161.60821691939609, --, --, --, --, --, --, --, --,\n",
       "                    152.6621931999243, --, --, --, --, --, --,\n",
       "                    228.30725366404758, --, 1311.9310127478552, --, --, --,\n",
       "                    --, 282.60408263329464, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    1424.9390375164671, 104.55457967167372, --, --, --, --,\n",
       "                    960.0648711417111, --, 144.73509188167773, --,\n",
       "                    867.4331680136463, --, --, --, --, --, --,\n",
       "                    916.808088606391, --, --, --, --, --, --, --, --,\n",
       "                    141.12133312677497, --, --, --, --, --, --, --,\n",
       "                    359.26891201801095, --, --, --, 166.42313068936446, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 149.904331147628, --, --, --,\n",
       "                    1140.261988806333, --, --, --, --, --, --,\n",
       "                    573.204887498955, 5622.65698277594, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --,\n",
       "                    2232.1989866753925, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 4051.2834515766626, 662.6845697876001, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    851.7663069328822, 326.8526863010516,\n",
       "                    1905.8879309109736, --, --, --, --, --, --, --, --, --,\n",
       "                    396.1688126960533, --, --, --, --, --,\n",
       "                    8879.595379575447, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 816.8098301137882, --, --, --, --, --, --,\n",
       "                    210.12612134175228, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 157.32011808375265, --,\n",
       "                    --, --, 150.1304855228217, --, 9740.67845625319, --,\n",
       "                    --, --, --, --, --, --, 305.1381442750077, --, --, --,\n",
       "                    --, 1165.9513013703906, --, --, --, --, --, --, --, --,\n",
       "                    --, 330.56577672783214, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 3712.282268294319, --, --, --, --,\n",
       "                    --, 5827.437277405556, 7318.20209082838, --, --, --,\n",
       "                    --, --, --, --, --, --, 607.0042628061335,\n",
       "                    1381.0663693169138, --, 1330.6722058194077, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 956.1732840701477, --, --,\n",
       "                    --, --, 5710.462398311651, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    258.41799203029416, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 1273.8833080615482, --, --, --, --,\n",
       "                    8719.56001909118, 207.6131922927399, --,\n",
       "                    1719.0195100634694, --, 578.2452860928365,\n",
       "                    1045.5887108971615, 2579.712142388589, --, --, --, --],\n",
       "              mask=[ True, False,  True,  True, False, False, False, False,\n",
       "                    False,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True, False,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True, False, False,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True, False,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True, False,  True, False,  True, False,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True, False, False, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True, False,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True, False,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True,  True, False,  True, False,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True, False, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False, False, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True, False,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False, False,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True, False, False,  True, False,\n",
       "                     True, False, False, False,  True,  True,  True,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_regressor:ridge_regression:fit_intercept': masked_array(data=[--, 'True', --, --, 'True', 'True', 'True', 'True',\n",
       "                    'True', --, --, --, --, --, 'True', --, --, 'True', --,\n",
       "                    --, 'True', --, --, --, --, --, --, 'True', --, --,\n",
       "                    'True', 'True', --, 'True', --, --, --, --, --, --, --,\n",
       "                    --, --, 'True', --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 'True', --, --, 'True', --, --, --, 'True', --, --,\n",
       "                    --, --, --, 'True', --, --, --, --, 'True', --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 'True', --, --, --,\n",
       "                    'True', --, 'True', --, 'True', --, --, --, 'True', --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 'True', --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, 'True', --, --,\n",
       "                    --, --, --, --, --, 'True', --, --, --, --, --, --, --,\n",
       "                    --, --, --, 'True', --, --, --, --, --, --, --, 'True',\n",
       "                    --, 'True', 'True', 'True', --, --, --, --, --, --, --,\n",
       "                    --, 'True', --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 'True', --, --, --,\n",
       "                    --, --, 'True', --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 'True', --, 'True',\n",
       "                    --, --, --, 'True', --, --, --, --, --, 'True', --, --,\n",
       "                    --, --, --, --, --, --, --, 'True', --, --, --, --, --,\n",
       "                    --, --, --, --, 'True', --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 'True', --, 'True',\n",
       "                    --, --, --, --, --, --, 'True', --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 'True', --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 'True', --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 'True', --, --, 'True',\n",
       "                    --, --, --, --, --, 'True', --, --, --, --, --, 'True',\n",
       "                    --, --, --, --, --, --, --, 'True', --, --, --, --, --,\n",
       "                    --, --, --, 'True', --, --, --, --, --, --, 'True', --,\n",
       "                    'True', --, --, --, --, 'True', --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 'True', 'True', --, --, --, --, 'True', --, 'True',\n",
       "                    --, 'True', --, --, --, --, --, --, 'True', --, --, --,\n",
       "                    --, --, --, --, --, 'True', --, --, --, --, --, --, --,\n",
       "                    'True', --, --, --, 'True', --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, 'True', --, --,\n",
       "                    --, 'True', --, --, --, --, --, --, 'True', 'True', --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    'True', --, --, --, --, --, --, --, --, --, --, 'True',\n",
       "                    'True', --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 'True', 'True', 'True', --, --, --, --,\n",
       "                    --, --, --, --, --, 'True', --, --, --, --, --, 'True',\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, 'True',\n",
       "                    --, --, --, --, --, --, 'True', --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, 'True', --,\n",
       "                    --, --, 'True', --, 'True', --, --, --, --, --, --, --,\n",
       "                    'True', --, --, --, --, 'True', --, --, --, --, --, --,\n",
       "                    --, --, --, 'True', --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 'True', --, --, --, --, --, 'True',\n",
       "                    'True', --, --, --, --, --, --, --, --, --, 'True',\n",
       "                    'True', --, 'True', --, --, --, --, --, --, --, --, --,\n",
       "                    --, 'True', --, --, --, --, 'True', --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    'True', --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 'True', --, --, --, --, 'True', 'True', --, 'True',\n",
       "                    --, 'True', 'True', 'True', --, --, --, --],\n",
       "              mask=[ True, False,  True,  True, False, False, False, False,\n",
       "                    False,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True, False,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True, False, False,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True, False,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True, False,  True, False,  True, False,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True, False, False, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True, False,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True, False,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True,  True, False,  True, False,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True, False, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False, False, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True, False,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False, False,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True, False, False,  True, False,\n",
       "                     True, False, False, False,  True,  True,  True,  True],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U32'),\n",
       " 'param_regressor:ridge_regression:tol': masked_array(data=[--, 8.350228451576657e-05, --, --,\n",
       "                    2.0946013955443033e-06, 5.252842350951952e-06,\n",
       "                    8.254938687894747e-05, 3.410730962937692e-05,\n",
       "                    4.1644432614591594e-07, --, --, --, --, --,\n",
       "                    3.033234603257519e-07, --, --, 4.152884927148613e-06,\n",
       "                    --, --, 4.008953772397296e-06, --, --, --, --, --, --,\n",
       "                    1.6998287886973953e-05, --, --, 9.152420329446992e-07,\n",
       "                    2.3865399053543293e-07, --, 1.4064507728075262e-06, --,\n",
       "                    --, --, --, --, --, --, --, --, 5.02820100935429e-07,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    3.597585057849383e-05, --, --, 6.222361479591972e-05,\n",
       "                    --, --, --, 2.3309023039977313e-07, --, --, --, --, --,\n",
       "                    1.4588763563386215e-05, --, --, --, --,\n",
       "                    1.0529735570763943e-05, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 8.647440038949547e-05, --, --, --,\n",
       "                    1.614428946992549e-06, --, 2.2964188398190233e-05, --,\n",
       "                    4.2889960027861224e-06, --, --, --,\n",
       "                    1.363093741531062e-07, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 5.772340527903332e-07,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 1.7246846099630385e-07, --,\n",
       "                    --, --, --, --, --, --, 7.424163333155804e-06, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 3.6186467979736135e-05,\n",
       "                    --, --, --, --, --, --, --, 2.694770119011952e-05, --,\n",
       "                    1.3215892368670988e-06, 4.623820818163569e-05,\n",
       "                    5.613153914486779e-06, --, --, --, --, --, --, --, --,\n",
       "                    9.430935935002632e-06, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    3.813550411304487e-05, --, --, --, --, --,\n",
       "                    1.5242231978076232e-06, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    5.186559866196402e-07, --, 2.8840370949989165e-06, --,\n",
       "                    --, --, 3.215920568676646e-05, --, --, --, --, --,\n",
       "                    1.1465466365904057e-05, --, --, --, --, --, --, --, --,\n",
       "                    --, 3.278394403811397e-05, --, --, --, --, --, --, --,\n",
       "                    --, --, 3.856404664779095e-06, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    6.916856028345069e-07, --, 2.0286301547086203e-07, --,\n",
       "                    --, --, --, --, --, 5.3883436479428155e-05, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    1.658048117118359e-06, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 3.432643954131498e-05, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 3.0128734232620158e-05, --,\n",
       "                    --, 5.480775989038313e-07, --, --, --, --, --,\n",
       "                    3.8088901515802023e-06, --, --, --, --, --,\n",
       "                    7.098661839784815e-05, --, --, --, --, --, --, --,\n",
       "                    8.980466030863952e-07, --, --, --, --, --, --, --, --,\n",
       "                    4.601521183474215e-06, --, --, --, --, --, --,\n",
       "                    7.389643154429484e-05, --, 1.886481815695251e-07, --,\n",
       "                    --, --, --, 6.505594324130389e-05, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 2.3991176556368542e-06, 1.844200675625974e-05,\n",
       "                    --, --, --, --, 9.281298111227914e-07, --,\n",
       "                    5.0269072431162524e-05, --, 3.474624777203255e-05, --,\n",
       "                    --, --, --, --, --, 4.173582626121861e-07, --, --, --,\n",
       "                    --, --, --, --, --, 4.859700990911062e-05, --, --, --,\n",
       "                    --, --, --, --, 3.9453657269562633e-07, --, --, --,\n",
       "                    1.0052410477086568e-06, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --,\n",
       "                    3.1061768547376794e-06, --, --, --,\n",
       "                    4.23449692061904e-06, --, --, --, --, --, --,\n",
       "                    2.646001201702952e-07, 3.807167203864494e-06, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    9.986288554021866e-05, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 3.700485454006754e-05, 4.861366586129698e-05,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 2.2543866863656948e-06, 5.705489022615904e-05,\n",
       "                    2.6213061701125662e-05, --, --, --, --, --, --, --, --,\n",
       "                    --, 1.3837588509465938e-06, --, --, --, --, --,\n",
       "                    9.349119476441584e-07, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 4.7425933216451976e-07, --, --, --, --,\n",
       "                    --, --, 6.924583804438802e-06, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    2.091563625361077e-06, --, --, --,\n",
       "                    2.967291986690146e-07, --, 9.363735456979302e-06, --,\n",
       "                    --, --, --, --, --, --, 7.427877469158044e-07, --, --,\n",
       "                    --, --, 5.088808495610496e-07, --, --, --, --, --, --,\n",
       "                    --, --, --, 7.118162510607255e-06, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 4.57324082613091e-06,\n",
       "                    --, --, --, --, --, 1.7080863088396815e-07,\n",
       "                    3.199868314800029e-05, --, --, --, --, --, --, --, --,\n",
       "                    --, 5.118607061329419e-06, 6.0843277102022e-05, --,\n",
       "                    1.785420079006316e-05, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 2.388373616615307e-07, --, --, --, --,\n",
       "                    6.16876525521695e-05, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    3.5982345483844743e-06, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 2.0527377843267733e-05, --, --, --,\n",
       "                    --, 2.597079295986103e-06, 2.830806149114666e-05, --,\n",
       "                    1.0349749299742484e-07, --, 1.4017850503912311e-05,\n",
       "                    7.429124269442793e-05, 2.335511570780284e-05, --, --,\n",
       "                    --, --],\n",
       "              mask=[ True, False,  True,  True, False, False, False, False,\n",
       "                    False,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True, False,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True, False, False,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True, False,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True, False,  True, False,  True, False,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True, False, False, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True, False,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True, False,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True,  True, False,  True, False,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True, False, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False, False, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True, False,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False, False,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True, False, False,  True, False,\n",
       "                     True, False, False, False,  True,  True,  True,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_feature_preprocessor:fast_ica:n_components': masked_array(data=[--, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 12.0, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    971.0, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 55.0, --, --, --, 1735.0, --, --, --,\n",
       "                    511.0, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 565.0, --, 1550.0, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, 1066.0, --,\n",
       "                    --, --, --, --, --, --, --, 1477.0, 173.0, 1678.0, --,\n",
       "                    1783.0, 274.0, --, --, --, --, 207.0, --, 1427.0,\n",
       "                    1284.0, --, --, --, --, --, 1514.0, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, 859.0, --, --,\n",
       "                    --, 193.0, --, --, --, 1444.0, --, 1608.0, 1609.0,\n",
       "                    1156.0, 1908.0, --, --, --, --, --, 1658.0, --, 1284.0,\n",
       "                    --, --, --, 1308.0, --, --, --, 834.0, --, --, --,\n",
       "                    1326.0, --, --, --, --, --, --, 941.0, --, --, --, --,\n",
       "                    --, --, --, --, 76.0, --, 1555.0, --, --, --, --, --,\n",
       "                    --, --, 127.0, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 1278.0, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 298.0, --, --, --, --, --, --, --,\n",
       "                    100.0, --, --, --, --, --, 170.0, 676.0, 945.0, --, --,\n",
       "                    --, --, --, --, --, 526.0, 397.0, --, 1306.0, --,\n",
       "                    1077.0, --, 1303.0, --, 1660.0, 588.0, --, --, --, --,\n",
       "                    --, --, 1570.0, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 1957.0, --, --, --, --, 1884.0,\n",
       "                    --, --, 802.0, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 100.0, --, --, --, 225.0, --, --, --, 1797.0,\n",
       "                    --, 1825.0, --, --, --, --, --, 960.0, 354.0, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    1666.0, --, --, --, --, --, --, --, --, --, 1340.0, --,\n",
       "                    --, 65.0, 1559.0, --, --, 1271.0, 1236.0, 579.0, 286.0,\n",
       "                    152.0, --, --, --, --, --, --, 1170.0, --, --, --, --,\n",
       "                    --, 384.0, 10.0, --, --, --, --, --, --, 410.0, --,\n",
       "                    772.0, --, 170.0, --, --, --, 1033.0, --, --, --, --,\n",
       "                    152.0, 1617.0, --, --, --, 1980.0, 860.0, --, --, --,\n",
       "                    --, --, 93.0, --, --, --, --, --, --, --, 292.0, --,\n",
       "                    --, 199.0, 514.0, --, --, --, 1775.0, --, --, 203.0,\n",
       "                    --, --, --, 24.0, --, --, --, --, 1754.0, --, 36.0, --,\n",
       "                    31.0, 95.0, --, 941.0, --, 40.0, --, 42.0, 43.0, --,\n",
       "                    --, --, 159.0, --, --, --, --, 153.0, 20.0, --, --, --,\n",
       "                    1014.0, --, 36.0, --, --, --, --, --, --, 100.0, --,\n",
       "                    1608.0, --, 1196.0, --, --, 450.0, --, 62.0, 266.0,\n",
       "                    100.0, 249.0, 66.0, --, --, 1911.0, 1840.0, --, --,\n",
       "                    1660.0, --, 1337.0, --, 121.0, --, --, 484.0, 1307.0,\n",
       "                    --, --, 69.0, 77.0, --, 164.0, 1998.0, 259.0, 146.0,\n",
       "                    --, --, 157.0, 665.0, --, --, 215.0, --, 290.0, --,\n",
       "                    401.0, 525.0, 154.0, --, 338.0, --, --, --, --, --,\n",
       "                    736.0, --, --, --, --, 1080.0, 205.0, 1307.0, --, --,\n",
       "                    --, --, --, 226.0, --, --, --, --, --, 1188.0, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 426.0, --, --, --, --, --, --, --, --, 1186.0, --,\n",
       "                    --, 165.0, --, --, --, --, --, 294.0, --, 430.0, --,\n",
       "                    1577.0, --, --, --, --, --, --, --, 601.0, 82.0, --,\n",
       "                    --, --, --, --, --, --, --, 152.0, --, 33.0, --, --,\n",
       "                    1882.0, --, --, --, --, --, --, --, --, 149.0, 20.0,\n",
       "                    --, --, 504.0, 1327.0, 455.0, --, 154.0, --, --, --,\n",
       "                    276.0, --, --, --, --, --, 116.0, 1512.0, 704.0, --,\n",
       "                    --, --, --, --, --, --, 68.0, --, 116.0, --, 1275.0,\n",
       "                    597.0, --, 82.0, --, 160.0, --, 382.0, --, 145.0,\n",
       "                    165.0, --, 26.0, --, 11.0, 358.0, 92.0, 239.0, 244.0,\n",
       "                    --, 29.0, 601.0, 601.0, 260.0, --, 121.0, 272.0, --,\n",
       "                    --, --, --, --, 260.0, 100.0, 480.0, 1042.0, --, 209.0,\n",
       "                    --, --, --, --, 224.0, --, --, --, 100.0, 219.0, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 36.0, 563.0, --,\n",
       "                    --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True, False,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False, False, False,  True, False, False,  True,  True,\n",
       "                     True,  True, False,  True, False, False,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True, False,\n",
       "                     True,  True,  True, False,  True, False, False, False,\n",
       "                    False,  True,  True,  True,  True,  True, False,  True,\n",
       "                    False,  True,  True,  True, False,  True,  True,  True,\n",
       "                    False,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True, False, False, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False, False,  True, False,  True,\n",
       "                    False,  True, False,  True, False, False,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True, False,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True, False,  True,\n",
       "                     True,  True, False,  True, False,  True,  True,  True,\n",
       "                     True,  True, False, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                    False, False,  True,  True, False, False, False, False,\n",
       "                    False,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True, False, False,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True, False,\n",
       "                     True, False,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True, False, False,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True, False, False,  True,  True,  True, False,  True,\n",
       "                     True, False,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True, False,  True, False,  True, False, False,\n",
       "                     True, False,  True, False,  True, False, False,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True, False,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True, False,\n",
       "                     True, False,  True,  True, False,  True, False, False,\n",
       "                    False, False, False,  True,  True, False, False,  True,\n",
       "                     True, False,  True, False,  True, False,  True,  True,\n",
       "                    False, False,  True,  True, False, False,  True, False,\n",
       "                    False, False, False,  True,  True, False, False,  True,\n",
       "                     True, False,  True, False,  True, False, False, False,\n",
       "                     True, False,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True, False, False, False,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True, False,  True,\n",
       "                    False,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True, False,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False, False,  True,  True, False, False,\n",
       "                    False,  True, False,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True, False, False, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                    False,  True, False, False,  True, False,  True, False,\n",
       "                     True, False,  True, False, False,  True, False,  True,\n",
       "                    False, False, False, False, False,  True, False, False,\n",
       "                    False, False,  True, False, False,  True,  True,  True,\n",
       "                     True,  True, False, False, False, False,  True, False,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                    False, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False, False,  True,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_feature_preprocessor:kernel_pca:coef0': masked_array(data=[--, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 0.10480631736353785, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 0.6331171932872737, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 0.9603247074362007, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    0.538444404057747, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_feature_preprocessor:kernel_pca:degree': masked_array(data=[--, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 5.0, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 3.0, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    4.0, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_feature_preprocessor:kernel_pca:gamma': masked_array(data=[--, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 0.342770773052593, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 0.08498747147500653, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --,\n",
       "                    0.2028330668617213, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 1.4764653976914917, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 0.029405498020987582, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 1.3835004231842587, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_feature_preprocessor:nystroem_sampler:coef0': masked_array(data=[--, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, -0.3032067704870627, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_feature_preprocessor:nystroem_sampler:degree': masked_array(data=[--, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20,\n",
       "             dtype=float64),\n",
       " 'param_feature_preprocessor:nystroem_sampler:gamma': masked_array(data=[--, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 6.492052790300398e-05, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 3.696700406797084e-05, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_tf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.2, SimpleRegressionPipeline({'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding', 'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer', 'data_preprocessing:numerical_transformer:imputation:strategy': 'mean', 'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize', 'feature_preprocessor:__choice__': 'pca', 'regressor:__choice__': 'decision_tree', 'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.15106317403639516, 'feature_preprocessor:pca:keep_variance': 0.5660771291590012, 'feature_preprocessor:pca:whiten': 'True', 'regressor:decision_tree:criterion': 'mae', 'regressor:decision_tree:max_depth_factor': 0.6095050686448309, 'regressor:decision_tree:max_features': 1.0, 'regressor:decision_tree:max_leaf_nodes': 'None', 'regressor:decision_tree:min_impurity_decrease': 0.0, 'regressor:decision_tree:min_samples_leaf': 4, 'regressor:decision_tree:min_samples_split': 3, 'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
      "dataset_properties={\n",
      "  'task': 5,\n",
      "  'sparse': False,\n",
      "  'multioutput': True,\n",
      "  'target_type': 'regression',\n",
      "  'signed': False})), (0.14, SimpleRegressionPipeline({'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding', 'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense', 'data_preprocessing:numerical_transformer:imputation:strategy': 'mean', 'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer', 'feature_preprocessor:__choice__': 'pca', 'regressor:__choice__': 'decision_tree', 'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 792, 'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'normal', 'feature_preprocessor:pca:keep_variance': 0.5150397929969202, 'feature_preprocessor:pca:whiten': 'False', 'regressor:decision_tree:criterion': 'mae', 'regressor:decision_tree:max_depth_factor': 0.30043377411209327, 'regressor:decision_tree:max_features': 1.0, 'regressor:decision_tree:max_leaf_nodes': 'None', 'regressor:decision_tree:min_impurity_decrease': 0.0, 'regressor:decision_tree:min_samples_leaf': 2, 'regressor:decision_tree:min_samples_split': 13, 'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
      "dataset_properties={\n",
      "  'task': 5,\n",
      "  'sparse': False,\n",
      "  'multioutput': True,\n",
      "  'target_type': 'regression',\n",
      "  'signed': False})), (0.12, SimpleRegressionPipeline({'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding', 'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer', 'data_preprocessing:numerical_transformer:imputation:strategy': 'mean', 'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none', 'feature_preprocessor:__choice__': 'no_preprocessing', 'regressor:__choice__': 'decision_tree', 'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.12166657203197262, 'regressor:decision_tree:criterion': 'mae', 'regressor:decision_tree:max_depth_factor': 0.7305809724585708, 'regressor:decision_tree:max_features': 1.0, 'regressor:decision_tree:max_leaf_nodes': 'None', 'regressor:decision_tree:min_impurity_decrease': 0.0, 'regressor:decision_tree:min_samples_leaf': 3, 'regressor:decision_tree:min_samples_split': 13, 'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
      "dataset_properties={\n",
      "  'task': 5,\n",
      "  'sparse': False,\n",
      "  'multioutput': True,\n",
      "  'target_type': 'regression',\n",
      "  'signed': False})), (0.1, SimpleRegressionPipeline({'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding', 'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense', 'data_preprocessing:numerical_transformer:imputation:strategy': 'mean', 'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler', 'feature_preprocessor:__choice__': 'fast_ica', 'regressor:__choice__': 'decision_tree', 'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.7190818190512768, 'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.25620704804486827, 'feature_preprocessor:fast_ica:algorithm': 'deflation', 'feature_preprocessor:fast_ica:fun': 'logcosh', 'feature_preprocessor:fast_ica:whiten': 'True', 'regressor:decision_tree:criterion': 'friedman_mse', 'regressor:decision_tree:max_depth_factor': 0.014040162423953251, 'regressor:decision_tree:max_features': 1.0, 'regressor:decision_tree:max_leaf_nodes': 'None', 'regressor:decision_tree:min_impurity_decrease': 0.0, 'regressor:decision_tree:min_samples_leaf': 6, 'regressor:decision_tree:min_samples_split': 13, 'regressor:decision_tree:min_weight_fraction_leaf': 0.0, 'feature_preprocessor:fast_ica:n_components': 601},\n",
      "dataset_properties={\n",
      "  'task': 5,\n",
      "  'sparse': False,\n",
      "  'multioutput': True,\n",
      "  'target_type': 'regression',\n",
      "  'signed': False})), (0.08, SimpleRegressionPipeline({'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding', 'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense', 'data_preprocessing:numerical_transformer:imputation:strategy': 'median', 'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler', 'feature_preprocessor:__choice__': 'fast_ica', 'regressor:__choice__': 'decision_tree', 'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.7360149811711411, 'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.2522095207581007, 'feature_preprocessor:fast_ica:algorithm': 'deflation', 'feature_preprocessor:fast_ica:fun': 'logcosh', 'feature_preprocessor:fast_ica:whiten': 'True', 'regressor:decision_tree:criterion': 'friedman_mse', 'regressor:decision_tree:max_depth_factor': 0.014040162423953251, 'regressor:decision_tree:max_features': 1.0, 'regressor:decision_tree:max_leaf_nodes': 'None', 'regressor:decision_tree:min_impurity_decrease': 0.0, 'regressor:decision_tree:min_samples_leaf': 6, 'regressor:decision_tree:min_samples_split': 2, 'regressor:decision_tree:min_weight_fraction_leaf': 0.0, 'feature_preprocessor:fast_ica:n_components': 563},\n",
      "dataset_properties={\n",
      "  'task': 5,\n",
      "  'sparse': False,\n",
      "  'multioutput': True,\n",
      "  'target_type': 'regression',\n",
      "  'signed': False})), (0.06, SimpleRegressionPipeline({'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding', 'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer', 'data_preprocessing:numerical_transformer:imputation:strategy': 'median', 'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler', 'feature_preprocessor:__choice__': 'fast_ica', 'regressor:__choice__': 'decision_tree', 'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.012353485693373037, 'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.7395519899017703, 'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.21840286321120986, 'feature_preprocessor:fast_ica:algorithm': 'deflation', 'feature_preprocessor:fast_ica:fun': 'logcosh', 'feature_preprocessor:fast_ica:whiten': 'True', 'regressor:decision_tree:criterion': 'friedman_mse', 'regressor:decision_tree:max_depth_factor': 0.00887780879253533, 'regressor:decision_tree:max_features': 1.0, 'regressor:decision_tree:max_leaf_nodes': 'None', 'regressor:decision_tree:min_impurity_decrease': 0.0, 'regressor:decision_tree:min_samples_leaf': 6, 'regressor:decision_tree:min_samples_split': 13, 'regressor:decision_tree:min_weight_fraction_leaf': 0.0, 'feature_preprocessor:fast_ica:n_components': 11},\n",
      "dataset_properties={\n",
      "  'task': 5,\n",
      "  'sparse': False,\n",
      "  'multioutput': True,\n",
      "  'target_type': 'regression',\n",
      "  'signed': False})), (0.06, SimpleRegressionPipeline({'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding', 'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense', 'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent', 'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler', 'feature_preprocessor:__choice__': 'fast_ica', 'regressor:__choice__': 'decision_tree', 'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.75, 'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.29318414921294567, 'feature_preprocessor:fast_ica:algorithm': 'deflation', 'feature_preprocessor:fast_ica:fun': 'logcosh', 'feature_preprocessor:fast_ica:whiten': 'True', 'regressor:decision_tree:criterion': 'mse', 'regressor:decision_tree:max_depth_factor': 0.27597760286275197, 'regressor:decision_tree:max_features': 1.0, 'regressor:decision_tree:max_leaf_nodes': 'None', 'regressor:decision_tree:min_impurity_decrease': 0.0, 'regressor:decision_tree:min_samples_leaf': 6, 'regressor:decision_tree:min_samples_split': 13, 'regressor:decision_tree:min_weight_fraction_leaf': 0.0, 'feature_preprocessor:fast_ica:n_components': 358},\n",
      "dataset_properties={\n",
      "  'task': 5,\n",
      "  'sparse': False,\n",
      "  'multioutput': True,\n",
      "  'target_type': 'regression',\n",
      "  'signed': False})), (0.06, SimpleRegressionPipeline({'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding', 'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer', 'data_preprocessing:numerical_transformer:imputation:strategy': 'mean', 'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize', 'feature_preprocessor:__choice__': 'fast_ica', 'regressor:__choice__': 'decision_tree', 'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.008464172832296692, 'feature_preprocessor:fast_ica:algorithm': 'deflation', 'feature_preprocessor:fast_ica:fun': 'logcosh', 'feature_preprocessor:fast_ica:whiten': 'True', 'regressor:decision_tree:criterion': 'friedman_mse', 'regressor:decision_tree:max_depth_factor': 0.43009879865610634, 'regressor:decision_tree:max_features': 1.0, 'regressor:decision_tree:max_leaf_nodes': 'None', 'regressor:decision_tree:min_impurity_decrease': 0.0, 'regressor:decision_tree:min_samples_leaf': 6, 'regressor:decision_tree:min_samples_split': 13, 'regressor:decision_tree:min_weight_fraction_leaf': 0.0, 'feature_preprocessor:fast_ica:n_components': 239},\n",
      "dataset_properties={\n",
      "  'task': 5,\n",
      "  'sparse': False,\n",
      "  'multioutput': True,\n",
      "  'target_type': 'regression',\n",
      "  'signed': False})), (0.04, SimpleRegressionPipeline({'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding', 'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer', 'data_preprocessing:numerical_transformer:imputation:strategy': 'median', 'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler', 'feature_preprocessor:__choice__': 'fast_ica', 'regressor:__choice__': 'decision_tree', 'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.012969796256549726, 'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.7579859599648943, 'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.25, 'feature_preprocessor:fast_ica:algorithm': 'deflation', 'feature_preprocessor:fast_ica:fun': 'logcosh', 'feature_preprocessor:fast_ica:whiten': 'True', 'regressor:decision_tree:criterion': 'mse', 'regressor:decision_tree:max_depth_factor': 0.31865307212780547, 'regressor:decision_tree:max_features': 1.0, 'regressor:decision_tree:max_leaf_nodes': 'None', 'regressor:decision_tree:min_impurity_decrease': 0.0, 'regressor:decision_tree:min_samples_leaf': 6, 'regressor:decision_tree:min_samples_split': 13, 'regressor:decision_tree:min_weight_fraction_leaf': 0.0, 'feature_preprocessor:fast_ica:n_components': 121},\n",
      "dataset_properties={\n",
      "  'task': 5,\n",
      "  'sparse': False,\n",
      "  'multioutput': True,\n",
      "  'target_type': 'regression',\n",
      "  'signed': False})), (0.04, SimpleRegressionPipeline({'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding', 'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer', 'data_preprocessing:numerical_transformer:imputation:strategy': 'median', 'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize', 'feature_preprocessor:__choice__': 'fast_ica', 'regressor:__choice__': 'decision_tree', 'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.006496772904799362, 'feature_preprocessor:fast_ica:algorithm': 'deflation', 'feature_preprocessor:fast_ica:fun': 'logcosh', 'feature_preprocessor:fast_ica:whiten': 'True', 'regressor:decision_tree:criterion': 'friedman_mse', 'regressor:decision_tree:max_depth_factor': 0.32050011710501625, 'regressor:decision_tree:max_features': 1.0, 'regressor:decision_tree:max_leaf_nodes': 'None', 'regressor:decision_tree:min_impurity_decrease': 0.0, 'regressor:decision_tree:min_samples_leaf': 6, 'regressor:decision_tree:min_samples_split': 13, 'regressor:decision_tree:min_weight_fraction_leaf': 0.0, 'feature_preprocessor:fast_ica:n_components': 33},\n",
      "dataset_properties={\n",
      "  'task': 5,\n",
      "  'sparse': False,\n",
      "  'multioutput': True,\n",
      "  'target_type': 'regression',\n",
      "  'signed': False})), (0.04, SimpleRegressionPipeline({'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding', 'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense', 'data_preprocessing:numerical_transformer:imputation:strategy': 'mean', 'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize', 'feature_preprocessor:__choice__': 'fast_ica', 'regressor:__choice__': 'decision_tree', 'feature_preprocessor:fast_ica:algorithm': 'deflation', 'feature_preprocessor:fast_ica:fun': 'logcosh', 'feature_preprocessor:fast_ica:whiten': 'True', 'regressor:decision_tree:criterion': 'friedman_mse', 'regressor:decision_tree:max_depth_factor': 0.30815087435987, 'regressor:decision_tree:max_features': 1.0, 'regressor:decision_tree:max_leaf_nodes': 'None', 'regressor:decision_tree:min_impurity_decrease': 0.0, 'regressor:decision_tree:min_samples_leaf': 6, 'regressor:decision_tree:min_samples_split': 13, 'regressor:decision_tree:min_weight_fraction_leaf': 0.0, 'feature_preprocessor:fast_ica:n_components': 244},\n",
      "dataset_properties={\n",
      "  'task': 5,\n",
      "  'sparse': False,\n",
      "  'multioutput': True,\n",
      "  'target_type': 'regression',\n",
      "  'signed': False})), (0.02, SimpleRegressionPipeline({'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding', 'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer', 'data_preprocessing:numerical_transformer:imputation:strategy': 'median', 'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize', 'feature_preprocessor:__choice__': 'fast_ica', 'regressor:__choice__': 'decision_tree', 'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.012104360763673319, 'feature_preprocessor:fast_ica:algorithm': 'deflation', 'feature_preprocessor:fast_ica:fun': 'logcosh', 'feature_preprocessor:fast_ica:whiten': 'True', 'regressor:decision_tree:criterion': 'friedman_mse', 'regressor:decision_tree:max_depth_factor': 0.2760884242071161, 'regressor:decision_tree:max_features': 1.0, 'regressor:decision_tree:max_leaf_nodes': 'None', 'regressor:decision_tree:min_impurity_decrease': 0.0, 'regressor:decision_tree:min_samples_leaf': 6, 'regressor:decision_tree:min_samples_split': 13, 'regressor:decision_tree:min_weight_fraction_leaf': 0.0, 'feature_preprocessor:fast_ica:n_components': 68},\n",
      "dataset_properties={\n",
      "  'task': 5,\n",
      "  'sparse': False,\n",
      "  'multioutput': True,\n",
      "  'target_type': 'regression',\n",
      "  'signed': False})), (0.02, SimpleRegressionPipeline({'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding', 'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer', 'data_preprocessing:numerical_transformer:imputation:strategy': 'median', 'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler', 'feature_preprocessor:__choice__': 'fast_ica', 'regressor:__choice__': 'decision_tree', 'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.013804434275468664, 'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.7484657809567563, 'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.19729830160438497, 'feature_preprocessor:fast_ica:algorithm': 'deflation', 'feature_preprocessor:fast_ica:fun': 'logcosh', 'feature_preprocessor:fast_ica:whiten': 'True', 'regressor:decision_tree:criterion': 'mse', 'regressor:decision_tree:max_depth_factor': 0.307778845149439, 'regressor:decision_tree:max_features': 1.0, 'regressor:decision_tree:max_leaf_nodes': 'None', 'regressor:decision_tree:min_impurity_decrease': 0.0, 'regressor:decision_tree:min_samples_leaf': 6, 'regressor:decision_tree:min_samples_split': 13, 'regressor:decision_tree:min_weight_fraction_leaf': 0.0, 'feature_preprocessor:fast_ica:n_components': 29},\n",
      "dataset_properties={\n",
      "  'task': 5,\n",
      "  'sparse': False,\n",
      "  'multioutput': True,\n",
      "  'target_type': 'regression',\n",
      "  'signed': False})), (0.02, SimpleRegressionPipeline({'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding', 'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense', 'data_preprocessing:numerical_transformer:imputation:strategy': 'median', 'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler', 'feature_preprocessor:__choice__': 'fast_ica', 'regressor:__choice__': 'decision_tree', 'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.7334909115371182, 'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.2484969422715976, 'feature_preprocessor:fast_ica:algorithm': 'deflation', 'feature_preprocessor:fast_ica:fun': 'logcosh', 'feature_preprocessor:fast_ica:whiten': 'True', 'regressor:decision_tree:criterion': 'friedman_mse', 'regressor:decision_tree:max_depth_factor': 0.31499046358670085, 'regressor:decision_tree:max_features': 1.0, 'regressor:decision_tree:max_leaf_nodes': 'None', 'regressor:decision_tree:min_impurity_decrease': 0.0, 'regressor:decision_tree:min_samples_leaf': 6, 'regressor:decision_tree:min_samples_split': 13, 'regressor:decision_tree:min_weight_fraction_leaf': 0.0, 'feature_preprocessor:fast_ica:n_components': 100},\n",
      "dataset_properties={\n",
      "  'task': 5,\n",
      "  'sparse': False,\n",
      "  'multioutput': True,\n",
      "  'target_type': 'regression',\n",
      "  'signed': False}))]\n",
      "auto-sklearn results:\n",
      "  Dataset name: af930ff75920e8865ec6c07a561b36d5\n",
      "  Metric: r2\n",
      "  Best validation score: -0.040391\n",
      "  Number of target algorithm runs: 760\n",
      "  Number of successful target algorithm runs: 434\n",
      "  Number of crashed target algorithm runs: 326\n",
      "  Number of target algorithms that exceeded the time limit: 0\n",
      "  Number of target algorithms that exceeded the memory limit: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(reg_tf.get_models_with_weights())\n",
    "print(reg_tf.sprint_statistics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/anaconda3/envs/autoskdev/lib/python3.7/site-packages/sklearn/base.py:197: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AutoSklearnRegressor(delete_output_folder_after_terminate=False,\n",
       "                     delete_tmp_folder_after_terminate=False,\n",
       "                     disable_evaluator_output=False, ensemble_memory_limit=5120,\n",
       "                     ensemble_nbest=20, ensemble_size=50,\n",
       "                     exclude_estimators=None, exclude_preprocessors=None,\n",
       "                     get_smac_object_callback=None, include_estimators=None,\n",
       "                     include_preprocessors=None,\n",
       "                     initial_configuration...\n",
       "                     logging_config=None, max_models_on_disc=50,\n",
       "                     metadata_directory=None, metric=None, ml_memory_limit=6144,\n",
       "                     n_jobs=6, output_folder='out5313', per_run_time_limit=600,\n",
       "                     resampling_strategy=<class 'sklearn.model_selection._split.TimeSeriesSplit'>,\n",
       "                     resampling_strategy_arguments={'folds': 5}, seed=123,\n",
       "                     shared_mode=False, smac_scenario_args=None,\n",
       "                     time_left_for_this_task=6000, tmp_folder='tmp5313')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_tf.refit(ftrain_tf, ttrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 551796.6778278005\n",
      "MAE: 283.93971994401556\n",
      "r2_score: 0.39711524788214864\n",
      "MSE: 285767.04502082994\n",
      "MAE: 240.56785462065895\n",
      "r2_score: 0.5476141499744366\n"
     ]
    }
   ],
   "source": [
    "ypred_tf = reg_tf.predict(ftest_tf)\n",
    "yhat_tf = reg_tf.predict(ftrain_tf)\n",
    "get_eval(ttest, ypred_tf)\n",
    "get_eval(ttrain, yhat_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f2ef543f650>]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2tf_list_test = []\n",
    "for i in range(500):\n",
    "    o_y = np.transpose(ttest.iloc[i,:].to_numpy().reshape(1,-1))\n",
    "    p_y = np.transpose(ypred_tf[i,:].reshape(1,-1))\n",
    "    r2 = r2_score(o_y, p_y)\n",
    "    r2tf_list_test.append(r2)\n",
    "fig = plt.figure(figsize = (16, 7))\n",
    "plt.ylim(-0.5,0.9)\n",
    "plt.plot(r2tf_list_test, 'b-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Confidecne interval**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**random sampling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "n_bootstraps = 50\n",
    "b_x = []\n",
    "b_y = []\n",
    "for _ in range(n_bootstraps):\n",
    "    sample_X, sample_y = resample(ftrain_tf, ttrain, n_samples = 2500)\n",
    "    b_x.append(sample_X)\n",
    "    b_y.append(sample_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = []\n",
    "\n",
    "for i, feature in enumerate(b_x):\n",
    "    reg_tf.refit(feature, b_y[i])\n",
    "    prediction.append(reg_tf.predict(ftest_tf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_eval(ttest, np.quantile(prediction, 0.5, axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (15,7))\n",
    "plt.plot(np.quantile(prediction, 0.9, axis = 0)[0,:], 'g--')\n",
    "plt.plot(np.quantile(prediction, 0.1, axis = 0)[0,:], 'g--')\n",
    "plt.plot(np.quantile(prediction, 0.5, axis = 0)[0,:], 'b-')\n",
    "plt.plot(ttest.to_numpy()[0,:], 'ro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fix time frame randomized rolling sampling- should change to backtesting later**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedKFold, KFold\n",
    "n_bootstraps = 50\n",
    "b_x = []\n",
    "b_y = []\n",
    "kfcv = KFold(n_splits = 3, random_state = None)\n",
    "for train_idx, test_idx in kfcv.split(ftrain_tf):\n",
    "    print(len(train_idx))\n",
    "# for _ in range(n_bootstraps):\n",
    "    sample_X, sample_y = ftrain_tf.to_numpy()[train_idx,], ttrain.to_numpy()[train_idx,]\n",
    "    b_x.append(sample_X)\n",
    "    b_y.append(sample_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = []\n",
    "\n",
    "for i, feature in enumerate(b_x):\n",
    "    reg_tf.refit(feature, b_y[i])\n",
    "    prediction.append(reg_tf.predict(ftest_tf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_eval(ttest, np.quantile(prediction, 0.5, axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (15,7))\n",
    "plt.plot(np.quantile(prediction, 0.95, axis = 0)[100,:], 'g--')\n",
    "plt.plot(np.quantile(prediction, 0.05, axis = 0)[100,:], 'g--')\n",
    "plt.plot(np.quantile(prediction, 0.5, axis = 0)[100,:], 'b-')\n",
    "plt.plot(ttest.to_numpy()[100,:], 'ro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] [2020-07-15 01:45:35,021:AutoMLSMBO(478162242)::a3afddb7f63baf6b400604ed9c94ef52] Could not find meta-data directory /home/charles/anaconda3/envs/autosk07/lib/python3.7/site-packages/autosklearn/metalearning/files/r2_multioutput.regression_dense\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process pynisher function call:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/charles/anaconda3/envs/autosk07/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/charles/anaconda3/envs/autosk07/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/charles/anaconda3/envs/autosk07/lib/python3.7/site-packages/pynisher/limit_function_call.py\", line 93, in subprocess_func\n",
      "    return_value = ((func(*args, **kwargs), 0))\n",
      "  File \"/home/charles/anaconda3/envs/autosk07/lib/python3.7/site-packages/autosklearn/ensemble_builder.py\", line 331, in main\n",
      "    time.sleep(self.sleep_duration)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-8fd74c33d658>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mftrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mttrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/autosk07/lib/python3.7/site-packages/autosklearn/estimators.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, X_test, y_test, feat_type, dataset_name)\u001b[0m\n\u001b[1;32m    812\u001b[0m             \u001b[0my_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m             \u001b[0mfeat_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeat_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m             \u001b[0mdataset_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m         )\n\u001b[1;32m    816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/autosk07/lib/python3.7/site-packages/autosklearn/estimators.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    432\u001b[0m                 \u001b[0mautoml\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_automl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m                 \u001b[0mload_models\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m             )\n\u001b[1;32m    436\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprocesses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/autosk07/lib/python3.7/site-packages/autosklearn/estimators.py\u001b[0m in \u001b[0;36m_fit_automl\u001b[0;34m(automl, kwargs, load_models)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_fit_automl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mautoml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_models\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mautoml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_models\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mload_models\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/autosk07/lib/python3.7/site-packages/autosklearn/automl.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, X_test, y_test, feat_type, dataset_name, only_return_configuration_space, load_models)\u001b[0m\n\u001b[1;32m   1135\u001b[0m             \u001b[0mdataset_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m             \u001b[0monly_return_configuration_space\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0monly_return_configuration_space\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1137\u001b[0;31m             \u001b[0mload_models\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mload_models\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1138\u001b[0m         )\n\u001b[1;32m   1139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/autosk07/lib/python3.7/site-packages/autosklearn/automl.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, task, X_test, y_test, feat_type, dataset_name, only_return_configuration_space, load_models)\u001b[0m\n\u001b[1;32m    483\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunhistory_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrajectory_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_budget_type\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 485\u001b[0;31m                     \u001b[0m_proc_smac\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_smbo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    486\u001b[0m                 trajectory_filename = os.path.join(\n\u001b[1;32m    487\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_smac_output_directory_for_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_seed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/autosk07/lib/python3.7/site-packages/autosklearn/smbo.py\u001b[0m in \u001b[0;36mrun_smbo\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    471\u001b[0m             \u001b[0msmac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_smac_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0msmac_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m         \u001b[0msmac\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;31m# Patch SMAC to read in data from parallel runs after the last\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/autosk07/lib/python3.7/site-packages/smac/facade/smac_ac_facade.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    565\u001b[0m         \u001b[0mincumbent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m             \u001b[0mincumbent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/autosk07/lib/python3.7/site-packages/smac/optimizer/smbo.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    213\u001b[0m                         \u001b[0mincumbent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mincumbent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m                         \u001b[0mrun_history\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunhistory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m                         time_bound=max(self.intensifier._min_time, time_left))\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mFirstRunCrashedException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/autosk07/lib/python3.7/site-packages/smac/intensification/intensification.py\u001b[0m in \u001b[0;36meval_challenger\u001b[0;34m(self, challenger, incumbent, run_history, time_bound, log_traj)\u001b[0m\n\u001b[1;32m    208\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstage\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mIntensifierStage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRUN_INCUMBENT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;31m# Lines 3-7\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_inc_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mincumbent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mincumbent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_history\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_traj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog_traj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstage\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mIntensifierStage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRUN_CHALLENGER\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstage\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mIntensifierStage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRUN_BASIS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/autosk07/lib/python3.7/site-packages/smac/intensification/intensification.py\u001b[0m in \u001b[0;36m_add_inc_run\u001b[0;34m(self, incumbent, run_history, log_traj)\u001b[0m\n\u001b[1;32m    312\u001b[0m                     \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnext_seed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m                     \u001b[0mcutoff\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcutoff\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m                     instance_specific=self.instance_specifics.get(next_instance, \"0\"))\n\u001b[0m\u001b[1;32m    315\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ta_time\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdur\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/autosk07/lib/python3.7/site-packages/autosklearn/evaluation/__init__.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self, config, instance, cutoff, seed, budget, instance_specific, capped)\u001b[0m\n\u001b[1;32m    211\u001b[0m         return super().start(config=config, instance=instance, cutoff=cutoff,\n\u001b[1;32m    212\u001b[0m                              \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance_specific\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minstance_specific\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m                              capped=capped, budget=budget)\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     def run(self, config, instance=None,\n",
      "\u001b[0;32m~/anaconda3/envs/autosk07/lib/python3.7/site-packages/smac/tae/execute_ta_run.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self, config, instance, cutoff, seed, budget, instance_specific, capped)\u001b[0m\n\u001b[1;32m    198\u001b[0m                                                           \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m                                                           \u001b[0mbudget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbudget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m                                                           instance_specific=instance_specific)\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbudget\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mStatusType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDONOTADVANCE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             raise ValueError(\"Cannot handle DONOTADVANCE state when using intensify or SH/HB on \"\n",
      "\u001b[0;32m~/anaconda3/envs/autosk07/lib/python3.7/site-packages/autosklearn/evaluation/__init__.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, config, instance, cutoff, seed, budget, instance_specific)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpynisher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menforce_limits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0marguments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mobj_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         if obj.exit_status in (pynisher.TimeoutException,\n",
      "\u001b[0;32m~/anaconda3/envs/autosk07/lib/python3.7/site-packages/pynisher/limit_function_call.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self2, *args, **kwargs)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m                                         \u001b[0;31m# don't leave zombies behind\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m                                         \u001b[0msubproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m                                 \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/autosk07/lib/python3.7/multiprocessing/process.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_pid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'can only join a child process'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'can only join a started process'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0m_children\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/autosk07/lib/python3.7/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     46\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;31m# This shouldn't block if wait() returned successfully.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWNOHANG\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/autosk07/lib/python3.7/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, flag)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0;31m# Child process not yet created. See #1731717\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process pynisher function call:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/charles/anaconda3/envs/autosk07/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/charles/anaconda3/envs/autosk07/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/charles/anaconda3/envs/autosk07/lib/python3.7/site-packages/pynisher/limit_function_call.py\", line 93, in subprocess_func\n",
      "    return_value = ((func(*args, **kwargs), 0))\n",
      "  File \"/home/charles/anaconda3/envs/autosk07/lib/python3.7/site-packages/autosklearn/evaluation/__init__.py\", line 29, in fit_predict_try_except_decorator\n",
      "    return ta(queue=queue, **kwargs)\n",
      "  File \"/home/charles/anaconda3/envs/autosk07/lib/python3.7/site-packages/autosklearn/evaluation/train_evaluator.py\", line 1239, in eval_cv\n",
      "    evaluator.fit_predict_and_loss(iterative=iterative)\n",
      "  File \"/home/charles/anaconda3/envs/autosk07/lib/python3.7/site-packages/autosklearn/evaluation/train_evaluator.py\", line 463, in fit_predict_and_loss\n",
      "    add_model_to_self=self.num_cv_folds == 1,\n",
      "  File \"/home/charles/anaconda3/envs/autosk07/lib/python3.7/site-packages/autosklearn/evaluation/train_evaluator.py\", line 804, in _partial_fit_and_predict_standard\n",
      "    self.Y_train[train_indices],\n",
      "  File \"/home/charles/anaconda3/envs/autosk07/lib/python3.7/site-packages/autosklearn/evaluation/abstract_evaluator.py\", line 110, in _fit_and_suppress_warnings\n",
      "    model.fit(X, y)\n",
      "  File \"/home/charles/anaconda3/envs/autosk07/lib/python3.7/site-packages/autosklearn/pipeline/base.py\", line 92, in fit\n",
      "    self.fit_estimator(X, y, **fit_params)\n",
      "  File \"/home/charles/anaconda3/envs/autosk07/lib/python3.7/site-packages/autosklearn/pipeline/regression.py\", line 82, in fit_estimator\n",
      "    X, y, **fit_params)\n",
      "  File \"/home/charles/anaconda3/envs/autosk07/lib/python3.7/site-packages/autosklearn/pipeline/base.py\", line 109, in fit_estimator\n",
      "    self._final_estimator.fit(X, y, **fit_params)\n",
      "  File \"/home/charles/anaconda3/envs/autosk07/lib/python3.7/site-packages/autosklearn/pipeline/components/base.py\", line 419, in fit\n",
      "    return self.choice.fit(X, y, **kwargs)\n",
      "  File \"/home/charles/anaconda3/envs/autosk07/lib/python3.7/site-packages/autosklearn/pipeline/components/base.py\", line 147, in fit\n",
      "    self.iterative_fit(X, y, n_iter=2, refit=True)\n",
      "  File \"/home/charles/anaconda3/envs/autosk07/lib/python3.7/site-packages/autosklearn/pipeline/components/regression/random_forest.py\", line 79, in iterative_fit\n",
      "    self.estimator.fit(X, y)\n",
      "  File \"/home/charles/anaconda3/envs/autosk07/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\", line 383, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"/home/charles/anaconda3/envs/autosk07/lib/python3.7/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/charles/anaconda3/envs/autosk07/lib/python3.7/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/charles/anaconda3/envs/autosk07/lib/python3.7/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/charles/anaconda3/envs/autosk07/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 206, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/charles/anaconda3/envs/autosk07/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 570, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/charles/anaconda3/envs/autosk07/lib/python3.7/site-packages/joblib/parallel.py\", line 253, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/charles/anaconda3/envs/autosk07/lib/python3.7/site-packages/joblib/parallel.py\", line 253, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/charles/anaconda3/envs/autosk07/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\", line 167, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n",
      "  File \"/home/charles/anaconda3/envs/autosk07/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 1225, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/home/charles/anaconda3/envs/autosk07/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 367, in fit\n",
      "    builder.build(self.tree_, X, y, sample_weight, X_idx_sorted)\n",
      "KeyboardInterrupt\n",
      "Process Process-52:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/charles/anaconda3/envs/autosk07/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/charles/anaconda3/envs/autosk07/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/charles/anaconda3/envs/autosk07/lib/python3.7/site-packages/autosklearn/estimators.py\", line 16, in _fit_automl\n",
      "    return automl.fit(load_models=load_models, **kwargs)\n",
      "  File \"/home/charles/anaconda3/envs/autosk07/lib/python3.7/site-packages/autosklearn/automl.py\", line 1137, in fit\n",
      "    load_models=load_models,\n",
      "  File \"/home/charles/anaconda3/envs/autosk07/lib/python3.7/site-packages/autosklearn/automl.py\", line 485, in fit\n",
      "    _proc_smac.run_smbo()\n",
      "  File \"/home/charles/anaconda3/envs/autosk07/lib/python3.7/site-packages/autosklearn/smbo.py\", line 473, in run_smbo\n",
      "    smac.optimize()\n",
      "  File \"/home/charles/anaconda3/envs/autosk07/lib/python3.7/site-packages/smac/facade/smac_ac_facade.py\", line 567, in optimize\n",
      "    incumbent = self.solver.run()\n",
      "  File \"/home/charles/anaconda3/envs/autosk07/lib/python3.7/site-packages/smac/optimizer/smbo.py\", line 215, in run\n",
      "    time_bound=max(self.intensifier._min_time, time_left))\n",
      "  File \"/home/charles/anaconda3/envs/autosk07/lib/python3.7/site-packages/smac/intensification/intensification.py\", line 210, in eval_challenger\n",
      "    self._add_inc_run(incumbent=incumbent, run_history=run_history, log_traj=log_traj)\n",
      "  File \"/home/charles/anaconda3/envs/autosk07/lib/python3.7/site-packages/smac/intensification/intensification.py\", line 314, in _add_inc_run\n",
      "    instance_specific=self.instance_specifics.get(next_instance, \"0\"))\n",
      "  File \"/home/charles/anaconda3/envs/autosk07/lib/python3.7/site-packages/autosklearn/evaluation/__init__.py\", line 213, in start\n",
      "    capped=capped, budget=budget)\n",
      "  File \"/home/charles/anaconda3/envs/autosk07/lib/python3.7/site-packages/smac/tae/execute_ta_run.py\", line 200, in start\n",
      "    instance_specific=instance_specific)\n",
      "  File \"/home/charles/anaconda3/envs/autosk07/lib/python3.7/site-packages/autosklearn/evaluation/__init__.py\", line 257, in run\n",
      "    obj(**obj_kwargs)\n",
      "  File \"/home/charles/anaconda3/envs/autosk07/lib/python3.7/site-packages/pynisher/limit_function_call.py\", line 232, in __call__\n",
      "    subproc.join()\n",
      "  File \"/home/charles/anaconda3/envs/autosk07/lib/python3.7/multiprocessing/process.py\", line 140, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/home/charles/anaconda3/envs/autosk07/lib/python3.7/multiprocessing/popen_fork.py\", line 48, in wait\n",
      "    return self.poll(os.WNOHANG if timeout == 0.0 else 0)\n",
      "  File \"/home/charles/anaconda3/envs/autosk07/lib/python3.7/multiprocessing/popen_fork.py\", line 28, in poll\n",
      "    pid, sts = os.waitpid(self.pid, flag)\n",
      "KeyboardInterrupt\n",
      "Process pynisher function call:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/charles/anaconda3/envs/autosk07/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/charles/anaconda3/envs/autosk07/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/charles/anaconda3/envs/autosk07/lib/python3.7/site-packages/pynisher/limit_function_call.py\", line 93, in subprocess_func\n",
      "    return_value = ((func(*args, **kwargs), 0))\n",
      "  File \"/home/charles/anaconda3/envs/autosk07/lib/python3.7/site-packages/autosklearn/evaluation/__init__.py\", line 29, in fit_predict_try_except_decorator\n",
      "    return ta(queue=queue, **kwargs)\n",
      "  File \"/home/charles/anaconda3/envs/autosk07/lib/python3.7/site-packages/autosklearn/evaluation/train_evaluator.py\", line 1239, in eval_cv\n",
      "    evaluator.fit_predict_and_loss(iterative=iterative)\n",
      "  File \"/home/charles/anaconda3/envs/autosk07/lib/python3.7/site-packages/autosklearn/evaluation/train_evaluator.py\", line 463, in fit_predict_and_loss\n",
      "    add_model_to_self=self.num_cv_folds == 1,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/charles/anaconda3/envs/autosk07/lib/python3.7/site-packages/autosklearn/evaluation/train_evaluator.py\", line 804, in _partial_fit_and_predict_standard\n",
      "    self.Y_train[train_indices],\n",
      "  File \"/home/charles/anaconda3/envs/autosk07/lib/python3.7/site-packages/autosklearn/evaluation/abstract_evaluator.py\", line 110, in _fit_and_suppress_warnings\n",
      "    model.fit(X, y)\n",
      "  File \"/home/charles/anaconda3/envs/autosk07/lib/python3.7/site-packages/autosklearn/pipeline/base.py\", line 92, in fit\n",
      "    self.fit_estimator(X, y, **fit_params)\n",
      "  File \"/home/charles/anaconda3/envs/autosk07/lib/python3.7/site-packages/autosklearn/pipeline/regression.py\", line 82, in fit_estimator\n",
      "    X, y, **fit_params)\n",
      "  File \"/home/charles/anaconda3/envs/autosk07/lib/python3.7/site-packages/autosklearn/pipeline/base.py\", line 109, in fit_estimator\n",
      "    self._final_estimator.fit(X, y, **fit_params)\n",
      "  File \"/home/charles/anaconda3/envs/autosk07/lib/python3.7/site-packages/autosklearn/pipeline/components/base.py\", line 419, in fit\n",
      "    return self.choice.fit(X, y, **kwargs)\n",
      "  File \"/home/charles/anaconda3/envs/autosk07/lib/python3.7/site-packages/autosklearn/pipeline/components/base.py\", line 147, in fit\n",
      "    self.iterative_fit(X, y, n_iter=2, refit=True)\n",
      "  File \"/home/charles/anaconda3/envs/autosk07/lib/python3.7/site-packages/autosklearn/pipeline/components/regression/random_forest.py\", line 79, in iterative_fit\n",
      "    self.estimator.fit(X, y)\n",
      "  File \"/home/charles/anaconda3/envs/autosk07/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\", line 383, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"/home/charles/anaconda3/envs/autosk07/lib/python3.7/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/charles/anaconda3/envs/autosk07/lib/python3.7/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/charles/anaconda3/envs/autosk07/lib/python3.7/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/charles/anaconda3/envs/autosk07/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 206, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/charles/anaconda3/envs/autosk07/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 570, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/charles/anaconda3/envs/autosk07/lib/python3.7/site-packages/joblib/parallel.py\", line 253, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/charles/anaconda3/envs/autosk07/lib/python3.7/site-packages/joblib/parallel.py\", line 253, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/charles/anaconda3/envs/autosk07/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\", line 165, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/home/charles/anaconda3/envs/autosk07/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 1225, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/home/charles/anaconda3/envs/autosk07/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 367, in fit\n",
      "    builder.build(self.tree_, X, y, sample_weight, X_idx_sorted)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit, KFold\n",
    "reg = autoreg.AutoSklearnRegressor(time_left_for_this_task=100000,\n",
    "                                           per_run_time_limit=10000,\n",
    "                                           initial_configurations_via_metalearning=0,\n",
    "                                           ensemble_size=50, \n",
    "                                           ensemble_nbest=25,\n",
    "                                           ensemble_memory_limit=5120, \n",
    "                                           seed=121, ml_memory_limit=10092, \n",
    "                                           include_estimators=None,\n",
    "                                           exclude_estimators=['gaussian_process','k_nearest_neighbors','decision_tree'], \n",
    "                                           include_preprocessors=None, \n",
    "                                           exclude_preprocessors=None, \n",
    "                                           resampling_strategy = 'cv',\n",
    "                                           resampling_strategy_arguments={'folds':5,\n",
    "                                                                          'shuffle': False},\n",
    "                                           tmp_folder=None, \n",
    "                                           output_folder=None, \n",
    "                                           delete_tmp_folder_after_terminate=False, \n",
    "                                           delete_output_folder_after_terminate=False, \n",
    "                                           shared_mode=False, \n",
    "                                           n_jobs = 3, \n",
    "                                           disable_evaluator_output=False, \n",
    "                                           get_smac_object_callback=None, \n",
    "                                           smac_scenario_args=None, \n",
    "                                           logging_config=None,\n",
    "                                           metadata_directory=None)\n",
    "\n",
    "\n",
    "reg.fit(ftrain, ttrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lag features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit, KFold\n",
    "regl = autoreg.AutoSklearnRegressor(time_left_for_this_task=36000,\n",
    "                                           per_run_time_limit=3600,\n",
    "                                           initial_configurations_via_metalearning=0,\n",
    "                                           ensemble_size=50, \n",
    "                                           ensemble_nbest=25,\n",
    "                                           ensemble_memory_limit=5120, \n",
    "                                           seed=121, ml_memory_limit=10092, \n",
    "                                           include_estimators=None,\n",
    "                                           exclude_estimators=['gaussian_process','k_nearest_neighbors','decision_tree'], \n",
    "                                           include_preprocessors=None, \n",
    "                                           exclude_preprocessors=None, \n",
    "                                           resampling_strategy = 'cv',\n",
    "                                           resampling_strategy_arguments={'folds':5,\n",
    "                                                                          'shuffle': False},\n",
    "                                           tmp_folder=None, \n",
    "                                           output_folder=None, \n",
    "                                           delete_tmp_folder_after_terminate=False, \n",
    "                                           delete_output_folder_after_terminate=False, \n",
    "                                           shared_mode=False, \n",
    "                                           n_jobs = 4, \n",
    "                                           disable_evaluator_output=False, \n",
    "                                           get_smac_object_callback=None, \n",
    "                                           smac_scenario_args=None, \n",
    "                                           logging_config=None,\n",
    "                                           metadata_directory='solar_meta')\n",
    "\n",
    "\n",
    "regl.fit(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_test_score': array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.70171975e-01,\n",
       "        0.00000000e+00, 2.85060943e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 6.38714214e-01, 6.70980938e-01,\n",
       "        6.46353252e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        6.54990383e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 6.69998101e-01, 6.70303723e-01, 2.81113455e-02,\n",
       "        0.00000000e+00, 6.70313556e-01, 5.84200316e-01, 6.70612808e-01,\n",
       "        6.60794705e-01, 6.64222841e-01, 0.00000000e+00, 6.25268288e-01,\n",
       "        6.70779379e-01, 6.70704037e-01, 2.77950447e-02, 6.70704037e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 6.70735946e-01, 6.70776494e-01,\n",
       "        6.70494984e-01, 6.70663884e-01, 0.00000000e+00, 6.68625253e-01,\n",
       "        0.00000000e+00, 6.68218982e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        6.70631792e-01, 6.70740471e-01, 6.70296859e-01, 6.70157901e-01,\n",
       "        6.65105864e-01, 6.72516376e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        6.70226560e-01, 0.00000000e+00, 0.00000000e+00, 6.21994740e-01,\n",
       "        6.70404361e-01, 0.00000000e+00, 0.00000000e+00, 6.70527955e-01,\n",
       "        6.70385054e-01, 6.70762451e-01, 6.70764684e-01, 6.70725757e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 6.70264284e-01, 6.70754084e-01,\n",
       "        6.70671712e-01, 6.70612576e-01, 0.00000000e+00, 6.47348236e-01,\n",
       "        5.89110411e-01, 6.69528742e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 1.66534899e-03, 0.00000000e+00, 1.64889856e-03,\n",
       "        6.70739182e-01, 6.70442526e-01, 6.70739182e-01, 0.00000000e+00,\n",
       "        1.15161249e-04, 4.21738370e-01, 6.70735946e-01, 6.63743063e-01,\n",
       "        6.71258849e-01, 5.57845615e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.25455185e-01,\n",
       "        6.70773878e-01, 0.00000000e+00, 6.70775415e-01, 6.66338506e-01,\n",
       "        0.00000000e+00, 7.07071021e-01, 6.64594227e-01, 0.00000000e+00,\n",
       "        0.00000000e+00, 6.64588849e-01, 0.00000000e+00, 6.58941192e-01,\n",
       "        0.00000000e+00, 6.63598159e-01, 6.35556602e-01, 6.70391565e-01,\n",
       "        6.65968456e-01, 6.66484651e-01, 0.00000000e+00, 7.09217739e-01,\n",
       "        6.65061940e-01, 6.73393494e-01, 6.70924939e-01, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00]),\n",
       " 'mean_fit_time': array([2.52277123e+03, 3.60001749e+03, 3.60011366e+03, 5.20511794e+00,\n",
       "        3.60010672e+03, 2.57575126e+01, 4.95615244e-01, 3.60010547e+03,\n",
       "        3.60016015e+03, 3.60011737e+03, 4.34229994e+00, 6.68786287e+00,\n",
       "        7.72863150e+00, 6.11946495e+01, 3.60010843e+03, 1.00805369e+03,\n",
       "        4.31070795e+01, 3.60006132e+03, 2.38277505e+03, 3.60028761e+03,\n",
       "        3.60010581e+03, 8.88692141e+00, 5.51896381e+00, 1.34443336e+01,\n",
       "        3.60010463e+03, 1.75386829e+02, 5.84200716e+00, 7.73237085e+00,\n",
       "        8.81189847e+00, 7.53374743e+00, 3.60014023e+03, 4.64315009e+00,\n",
       "        8.83596468e+00, 8.16225433e+00, 1.86609327e+02, 6.43275404e+00,\n",
       "        3.60139088e+03, 3.60027473e+03, 1.41794328e+03, 1.05388772e+01,\n",
       "        9.17671704e+00, 9.26350689e+00, 3.60010866e+03, 8.25811148e+00,\n",
       "        7.54022837e-01, 8.98070478e+00, 1.29716496e+03, 7.29788452e+02,\n",
       "        1.00910833e+01, 1.00983558e+01, 4.62893956e+01, 5.75936389e+00,\n",
       "        7.30257442e+01, 9.20925450e+00, 3.60011170e+03, 3.60007810e+03,\n",
       "        3.60011524e+03, 1.61614823e+00, 5.50346136e-01, 3.60011618e+03,\n",
       "        5.94595909e+00, 7.86961651e+02, 2.26942555e+03, 9.82188654e+00,\n",
       "        7.27410531e+00, 6.78160045e+01, 9.33254867e+01, 1.07559996e+01,\n",
       "        6.25813055e+00, 4.41875076e+00, 8.28308749e+00, 4.60155106e+00,\n",
       "        3.60012225e+03, 3.60012520e+03, 1.43840051e+01, 6.02298450e+00,\n",
       "        5.41208696e+00, 1.67779862e+03, 6.80104733e-01, 5.85110197e+01,\n",
       "        3.42720912e+01, 8.96049571e+00, 2.98430145e+01, 3.60010596e+03,\n",
       "        3.60013112e+03, 6.96422265e+01, 3.60001346e+03, 4.89982311e+02,\n",
       "        7.88890481e+00, 5.09222865e+00, 7.49150872e+00, 7.48258440e+02,\n",
       "        3.19796103e+03, 6.38734102e+00, 5.18316913e+00, 5.70509632e+01,\n",
       "        7.76444316e+00, 7.50731683e+00, 3.60011271e+03, 3.60011152e+03,\n",
       "        2.47635384e+01, 8.33843565e+00, 3.60011337e+03, 3.83673429e+02,\n",
       "        5.09641886e+00, 3.60010831e+03, 5.13238549e+00, 5.94882274e+01,\n",
       "        3.60010869e+03, 2.18973139e+03, 8.54278312e+01, 1.74135816e+03,\n",
       "        3.60005043e+03, 6.06488619e+01, 3.60011074e+03, 5.82283227e+01,\n",
       "        6.77137828e+01, 2.98646710e+01, 4.92460513e+00, 7.01186085e+00,\n",
       "        1.09329871e+02, 9.89770737e+01, 6.34113699e+02, 1.20521020e+03,\n",
       "        3.89558396e+01, 5.91030550e+00, 5.52499199e+00, 7.20827613e+01,\n",
       "        2.21410638e+03, 3.02411008e+03]),\n",
       " 'params': [{'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.01,\n",
       "   'regressor:random_forest:bootstrap': 'True',\n",
       "   'regressor:random_forest:criterion': 'mse',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 1.0,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 1,\n",
       "   'regressor:random_forest:min_samples_split': 2,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:ridge_regression:alpha': 251.64290429823575,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 1.785648071403803e-07,\n",
       "   'feature_preprocessor:fast_ica:n_components': 1765},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'regressor:random_forest:bootstrap': 'False',\n",
       "   'regressor:random_forest:criterion': 'mse',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.6171127451399442,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 18,\n",
       "   'regressor:random_forest:min_samples_split': 3,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.018225373154476403,\n",
       "   'regressor:ridge_regression:alpha': 118.13970161044887,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 4.941398947613314e-07},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.857856422838131,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.16270327064031528,\n",
       "   'regressor:random_forest:bootstrap': 'True',\n",
       "   'regressor:random_forest:criterion': 'mae',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.3727136330076082,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 14,\n",
       "   'regressor:random_forest:min_samples_split': 6,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'nystroem_sampler',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.7290527372667672,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.1675235381095665,\n",
       "   'feature_preprocessor:nystroem_sampler:kernel': 'cosine',\n",
       "   'feature_preprocessor:nystroem_sampler:n_components': 1484,\n",
       "   'regressor:ridge_regression:alpha': 9879.424292624131,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 6.151851245014563e-05},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.7436805191863465,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.11916328045224628,\n",
       "   'feature_preprocessor:polynomial:degree': 3,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'False',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'True',\n",
       "   'regressor:random_forest:bootstrap': 'False',\n",
       "   'regressor:random_forest:criterion': 'mae',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.3685612783283523,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 3,\n",
       "   'regressor:random_forest:min_samples_split': 14,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 480,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'uniform',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:random_forest:bootstrap': 'True',\n",
       "   'regressor:random_forest:criterion': 'mae',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.15608611895950877,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 13,\n",
       "   'regressor:random_forest:min_samples_split': 3,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 1417},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'feature_agglomeration',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.01587482042558028,\n",
       "   'feature_preprocessor:feature_agglomeration:affinity': 'euclidean',\n",
       "   'feature_preprocessor:feature_agglomeration:linkage': 'average',\n",
       "   'feature_preprocessor:feature_agglomeration:n_clusters': 247,\n",
       "   'feature_preprocessor:feature_agglomeration:pooling_func': 'median',\n",
       "   'regressor:random_forest:bootstrap': 'False',\n",
       "   'regressor:random_forest:criterion': 'friedman_mse',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.43966055136547555,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 19,\n",
       "   'regressor:random_forest:min_samples_split': 20,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.9797829546144647,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.22911553274913804,\n",
       "   'feature_preprocessor:pca:keep_variance': 0.7597024223078015,\n",
       "   'feature_preprocessor:pca:whiten': 'True',\n",
       "   'regressor:extra_trees:bootstrap': 'True',\n",
       "   'regressor:extra_trees:criterion': 'mae',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.952103089326412,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 3,\n",
       "   'regressor:extra_trees:min_samples_split': 12},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'nystroem_sampler',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.031519383715223226,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.8983178657352634,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.2796707413712671,\n",
       "   'feature_preprocessor:nystroem_sampler:kernel': 'cosine',\n",
       "   'feature_preprocessor:nystroem_sampler:n_components': 197,\n",
       "   'regressor:ridge_regression:alpha': 228.5982297578523,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 3.831709023607285e-07},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'feature_agglomeration',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.16464462190388976,\n",
       "   'feature_preprocessor:feature_agglomeration:affinity': 'cosine',\n",
       "   'feature_preprocessor:feature_agglomeration:linkage': 'complete',\n",
       "   'feature_preprocessor:feature_agglomeration:n_clusters': 179,\n",
       "   'feature_preprocessor:feature_agglomeration:pooling_func': 'max',\n",
       "   'regressor:ridge_regression:alpha': 5329.339413938869,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 4.949503066482948e-06},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'feature_agglomeration',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0016477063712300928,\n",
       "   'feature_preprocessor:feature_agglomeration:affinity': 'cosine',\n",
       "   'feature_preprocessor:feature_agglomeration:linkage': 'average',\n",
       "   'feature_preprocessor:feature_agglomeration:n_clusters': 21,\n",
       "   'feature_preprocessor:feature_agglomeration:pooling_func': 'median',\n",
       "   'regressor:ridge_regression:alpha': 8909.038912943726,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 1.6606957980157686e-06},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.018428862457105236,\n",
       "   'feature_preprocessor:polynomial:degree': 2,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'True',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'True',\n",
       "   'regressor:ridge_regression:alpha': 403.63559839161786,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 1.222205461967052e-06},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'feature_agglomeration',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'feature_preprocessor:feature_agglomeration:affinity': 'euclidean',\n",
       "   'feature_preprocessor:feature_agglomeration:linkage': 'ward',\n",
       "   'feature_preprocessor:feature_agglomeration:n_clusters': 101,\n",
       "   'feature_preprocessor:feature_agglomeration:pooling_func': 'max',\n",
       "   'regressor:extra_trees:bootstrap': 'False',\n",
       "   'regressor:extra_trees:criterion': 'mae',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.7561693604244872,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 2,\n",
       "   'regressor:extra_trees:min_samples_split': 20},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'feature_agglomeration',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.994735436444351,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.020688473971890227,\n",
       "   'feature_preprocessor:feature_agglomeration:affinity': 'cosine',\n",
       "   'feature_preprocessor:feature_agglomeration:linkage': 'complete',\n",
       "   'feature_preprocessor:feature_agglomeration:n_clusters': 382,\n",
       "   'feature_preprocessor:feature_agglomeration:pooling_func': 'max',\n",
       "   'regressor:extra_trees:bootstrap': 'False',\n",
       "   'regressor:extra_trees:criterion': 'friedman_mse',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.30901038836721584,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 12,\n",
       "   'regressor:extra_trees:min_samples_split': 18},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0009339910521186708,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 743,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'uniform',\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'True',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 5,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 19,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 4,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 62,\n",
       "   'regressor:ridge_regression:alpha': 5591.539001489194,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 7.156313591713281e-06},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'True',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 4,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 16,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 17,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 86,\n",
       "   'regressor:random_forest:bootstrap': 'True',\n",
       "   'regressor:random_forest:criterion': 'friedman_mse',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.7599857996442769,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 6,\n",
       "   'regressor:random_forest:min_samples_split': 2,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.03380423545174408,\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'True',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 9,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 18,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 10,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 92,\n",
       "   'regressor:extra_trees:bootstrap': 'False',\n",
       "   'regressor:extra_trees:criterion': 'friedman_mse',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.21420968661885487,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 3,\n",
       "   'regressor:extra_trees:min_samples_split': 20},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 1104,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'uniform',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'False',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'friedman_mse',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.7674378357889092,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 19,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 5,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:random_forest:bootstrap': 'True',\n",
       "   'regressor:random_forest:criterion': 'mae',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.9130339898205108,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 4,\n",
       "   'regressor:random_forest:min_samples_split': 20,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:random_forest:bootstrap': 'False',\n",
       "   'regressor:random_forest:criterion': 'mse',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.8925031600429947,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 12,\n",
       "   'regressor:random_forest:min_samples_split': 8,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 578},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'feature_agglomeration',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.005265624963152827,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.8900236538967836,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.21963522074085387,\n",
       "   'feature_preprocessor:feature_agglomeration:affinity': 'cosine',\n",
       "   'feature_preprocessor:feature_agglomeration:linkage': 'complete',\n",
       "   'feature_preprocessor:feature_agglomeration:n_clusters': 182,\n",
       "   'feature_preprocessor:feature_agglomeration:pooling_func': 'median',\n",
       "   'regressor:ridge_regression:alpha': 5932.043680333357,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 2.4203886872176227e-07},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0002073104715798369,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 1216,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'normal',\n",
       "   'regressor:ridge_regression:alpha': 4869.752248766393,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 2.165382616171651e-07},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'kitchen_sinks',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'feature_preprocessor:kitchen_sinks:gamma': 4.578081692221954,\n",
       "   'feature_preprocessor:kitchen_sinks:n_components': 891,\n",
       "   'regressor:ridge_regression:alpha': 1514.598041830289,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 6.778076880265568e-05},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.010319779633662133,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'False',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'mae',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.31652668742664525,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 6,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 18,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:ridge_regression:alpha': 241.09456662675674,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 1.1816120350010204e-05},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.02769366214354228,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'False',\n",
       "   'regressor:ridge_regression:alpha': 220.18392019057575,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 1.9920068206713036e-06},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'feature_preprocessor:pca:keep_variance': 0.6141215545759248,\n",
       "   'feature_preprocessor:pca:whiten': 'True',\n",
       "   'regressor:ridge_regression:alpha': 5315.152637030628,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 4.873745048608924e-05},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'feature_agglomeration',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.31143906972438024,\n",
       "   'feature_preprocessor:feature_agglomeration:affinity': 'manhattan',\n",
       "   'feature_preprocessor:feature_agglomeration:linkage': 'complete',\n",
       "   'feature_preprocessor:feature_agglomeration:n_clusters': 376,\n",
       "   'feature_preprocessor:feature_agglomeration:pooling_func': 'max',\n",
       "   'regressor:ridge_regression:alpha': 3202.9685614699606,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 2.862822150863437e-07},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'feature_agglomeration',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.00010641369766317917,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 838,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'normal',\n",
       "   'feature_preprocessor:feature_agglomeration:affinity': 'euclidean',\n",
       "   'feature_preprocessor:feature_agglomeration:linkage': 'average',\n",
       "   'feature_preprocessor:feature_agglomeration:n_clusters': 25,\n",
       "   'feature_preprocessor:feature_agglomeration:pooling_func': 'mean',\n",
       "   'regressor:ridge_regression:alpha': 4525.569964033496,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 2.165382616171651e-07},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'feature_agglomeration',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.00032397219493259086,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 1000,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'normal',\n",
       "   'feature_preprocessor:feature_agglomeration:affinity': 'cosine',\n",
       "   'feature_preprocessor:feature_agglomeration:linkage': 'complete',\n",
       "   'feature_preprocessor:feature_agglomeration:n_clusters': 16,\n",
       "   'feature_preprocessor:feature_agglomeration:pooling_func': 'max',\n",
       "   'regressor:ridge_regression:alpha': 4869.752248766393,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 1.9450446227639814e-07},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.060844685912740976,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'True',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'friedman_mse',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.8717152804886077,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 20,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 2,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:random_forest:bootstrap': 'False',\n",
       "   'regressor:random_forest:criterion': 'mae',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.8116107525833972,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 6,\n",
       "   'regressor:random_forest:min_samples_split': 14,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.00025963678346270876,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 2000,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'uniform',\n",
       "   'feature_preprocessor:pca:keep_variance': 0.6753054326391816,\n",
       "   'feature_preprocessor:pca:whiten': 'True',\n",
       "   'regressor:ridge_regression:alpha': 102.44359702118479,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 3.51771347181206e-07},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'feature_agglomeration',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.01454485937859754,\n",
       "   'feature_preprocessor:feature_agglomeration:affinity': 'euclidean',\n",
       "   'feature_preprocessor:feature_agglomeration:linkage': 'complete',\n",
       "   'feature_preprocessor:feature_agglomeration:n_clusters': 320,\n",
       "   'feature_preprocessor:feature_agglomeration:pooling_func': 'mean',\n",
       "   'regressor:ridge_regression:alpha': 1682.7292738873452,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 3.4350564167465105e-07},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'feature_agglomeration',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.07167013927558084,\n",
       "   'feature_preprocessor:feature_agglomeration:affinity': 'manhattan',\n",
       "   'feature_preprocessor:feature_agglomeration:linkage': 'complete',\n",
       "   'feature_preprocessor:feature_agglomeration:n_clusters': 298,\n",
       "   'feature_preprocessor:feature_agglomeration:pooling_func': 'max',\n",
       "   'regressor:ridge_regression:alpha': 2577.9795274879525,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 1.4190891255147433e-07},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'nystroem_sampler',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.004803690343957523,\n",
       "   'feature_preprocessor:nystroem_sampler:kernel': 'rbf',\n",
       "   'feature_preprocessor:nystroem_sampler:n_components': 3782,\n",
       "   'regressor:ridge_regression:alpha': 6870.106567085016,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 8.752672977472674e-07,\n",
       "   'feature_preprocessor:nystroem_sampler:gamma': 9.89927316778072e-05},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'feature_agglomeration',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.12472415873398403,\n",
       "   'feature_preprocessor:feature_agglomeration:affinity': 'euclidean',\n",
       "   'feature_preprocessor:feature_agglomeration:linkage': 'average',\n",
       "   'feature_preprocessor:feature_agglomeration:n_clusters': 266,\n",
       "   'feature_preprocessor:feature_agglomeration:pooling_func': 'max',\n",
       "   'regressor:ridge_regression:alpha': 2577.9795274879525,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 1.331792871051354e-07},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'regressor:random_forest:bootstrap': 'True',\n",
       "   'regressor:random_forest:criterion': 'friedman_mse',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.4540546893452445,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 7,\n",
       "   'regressor:random_forest:min_samples_split': 6,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.00047167414606260645,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 591,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'normal',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'cube',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:random_forest:bootstrap': 'False',\n",
       "   'regressor:random_forest:criterion': 'mse',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.6137693018821133,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 11,\n",
       "   'regressor:random_forest:min_samples_split': 10,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:fast_ica:n_components': 26},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.2628369688469089,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.8782349391062089,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.21360564175822855,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'exp',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'False',\n",
       "   'regressor:ridge_regression:alpha': 997.3917993469088,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 2.662530681849979e-07},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'feature_agglomeration',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.009733627378880923,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.75,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.2607931921678484,\n",
       "   'feature_preprocessor:feature_agglomeration:affinity': 'euclidean',\n",
       "   'feature_preprocessor:feature_agglomeration:linkage': 'ward',\n",
       "   'feature_preprocessor:feature_agglomeration:n_clusters': 285,\n",
       "   'feature_preprocessor:feature_agglomeration:pooling_func': 'mean',\n",
       "   'regressor:ridge_regression:alpha': 1365.0570480315653,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 1.5077251580387525e-07},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'feature_agglomeration',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.007430049210347528,\n",
       "   'feature_preprocessor:feature_agglomeration:affinity': 'euclidean',\n",
       "   'feature_preprocessor:feature_agglomeration:linkage': 'average',\n",
       "   'feature_preprocessor:feature_agglomeration:n_clusters': 87,\n",
       "   'feature_preprocessor:feature_agglomeration:pooling_func': 'mean',\n",
       "   'regressor:ridge_regression:alpha': 567.9963096413372,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 1.459775962723201e-07},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'feature_agglomeration',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.006124527231668457,\n",
       "   'feature_preprocessor:feature_agglomeration:affinity': 'cosine',\n",
       "   'feature_preprocessor:feature_agglomeration:linkage': 'average',\n",
       "   'feature_preprocessor:feature_agglomeration:n_clusters': 325,\n",
       "   'feature_preprocessor:feature_agglomeration:pooling_func': 'mean',\n",
       "   'regressor:ridge_regression:alpha': 727.0491382018473,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 1.0835903481063717e-07},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.4522263915992745,\n",
       "   'regressor:random_forest:bootstrap': 'True',\n",
       "   'regressor:random_forest:criterion': 'mae',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.3617900046399175,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 13,\n",
       "   'regressor:random_forest:min_samples_split': 20,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.015568372971125646,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 263,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'normal',\n",
       "   'feature_preprocessor:pca:keep_variance': 0.962823709365242,\n",
       "   'feature_preprocessor:pca:whiten': 'True',\n",
       "   'regressor:ridge_regression:alpha': 1059.8220838933305,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 1.2990395212240492e-07},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'feature_preprocessor:polynomial:degree': 3,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'False',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'True',\n",
       "   'regressor:extra_trees:bootstrap': 'True',\n",
       "   'regressor:extra_trees:criterion': 'friedman_mse',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.7836646880154006,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 8,\n",
       "   'regressor:extra_trees:min_samples_split': 3},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'feature_agglomeration',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.16230286319906675,\n",
       "   'feature_preprocessor:feature_agglomeration:affinity': 'euclidean',\n",
       "   'feature_preprocessor:feature_agglomeration:linkage': 'ward',\n",
       "   'feature_preprocessor:feature_agglomeration:n_clusters': 25,\n",
       "   'feature_preprocessor:feature_agglomeration:pooling_func': 'max',\n",
       "   'regressor:ridge_regression:alpha': 235.635582015798,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 3.304597658389447e-07},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0037663019916282245,\n",
       "   'feature_preprocessor:pca:keep_variance': 0.757716943583408,\n",
       "   'feature_preprocessor:pca:whiten': 'True',\n",
       "   'regressor:random_forest:bootstrap': 'False',\n",
       "   'regressor:random_forest:criterion': 'friedman_mse',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.8524597601744566,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 20,\n",
       "   'regressor:random_forest:min_samples_split': 4,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'feature_preprocessor:pca:keep_variance': 0.9134536500100956,\n",
       "   'feature_preprocessor:pca:whiten': 'True',\n",
       "   'regressor:extra_trees:bootstrap': 'False',\n",
       "   'regressor:extra_trees:criterion': 'friedman_mse',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.45823543256784804,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 3,\n",
       "   'regressor:extra_trees:min_samples_split': 20},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'feature_agglomeration',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.07531834070187314,\n",
       "   'feature_preprocessor:feature_agglomeration:affinity': 'cosine',\n",
       "   'feature_preprocessor:feature_agglomeration:linkage': 'average',\n",
       "   'feature_preprocessor:feature_agglomeration:n_clusters': 156,\n",
       "   'feature_preprocessor:feature_agglomeration:pooling_func': 'median',\n",
       "   'regressor:ridge_regression:alpha': 398.2364083728594,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 1.6849850445595085e-07},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'feature_agglomeration',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.17096851867485746,\n",
       "   'feature_preprocessor:feature_agglomeration:affinity': 'cosine',\n",
       "   'feature_preprocessor:feature_agglomeration:linkage': 'average',\n",
       "   'feature_preprocessor:feature_agglomeration:n_clusters': 390,\n",
       "   'feature_preprocessor:feature_agglomeration:pooling_func': 'max',\n",
       "   'regressor:ridge_regression:alpha': 1022.5394038849355,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 1.0568816365268719e-07},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'regressor:ridge_regression:alpha': 206.5673628756533,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 4.450362990645943e-06},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'regressor:ridge_regression:alpha': 109.42464068550348,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 7.740120494214784e-06},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.8575562916534851,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.19295076377819753,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'True',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'friedman_mse',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.49565336345527633,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 14,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 3,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:ridge_regression:alpha': 306.8582872572692,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 3.005863415778308e-05},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'feature_agglomeration',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.06679923104211231,\n",
       "   'feature_preprocessor:feature_agglomeration:affinity': 'manhattan',\n",
       "   'feature_preprocessor:feature_agglomeration:linkage': 'complete',\n",
       "   'feature_preprocessor:feature_agglomeration:n_clusters': 149,\n",
       "   'feature_preprocessor:feature_agglomeration:pooling_func': 'max',\n",
       "   'regressor:ridge_regression:alpha': 398.2364083728594,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 2.0632663912993007e-07},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'regressor:random_forest:bootstrap': 'False',\n",
       "   'regressor:random_forest:criterion': 'mae',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.9329918389865737,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 5,\n",
       "   'regressor:random_forest:min_samples_split': 6,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.9915188892728427,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.25379581948682567,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'False',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'friedman_mse',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.7627395281282661,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 1,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 16,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:random_forest:bootstrap': 'False',\n",
       "   'regressor:random_forest:criterion': 'mae',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.4194485895916473,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 19,\n",
       "   'regressor:random_forest:min_samples_split': 5,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0001143008304053733,\n",
       "   'feature_preprocessor:polynomial:degree': 2,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'True',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'False',\n",
       "   'regressor:extra_trees:bootstrap': 'False',\n",
       "   'regressor:extra_trees:criterion': 'friedman_mse',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.6129946702308617,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 6,\n",
       "   'regressor:extra_trees:min_samples_split': 15},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0001182659453314944,\n",
       "   'feature_preprocessor:polynomial:degree': 3,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'True',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'True',\n",
       "   'regressor:random_forest:bootstrap': 'False',\n",
       "   'regressor:random_forest:criterion': 'mse',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.36554379670330617,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 4,\n",
       "   'regressor:random_forest:min_samples_split': 17,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'feature_preprocessor:polynomial:degree': 3,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'False',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'True',\n",
       "   'regressor:ridge_regression:alpha': 4459.351246960449,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 1.6219397810716745e-06},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.061866534063428034,\n",
       "   'feature_preprocessor:polynomial:degree': 2,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'False',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'False',\n",
       "   'regressor:extra_trees:bootstrap': 'False',\n",
       "   'regressor:extra_trees:criterion': 'mse',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.441358510419701,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 12,\n",
       "   'regressor:extra_trees:min_samples_split': 18},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'feature_agglomeration',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.004765134371201316,\n",
       "   'feature_preprocessor:feature_agglomeration:affinity': 'manhattan',\n",
       "   'feature_preprocessor:feature_agglomeration:linkage': 'complete',\n",
       "   'feature_preprocessor:feature_agglomeration:n_clusters': 290,\n",
       "   'feature_preprocessor:feature_agglomeration:pooling_func': 'mean',\n",
       "   'regressor:ridge_regression:alpha': 154.15371317803957,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 1.745799608994748e-07},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.018230516330224853,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'exp',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'False',\n",
       "   'regressor:extra_trees:bootstrap': 'True',\n",
       "   'regressor:extra_trees:criterion': 'friedman_mse',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.44926495807799216,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 6,\n",
       "   'regressor:extra_trees:min_samples_split': 16},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.29985772198416394,\n",
       "   'feature_preprocessor:polynomial:degree': 2,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'True',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'False',\n",
       "   'regressor:random_forest:bootstrap': 'False',\n",
       "   'regressor:random_forest:criterion': 'mse',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.490770416599577,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 15,\n",
       "   'regressor:random_forest:min_samples_split': 12,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 1965,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'normal',\n",
       "   'feature_preprocessor:pca:keep_variance': 0.5628006106285901,\n",
       "   'feature_preprocessor:pca:whiten': 'True',\n",
       "   'regressor:ridge_regression:alpha': 851.3665459916309,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 1.0485936584738877e-05},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'feature_agglomeration',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.004653690952636547,\n",
       "   'feature_preprocessor:feature_agglomeration:affinity': 'cosine',\n",
       "   'feature_preprocessor:feature_agglomeration:linkage': 'complete',\n",
       "   'feature_preprocessor:feature_agglomeration:n_clusters': 375,\n",
       "   'feature_preprocessor:feature_agglomeration:pooling_func': 'median',\n",
       "   'regressor:ridge_regression:alpha': 304.04975384858267,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 1.616656653428657e-05},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.003704268441902656,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.925159394762694,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.2364019812469151,\n",
       "   'feature_preprocessor:polynomial:degree': 2,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'False',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'False',\n",
       "   'regressor:extra_trees:bootstrap': 'False',\n",
       "   'regressor:extra_trees:criterion': 'mse',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.1435060136758555,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 10,\n",
       "   'regressor:extra_trees:min_samples_split': 2},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.03226742060891215,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.7740090729004457,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.07282418654683423,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'True',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'mse',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.684536617609959,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 8,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 2,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:extra_trees:bootstrap': 'False',\n",
       "   'regressor:extra_trees:criterion': 'mse',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.13160097958529787,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 1,\n",
       "   'regressor:extra_trees:min_samples_split': 2},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'feature_agglomeration',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.1240841636140683,\n",
       "   'feature_preprocessor:feature_agglomeration:affinity': 'manhattan',\n",
       "   'feature_preprocessor:feature_agglomeration:linkage': 'complete',\n",
       "   'feature_preprocessor:feature_agglomeration:n_clusters': 154,\n",
       "   'feature_preprocessor:feature_agglomeration:pooling_func': 'median',\n",
       "   'regressor:ridge_regression:alpha': 282.61339287398687,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 2.4607264154829007e-07},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'feature_agglomeration',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.006230462700721226,\n",
       "   'feature_preprocessor:feature_agglomeration:affinity': 'manhattan',\n",
       "   'feature_preprocessor:feature_agglomeration:linkage': 'complete',\n",
       "   'feature_preprocessor:feature_agglomeration:n_clusters': 256,\n",
       "   'feature_preprocessor:feature_agglomeration:pooling_func': 'max',\n",
       "   'regressor:ridge_regression:alpha': 284.6597986859927,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 2.1367976061466478e-07},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.06182459627858525,\n",
       "   'regressor:ridge_regression:alpha': 2013.8759864172823,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 1.357245545164312e-07},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.15560814642506554,\n",
       "   'regressor:ridge_regression:alpha': 1202.2274776558202,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 1.2772345973501513e-07},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.1876120251369115,\n",
       "   'regressor:ridge_regression:alpha': 946.2859644993731,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 1.708508807649327e-07},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.016199831041287433,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.9870545192045517,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.17458287943236145,\n",
       "   'regressor:random_forest:bootstrap': 'True',\n",
       "   'regressor:random_forest:criterion': 'mae',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.21063107873516385,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 18,\n",
       "   'regressor:random_forest:min_samples_split': 9,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'True',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 3,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 1,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 2,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 83,\n",
       "   'regressor:random_forest:bootstrap': 'True',\n",
       "   'regressor:random_forest:criterion': 'mse',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.8200090550596884,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 14,\n",
       "   'regressor:random_forest:min_samples_split': 17,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'feature_agglomeration',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.025627780631743393,\n",
       "   'feature_preprocessor:feature_agglomeration:affinity': 'euclidean',\n",
       "   'feature_preprocessor:feature_agglomeration:linkage': 'complete',\n",
       "   'feature_preprocessor:feature_agglomeration:n_clusters': 322,\n",
       "   'feature_preprocessor:feature_agglomeration:pooling_func': 'max',\n",
       "   'regressor:ridge_regression:alpha': 181.34798281202396,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 1.4320890748340824e-07},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.38570462781045994,\n",
       "   'regressor:ridge_regression:alpha': 2117.4977633436038,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 1.5059773355213637e-06},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.1379024399075265,\n",
       "   'regressor:ridge_regression:alpha': 2816.778369580754,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 8.679092713200136e-07},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.04965344815508581,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'exp',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'False',\n",
       "   'regressor:ridge_regression:alpha': 604.350990201261,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 3.5721173001895457e-07},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'feature_preprocessor:polynomial:degree': 3,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'False',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'True',\n",
       "   'regressor:extra_trees:bootstrap': 'False',\n",
       "   'regressor:extra_trees:criterion': 'friedman_mse',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.6493394975543538,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 2,\n",
       "   'regressor:extra_trees:min_samples_split': 5},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.07503828417582162,\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'False',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 9,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 13,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 7,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 15,\n",
       "   'regressor:ridge_regression:alpha': 102.03701247340433,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 2.3170415387055311e-07},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0638618790992277,\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'True',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 2,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 13,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 13,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 12,\n",
       "   'regressor:ridge_regression:alpha': 101.8709764121046,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 4.31240486122738e-06},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'feature_agglomeration',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'feature_preprocessor:feature_agglomeration:affinity': 'manhattan',\n",
       "   'feature_preprocessor:feature_agglomeration:linkage': 'complete',\n",
       "   'feature_preprocessor:feature_agglomeration:n_clusters': 208,\n",
       "   'feature_preprocessor:feature_agglomeration:pooling_func': 'median',\n",
       "   'regressor:ridge_regression:alpha': 8440.46782148219,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 3.579108335032788e-07},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'kernel_pca',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.04362528178935715,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 491,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'normal',\n",
       "   'feature_preprocessor:kernel_pca:kernel': 'rbf',\n",
       "   'feature_preprocessor:kernel_pca:n_components': 439,\n",
       "   'regressor:ridge_regression:alpha': 680.6245135254732,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 5.778146939654804e-07,\n",
       "   'feature_preprocessor:kernel_pca:gamma': 0.26930393317792434},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.009439925924704577,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 298,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'uniform',\n",
       "   'feature_preprocessor:polynomial:degree': 2,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'False',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'True',\n",
       "   'regressor:random_forest:bootstrap': 'True',\n",
       "   'regressor:random_forest:criterion': 'mae',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.5753873145265312,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 11,\n",
       "   'regressor:random_forest:min_samples_split': 9,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'regressor:random_forest:bootstrap': 'False',\n",
       "   'regressor:random_forest:criterion': 'friedman_mse',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.9856315880871942,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 11,\n",
       "   'regressor:random_forest:min_samples_split': 3,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.05602708968616209,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:ridge_regression:alpha': 427.2213005218416,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 6.204106646817834e-05,\n",
       "   'feature_preprocessor:fast_ica:n_components': 94},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.18704282490072735,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'False',\n",
       "   'regressor:ridge_regression:alpha': 426.6105391976211,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 1.5124495966064339e-07},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.1619387788708421,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'exp',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:ridge_regression:alpha': 429.5597233606686,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 1.612775317418577e-07,\n",
       "   'feature_preprocessor:fast_ica:n_components': 279},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'feature_agglomeration',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0035139043560294594,\n",
       "   'feature_preprocessor:feature_agglomeration:affinity': 'euclidean',\n",
       "   'feature_preprocessor:feature_agglomeration:linkage': 'complete',\n",
       "   'feature_preprocessor:feature_agglomeration:n_clusters': 219,\n",
       "   'feature_preprocessor:feature_agglomeration:pooling_func': 'median',\n",
       "   'regressor:ridge_regression:alpha': 1015.1996461594002,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 5.249342158454455e-07},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.05548618070018443,\n",
       "   'regressor:ridge_regression:alpha': 345.3655981082463,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 7.82606254681903e-05},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'feature_agglomeration',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0035139043560294594,\n",
       "   'feature_preprocessor:feature_agglomeration:affinity': 'euclidean',\n",
       "   'feature_preprocessor:feature_agglomeration:linkage': 'complete',\n",
       "   'feature_preprocessor:feature_agglomeration:n_clusters': 219,\n",
       "   'feature_preprocessor:feature_agglomeration:pooling_func': 'median',\n",
       "   'regressor:ridge_regression:alpha': 1015.1996461594002,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 5.615163057927447e-07},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.004588712935353821,\n",
       "   'regressor:extra_trees:bootstrap': 'False',\n",
       "   'regressor:extra_trees:criterion': 'mse',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.19142808468727923,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 1,\n",
       "   'regressor:extra_trees:min_samples_split': 14},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.01710909782190678,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:ridge_regression:alpha': 837.8899864250509,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 1.459775962723201e-07,\n",
       "   'feature_preprocessor:fast_ica:n_components': 111},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'kitchen_sinks',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0038479498657412736,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.771122294927281,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.27245697753095954,\n",
       "   'feature_preprocessor:kitchen_sinks:gamma': 0.00010518986968354852,\n",
       "   'feature_preprocessor:kitchen_sinks:n_components': 229,\n",
       "   'regressor:ridge_regression:alpha': 247.28521063594175,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 1.2179594324959094e-05},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.17670917565193384,\n",
       "   'regressor:ridge_regression:alpha': 997.3917993469088,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 1.2420814853913253e-07},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'True',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'friedman_mse',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.41171688712811005,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 11,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 18,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:ridge_regression:alpha': 246.68184310555154,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 1.214280813254371e-05},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'feature_agglomeration',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.19643029797619796,\n",
       "   'feature_preprocessor:feature_agglomeration:affinity': 'euclidean',\n",
       "   'feature_preprocessor:feature_agglomeration:linkage': 'complete',\n",
       "   'feature_preprocessor:feature_agglomeration:n_clusters': 30,\n",
       "   'feature_preprocessor:feature_agglomeration:pooling_func': 'max',\n",
       "   'regressor:ridge_regression:alpha': 1140.2382279388025,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 1.02078346656144e-07},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'feature_agglomeration',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.14503759738418542,\n",
       "   'feature_preprocessor:feature_agglomeration:affinity': 'euclidean',\n",
       "   'feature_preprocessor:feature_agglomeration:linkage': 'complete',\n",
       "   'feature_preprocessor:feature_agglomeration:n_clusters': 3,\n",
       "   'feature_preprocessor:feature_agglomeration:pooling_func': 'max',\n",
       "   'regressor:ridge_regression:alpha': 2058.6980997049554,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 1.0395430611891885e-07},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0004013957326273702,\n",
       "   'feature_preprocessor:polynomial:degree': 2,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'False',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'False',\n",
       "   'regressor:random_forest:bootstrap': 'False',\n",
       "   'regressor:random_forest:criterion': 'mae',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.5896697784449347,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 2,\n",
       "   'regressor:random_forest:min_samples_split': 5,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.43158603665302636,\n",
       "   'regressor:random_forest:bootstrap': 'True',\n",
       "   'regressor:random_forest:criterion': 'friedman_mse',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.6238016332735743,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 9,\n",
       "   'regressor:random_forest:min_samples_split': 20,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'kernel_pca',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0005003330413156686,\n",
       "   'feature_preprocessor:kernel_pca:kernel': 'rbf',\n",
       "   'feature_preprocessor:kernel_pca:n_components': 1595,\n",
       "   'regressor:ridge_regression:alpha': 224.87840598015808,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 7.240072896967454e-07,\n",
       "   'feature_preprocessor:kernel_pca:gamma': 0.00014778602331160602},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'feature_preprocessor:polynomial:degree': 3,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'True',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'False',\n",
       "   'regressor:random_forest:bootstrap': 'True',\n",
       "   'regressor:random_forest:criterion': 'mae',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.33392393701443845,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 4,\n",
       "   'regressor:random_forest:min_samples_split': 16,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.004773954938851752,\n",
       "   'feature_preprocessor:pca:keep_variance': 0.5967280105839579,\n",
       "   'feature_preprocessor:pca:whiten': 'True',\n",
       "   'regressor:random_forest:bootstrap': 'True',\n",
       "   'regressor:random_forest:criterion': 'mae',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.25385437486349927,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 8,\n",
       "   'regressor:random_forest:min_samples_split': 15,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 1203,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'uniform',\n",
       "   'feature_preprocessor:pca:keep_variance': 0.6460060439477255,\n",
       "   'feature_preprocessor:pca:whiten': 'True',\n",
       "   'regressor:extra_trees:bootstrap': 'False',\n",
       "   'regressor:extra_trees:criterion': 'friedman_mse',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.30297201449265165,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 14,\n",
       "   'regressor:extra_trees:min_samples_split': 14},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.07046543983677538,\n",
       "   'regressor:ridge_regression:alpha': 1830.5021507821218,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 6.435525165118922e-07},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0004403208803908124,\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'True',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 4,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 14,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 17,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 46,\n",
       "   'regressor:random_forest:bootstrap': 'True',\n",
       "   'regressor:random_forest:criterion': 'mae',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.9196484334535514,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 20,\n",
       "   'regressor:random_forest:min_samples_split': 18,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.2660519653011405,\n",
       "   'regressor:ridge_regression:alpha': 1343.8188353278997,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 1.3929528635141116e-07},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.06739269463625112,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.9886214630162944,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.17251642631953762,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'True',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'friedman_mse',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.4765491223854692,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 19,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 12,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:ridge_regression:alpha': 361.5422846364324,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 1.2842725918655613e-06},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'feature_agglomeration',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.017656970926967604,\n",
       "   'feature_preprocessor:feature_agglomeration:affinity': 'euclidean',\n",
       "   'feature_preprocessor:feature_agglomeration:linkage': 'ward',\n",
       "   'feature_preprocessor:feature_agglomeration:n_clusters': 114,\n",
       "   'feature_preprocessor:feature_agglomeration:pooling_func': 'max',\n",
       "   'regressor:extra_trees:bootstrap': 'False',\n",
       "   'regressor:extra_trees:criterion': 'mae',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.5987119262641407,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 7,\n",
       "   'regressor:extra_trees:min_samples_split': 12},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'regressor:random_forest:bootstrap': 'True',\n",
       "   'regressor:random_forest:criterion': 'friedman_mse',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.1011034925764151,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 19,\n",
       "   'regressor:random_forest:min_samples_split': 17,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.14366815826505042,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.9729478107777767,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.29203876107216736,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'False',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'friedman_mse',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.1721366800763598,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 3,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 15,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:ridge_regression:alpha': 4967.343418282986,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 2.2579200483044577e-07},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'True',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 8,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 14,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 12,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 17,\n",
       "   'regressor:extra_trees:bootstrap': 'False',\n",
       "   'regressor:extra_trees:criterion': 'friedman_mse',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.2526807361961485,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 9,\n",
       "   'regressor:extra_trees:min_samples_split': 19},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.03337225996513277,\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'True',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 2,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 16,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 12,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 70,\n",
       "   'regressor:random_forest:bootstrap': 'True',\n",
       "   'regressor:random_forest:criterion': 'mae',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.5097653925592535,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 19,\n",
       "   'regressor:random_forest:min_samples_split': 11,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.15353203141008892,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.9632264844386853,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.17251642631953762,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'True',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'mse',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.4765491223854692,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 15,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 12,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:ridge_regression:alpha': 702.8418264371663,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 2.8612927121827023e-06},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'feature_agglomeration',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.00797365349826379,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 1347,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'normal',\n",
       "   'feature_preprocessor:feature_agglomeration:affinity': 'euclidean',\n",
       "   'feature_preprocessor:feature_agglomeration:linkage': 'complete',\n",
       "   'feature_preprocessor:feature_agglomeration:n_clusters': 175,\n",
       "   'feature_preprocessor:feature_agglomeration:pooling_func': 'max',\n",
       "   'regressor:extra_trees:bootstrap': 'False',\n",
       "   'regressor:extra_trees:criterion': 'mae',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.1557291856564538,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 7,\n",
       "   'regressor:extra_trees:min_samples_split': 3},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.024732837477146014,\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'False',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 2,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 2,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 10,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 44,\n",
       "   'regressor:ridge_regression:alpha': 1133.8273382498498,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 1.640562394961934e-07},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.13517017206182202,\n",
       "   'feature_preprocessor:polynomial:degree': 2,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'False',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'False',\n",
       "   'regressor:ridge_regression:alpha': 714.4378168754694,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 1.9809069119474426e-05},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.010000000000000004,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'True',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'friedman_mse',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.19727460370839456,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 15,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 14,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:ridge_regression:alpha': 3525.5527967092194,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 9.022558952173345e-07},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'feature_preprocessor:pca:keep_variance': 0.7911899246981227,\n",
       "   'feature_preprocessor:pca:whiten': 'True',\n",
       "   'regressor:ridge_regression:alpha': 3640.0869069841997,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 3.8881067360985393e-07},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'feature_agglomeration',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.22878556812194428,\n",
       "   'feature_preprocessor:feature_agglomeration:affinity': 'manhattan',\n",
       "   'feature_preprocessor:feature_agglomeration:linkage': 'average',\n",
       "   'feature_preprocessor:feature_agglomeration:n_clusters': 395,\n",
       "   'feature_preprocessor:feature_agglomeration:pooling_func': 'max',\n",
       "   'regressor:ridge_regression:alpha': 291.09394060447465,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 1.606323351105396e-05},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'False',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'friedman_mse',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.8254656575948118,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 14,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 7,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:ridge_regression:alpha': 1305.0389433795815,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 3.731444974835353e-05},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.1166445026239193,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'False',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'friedman_mse',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.7841133578114059,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 17,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 9,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:ridge_regression:alpha': 4612.353089482255,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 2.665622231697457e-07},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0013675672974993811,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.8754878036637634,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.10098283441786471,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'False',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'mae',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.9887486805482828,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 12,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 14,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:random_forest:bootstrap': 'False',\n",
       "   'regressor:random_forest:criterion': 'mae',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.23684671922922562,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 19,\n",
       "   'regressor:random_forest:min_samples_split': 6,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 783,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'uniform',\n",
       "   'regressor:extra_trees:bootstrap': 'True',\n",
       "   'regressor:extra_trees:criterion': 'mse',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.9353708147244134,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 18,\n",
       "   'regressor:extra_trees:min_samples_split': 7},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'True',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'friedman_mse',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.2666258236594137,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 6,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 18,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:ridge_regression:alpha': 651.119867956726,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 3.277887103958789e-07},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'feature_agglomeration',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.03769544930976186,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.9411329267112912,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.28087845703642267,\n",
       "   'feature_preprocessor:feature_agglomeration:affinity': 'manhattan',\n",
       "   'feature_preprocessor:feature_agglomeration:linkage': 'complete',\n",
       "   'feature_preprocessor:feature_agglomeration:n_clusters': 127,\n",
       "   'feature_preprocessor:feature_agglomeration:pooling_func': 'max',\n",
       "   'regressor:ridge_regression:alpha': 1507.5087892771232,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 6.441110183898934e-05},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'feature_agglomeration',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.03532912214147506,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.8778510798440018,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.17600799709583767,\n",
       "   'feature_preprocessor:feature_agglomeration:affinity': 'cosine',\n",
       "   'feature_preprocessor:feature_agglomeration:linkage': 'complete',\n",
       "   'feature_preprocessor:feature_agglomeration:n_clusters': 25,\n",
       "   'feature_preprocessor:feature_agglomeration:pooling_func': 'max',\n",
       "   'regressor:ridge_regression:alpha': 1042.5057960510446,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 3.005863415778308e-05},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'feature_agglomeration',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'feature_preprocessor:feature_agglomeration:affinity': 'euclidean',\n",
       "   'feature_preprocessor:feature_agglomeration:linkage': 'complete',\n",
       "   'feature_preprocessor:feature_agglomeration:n_clusters': 250,\n",
       "   'feature_preprocessor:feature_agglomeration:pooling_func': 'mean',\n",
       "   'regressor:random_forest:bootstrap': 'False',\n",
       "   'regressor:random_forest:criterion': 'mae',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.6569422856214476,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 6,\n",
       "   'regressor:random_forest:min_samples_split': 8,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.06040661385678763,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'False',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'mae',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.3595616571193596,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 4,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 4,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:ridge_regression:alpha': 4258.664590999392,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 3.439209059533015e-07},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.010000000000000004,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'True',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'mae',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.12550379013234467,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 1,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 8,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:ridge_regression:alpha': 1314.8244938747746,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 2.0664914624836635e-07}],\n",
       " 'rank_test_scores': array([75, 75, 75, 39, 75, 69, 75, 75, 75, 75, 60,  6, 59, 75, 75, 75, 57,\n",
       "        75, 75, 75, 75, 41, 35, 70, 75, 34, 66, 26, 55, 52, 75, 63,  8, 21,\n",
       "        71, 21, 75, 75, 18,  9, 29, 24, 75, 43, 75, 44, 75, 75, 25, 15, 36,\n",
       "        40, 48,  4, 75, 75, 75, 75, 75, 75, 38, 75, 75, 64, 31, 75, 75, 28,\n",
       "        33, 13, 12, 20, 75, 75, 37, 14, 23, 27, 75, 58, 65, 42, 75, 75, 75,\n",
       "        72, 75, 73, 16, 30, 16, 75, 74, 68, 18, 53,  5, 67, 75, 75, 75, 75,\n",
       "        75, 62, 11, 75, 10, 46, 75,  2, 50, 75, 75, 51, 75, 56, 75, 54, 61,\n",
       "        32, 47, 45, 75,  1, 49,  3,  7, 75, 75, 75]),\n",
       " 'status': ['Memout',\n",
       "  'Timeout',\n",
       "  'Timeout',\n",
       "  'Success',\n",
       "  'Timeout',\n",
       "  'Success',\n",
       "  'Memout',\n",
       "  'Timeout',\n",
       "  'Timeout',\n",
       "  'Timeout',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Memout',\n",
       "  'Timeout',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Timeout',\n",
       "  'Memout',\n",
       "  'Timeout',\n",
       "  'Timeout',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Timeout',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Timeout',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Timeout',\n",
       "  'Timeout',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Timeout',\n",
       "  'Success',\n",
       "  'Memout',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Memout',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Timeout',\n",
       "  'Timeout',\n",
       "  'Timeout',\n",
       "  'Memout',\n",
       "  'Memout',\n",
       "  'Timeout',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Crash',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Timeout',\n",
       "  'Timeout',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Memout',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Timeout',\n",
       "  'Timeout',\n",
       "  'Success',\n",
       "  'Timeout',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Memout',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Timeout',\n",
       "  'Timeout',\n",
       "  'Crash',\n",
       "  'Memout',\n",
       "  'Timeout',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Timeout',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Timeout',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Timeout',\n",
       "  'Success',\n",
       "  'Timeout',\n",
       "  'Success',\n",
       "  'Memout',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Timeout',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Timeout',\n",
       "  'Timeout',\n",
       "  'Timeout'],\n",
       " 'budgets': [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " 'param_data_preprocessing:categorical_transformer:categorical_encoding:__choice__': masked_array(data=['one_hot_encoding', 'no_encoding', 'no_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding', 'no_encoding',\n",
       "                    'no_encoding', 'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding', 'no_encoding',\n",
       "                    'no_encoding', 'no_encoding', 'one_hot_encoding',\n",
       "                    'no_encoding', 'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'no_encoding', 'no_encoding', 'no_encoding',\n",
       "                    'one_hot_encoding', 'no_encoding', 'no_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding', 'no_encoding',\n",
       "                    'no_encoding', 'one_hot_encoding', 'no_encoding',\n",
       "                    'no_encoding', 'no_encoding', 'one_hot_encoding',\n",
       "                    'no_encoding', 'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'no_encoding', 'one_hot_encoding',\n",
       "                    'no_encoding', 'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'no_encoding', 'no_encoding', 'no_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding', 'no_encoding',\n",
       "                    'one_hot_encoding', 'no_encoding', 'one_hot_encoding',\n",
       "                    'no_encoding', 'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'no_encoding', 'one_hot_encoding',\n",
       "                    'no_encoding', 'one_hot_encoding', 'no_encoding',\n",
       "                    'one_hot_encoding', 'no_encoding', 'no_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding', 'no_encoding',\n",
       "                    'one_hot_encoding', 'no_encoding', 'no_encoding',\n",
       "                    'one_hot_encoding', 'no_encoding', 'one_hot_encoding',\n",
       "                    'no_encoding', 'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'no_encoding', 'one_hot_encoding', 'no_encoding',\n",
       "                    'no_encoding', 'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding', 'no_encoding',\n",
       "                    'one_hot_encoding', 'no_encoding', 'no_encoding',\n",
       "                    'no_encoding', 'no_encoding', 'one_hot_encoding',\n",
       "                    'no_encoding', 'no_encoding', 'no_encoding',\n",
       "                    'no_encoding', 'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'no_encoding', 'one_hot_encoding', 'no_encoding',\n",
       "                    'no_encoding', 'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'no_encoding', 'one_hot_encoding', 'no_encoding',\n",
       "                    'no_encoding', 'no_encoding', 'no_encoding',\n",
       "                    'no_encoding', 'no_encoding', 'no_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding', 'no_encoding',\n",
       "                    'one_hot_encoding', 'no_encoding', 'one_hot_encoding',\n",
       "                    'no_encoding', 'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'no_encoding', 'no_encoding'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U16'),\n",
       " 'param_data_preprocessing:categorical_transformer:category_coalescence:__choice__': masked_array(data=['minority_coalescer', 'no_coalescense',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'no_coalescense', 'no_coalescense', 'no_coalescense',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'no_coalescense', 'no_coalescense',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'no_coalescense', 'no_coalescense',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'no_coalescense', 'no_coalescense',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'minority_coalescer'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U18'),\n",
       " 'param_data_preprocessing:numerical_transformer:imputation:strategy': masked_array(data=['mean', 'most_frequent', 'median', 'median',\n",
       "                    'most_frequent', 'mean', 'median', 'most_frequent',\n",
       "                    'mean', 'mean', 'mean', 'most_frequent',\n",
       "                    'most_frequent', 'most_frequent', 'median', 'median',\n",
       "                    'median', 'most_frequent', 'median', 'median', 'mean',\n",
       "                    'most_frequent', 'most_frequent', 'most_frequent',\n",
       "                    'median', 'most_frequent', 'most_frequent', 'median',\n",
       "                    'most_frequent', 'most_frequent', 'mean', 'median',\n",
       "                    'median', 'median', 'median', 'most_frequent',\n",
       "                    'most_frequent', 'median', 'mean', 'most_frequent',\n",
       "                    'most_frequent', 'mean', 'most_frequent', 'median',\n",
       "                    'mean', 'most_frequent', 'median', 'mean', 'median',\n",
       "                    'mean', 'mean', 'mean', 'median', 'most_frequent',\n",
       "                    'mean', 'mean', 'mean', 'most_frequent', 'mean',\n",
       "                    'mean', 'median', 'mean', 'median', 'mean',\n",
       "                    'most_frequent', 'median', 'mean', 'most_frequent',\n",
       "                    'most_frequent', 'most_frequent', 'median', 'median',\n",
       "                    'mean', 'median', 'most_frequent', 'most_frequent',\n",
       "                    'most_frequent', 'median', 'median', 'most_frequent',\n",
       "                    'most_frequent', 'most_frequent', 'median', 'median',\n",
       "                    'median', 'median', 'mean', 'most_frequent', 'median',\n",
       "                    'median', 'median', 'most_frequent', 'most_frequent',\n",
       "                    'median', 'most_frequent', 'mean', 'mean', 'mean',\n",
       "                    'mean', 'median', 'most_frequent', 'median',\n",
       "                    'most_frequent', 'mean', 'mean', 'median', 'median',\n",
       "                    'most_frequent', 'median', 'mean', 'most_frequent',\n",
       "                    'median', 'mean', 'most_frequent', 'median', 'median',\n",
       "                    'most_frequent', 'most_frequent', 'mean',\n",
       "                    'most_frequent', 'median', 'mean', 'mean', 'median',\n",
       "                    'most_frequent', 'most_frequent', 'most_frequent',\n",
       "                    'most_frequent', 'median', 'median'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U13'),\n",
       " 'param_data_preprocessing:numerical_transformer:rescaling:__choice__': masked_array(data=['standardize', 'none', 'standardize', 'normalize',\n",
       "                    'robust_scaler', 'robust_scaler', 'robust_scaler',\n",
       "                    'quantile_transformer', 'standardize', 'robust_scaler',\n",
       "                    'robust_scaler', 'minmax', 'none', 'none', 'normalize',\n",
       "                    'robust_scaler', 'quantile_transformer', 'normalize',\n",
       "                    'minmax', 'quantile_transformer', 'normalize',\n",
       "                    'robust_scaler', 'quantile_transformer', 'minmax',\n",
       "                    'standardize', 'none', 'minmax', 'normalize',\n",
       "                    'quantile_transformer', 'quantile_transformer', 'none',\n",
       "                    'quantile_transformer', 'standardize', 'standardize',\n",
       "                    'none', 'normalize', 'standardize',\n",
       "                    'quantile_transformer', 'robust_scaler',\n",
       "                    'robust_scaler', 'none', 'minmax', 'standardize',\n",
       "                    'quantile_transformer', 'standardize', 'standardize',\n",
       "                    'normalize', 'normalize', 'standardize', 'normalize',\n",
       "                    'standardize', 'minmax', 'robust_scaler', 'normalize',\n",
       "                    'minmax', 'robust_scaler', 'normalize', 'none', 'none',\n",
       "                    'minmax', 'normalize', 'none', 'none',\n",
       "                    'quantile_transformer', 'standardize', 'robust_scaler',\n",
       "                    'robust_scaler', 'minmax', 'minmax', 'minmax',\n",
       "                    'standardize', 'standardize', 'robust_scaler', 'none',\n",
       "                    'minmax', 'normalize', 'normalize', 'normalize',\n",
       "                    'none', 'normalize', 'normalize', 'normalize',\n",
       "                    'quantile_transformer', 'quantile_transformer',\n",
       "                    'normalize', 'minmax', 'normalize', 'standardize',\n",
       "                    'none', 'normalize', 'none', 'none', 'minmax',\n",
       "                    'robust_scaler', 'normalize', 'normalize', 'normalize',\n",
       "                    'normalize', 'standardize', 'normalize', 'none',\n",
       "                    'standardize', 'minmax', 'quantile_transformer',\n",
       "                    'none', 'minmax', 'none', 'robust_scaler', 'minmax',\n",
       "                    'minmax', 'robust_scaler', 'minmax', 'standardize',\n",
       "                    'robust_scaler', 'quantile_transformer', 'minmax',\n",
       "                    'none', 'none', 'standardize', 'normalize', 'minmax',\n",
       "                    'none', 'robust_scaler', 'quantile_transformer',\n",
       "                    'minmax', 'robust_scaler', 'robust_scaler', 'none',\n",
       "                    'minmax', 'standardize'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U20'),\n",
       " 'param_feature_preprocessor:__choice__': masked_array(data=['no_preprocessing', 'fast_ica', 'no_preprocessing',\n",
       "                    'no_preprocessing', 'no_preprocessing',\n",
       "                    'nystroem_sampler', 'polynomial', 'fast_ica',\n",
       "                    'feature_agglomeration', 'pca', 'nystroem_sampler',\n",
       "                    'feature_agglomeration', 'feature_agglomeration',\n",
       "                    'polynomial', 'feature_agglomeration',\n",
       "                    'feature_agglomeration', 'random_trees_embedding',\n",
       "                    'random_trees_embedding', 'random_trees_embedding',\n",
       "                    'extra_trees_preproc_for_regression', 'fast_ica',\n",
       "                    'feature_agglomeration', 'no_preprocessing',\n",
       "                    'kitchen_sinks', 'extra_trees_preproc_for_regression',\n",
       "                    'fast_ica', 'pca', 'feature_agglomeration',\n",
       "                    'feature_agglomeration', 'feature_agglomeration',\n",
       "                    'extra_trees_preproc_for_regression', 'pca',\n",
       "                    'feature_agglomeration', 'feature_agglomeration',\n",
       "                    'nystroem_sampler', 'feature_agglomeration',\n",
       "                    'no_preprocessing', 'fast_ica', 'fast_ica',\n",
       "                    'feature_agglomeration', 'feature_agglomeration',\n",
       "                    'feature_agglomeration', 'no_preprocessing', 'pca',\n",
       "                    'polynomial', 'feature_agglomeration', 'pca', 'pca',\n",
       "                    'feature_agglomeration', 'feature_agglomeration',\n",
       "                    'no_preprocessing', 'no_preprocessing',\n",
       "                    'extra_trees_preproc_for_regression',\n",
       "                    'feature_agglomeration', 'no_preprocessing',\n",
       "                    'extra_trees_preproc_for_regression', 'polynomial',\n",
       "                    'polynomial', 'polynomial', 'polynomial',\n",
       "                    'feature_agglomeration', 'fast_ica', 'polynomial',\n",
       "                    'pca', 'feature_agglomeration', 'polynomial',\n",
       "                    'extra_trees_preproc_for_regression',\n",
       "                    'feature_agglomeration', 'feature_agglomeration',\n",
       "                    'no_preprocessing', 'no_preprocessing',\n",
       "                    'no_preprocessing', 'no_preprocessing',\n",
       "                    'random_trees_embedding', 'feature_agglomeration',\n",
       "                    'no_preprocessing', 'no_preprocessing', 'fast_ica',\n",
       "                    'polynomial', 'random_trees_embedding',\n",
       "                    'random_trees_embedding', 'feature_agglomeration',\n",
       "                    'kernel_pca', 'polynomial', 'no_preprocessing',\n",
       "                    'fast_ica', 'fast_ica', 'fast_ica',\n",
       "                    'feature_agglomeration', 'no_preprocessing',\n",
       "                    'feature_agglomeration', 'no_preprocessing',\n",
       "                    'fast_ica', 'kitchen_sinks', 'no_preprocessing',\n",
       "                    'extra_trees_preproc_for_regression',\n",
       "                    'feature_agglomeration', 'feature_agglomeration',\n",
       "                    'polynomial', 'no_preprocessing', 'kernel_pca',\n",
       "                    'polynomial', 'pca', 'pca', 'no_preprocessing',\n",
       "                    'random_trees_embedding', 'no_preprocessing',\n",
       "                    'extra_trees_preproc_for_regression',\n",
       "                    'feature_agglomeration', 'no_preprocessing',\n",
       "                    'extra_trees_preproc_for_regression',\n",
       "                    'random_trees_embedding', 'random_trees_embedding',\n",
       "                    'extra_trees_preproc_for_regression',\n",
       "                    'feature_agglomeration', 'random_trees_embedding',\n",
       "                    'polynomial', 'extra_trees_preproc_for_regression',\n",
       "                    'pca', 'feature_agglomeration',\n",
       "                    'extra_trees_preproc_for_regression',\n",
       "                    'extra_trees_preproc_for_regression',\n",
       "                    'extra_trees_preproc_for_regression',\n",
       "                    'no_preprocessing',\n",
       "                    'extra_trees_preproc_for_regression',\n",
       "                    'feature_agglomeration', 'feature_agglomeration',\n",
       "                    'feature_agglomeration',\n",
       "                    'extra_trees_preproc_for_regression',\n",
       "                    'extra_trees_preproc_for_regression'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U34'),\n",
       " 'param_regressor:__choice__': masked_array(data=['random_forest', 'ridge_regression', 'random_forest',\n",
       "                    'ridge_regression', 'random_forest',\n",
       "                    'ridge_regression', 'random_forest', 'random_forest',\n",
       "                    'random_forest', 'extra_trees', 'ridge_regression',\n",
       "                    'ridge_regression', 'ridge_regression',\n",
       "                    'ridge_regression', 'extra_trees', 'extra_trees',\n",
       "                    'ridge_regression', 'random_forest', 'extra_trees',\n",
       "                    'random_forest', 'random_forest', 'ridge_regression',\n",
       "                    'ridge_regression', 'ridge_regression',\n",
       "                    'ridge_regression', 'ridge_regression',\n",
       "                    'ridge_regression', 'ridge_regression',\n",
       "                    'ridge_regression', 'ridge_regression',\n",
       "                    'random_forest', 'ridge_regression',\n",
       "                    'ridge_regression', 'ridge_regression',\n",
       "                    'ridge_regression', 'ridge_regression',\n",
       "                    'random_forest', 'random_forest', 'ridge_regression',\n",
       "                    'ridge_regression', 'ridge_regression',\n",
       "                    'ridge_regression', 'random_forest',\n",
       "                    'ridge_regression', 'extra_trees', 'ridge_regression',\n",
       "                    'random_forest', 'extra_trees', 'ridge_regression',\n",
       "                    'ridge_regression', 'ridge_regression',\n",
       "                    'ridge_regression', 'ridge_regression',\n",
       "                    'ridge_regression', 'random_forest', 'random_forest',\n",
       "                    'extra_trees', 'random_forest', 'ridge_regression',\n",
       "                    'extra_trees', 'ridge_regression', 'extra_trees',\n",
       "                    'random_forest', 'ridge_regression',\n",
       "                    'ridge_regression', 'extra_trees', 'extra_trees',\n",
       "                    'ridge_regression', 'ridge_regression',\n",
       "                    'ridge_regression', 'ridge_regression',\n",
       "                    'ridge_regression', 'random_forest', 'random_forest',\n",
       "                    'ridge_regression', 'ridge_regression',\n",
       "                    'ridge_regression', 'ridge_regression', 'extra_trees',\n",
       "                    'ridge_regression', 'ridge_regression',\n",
       "                    'ridge_regression', 'ridge_regression',\n",
       "                    'random_forest', 'random_forest', 'ridge_regression',\n",
       "                    'ridge_regression', 'ridge_regression',\n",
       "                    'ridge_regression', 'ridge_regression',\n",
       "                    'ridge_regression', 'extra_trees', 'ridge_regression',\n",
       "                    'ridge_regression', 'ridge_regression',\n",
       "                    'ridge_regression', 'ridge_regression',\n",
       "                    'ridge_regression', 'random_forest', 'random_forest',\n",
       "                    'ridge_regression', 'random_forest', 'random_forest',\n",
       "                    'extra_trees', 'ridge_regression', 'random_forest',\n",
       "                    'ridge_regression', 'ridge_regression', 'extra_trees',\n",
       "                    'random_forest', 'ridge_regression', 'extra_trees',\n",
       "                    'random_forest', 'ridge_regression', 'extra_trees',\n",
       "                    'ridge_regression', 'ridge_regression',\n",
       "                    'ridge_regression', 'ridge_regression',\n",
       "                    'ridge_regression', 'ridge_regression',\n",
       "                    'ridge_regression', 'random_forest', 'extra_trees',\n",
       "                    'ridge_regression', 'ridge_regression',\n",
       "                    'ridge_regression', 'random_forest',\n",
       "                    'ridge_regression', 'ridge_regression'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U16'),\n",
       " 'param_data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': masked_array(data=[0.01, --, --, 0.018225373154476403, --, --, --, --,\n",
       "                    0.01587482042558028, --, 0.031519383715223226,\n",
       "                    0.16464462190388976, 0.0016477063712300928,\n",
       "                    0.018428862457105236, --, --, 0.0009339910521186708,\n",
       "                    --, 0.03380423545174408, --, --, 0.005265624963152827,\n",
       "                    0.0002073104715798369, --, 0.010319779633662133,\n",
       "                    0.02769366214354228, --, 0.31143906972438024,\n",
       "                    0.00010641369766317917, 0.00032397219493259086,\n",
       "                    0.060844685912740976, 0.00025963678346270876,\n",
       "                    0.01454485937859754, 0.07167013927558084,\n",
       "                    0.004803690343957523, 0.12472415873398403, --,\n",
       "                    0.00047167414606260645, 0.2628369688469089,\n",
       "                    0.009733627378880923, 0.007430049210347528,\n",
       "                    0.006124527231668457, 0.4522263915992745,\n",
       "                    0.015568372971125646, --, 0.16230286319906675,\n",
       "                    0.0037663019916282245, --, 0.07531834070187314,\n",
       "                    0.17096851867485746, --, --, --, 0.06679923104211231,\n",
       "                    --, --, 0.0001143008304053733, 0.0001182659453314944,\n",
       "                    --, 0.061866534063428034, 0.004765134371201316,\n",
       "                    0.018230516330224853, 0.29985772198416394, --,\n",
       "                    0.004653690952636547, 0.003704268441902656,\n",
       "                    0.03226742060891215, 0.1240841636140683,\n",
       "                    0.006230462700721226, 0.06182459627858525,\n",
       "                    0.15560814642506554, 0.1876120251369115,\n",
       "                    0.016199831041287433, --, 0.025627780631743393,\n",
       "                    0.38570462781045994, 0.1379024399075265,\n",
       "                    0.04965344815508581, --, 0.07503828417582162,\n",
       "                    0.0638618790992277, --, 0.04362528178935715,\n",
       "                    0.009439925924704577, --, 0.05602708968616209,\n",
       "                    0.18704282490072735, 0.1619387788708421,\n",
       "                    0.0035139043560294594, 0.05548618070018443,\n",
       "                    0.0035139043560294594, 0.004588712935353821,\n",
       "                    0.01710909782190678, 0.0038479498657412736,\n",
       "                    0.17670917565193384, --, 0.19643029797619796,\n",
       "                    0.14503759738418542, 0.0004013957326273702,\n",
       "                    0.43158603665302636, 0.0005003330413156686, --,\n",
       "                    0.004773954938851752, --, 0.07046543983677538,\n",
       "                    0.0004403208803908124, 0.2660519653011405,\n",
       "                    0.06739269463625112, 0.017656970926967604, --,\n",
       "                    0.14366815826505042, --, 0.03337225996513277,\n",
       "                    0.15353203141008892, 0.00797365349826379,\n",
       "                    0.024732837477146014, 0.13517017206182202,\n",
       "                    0.010000000000000004, --, 0.22878556812194428, --,\n",
       "                    0.1166445026239193, 0.0013675672974993811, --, --,\n",
       "                    0.03769544930976186, 0.03532912214147506, --,\n",
       "                    0.06040661385678763, 0.010000000000000004],\n",
       "              mask=[False,  True,  True, False,  True,  True,  True,  True,\n",
       "                    False,  True, False, False, False, False,  True,  True,\n",
       "                    False,  True, False,  True,  True, False, False,  True,\n",
       "                    False, False,  True, False, False, False, False, False,\n",
       "                    False, False, False, False,  True, False, False, False,\n",
       "                    False, False, False, False,  True, False, False,  True,\n",
       "                    False, False,  True,  True,  True, False,  True,  True,\n",
       "                    False, False,  True, False, False, False, False,  True,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False,  True, False, False, False, False,  True, False,\n",
       "                    False,  True, False, False,  True, False, False, False,\n",
       "                    False, False, False, False, False, False, False,  True,\n",
       "                    False, False, False, False, False,  True, False,  True,\n",
       "                    False, False, False, False, False,  True, False,  True,\n",
       "                    False, False, False, False, False, False,  True, False,\n",
       "                     True, False, False,  True,  True, False, False,  True,\n",
       "                    False, False],\n",
       "        fill_value=1e+20),\n",
       " 'param_data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': masked_array(data=[--, --, --, --, --, --, --, 480.0, --, --, --, --, --,\n",
       "                    --, --, --, 743.0, --, --, 1104.0, --, --, 1216.0, --,\n",
       "                    --, --, --, --, 838.0, 1000.0, --, 2000.0, --, --, --,\n",
       "                    --, --, 591.0, --, --, --, --, --, 263.0, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 1965.0, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 491.0, 298.0, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 1203.0, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 1347.0, --, --, --, --, --, --, --, --, 783.0, --,\n",
       "                    --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True, False,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True, False, False,  True, False,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': masked_array(data=[--, --, --, --, --, --, --, 'uniform', --, --, --, --,\n",
       "                    --, --, --, --, 'uniform', --, --, 'uniform', --, --,\n",
       "                    'normal', --, --, --, --, --, 'normal', 'normal', --,\n",
       "                    'uniform', --, --, --, --, --, 'normal', --, --, --,\n",
       "                    --, --, 'normal', --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, 'normal', --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 'normal', 'uniform', --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    'uniform', --, --, --, --, --, --, --, --, --, --,\n",
       "                    'normal', --, --, --, --, --, --, --, --, 'uniform',\n",
       "                    --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True, False,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True, False, False,  True, False,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U32'),\n",
       " 'param_data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': masked_array(data=[--, --, --, --, 0.857856422838131, 0.7290527372667672,\n",
       "                    0.7436805191863465, --, --, 0.9797829546144647,\n",
       "                    0.8983178657352634, --, --, --, --, 0.994735436444351,\n",
       "                    --, --, --, --, --, 0.8900236538967836, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    0.8782349391062089, 0.75, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 0.8575562916534851, --, --,\n",
       "                    0.9915188892728427, --, --, --, --, --, --, --, --, --,\n",
       "                    0.925159394762694, 0.7740090729004457, --, --, --, --,\n",
       "                    --, 0.9870545192045517, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    0.771122294927281, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 0.9886214630162944, --, --,\n",
       "                    0.9729478107777767, --, --, 0.9632264844386853, --, --,\n",
       "                    --, --, --, --, --, --, 0.8754878036637634, --, --,\n",
       "                    0.9411329267112912, 0.8778510798440018, --, --, --],\n",
       "              mask=[ True,  True,  True,  True, False, False, False,  True,\n",
       "                     True, False, False,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False, False,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True, False,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True, False, False,  True,\n",
       "                     True,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': masked_array(data=[--, --, --, --, 0.16270327064031528,\n",
       "                    0.1675235381095665, 0.11916328045224628, --, --,\n",
       "                    0.22911553274913804, 0.2796707413712671, --, --, --,\n",
       "                    --, 0.020688473971890227, --, --, --, --, --,\n",
       "                    0.21963522074085387, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 0.21360564175822855,\n",
       "                    0.2607931921678484, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 0.19295076377819753, --, --,\n",
       "                    0.25379581948682567, --, --, --, --, --, --, --, --,\n",
       "                    --, 0.2364019812469151, 0.07282418654683423, --, --,\n",
       "                    --, --, --, 0.17458287943236145, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 0.27245697753095954, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 0.17251642631953762, --, --,\n",
       "                    0.29203876107216736, --, --, 0.17251642631953762, --,\n",
       "                    --, --, --, --, --, --, --, 0.10098283441786471, --,\n",
       "                    --, 0.28087845703642267, 0.17600799709583767, --, --,\n",
       "                    --],\n",
       "              mask=[ True,  True,  True,  True, False, False, False,  True,\n",
       "                     True, False, False,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False, False,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True, False,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True, False, False,  True,\n",
       "                     True,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': masked_array(data=[--, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 'False', --, --, --, --, 'False',\n",
       "                    --, --, --, --, --, 'True', --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    'True', --, --, 'False', --, --, --, --, --, --, --,\n",
       "                    --, --, --, 'True', --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 'True', --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 'True', --, --, 'False', --, --,\n",
       "                    'True', --, --, --, 'True', --, --, 'False', 'False',\n",
       "                    'False', --, 'True', --, --, --, 'False', 'True'],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True, False,  True,\n",
       "                     True, False,  True,  True,  True, False,  True,  True,\n",
       "                    False, False, False,  True, False,  True,  True,  True,\n",
       "                    False, False],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U32'),\n",
       " 'param_feature_preprocessor:extra_trees_preproc_for_regression:criterion': masked_array(data=[--, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 'friedman_mse', --, --, --, --,\n",
       "                    'mae', --, --, --, --, --, 'friedman_mse', --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 'friedman_mse', --, --, 'friedman_mse',\n",
       "                    --, --, --, --, --, --, --, --, --, --, 'mse', --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    'friedman_mse', --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 'friedman_mse', --, --, 'friedman_mse', --, --,\n",
       "                    'mse', --, --, --, 'friedman_mse', --, --,\n",
       "                    'friedman_mse', 'friedman_mse', 'mae', --,\n",
       "                    'friedman_mse', --, --, --, 'mae', 'mae'],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True, False,  True,\n",
       "                     True, False,  True,  True,  True, False,  True,  True,\n",
       "                    False, False, False,  True, False,  True,  True,  True,\n",
       "                    False, False],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U32'),\n",
       " 'param_feature_preprocessor:extra_trees_preproc_for_regression:max_depth': masked_array(data=[--, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 'None', --, --, --, --, 'None', --,\n",
       "                    --, --, --, --, 'None', --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    'None', --, --, 'None', --, --, --, --, --, --, --, --,\n",
       "                    --, --, 'None', --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 'None', --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 'None', --, --, 'None', --, --, 'None', --,\n",
       "                    --, --, 'None', --, --, 'None', 'None', 'None', --,\n",
       "                    'None', --, --, --, 'None', 'None'],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True, False,  True,\n",
       "                     True, False,  True,  True,  True, False,  True,  True,\n",
       "                    False, False, False,  True, False,  True,  True,  True,\n",
       "                    False, False],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U32'),\n",
       " 'param_feature_preprocessor:extra_trees_preproc_for_regression:max_features': masked_array(data=[--, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 0.7674378357889092, --, --, --, --,\n",
       "                    0.31652668742664525, --, --, --, --, --,\n",
       "                    0.8717152804886077, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    0.49565336345527633, --, --, 0.7627395281282661, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 0.684536617609959,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    0.41171688712811005, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 0.4765491223854692, --, --,\n",
       "                    0.1721366800763598, --, --, 0.4765491223854692, --, --,\n",
       "                    --, 0.19727460370839456, --, --, 0.8254656575948118,\n",
       "                    0.7841133578114059, 0.9887486805482828, --,\n",
       "                    0.2666258236594137, --, --, --, 0.3595616571193596,\n",
       "                    0.12550379013234467],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True, False,  True,\n",
       "                     True, False,  True,  True,  True, False,  True,  True,\n",
       "                    False, False, False,  True, False,  True,  True,  True,\n",
       "                    False, False],\n",
       "        fill_value=1e+20),\n",
       " 'param_feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': masked_array(data=[--, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 'None', --, --, --, --, 'None', --,\n",
       "                    --, --, --, --, 'None', --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    'None', --, --, 'None', --, --, --, --, --, --, --, --,\n",
       "                    --, --, 'None', --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 'None', --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 'None', --, --, 'None', --, --, 'None', --,\n",
       "                    --, --, 'None', --, --, 'None', 'None', 'None', --,\n",
       "                    'None', --, --, --, 'None', 'None'],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True, False,  True,\n",
       "                     True, False,  True,  True,  True, False,  True,  True,\n",
       "                    False, False, False,  True, False,  True,  True,  True,\n",
       "                    False, False],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U32'),\n",
       " 'param_feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': masked_array(data=[--, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 19.0, --, --, --, --, 6.0, --, --,\n",
       "                    --, --, --, 20.0, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, 14.0,\n",
       "                    --, --, 1.0, --, --, --, --, --, --, --, --, --, --,\n",
       "                    8.0, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 11.0, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 19.0, --, --, 3.0, --, --, 15.0, --, --, --, 15.0,\n",
       "                    --, --, 14.0, 17.0, 12.0, --, 6.0, --, --, --, 4.0,\n",
       "                    1.0],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True, False,  True,\n",
       "                     True, False,  True,  True,  True, False,  True,  True,\n",
       "                    False, False, False,  True, False,  True,  True,  True,\n",
       "                    False, False],\n",
       "        fill_value=1e+20),\n",
       " 'param_feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': masked_array(data=[--, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 5.0, --, --, --, --, 18.0, --, --,\n",
       "                    --, --, --, 2.0, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, 3.0,\n",
       "                    --, --, 16.0, --, --, --, --, --, --, --, --, --, --,\n",
       "                    2.0, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 18.0, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 12.0, --, --, 15.0, --, --, 12.0, --, --, --, 14.0,\n",
       "                    --, --, 7.0, 9.0, 14.0, --, 18.0, --, --, --, 4.0, 8.0],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True, False,  True,\n",
       "                     True, False,  True,  True,  True, False,  True,  True,\n",
       "                    False, False, False,  True, False,  True,  True,  True,\n",
       "                    False, False],\n",
       "        fill_value=1e+20),\n",
       " 'param_feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': masked_array(data=[--, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 0.0, --, --, --, --, 0.0, --, --,\n",
       "                    --, --, --, 0.0, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, 0.0,\n",
       "                    --, --, 0.0, --, --, --, --, --, --, --, --, --, --,\n",
       "                    0.0, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 0.0, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 0.0, --, --, 0.0, --, --, 0.0, --, --, --, 0.0, --,\n",
       "                    --, 0.0, 0.0, 0.0, --, 0.0, --, --, --, 0.0, 0.0],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True, False,  True,\n",
       "                     True, False,  True,  True,  True, False,  True,  True,\n",
       "                    False, False, False,  True, False,  True,  True,  True,\n",
       "                    False, False],\n",
       "        fill_value=1e+20),\n",
       " 'param_feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': masked_array(data=[--, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 100.0, --, --, --, --, 100.0, --,\n",
       "                    --, --, --, --, 100.0, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    100.0, --, --, 100.0, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 100.0, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 100.0, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 100.0, --, --, 100.0, --, --, 100.0, --,\n",
       "                    --, --, 100.0, --, --, 100.0, 100.0, 100.0, --, 100.0,\n",
       "                    --, --, --, 100.0, 100.0],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True, False,  True,\n",
       "                     True, False,  True,  True,  True, False,  True,  True,\n",
       "                    False, False, False,  True, False,  True,  True,  True,\n",
       "                    False, False],\n",
       "        fill_value=1e+20),\n",
       " 'param_feature_preprocessor:fast_ica:algorithm': masked_array(data=[--, 'deflation', --, --, --, --, --, 'deflation', --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, 'parallel',\n",
       "                    --, --, --, --, 'parallel', --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 'deflation', 'deflation', --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 'parallel', --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 'deflation', --,\n",
       "                    --, --, --, --, --, --, 'parallel', 'deflation',\n",
       "                    'deflation', --, --, --, --, 'deflation', --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --],\n",
       "              mask=[ True, False,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False, False, False,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U32'),\n",
       " 'param_feature_preprocessor:fast_ica:fun': masked_array(data=[--, 'logcosh', --, --, --, --, --, 'logcosh', --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, 'logcosh', --,\n",
       "                    --, --, --, 'logcosh', --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 'cube', 'exp', --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 'exp', --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 'exp', --, --, --, --, --, --, --,\n",
       "                    'logcosh', 'logcosh', 'exp', --, --, --, --, 'logcosh',\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --],\n",
       "              mask=[ True, False,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False, False, False,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U32'),\n",
       " 'param_feature_preprocessor:fast_ica:whiten': masked_array(data=[--, 'True', --, --, --, --, --, 'True', --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 'True', --, --, --, --,\n",
       "                    'False', --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    'True', 'False', --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    'False', --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 'False', --, --, --, --, --, --, --,\n",
       "                    'True', 'False', 'True', --, --, --, --, 'True', --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --],\n",
       "              mask=[ True, False,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False, False, False,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U32'),\n",
       " 'param_feature_preprocessor:feature_agglomeration:affinity': masked_array(data=[--, --, --, --, --, --, --, --, 'euclidean', --, --,\n",
       "                    'cosine', 'cosine', --, 'euclidean', 'cosine', --, --,\n",
       "                    --, --, --, 'cosine', --, --, --, --, --, 'manhattan',\n",
       "                    'euclidean', 'cosine', --, --, 'euclidean',\n",
       "                    'manhattan', --, 'euclidean', --, --, --, 'euclidean',\n",
       "                    'euclidean', 'cosine', --, --, --, 'euclidean', --, --,\n",
       "                    'cosine', 'cosine', --, --, --, 'manhattan', --, --,\n",
       "                    --, --, --, --, 'manhattan', --, --, --, 'cosine', --,\n",
       "                    --, 'manhattan', 'manhattan', --, --, --, --, --,\n",
       "                    'euclidean', --, --, --, --, --, --, 'manhattan', --,\n",
       "                    --, --, --, --, --, 'euclidean', --, 'euclidean', --,\n",
       "                    --, --, --, --, 'euclidean', 'euclidean', --, --, --,\n",
       "                    --, --, --, --, --, --, --, 'euclidean', --, --, --,\n",
       "                    --, --, 'euclidean', --, --, --, --, 'manhattan', --,\n",
       "                    --, --, --, --, 'manhattan', 'cosine', 'euclidean', --,\n",
       "                    --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True, False, False,  True, False, False,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True, False, False, False,  True,  True,\n",
       "                    False, False,  True, False,  True,  True,  True, False,\n",
       "                    False, False,  True,  True,  True, False,  True,  True,\n",
       "                    False, False,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                    False,  True,  True, False, False,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True, False,  True,  True,  True,  True,  True,\n",
       "                    False, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True, False, False, False,\n",
       "                     True,  True],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U32'),\n",
       " 'param_feature_preprocessor:feature_agglomeration:linkage': masked_array(data=[--, --, --, --, --, --, --, --, 'average', --, --,\n",
       "                    'complete', 'average', --, 'ward', 'complete', --, --,\n",
       "                    --, --, --, 'complete', --, --, --, --, --, 'complete',\n",
       "                    'average', 'complete', --, --, 'complete', 'complete',\n",
       "                    --, 'average', --, --, --, 'ward', 'average',\n",
       "                    'average', --, --, --, 'ward', --, --, 'average',\n",
       "                    'average', --, --, --, 'complete', --, --, --, --, --,\n",
       "                    --, 'complete', --, --, --, 'complete', --, --,\n",
       "                    'complete', 'complete', --, --, --, --, --, 'complete',\n",
       "                    --, --, --, --, --, --, 'complete', --, --, --, --, --,\n",
       "                    --, 'complete', --, 'complete', --, --, --, --, --,\n",
       "                    'complete', 'complete', --, --, --, --, --, --, --, --,\n",
       "                    --, --, 'ward', --, --, --, --, --, 'complete', --, --,\n",
       "                    --, --, 'average', --, --, --, --, --, 'complete',\n",
       "                    'complete', 'complete', --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True, False, False,  True, False, False,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True, False, False, False,  True,  True,\n",
       "                    False, False,  True, False,  True,  True,  True, False,\n",
       "                    False, False,  True,  True,  True, False,  True,  True,\n",
       "                    False, False,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                    False,  True,  True, False, False,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True, False,  True,  True,  True,  True,  True,\n",
       "                    False, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True, False, False, False,\n",
       "                     True,  True],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U32'),\n",
       " 'param_feature_preprocessor:feature_agglomeration:n_clusters': masked_array(data=[--, --, --, --, --, --, --, --, 247.0, --, --, 179.0,\n",
       "                    21.0, --, 101.0, 382.0, --, --, --, --, --, 182.0, --,\n",
       "                    --, --, --, --, 376.0, 25.0, 16.0, --, --, 320.0,\n",
       "                    298.0, --, 266.0, --, --, --, 285.0, 87.0, 325.0, --,\n",
       "                    --, --, 25.0, --, --, 156.0, 390.0, --, --, --, 149.0,\n",
       "                    --, --, --, --, --, --, 290.0, --, --, --, 375.0, --,\n",
       "                    --, 154.0, 256.0, --, --, --, --, --, 322.0, --, --,\n",
       "                    --, --, --, --, 208.0, --, --, --, --, --, --, 219.0,\n",
       "                    --, 219.0, --, --, --, --, --, 30.0, 3.0, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 114.0, --, --, --, --, --,\n",
       "                    175.0, --, --, --, --, 395.0, --, --, --, --, --,\n",
       "                    127.0, 25.0, 250.0, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True, False, False,  True, False, False,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True, False, False, False,  True,  True,\n",
       "                    False, False,  True, False,  True,  True,  True, False,\n",
       "                    False, False,  True,  True,  True, False,  True,  True,\n",
       "                    False, False,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                    False,  True,  True, False, False,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True, False,  True,  True,  True,  True,  True,\n",
       "                    False, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True, False, False, False,\n",
       "                     True,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_feature_preprocessor:feature_agglomeration:pooling_func': masked_array(data=[--, --, --, --, --, --, --, --, 'median', --, --,\n",
       "                    'max', 'median', --, 'max', 'max', --, --, --, --, --,\n",
       "                    'median', --, --, --, --, --, 'max', 'mean', 'max', --,\n",
       "                    --, 'mean', 'max', --, 'max', --, --, --, 'mean',\n",
       "                    'mean', 'mean', --, --, --, 'max', --, --, 'median',\n",
       "                    'max', --, --, --, 'max', --, --, --, --, --, --,\n",
       "                    'mean', --, --, --, 'median', --, --, 'median', 'max',\n",
       "                    --, --, --, --, --, 'max', --, --, --, --, --, --,\n",
       "                    'median', --, --, --, --, --, --, 'median', --,\n",
       "                    'median', --, --, --, --, --, 'max', 'max', --, --, --,\n",
       "                    --, --, --, --, --, --, --, 'max', --, --, --, --, --,\n",
       "                    'max', --, --, --, --, 'max', --, --, --, --, --,\n",
       "                    'max', 'max', 'mean', --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True, False, False,  True, False, False,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True, False, False, False,  True,  True,\n",
       "                    False, False,  True, False,  True,  True,  True, False,\n",
       "                    False, False,  True,  True,  True, False,  True,  True,\n",
       "                    False, False,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                    False,  True,  True, False, False,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True, False,  True,  True,  True,  True,  True,\n",
       "                    False, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True, False, False, False,\n",
       "                     True,  True],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U32'),\n",
       " 'param_feature_preprocessor:kernel_pca:kernel': masked_array(data=[--, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, 'rbf',\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 'rbf', --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U32'),\n",
       " 'param_feature_preprocessor:kernel_pca:n_components': masked_array(data=[--, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, 439.0,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 1595.0, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_feature_preprocessor:kitchen_sinks:gamma': masked_array(data=[--, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 4.578081692221954,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    0.00010518986968354852, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_feature_preprocessor:kitchen_sinks:n_components': masked_array(data=[--, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 891.0, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, 229.0, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_feature_preprocessor:nystroem_sampler:kernel': masked_array(data=[--, --, --, --, --, 'cosine', --, --, --, --, 'cosine',\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 'rbf', --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U32'),\n",
       " 'param_feature_preprocessor:nystroem_sampler:n_components': masked_array(data=[--, --, --, --, --, 1484.0, --, --, --, --, 197.0, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 3782.0, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_feature_preprocessor:pca:keep_variance': masked_array(data=[--, --, --, --, --, --, --, --, --, 0.7597024223078015,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 0.6141215545759248, --, --, --, --,\n",
       "                    0.6753054326391816, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 0.962823709365242, --, --, 0.757716943583408,\n",
       "                    0.9134536500100956, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 0.5628006106285901, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 0.5967280105839579,\n",
       "                    0.6460060439477255, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 0.7911899246981227, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True, False, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_feature_preprocessor:pca:whiten': masked_array(data=[--, --, --, --, --, --, --, --, --, 'True', --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    'True', --, --, --, --, 'True', --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 'True', --, --, 'True', 'True', --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    'True', --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, 'True',\n",
       "                    'True', --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 'True', --, --, --, --, --, --, --, --, --, --,\n",
       "                    --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True, False, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U32'),\n",
       " 'param_feature_preprocessor:polynomial:degree': masked_array(data=[--, --, --, --, --, --, 3.0, --, --, --, --, --, --,\n",
       "                    2.0, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 3.0, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 2.0, 3.0, 3.0, 2.0, --, --, 2.0, --, --,\n",
       "                    2.0, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    3.0, --, --, --, --, 2.0, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 2.0, --, --, 3.0, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, 2.0,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False, False, False, False,  True,  True, False,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_feature_preprocessor:polynomial:include_bias': masked_array(data=[--, --, --, --, --, --, 'False', --, --, --, --, --,\n",
       "                    --, 'True', --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 'False', --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 'True', 'True', 'False', 'False',\n",
       "                    --, --, 'True', --, --, 'False', --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 'False', --, --, --, --,\n",
       "                    'False', --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 'False', --, --, 'True', --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, 'False', --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False, False, False, False,  True,  True, False,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U32'),\n",
       " 'param_feature_preprocessor:polynomial:interaction_only': masked_array(data=[--, --, --, --, --, --, 'True', --, --, --, --, --, --,\n",
       "                    'True', --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 'True', --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 'False', 'True', 'True', 'False', --, --,\n",
       "                    'False', --, --, 'False', --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 'True', --, --, --, --, 'True', --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    'False', --, --, 'False', --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 'False', --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False, False, False, False,  True,  True, False,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U32'),\n",
       " 'param_feature_preprocessor:random_trees_embedding:bootstrap': masked_array(data=[--, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 'True', 'True', 'True', --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 'True', --, --, --, --, --,\n",
       "                    'False', 'True', --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 'True', --, --, --, --, --, 'True', 'True', --, --,\n",
       "                    'False', --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False, False, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True, False,\n",
       "                    False,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U32'),\n",
       " 'param_feature_preprocessor:random_trees_embedding:max_depth': masked_array(data=[--, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 5.0, 4.0, 9.0, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 3.0, --, --, --, --, --, 9.0, 2.0, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 4.0, --, --, --,\n",
       "                    --, --, 8.0, 2.0, --, --, 2.0, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False, False, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True, False,\n",
       "                    False,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_feature_preprocessor:random_trees_embedding:max_leaf_nodes': masked_array(data=[--, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 'None', 'None', 'None', --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 'None', --, --, --, --, --,\n",
       "                    'None', 'None', --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    'None', --, --, --, --, --, 'None', 'None', --, --,\n",
       "                    'None', --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False, False, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True, False,\n",
       "                    False,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U32'),\n",
       " 'param_feature_preprocessor:random_trees_embedding:min_samples_leaf': masked_array(data=[--, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 19.0, 16.0, 18.0, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 1.0, --, --, --, --, --, 13.0,\n",
       "                    13.0, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, 14.0,\n",
       "                    --, --, --, --, --, 14.0, 16.0, --, --, 2.0, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False, False, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True, False,\n",
       "                    False,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_feature_preprocessor:random_trees_embedding:min_samples_split': masked_array(data=[--, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 4.0, 17.0, 10.0, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 2.0, --, --, --, --, --, 7.0, 13.0,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, 17.0, --, --,\n",
       "                    --, --, --, 12.0, 12.0, --, --, 10.0, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False, False, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True, False,\n",
       "                    False,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': masked_array(data=[--, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 1.0, 1.0, 1.0, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 1.0, --, --, --, --, --, 1.0, 1.0, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 1.0, --, --, --,\n",
       "                    --, --, 1.0, 1.0, --, --, 1.0, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False, False, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True, False,\n",
       "                    False,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_feature_preprocessor:random_trees_embedding:n_estimators': masked_array(data=[--, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 62.0, 86.0, 92.0, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 83.0, --, --, --, --, --, 15.0,\n",
       "                    12.0, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, 46.0,\n",
       "                    --, --, --, --, --, 17.0, 70.0, --, --, 44.0, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False, False, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True, False,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True, False,\n",
       "                    False,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_regressor:extra_trees:bootstrap': masked_array(data=[--, --, --, --, --, --, --, --, --, 'True', --, --, --,\n",
       "                    --, 'False', 'False', --, --, 'False', --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 'True', --, --, 'False',\n",
       "                    --, --, --, --, --, --, --, --, 'False', --, --,\n",
       "                    'False', --, 'True', --, --, --, 'False', 'False', --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, 'False', --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, 'False',\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, 'False',\n",
       "                    --, --, --, --, 'False', --, --, 'False', --, --,\n",
       "                    'False', --, --, --, --, --, --, --, --, 'True', --,\n",
       "                    --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True, False, False,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True, False,  True, False,  True,  True,\n",
       "                     True, False, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True, False,  True,  True, False,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U32'),\n",
       " 'param_regressor:extra_trees:criterion': masked_array(data=[--, --, --, --, --, --, --, --, --, 'mae', --, --, --,\n",
       "                    --, 'mae', 'friedman_mse', --, --, 'friedman_mse', --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, 'friedman_mse',\n",
       "                    --, --, 'friedman_mse', --, --, --, --, --, --, --, --,\n",
       "                    'friedman_mse', --, --, 'mse', --, 'friedman_mse', --,\n",
       "                    --, --, 'mse', 'mse', --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 'friedman_mse', --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 'mse', --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 'friedman_mse', --, --, --, --, 'mae',\n",
       "                    --, --, 'friedman_mse', --, --, 'mae', --, --, --, --,\n",
       "                    --, --, --, --, 'mse', --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True, False, False,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True, False,  True, False,  True,  True,\n",
       "                     True, False, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True, False,  True,  True, False,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U32'),\n",
       " 'param_regressor:extra_trees:max_depth': masked_array(data=[--, --, --, --, --, --, --, --, --, 'None', --, --, --,\n",
       "                    --, 'None', 'None', --, --, 'None', --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 'None', --, --, 'None', --, --,\n",
       "                    --, --, --, --, --, --, 'None', --, --, 'None', --,\n",
       "                    'None', --, --, --, 'None', 'None', --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 'None', --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 'None', --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 'None', --, --, --, --, 'None', --,\n",
       "                    --, 'None', --, --, 'None', --, --, --, --, --, --, --,\n",
       "                    --, 'None', --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True, False, False,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True, False,  True, False,  True,  True,\n",
       "                     True, False, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True, False,  True,  True, False,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U32'),\n",
       " 'param_regressor:extra_trees:max_features': masked_array(data=[--, --, --, --, --, --, --, --, --, 0.952103089326412,\n",
       "                    --, --, --, --, 0.7561693604244872,\n",
       "                    0.30901038836721584, --, --, 0.21420968661885487, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --,\n",
       "                    0.7836646880154006, --, --, 0.45823543256784804, --,\n",
       "                    --, --, --, --, --, --, --, 0.6129946702308617, --, --,\n",
       "                    0.441358510419701, --, 0.44926495807799216, --, --, --,\n",
       "                    0.1435060136758555, 0.13160097958529787, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 0.6493394975543538, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    0.19142808468727923, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 0.30297201449265165, --, --, --, --,\n",
       "                    0.5987119262641407, --, --, 0.2526807361961485, --, --,\n",
       "                    0.1557291856564538, --, --, --, --, --, --, --, --,\n",
       "                    0.9353708147244134, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True, False, False,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True, False,  True, False,  True,  True,\n",
       "                     True, False, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True, False,  True,  True, False,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_regressor:extra_trees:max_leaf_nodes': masked_array(data=[--, --, --, --, --, --, --, --, --, 'None', --, --, --,\n",
       "                    --, 'None', 'None', --, --, 'None', --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 'None', --, --, 'None', --, --,\n",
       "                    --, --, --, --, --, --, 'None', --, --, 'None', --,\n",
       "                    'None', --, --, --, 'None', 'None', --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 'None', --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 'None', --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 'None', --, --, --, --, 'None', --,\n",
       "                    --, 'None', --, --, 'None', --, --, --, --, --, --, --,\n",
       "                    --, 'None', --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True, False, False,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True, False,  True, False,  True,  True,\n",
       "                     True, False, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True, False,  True,  True, False,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U32'),\n",
       " 'param_regressor:extra_trees:min_impurity_decrease': masked_array(data=[--, --, --, --, --, --, --, --, --, 0.0, --, --, --,\n",
       "                    --, 0.0, 0.0, --, --, 0.0, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 0.0, --, --, 0.0, --, --, --, --, --,\n",
       "                    --, --, --, 0.0, --, --, 0.0, --, 0.0, --, --, --, 0.0,\n",
       "                    0.0, --, --, --, --, --, --, --, --, --, --, --, 0.0,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, 0.0,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, 0.0, --,\n",
       "                    --, --, --, 0.0, --, --, 0.0, --, --, 0.0, --, --, --,\n",
       "                    --, --, --, --, --, 0.0, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True, False, False,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True, False,  True, False,  True,  True,\n",
       "                     True, False, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True, False,  True,  True, False,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_regressor:extra_trees:min_samples_leaf': masked_array(data=[--, --, --, --, --, --, --, --, --, 3.0, --, --, --,\n",
       "                    --, 2.0, 12.0, --, --, 3.0, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 8.0, --, --, 3.0, --, --, --, --, --,\n",
       "                    --, --, --, 6.0, --, --, 12.0, --, 6.0, --, --, --,\n",
       "                    10.0, 1.0, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    2.0, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    1.0, --, --, --, --, --, --, --, --, --, --, --, 14.0,\n",
       "                    --, --, --, --, 7.0, --, --, 9.0, --, --, 7.0, --, --,\n",
       "                    --, --, --, --, --, --, 18.0, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True, False, False,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True, False,  True, False,  True,  True,\n",
       "                     True, False, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True, False,  True,  True, False,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_regressor:extra_trees:min_samples_split': masked_array(data=[--, --, --, --, --, --, --, --, --, 12.0, --, --, --,\n",
       "                    --, 20.0, 18.0, --, --, 20.0, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 3.0, --, --, 20.0, --, --, --, --,\n",
       "                    --, --, --, --, 15.0, --, --, 18.0, --, 16.0, --, --,\n",
       "                    --, 2.0, 2.0, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 5.0, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 14.0, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    14.0, --, --, --, --, 12.0, --, --, 19.0, --, --, 3.0,\n",
       "                    --, --, --, --, --, --, --, --, 7.0, --, --, --, --,\n",
       "                    --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True, False, False,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True, False,  True, False,  True,  True,\n",
       "                     True, False, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True, False,  True,  True, False,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_regressor:random_forest:bootstrap': masked_array(data=['True', --, 'False', --, 'True', --, 'False', 'True',\n",
       "                    'False', --, --, --, --, --, --, --, --, 'True', --,\n",
       "                    'True', 'False', --, --, --, --, --, --, --, --, --,\n",
       "                    'False', --, --, --, --, --, 'True', 'False', --, --,\n",
       "                    --, --, 'True', --, --, --, 'False', --, --, --, --,\n",
       "                    --, --, --, 'False', 'False', --, 'False', --, --, --,\n",
       "                    --, 'False', --, --, --, --, --, --, --, --, --,\n",
       "                    'True', 'True', --, --, --, --, --, --, --, --, --,\n",
       "                    'True', 'False', --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 'False', 'True', --, 'True', 'True',\n",
       "                    --, --, 'True', --, --, --, 'True', --, --, 'True', --,\n",
       "                    --, --, --, --, --, --, --, --, 'False', --, --, --,\n",
       "                    --, 'False', --, --],\n",
       "              mask=[False,  True, False,  True, False,  True, False, False,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True, False, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True, False, False,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False, False,\n",
       "                     True, False,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False, False,  True, False, False,  True,\n",
       "                     True, False,  True,  True,  True, False,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True, False,\n",
       "                     True,  True],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U5'),\n",
       " 'param_regressor:random_forest:criterion': masked_array(data=['mse', --, 'mse', --, 'mae', --, 'mae', 'mae',\n",
       "                    'friedman_mse', --, --, --, --, --, --, --, --,\n",
       "                    'friedman_mse', --, 'mae', 'mse', --, --, --, --, --,\n",
       "                    --, --, --, --, 'mae', --, --, --, --, --,\n",
       "                    'friedman_mse', 'mse', --, --, --, --, 'mae', --, --,\n",
       "                    --, 'friedman_mse', --, --, --, --, --, --, --, 'mae',\n",
       "                    'mae', --, 'mse', --, --, --, --, 'mse', --, --, --,\n",
       "                    --, --, --, --, --, --, 'mae', 'mse', --, --, --, --,\n",
       "                    --, --, --, --, --, 'mae', 'friedman_mse', --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, 'mae',\n",
       "                    'friedman_mse', --, 'mae', 'mae', --, --, 'mae', --,\n",
       "                    --, --, 'friedman_mse', --, --, 'mae', --, --, --, --,\n",
       "                    --, --, --, --, --, 'mae', --, --, --, --, 'mae', --,\n",
       "                    --],\n",
       "              mask=[False,  True, False,  True, False,  True, False, False,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True, False, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True, False, False,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False, False,\n",
       "                     True, False,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False, False,  True, False, False,  True,\n",
       "                     True, False,  True,  True,  True, False,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True, False,\n",
       "                     True,  True],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U12'),\n",
       " 'param_regressor:random_forest:max_depth': masked_array(data=['None', --, 'None', --, 'None', --, 'None', 'None',\n",
       "                    'None', --, --, --, --, --, --, --, --, 'None', --,\n",
       "                    'None', 'None', --, --, --, --, --, --, --, --, --,\n",
       "                    'None', --, --, --, --, --, 'None', 'None', --, --, --,\n",
       "                    --, 'None', --, --, --, 'None', --, --, --, --, --, --,\n",
       "                    --, 'None', 'None', --, 'None', --, --, --, --, 'None',\n",
       "                    --, --, --, --, --, --, --, --, --, 'None', 'None', --,\n",
       "                    --, --, --, --, --, --, --, --, 'None', 'None', --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, 'None',\n",
       "                    'None', --, 'None', 'None', --, --, 'None', --, --, --,\n",
       "                    'None', --, --, 'None', --, --, --, --, --, --, --, --,\n",
       "                    --, 'None', --, --, --, --, 'None', --, --],\n",
       "              mask=[False,  True, False,  True, False,  True, False, False,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True, False, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True, False, False,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False, False,\n",
       "                     True, False,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False, False,  True, False, False,  True,\n",
       "                     True, False,  True,  True,  True, False,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True, False,\n",
       "                     True,  True],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U4'),\n",
       " 'param_regressor:random_forest:max_features': masked_array(data=[1.0, --, 0.6171127451399442, --, 0.3727136330076082,\n",
       "                    --, 0.3685612783283523, 0.15608611895950877,\n",
       "                    0.43966055136547555, --, --, --, --, --, --, --, --,\n",
       "                    0.7599857996442769, --, 0.9130339898205108,\n",
       "                    0.8925031600429947, --, --, --, --, --, --, --, --, --,\n",
       "                    0.8116107525833972, --, --, --, --, --,\n",
       "                    0.4540546893452445, 0.6137693018821133, --, --, --, --,\n",
       "                    0.3617900046399175, --, --, --, 0.8524597601744566, --,\n",
       "                    --, --, --, --, --, --, 0.9329918389865737,\n",
       "                    0.4194485895916473, --, 0.36554379670330617, --, --,\n",
       "                    --, --, 0.490770416599577, --, --, --, --, --, --, --,\n",
       "                    --, --, 0.21063107873516385, 0.8200090550596884, --,\n",
       "                    --, --, --, --, --, --, --, --, 0.5753873145265312,\n",
       "                    0.9856315880871942, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 0.5896697784449347, 0.6238016332735743,\n",
       "                    --, 0.33392393701443845, 0.25385437486349927, --, --,\n",
       "                    0.9196484334535514, --, --, --, 0.1011034925764151, --,\n",
       "                    --, 0.5097653925592535, --, --, --, --, --, --, --, --,\n",
       "                    --, 0.23684671922922562, --, --, --, --,\n",
       "                    0.6569422856214476, --, --],\n",
       "              mask=[False,  True, False,  True, False,  True, False, False,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True, False, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True, False, False,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False, False,\n",
       "                     True, False,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False, False,  True, False, False,  True,\n",
       "                     True, False,  True,  True,  True, False,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True, False,\n",
       "                     True,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_regressor:random_forest:max_leaf_nodes': masked_array(data=['None', --, 'None', --, 'None', --, 'None', 'None',\n",
       "                    'None', --, --, --, --, --, --, --, --, 'None', --,\n",
       "                    'None', 'None', --, --, --, --, --, --, --, --, --,\n",
       "                    'None', --, --, --, --, --, 'None', 'None', --, --, --,\n",
       "                    --, 'None', --, --, --, 'None', --, --, --, --, --, --,\n",
       "                    --, 'None', 'None', --, 'None', --, --, --, --, 'None',\n",
       "                    --, --, --, --, --, --, --, --, --, 'None', 'None', --,\n",
       "                    --, --, --, --, --, --, --, --, 'None', 'None', --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, 'None',\n",
       "                    'None', --, 'None', 'None', --, --, 'None', --, --, --,\n",
       "                    'None', --, --, 'None', --, --, --, --, --, --, --, --,\n",
       "                    --, 'None', --, --, --, --, 'None', --, --],\n",
       "              mask=[False,  True, False,  True, False,  True, False, False,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True, False, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True, False, False,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False, False,\n",
       "                     True, False,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False, False,  True, False, False,  True,\n",
       "                     True, False,  True,  True,  True, False,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True, False,\n",
       "                     True,  True],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U4'),\n",
       " 'param_regressor:random_forest:min_impurity_decrease': masked_array(data=[0.0, --, 0.0, --, 0.0, --, 0.0, 0.0, 0.0, --, --, --,\n",
       "                    --, --, --, --, --, 0.0, --, 0.0, 0.0, --, --, --, --,\n",
       "                    --, --, --, --, --, 0.0, --, --, --, --, --, 0.0, 0.0,\n",
       "                    --, --, --, --, 0.0, --, --, --, 0.0, --, --, --, --,\n",
       "                    --, --, --, 0.0, 0.0, --, 0.0, --, --, --, --, 0.0, --,\n",
       "                    --, --, --, --, --, --, --, --, 0.0, 0.0, --, --, --,\n",
       "                    --, --, --, --, --, --, 0.0, 0.0, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 0.0, 0.0, --, 0.0, 0.0,\n",
       "                    --, --, 0.0, --, --, --, 0.0, --, --, 0.0, --, --, --,\n",
       "                    --, --, --, --, --, --, 0.0, --, --, --, --, 0.0, --,\n",
       "                    --],\n",
       "              mask=[False,  True, False,  True, False,  True, False, False,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True, False, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True, False, False,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False, False,\n",
       "                     True, False,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False, False,  True, False, False,  True,\n",
       "                     True, False,  True,  True,  True, False,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True, False,\n",
       "                     True,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_regressor:random_forest:min_samples_leaf': masked_array(data=[1.0, --, 18.0, --, 14.0, --, 3.0, 13.0, 19.0, --, --,\n",
       "                    --, --, --, --, --, --, 6.0, --, 4.0, 12.0, --, --, --,\n",
       "                    --, --, --, --, --, --, 6.0, --, --, --, --, --, 7.0,\n",
       "                    11.0, --, --, --, --, 13.0, --, --, --, 20.0, --, --,\n",
       "                    --, --, --, --, --, 5.0, 19.0, --, 4.0, --, --, --, --,\n",
       "                    15.0, --, --, --, --, --, --, --, --, --, 18.0, 14.0,\n",
       "                    --, --, --, --, --, --, --, --, --, 11.0, 11.0, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, 2.0, 9.0,\n",
       "                    --, 4.0, 8.0, --, --, 20.0, --, --, --, 19.0, --, --,\n",
       "                    19.0, --, --, --, --, --, --, --, --, --, 19.0, --, --,\n",
       "                    --, --, 6.0, --, --],\n",
       "              mask=[False,  True, False,  True, False,  True, False, False,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True, False, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True, False, False,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False, False,\n",
       "                     True, False,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False, False,  True, False, False,  True,\n",
       "                     True, False,  True,  True,  True, False,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True, False,\n",
       "                     True,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_regressor:random_forest:min_samples_split': masked_array(data=[2.0, --, 3.0, --, 6.0, --, 14.0, 3.0, 20.0, --, --, --,\n",
       "                    --, --, --, --, --, 2.0, --, 20.0, 8.0, --, --, --, --,\n",
       "                    --, --, --, --, --, 14.0, --, --, --, --, --, 6.0,\n",
       "                    10.0, --, --, --, --, 20.0, --, --, --, 4.0, --, --,\n",
       "                    --, --, --, --, --, 6.0, 5.0, --, 17.0, --, --, --, --,\n",
       "                    12.0, --, --, --, --, --, --, --, --, --, 9.0, 17.0,\n",
       "                    --, --, --, --, --, --, --, --, --, 9.0, 3.0, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, 5.0, 20.0,\n",
       "                    --, 16.0, 15.0, --, --, 18.0, --, --, --, 17.0, --, --,\n",
       "                    11.0, --, --, --, --, --, --, --, --, --, 6.0, --, --,\n",
       "                    --, --, 8.0, --, --],\n",
       "              mask=[False,  True, False,  True, False,  True, False, False,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True, False, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True, False, False,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False, False,\n",
       "                     True, False,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False, False,  True, False, False,  True,\n",
       "                     True, False,  True,  True,  True, False,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True, False,\n",
       "                     True,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_regressor:random_forest:min_weight_fraction_leaf': masked_array(data=[0.0, --, 0.0, --, 0.0, --, 0.0, 0.0, 0.0, --, --, --,\n",
       "                    --, --, --, --, --, 0.0, --, 0.0, 0.0, --, --, --, --,\n",
       "                    --, --, --, --, --, 0.0, --, --, --, --, --, 0.0, 0.0,\n",
       "                    --, --, --, --, 0.0, --, --, --, 0.0, --, --, --, --,\n",
       "                    --, --, --, 0.0, 0.0, --, 0.0, --, --, --, --, 0.0, --,\n",
       "                    --, --, --, --, --, --, --, --, 0.0, 0.0, --, --, --,\n",
       "                    --, --, --, --, --, --, 0.0, 0.0, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 0.0, 0.0, --, 0.0, 0.0,\n",
       "                    --, --, 0.0, --, --, --, 0.0, --, --, 0.0, --, --, --,\n",
       "                    --, --, --, --, --, --, 0.0, --, --, --, --, 0.0, --,\n",
       "                    --],\n",
       "              mask=[False,  True, False,  True, False,  True, False, False,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True, False, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True, False, False,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False, False,\n",
       "                     True, False,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False, False,  True, False, False,  True,\n",
       "                     True, False,  True,  True,  True, False,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True, False,\n",
       "                     True,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_regressor:ridge_regression:alpha': masked_array(data=[--, 251.64290429823575, --, 118.13970161044887, --,\n",
       "                    9879.424292624131, --, --, --, --, 228.5982297578523,\n",
       "                    5329.339413938869, 8909.038912943726,\n",
       "                    403.63559839161786, --, --, 5591.539001489194, --, --,\n",
       "                    --, --, 5932.043680333357, 4869.752248766393,\n",
       "                    1514.598041830289, 241.09456662675674,\n",
       "                    220.18392019057575, 5315.152637030628,\n",
       "                    3202.9685614699606, 4525.569964033496,\n",
       "                    4869.752248766393, --, 102.44359702118479,\n",
       "                    1682.7292738873452, 2577.9795274879525,\n",
       "                    6870.106567085016, 2577.9795274879525, --, --,\n",
       "                    997.3917993469088, 1365.0570480315653,\n",
       "                    567.9963096413372, 727.0491382018473, --,\n",
       "                    1059.8220838933305, --, 235.635582015798, --, --,\n",
       "                    398.2364083728594, 1022.5394038849355,\n",
       "                    206.5673628756533, 109.42464068550348,\n",
       "                    306.8582872572692, 398.2364083728594, --, --, --, --,\n",
       "                    4459.351246960449, --, 154.15371317803957, --, --,\n",
       "                    851.3665459916309, 304.04975384858267, --, --,\n",
       "                    282.61339287398687, 284.6597986859927,\n",
       "                    2013.8759864172823, 1202.2274776558202,\n",
       "                    946.2859644993731, --, --, 181.34798281202396,\n",
       "                    2117.4977633436038, 2816.778369580754,\n",
       "                    604.350990201261, --, 102.03701247340433,\n",
       "                    101.8709764121046, 8440.46782148219, 680.6245135254732,\n",
       "                    --, --, 427.2213005218416, 426.6105391976211,\n",
       "                    429.5597233606686, 1015.1996461594002,\n",
       "                    345.3655981082463, 1015.1996461594002, --,\n",
       "                    837.8899864250509, 247.28521063594175,\n",
       "                    997.3917993469088, 246.68184310555154,\n",
       "                    1140.2382279388025, 2058.6980997049554, --, --,\n",
       "                    224.87840598015808, --, --, --, 1830.5021507821218, --,\n",
       "                    1343.8188353278997, 361.5422846364324, --, --,\n",
       "                    4967.343418282986, --, --, 702.8418264371663, --,\n",
       "                    1133.8273382498498, 714.4378168754694,\n",
       "                    3525.5527967092194, 3640.0869069841997,\n",
       "                    291.09394060447465, 1305.0389433795815,\n",
       "                    4612.353089482255, --, --, 651.119867956726,\n",
       "                    1507.5087892771232, 1042.5057960510446, --,\n",
       "                    4258.664590999392, 1314.8244938747746],\n",
       "              mask=[ True, False,  True, False,  True, False,  True,  True,\n",
       "                     True,  True, False, False, False, False,  True,  True,\n",
       "                    False,  True,  True,  True,  True, False, False, False,\n",
       "                    False, False, False, False, False, False,  True, False,\n",
       "                    False, False, False, False,  True,  True, False, False,\n",
       "                    False, False,  True, False,  True, False,  True,  True,\n",
       "                    False, False, False, False, False, False,  True,  True,\n",
       "                     True,  True, False,  True, False,  True,  True, False,\n",
       "                    False,  True,  True, False, False, False, False, False,\n",
       "                     True,  True, False, False, False, False,  True, False,\n",
       "                    False, False, False,  True,  True, False, False, False,\n",
       "                    False, False, False,  True, False, False, False, False,\n",
       "                    False, False,  True,  True, False,  True,  True,  True,\n",
       "                    False,  True, False, False,  True,  True, False,  True,\n",
       "                     True, False,  True, False, False, False, False, False,\n",
       "                    False, False,  True,  True, False, False, False,  True,\n",
       "                    False, False],\n",
       "        fill_value=1e+20),\n",
       " 'param_regressor:ridge_regression:fit_intercept': masked_array(data=[--, 'True', --, 'True', --, 'True', --, --, --, --,\n",
       "                    'True', 'True', 'True', 'True', --, --, 'True', --, --,\n",
       "                    --, --, 'True', 'True', 'True', 'True', 'True', 'True',\n",
       "                    'True', 'True', 'True', --, 'True', 'True', 'True',\n",
       "                    'True', 'True', --, --, 'True', 'True', 'True', 'True',\n",
       "                    --, 'True', --, 'True', --, --, 'True', 'True', 'True',\n",
       "                    'True', 'True', 'True', --, --, --, --, 'True', --,\n",
       "                    'True', --, --, 'True', 'True', --, --, 'True', 'True',\n",
       "                    'True', 'True', 'True', --, --, 'True', 'True', 'True',\n",
       "                    'True', --, 'True', 'True', 'True', 'True', --, --,\n",
       "                    'True', 'True', 'True', 'True', 'True', 'True', --,\n",
       "                    'True', 'True', 'True', 'True', 'True', 'True', --, --,\n",
       "                    'True', --, --, --, 'True', --, 'True', 'True', --, --,\n",
       "                    'True', --, --, 'True', --, 'True', 'True', 'True',\n",
       "                    'True', 'True', 'True', 'True', --, --, 'True', 'True',\n",
       "                    'True', --, 'True', 'True'],\n",
       "              mask=[ True, False,  True, False,  True, False,  True,  True,\n",
       "                     True,  True, False, False, False, False,  True,  True,\n",
       "                    False,  True,  True,  True,  True, False, False, False,\n",
       "                    False, False, False, False, False, False,  True, False,\n",
       "                    False, False, False, False,  True,  True, False, False,\n",
       "                    False, False,  True, False,  True, False,  True,  True,\n",
       "                    False, False, False, False, False, False,  True,  True,\n",
       "                     True,  True, False,  True, False,  True,  True, False,\n",
       "                    False,  True,  True, False, False, False, False, False,\n",
       "                     True,  True, False, False, False, False,  True, False,\n",
       "                    False, False, False,  True,  True, False, False, False,\n",
       "                    False, False, False,  True, False, False, False, False,\n",
       "                    False, False,  True,  True, False,  True,  True,  True,\n",
       "                    False,  True, False, False,  True,  True, False,  True,\n",
       "                     True, False,  True, False, False, False, False, False,\n",
       "                    False, False,  True,  True, False, False, False,  True,\n",
       "                    False, False],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U32'),\n",
       " 'param_regressor:ridge_regression:tol': masked_array(data=[--, 1.785648071403803e-07, --, 4.941398947613314e-07,\n",
       "                    --, 6.151851245014563e-05, --, --, --, --,\n",
       "                    3.831709023607285e-07, 4.949503066482948e-06,\n",
       "                    1.6606957980157686e-06, 1.222205461967052e-06, --, --,\n",
       "                    7.156313591713281e-06, --, --, --, --,\n",
       "                    2.4203886872176227e-07, 2.165382616171651e-07,\n",
       "                    6.778076880265568e-05, 1.1816120350010204e-05,\n",
       "                    1.9920068206713036e-06, 4.873745048608924e-05,\n",
       "                    2.862822150863437e-07, 2.165382616171651e-07,\n",
       "                    1.9450446227639814e-07, --, 3.51771347181206e-07,\n",
       "                    3.4350564167465105e-07, 1.4190891255147433e-07,\n",
       "                    8.752672977472674e-07, 1.331792871051354e-07, --, --,\n",
       "                    2.662530681849979e-07, 1.5077251580387525e-07,\n",
       "                    1.459775962723201e-07, 1.0835903481063717e-07, --,\n",
       "                    1.2990395212240492e-07, --, 3.304597658389447e-07, --,\n",
       "                    --, 1.6849850445595085e-07, 1.0568816365268719e-07,\n",
       "                    4.450362990645943e-06, 7.740120494214784e-06,\n",
       "                    3.005863415778308e-05, 2.0632663912993007e-07, --, --,\n",
       "                    --, --, 1.6219397810716745e-06, --,\n",
       "                    1.745799608994748e-07, --, --, 1.0485936584738877e-05,\n",
       "                    1.616656653428657e-05, --, --, 2.4607264154829007e-07,\n",
       "                    2.1367976061466478e-07, 1.357245545164312e-07,\n",
       "                    1.2772345973501513e-07, 1.708508807649327e-07, --, --,\n",
       "                    1.4320890748340824e-07, 1.5059773355213637e-06,\n",
       "                    8.679092713200136e-07, 3.5721173001895457e-07, --,\n",
       "                    2.3170415387055311e-07, 4.31240486122738e-06,\n",
       "                    3.579108335032788e-07, 5.778146939654804e-07, --, --,\n",
       "                    6.204106646817834e-05, 1.5124495966064339e-07,\n",
       "                    1.612775317418577e-07, 5.249342158454455e-07,\n",
       "                    7.82606254681903e-05, 5.615163057927447e-07, --,\n",
       "                    1.459775962723201e-07, 1.2179594324959094e-05,\n",
       "                    1.2420814853913253e-07, 1.214280813254371e-05,\n",
       "                    1.02078346656144e-07, 1.0395430611891885e-07, --, --,\n",
       "                    7.240072896967454e-07, --, --, --,\n",
       "                    6.435525165118922e-07, --, 1.3929528635141116e-07,\n",
       "                    1.2842725918655613e-06, --, --, 2.2579200483044577e-07,\n",
       "                    --, --, 2.8612927121827023e-06, --,\n",
       "                    1.640562394961934e-07, 1.9809069119474426e-05,\n",
       "                    9.022558952173345e-07, 3.8881067360985393e-07,\n",
       "                    1.606323351105396e-05, 3.731444974835353e-05,\n",
       "                    2.665622231697457e-07, --, --, 3.277887103958789e-07,\n",
       "                    6.441110183898934e-05, 3.005863415778308e-05, --,\n",
       "                    3.439209059533015e-07, 2.0664914624836635e-07],\n",
       "              mask=[ True, False,  True, False,  True, False,  True,  True,\n",
       "                     True,  True, False, False, False, False,  True,  True,\n",
       "                    False,  True,  True,  True,  True, False, False, False,\n",
       "                    False, False, False, False, False, False,  True, False,\n",
       "                    False, False, False, False,  True,  True, False, False,\n",
       "                    False, False,  True, False,  True, False,  True,  True,\n",
       "                    False, False, False, False, False, False,  True,  True,\n",
       "                     True,  True, False,  True, False,  True,  True, False,\n",
       "                    False,  True,  True, False, False, False, False, False,\n",
       "                     True,  True, False, False, False, False,  True, False,\n",
       "                    False, False, False,  True,  True, False, False, False,\n",
       "                    False, False, False,  True, False, False, False, False,\n",
       "                    False, False,  True,  True, False,  True,  True,  True,\n",
       "                    False,  True, False, False,  True,  True, False,  True,\n",
       "                     True, False,  True, False, False, False, False, False,\n",
       "                    False, False,  True,  True, False, False, False,  True,\n",
       "                    False, False],\n",
       "        fill_value=1e+20),\n",
       " 'param_feature_preprocessor:fast_ica:n_components': masked_array(data=[--, 1765.0, --, --, --, --, --, 1417.0, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 578.0, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, 26.0,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 94.0, --, 279.0, --, --, --, --,\n",
       "                    111.0, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --],\n",
       "              mask=[ True, False,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True, False,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_feature_preprocessor:kernel_pca:coef0': masked_array(data=[--, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True],\n",
       "        fill_value=1e+20,\n",
       "             dtype=float64),\n",
       " 'param_feature_preprocessor:kernel_pca:degree': masked_array(data=[--, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True],\n",
       "        fill_value=1e+20,\n",
       "             dtype=float64),\n",
       " 'param_feature_preprocessor:kernel_pca:gamma': masked_array(data=[--, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    0.26930393317792434, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --,\n",
       "                    0.00014778602331160602, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_feature_preprocessor:nystroem_sampler:coef0': masked_array(data=[--, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True],\n",
       "        fill_value=1e+20,\n",
       "             dtype=float64),\n",
       " 'param_feature_preprocessor:nystroem_sampler:degree': masked_array(data=[--, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True],\n",
       "        fill_value=1e+20,\n",
       "             dtype=float64),\n",
       " 'param_feature_preprocessor:nystroem_sampler:gamma': masked_array(data=[--, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 9.89927316778072e-05, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True],\n",
       "        fill_value=1e+20)}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regl.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.56, SimpleRegressionPipeline({'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding', 'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer', 'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent', 'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize', 'feature_preprocessor:__choice__': 'feature_agglomeration', 'regressor:__choice__': 'ridge_regression', 'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.06679923104211231, 'feature_preprocessor:feature_agglomeration:affinity': 'manhattan', 'feature_preprocessor:feature_agglomeration:linkage': 'complete', 'feature_preprocessor:feature_agglomeration:n_clusters': 149, 'feature_preprocessor:feature_agglomeration:pooling_func': 'max', 'regressor:ridge_regression:alpha': 398.2364083728594, 'regressor:ridge_regression:fit_intercept': 'True', 'regressor:ridge_regression:tol': 2.0632663912993007e-07},\n",
      "dataset_properties={\n",
      "  'task': 5,\n",
      "  'sparse': False,\n",
      "  'multioutput': True,\n",
      "  'target_type': 'regression',\n",
      "  'signed': False})), (0.44, SimpleRegressionPipeline({'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding', 'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer', 'data_preprocessing:numerical_transformer:imputation:strategy': 'mean', 'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize', 'feature_preprocessor:__choice__': 'feature_agglomeration', 'regressor:__choice__': 'ridge_regression', 'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.19643029797619796, 'feature_preprocessor:feature_agglomeration:affinity': 'euclidean', 'feature_preprocessor:feature_agglomeration:linkage': 'complete', 'feature_preprocessor:feature_agglomeration:n_clusters': 30, 'feature_preprocessor:feature_agglomeration:pooling_func': 'max', 'regressor:ridge_regression:alpha': 1140.2382279388025, 'regressor:ridge_regression:fit_intercept': 'True', 'regressor:ridge_regression:tol': 1.02078346656144e-07},\n",
      "dataset_properties={\n",
      "  'task': 5,\n",
      "  'sparse': False,\n",
      "  'multioutput': True,\n",
      "  'target_type': 'regression',\n",
      "  'signed': False}))]\n",
      "auto-sklearn results:\n",
      "  Dataset name: 0955ac79f29fd1a32d878bf5acf9bf75\n",
      "  Metric: r2\n",
      "  Best validation score: 0.709218\n",
      "  Number of target algorithm runs: 130\n",
      "  Number of successful target algorithm runs: 74\n",
      "  Number of crashed target algorithm runs: 9\n",
      "  Number of target algorithms that exceeded the time limit: 35\n",
      "  Number of target algorithms that exceeded the memory limit: 12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(regl.get_models_with_weights())\n",
    "print(regl.sprint_statistics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "X, y = shuffle(ftrain, ttrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/anaconda3/envs/autosk07/lib/python3.7/site-packages/sklearn/base.py:197: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AutoSklearnRegressor(delete_output_folder_after_terminate=False,\n",
       "                     delete_tmp_folder_after_terminate=False,\n",
       "                     disable_evaluator_output=False, ensemble_memory_limit=5120,\n",
       "                     ensemble_nbest=25, ensemble_size=50,\n",
       "                     exclude_estimators=['gaussian_process',\n",
       "                                         'k_nearest_neighbors',\n",
       "                                         'decision_tree'],\n",
       "                     exclude_preprocessors=None, get_smac_object_callback=None,\n",
       "                     include_estimators...\n",
       "                     initial_configurations_via_metalearning=0,\n",
       "                     logging_config=None, max_models_on_disc=50,\n",
       "                     metadata_directory='solar_meta', metric=None,\n",
       "                     ml_memory_limit=10092, n_jobs=4, output_folder=None,\n",
       "                     per_run_time_limit=3600, resampling_strategy='cv',\n",
       "                     resampling_strategy_arguments={'folds': 5,\n",
       "                                                    'shuffle': False},\n",
       "                     seed=121, shared_mode=False, smac_scenario_args=None,\n",
       "                     time_left_for_this_task=36000, tmp_folder=None)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regl.refit(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 2.733220121759698\n",
      "MAE: 0.8936163464044133\n",
      "r2_score: 0.6478776716647127\n",
      "MSE: 1.988137048589388\n",
      "MAE: 0.7350975141067387\n",
      "r2_score: 0.6853023331367273\n"
     ]
    }
   ],
   "source": [
    "ypred = regl.predict(test_X)\n",
    "yhat = regl.predict(train_X)\n",
    "get_eval(test_Y, ypred)\n",
    "get_eval(train_Y, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f26cef23fd0>]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2l_list_test = []\n",
    "for i in range(4000):\n",
    "    o_y = np.transpose(test_Y.iloc[i,:].to_numpy().reshape(1,-1))\n",
    "    p_y = np.transpose(ypred[i,:].reshape(1,-1))\n",
    "    r2 = r2_score(o_y, p_y)\n",
    "    r2l_list_test.append(r2)\n",
    "fig = plt.figure(figsize = (16, 7))\n",
    "plt.plot(r2l_list_test, 'b-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f26cede27d0>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(test_Y.to_numpy()[100,])\n",
    "plt.plot(ypred[100,], 'ro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe0eac6dc10>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "plt.plot(ypred[192,:], 'b.')\n",
    "plt.plot(ttest.to_numpy()[192,:],'r-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import dump\n",
    "## pickle the model\n",
    "dump(regl, open('200lag_10hr','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load model\n",
    "from pickle import load\n",
    "with open('solar_200lag_10hr', 'rb') as pickcle_file:\n",
    "    model = load(pickcle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/anaconda3/envs/autosk07/lib/python3.7/site-packages/sklearn/base.py:197: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AutoSklearnRegressor(delete_output_folder_after_terminate=False,\n",
       "                     delete_tmp_folder_after_terminate=False,\n",
       "                     disable_evaluator_output=False, ensemble_memory_limit=5120,\n",
       "                     ensemble_nbest=25, ensemble_size=50,\n",
       "                     exclude_estimators=['gaussian_process',\n",
       "                                         'k_nearest_neighbors',\n",
       "                                         'decision_tree'],\n",
       "                     exclude_preprocessors=None, get_smac_object_callback=None,\n",
       "                     include_estimators...\n",
       "                     initial_configurations_via_metalearning=0,\n",
       "                     logging_config=None, max_models_on_disc=50,\n",
       "                     metadata_directory='solar_meta', metric=None,\n",
       "                     ml_memory_limit=10092, n_jobs=4, output_folder=None,\n",
       "                     per_run_time_limit=3600, resampling_strategy='cv',\n",
       "                     resampling_strategy_arguments={'folds': 5,\n",
       "                                                    'shuffle': False},\n",
       "                     seed=121, shared_mode=False, smac_scenario_args=None,\n",
       "                     time_left_for_this_task=36000, tmp_folder=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.refit(ftrain, ttrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "n_bootstraps = 50\n",
    "b_x = []\n",
    "b_y = []\n",
    "for _ in range(n_bootstraps):\n",
    "    sample_X, sample_y = resample(train_X, train_Y, n_samples = 4000)\n",
    "    b_x.append(sample_X)\n",
    "    b_y.append(sample_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = []\n",
    "\n",
    "for i, feature in enumerate(b_x):\n",
    "    model.refit(feature, b_y[i])\n",
    "    prediction.append(model.predict(test_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f7f88e80390>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize = (15,7))\n",
    "plt.plot(np.quantile(prediction, 0.5, axis = 0)[1000,:], 'b-')\n",
    "plt.plot(np.quantile(prediction, 0.9, axis = 0)[1000,:], 'g--')\n",
    "plt.plot(np.quantile(prediction, 0.1, axis = 0)[1000,:], 'g--')\n",
    "plt.plot(test_Y.to_numpy()[1000,:], 'ro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lag + tsfresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4509, 449), (4509, 758), (509, 449), (509, 758))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ftrain.shape, ftrain_tf.shape, ftest.shape, ftest_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftrain_lts = np.concatenate([ftrain.to_numpy(), ftrain_tf.to_numpy()], axis = 1)\n",
    "ftest_lts = np.concatenate([ftest.to_numpy(), ftest_tf.to_numpy()], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ftrain_lts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-b8c120e8bae1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mreg_lts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mftrain_lts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mttrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'ftrain_lts' is not defined"
     ]
    }
   ],
   "source": [
    "reg_lts = autoreg.AutoSklearnRegressor(time_left_for_this_task=1000,\n",
    "                                           per_run_time_limit=300,\n",
    "                                           initial_configurations_via_metalearning=0,\n",
    "                                           ensemble_size=0, \n",
    "                                           ensemble_nbest=0,\n",
    "                                           ensemble_memory_limit=5120, \n",
    "                                           seed=921, ml_memory_limit=6144, \n",
    "                                           include_estimators=None,\n",
    "                                           exclude_estimators='gaussian_process', \n",
    "                                           include_preprocessors=None, \n",
    "                                           exclude_preprocessors=None, \n",
    "                                           resampling_strategy=TimeSeriesSplit,\n",
    "                                           resampling_strategy_arguments={'folds': 5},\n",
    "                                           tmp_folder=None, \n",
    "                                           output_folder=None, \n",
    "                                           delete_tmp_folder_after_terminate=False, \n",
    "                                           delete_output_folder_after_terminate=False, \n",
    "                                           shared_mode=False, \n",
    "                                           n_jobs = 6, \n",
    "                                           disable_evaluator_output=False, \n",
    "                                           get_smac_object_callback=None, \n",
    "                                           smac_scenario_args=None, \n",
    "                                           logging_config=None,\n",
    "                                           metadata_directory=None)\n",
    "\n",
    "\n",
    "reg_lts.fit(ftrain_lts, ttrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_test_score': array([ 0.        ,  0.21177564,  0.        ,  0.        ,  0.        ,\n",
       "        -0.30709209, -0.02234649, -0.48586259,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        , -0.02585408,\n",
       "         0.        ,  0.        ,  0.09035615,  0.        ,  0.33210265,\n",
       "         0.        ,  0.        ,  0.2766813 ,  0.0669718 ,  0.        ,\n",
       "         0.        ,  0.08851303,  0.00925268,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.29825572,  0.0669718 ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ]),\n",
       " 'mean_fit_time': array([3.00120686e+02, 3.37824309e+01, 2.28317022e-01, 3.00091033e+02,\n",
       "        1.37731240e+01, 5.53160787e+00, 2.37721062e+00, 4.46084619e+00,\n",
       "        2.20927954e-01, 3.00126973e+02, 1.21481569e+01, 1.34432335e+01,\n",
       "        3.00078530e+02, 3.00068238e+02, 3.00122437e+02, 3.00086346e+02,\n",
       "        3.00116279e+02, 3.00116199e+02, 2.27455616e-01, 1.50515664e+01,\n",
       "        2.63315201e-01, 3.00116130e+02, 2.43955650e+01, 3.00115866e+02,\n",
       "        3.23726950e+01, 3.00044600e+02, 2.24849939e-01, 2.27398701e+01,\n",
       "        5.29926801e+00, 2.99118247e+02, 3.00119084e+02, 6.40285015e+00,\n",
       "        3.55917096e+00, 3.10491209e+01, 3.00117495e+02, 4.60598722e+01,\n",
       "        3.00116898e+02, 8.00958791e+01, 3.00086718e+02, 2.44663477e-01,\n",
       "        3.03998413e+01, 6.46242499e+00, 3.02175522e+00, 3.00117141e+02,\n",
       "        2.04932213e-01, 6.50384011e+01]),\n",
       " 'params': [{'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.01,\n",
       "   'regressor:random_forest:bootstrap': 'True',\n",
       "   'regressor:random_forest:criterion': 'mse',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 1.0,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 1,\n",
       "   'regressor:random_forest:min_samples_split': 2,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0026384245313872353,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'True',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'friedman_mse',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.8916423125520393,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 17,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 3,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 31,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'feature_preprocessor:polynomial:degree': 2,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'True',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'True',\n",
       "   'regressor:decision_tree:criterion': 'friedman_mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.7737834642318178,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 13,\n",
       "   'regressor:decision_tree:min_samples_split': 13,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:extra_trees:bootstrap': 'False',\n",
       "   'regressor:extra_trees:criterion': 'friedman_mse',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.889315445488316,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 7,\n",
       "   'regressor:extra_trees:min_samples_split': 8,\n",
       "   'feature_preprocessor:fast_ica:n_components': 539},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 782,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'normal',\n",
       "   'feature_preprocessor:polynomial:degree': 3,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'True',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'True',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 4,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'distance'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.008228181948465642,\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'False',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 8,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 8,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 13,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 60,\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 1,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.05280394571336593,\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'True',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 10,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 1,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 8,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 37,\n",
       "   'regressor:decision_tree:criterion': 'friedman_mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.8105100197700859,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 7,\n",
       "   'regressor:decision_tree:min_samples_split': 20,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'False',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 7,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 15,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 11,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 37,\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 1,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'feature_preprocessor:polynomial:degree': 2,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'False',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'True',\n",
       "   'regressor:random_forest:bootstrap': 'False',\n",
       "   'regressor:random_forest:criterion': 'mae',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.9658082569087674,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 19,\n",
       "   'regressor:random_forest:min_samples_split': 12,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'feature_agglomeration',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.008966101829575291,\n",
       "   'feature_preprocessor:feature_agglomeration:affinity': 'manhattan',\n",
       "   'feature_preprocessor:feature_agglomeration:linkage': 'complete',\n",
       "   'feature_preprocessor:feature_agglomeration:n_clusters': 152,\n",
       "   'feature_preprocessor:feature_agglomeration:pooling_func': 'mean',\n",
       "   'regressor:random_forest:bootstrap': 'False',\n",
       "   'regressor:random_forest:criterion': 'friedman_mse',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.9552504640093018,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 9,\n",
       "   'regressor:random_forest:min_samples_split': 3,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'feature_preprocessor:polynomial:degree': 3,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'False',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'False',\n",
       "   'regressor:extra_trees:bootstrap': 'True',\n",
       "   'regressor:extra_trees:criterion': 'mae',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.17888418316329135,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 12,\n",
       "   'regressor:extra_trees:min_samples_split': 11},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.7143371369676014,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.04794378208398888,\n",
       "   'feature_preprocessor:polynomial:degree': 3,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'True',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'False',\n",
       "   'regressor:extra_trees:bootstrap': 'True',\n",
       "   'regressor:extra_trees:criterion': 'mse',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.6624136583910045,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 2,\n",
       "   'regressor:extra_trees:min_samples_split': 5},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'kitchen_sinks',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'feature_preprocessor:kitchen_sinks:gamma': 0.00015592108351954417,\n",
       "   'feature_preprocessor:kitchen_sinks:n_components': 447,\n",
       "   'regressor:ridge_regression:alpha': 0.26972182640899706,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 0.0049514585167037715},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'pca',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.9458586151922455,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.033973270518143514,\n",
       "   'feature_preprocessor:pca:keep_variance': 0.916501074160355,\n",
       "   'feature_preprocessor:pca:whiten': 'True',\n",
       "   'regressor:ridge_regression:alpha': 0.0012978027102532436,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 0.0005436859891957444},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.018706846291046294,\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'True',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 4,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 5,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 16,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 29,\n",
       "   'regressor:ridge_regression:alpha': 0.07220695583272739,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 0.03281504701204836},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'True',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 8,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 14,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 2,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 16,\n",
       "   'regressor:extra_trees:bootstrap': 'False',\n",
       "   'regressor:extra_trees:criterion': 'mse',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.7048082419853497,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 1,\n",
       "   'regressor:extra_trees:min_samples_split': 19},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'feature_agglomeration',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.8908649969556265,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.23061291159288266,\n",
       "   'feature_preprocessor:feature_agglomeration:affinity': 'manhattan',\n",
       "   'feature_preprocessor:feature_agglomeration:linkage': 'complete',\n",
       "   'feature_preprocessor:feature_agglomeration:n_clusters': 341,\n",
       "   'feature_preprocessor:feature_agglomeration:pooling_func': 'mean',\n",
       "   'regressor:ridge_regression:alpha': 0.08648702344898193,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 3.507753673371878e-05},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.07573471956443811,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.9222381336818728,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.23125703348362994,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'exp',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'False',\n",
       "   'regressor:decision_tree:criterion': 'friedman_mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.959836402328228,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 8,\n",
       "   'regressor:decision_tree:min_samples_split': 6,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.006401132329816805,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 802,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'normal',\n",
       "   'feature_preprocessor:polynomial:degree': 2,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'False',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'False',\n",
       "   'regressor:extra_trees:bootstrap': 'True',\n",
       "   'regressor:extra_trees:criterion': 'mse',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.7246103277682895,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 9,\n",
       "   'regressor:extra_trees:min_samples_split': 15},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.9426251414675535,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.21098487877827368,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'True',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'mse',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.2981545058131393,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 14,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 14,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 1.776462544426102,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 4,\n",
       "   'regressor:decision_tree:min_samples_split': 7,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.00434032235492344,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'exp',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'False',\n",
       "   'regressor:ridge_regression:alpha': 0.23208682194269747,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 1.0174779784395646e-05},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.9324046202896481,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.24070305887016358,\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'True',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 5,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 7,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 5,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 77,\n",
       "   'regressor:random_forest:bootstrap': 'False',\n",
       "   'regressor:random_forest:criterion': 'mae',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.22676842993049168,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 14,\n",
       "   'regressor:random_forest:min_samples_split': 18,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.04328008478720413,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'False',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'friedman_mse',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.5297983199210101,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 19,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 12,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 6,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:extra_trees:bootstrap': 'False',\n",
       "   'regressor:extra_trees:criterion': 'mae',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.8241774216692473,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 14,\n",
       "   'regressor:extra_trees:min_samples_split': 2,\n",
       "   'feature_preprocessor:fast_ica:n_components': 1916},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'feature_agglomeration',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.9028878306178143,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.10562216348863988,\n",
       "   'feature_preprocessor:feature_agglomeration:affinity': 'manhattan',\n",
       "   'feature_preprocessor:feature_agglomeration:linkage': 'complete',\n",
       "   'feature_preprocessor:feature_agglomeration:n_clusters': 388,\n",
       "   'feature_preprocessor:feature_agglomeration:pooling_func': 'max',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 71,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'distance'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0014125663544520652,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 1753,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'normal',\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'False',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 5,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 1,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 19,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 89,\n",
       "   'regressor:random_forest:bootstrap': 'False',\n",
       "   'regressor:random_forest:criterion': 'mse',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.6664361259409552,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 6,\n",
       "   'regressor:random_forest:min_samples_split': 11,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'random_forest',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.08717627580708938,\n",
       "   'feature_preprocessor:polynomial:degree': 2,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'True',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'True',\n",
       "   'regressor:random_forest:bootstrap': 'True',\n",
       "   'regressor:random_forest:criterion': 'mse',\n",
       "   'regressor:random_forest:max_depth': 'None',\n",
       "   'regressor:random_forest:max_features': 0.9888221698889313,\n",
       "   'regressor:random_forest:max_leaf_nodes': 'None',\n",
       "   'regressor:random_forest:min_impurity_decrease': 0.0,\n",
       "   'regressor:random_forest:min_samples_leaf': 18,\n",
       "   'regressor:random_forest:min_samples_split': 11,\n",
       "   'regressor:random_forest:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'False',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'friedman_mse',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.18379814197130073,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 10,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 19,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 28,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'distance'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.7713495648528115,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.010153420179546516,\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.2165118379734059,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 3,\n",
       "   'regressor:decision_tree:min_samples_split': 17,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.8124343120257264,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.2645660734387229,\n",
       "   'regressor:extra_trees:bootstrap': 'False',\n",
       "   'regressor:extra_trees:criterion': 'mae',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.7096964681218927,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 17,\n",
       "   'regressor:extra_trees:min_samples_split': 14},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.08185943308131388,\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'False',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 8,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 1,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 12,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 92,\n",
       "   'regressor:ridge_regression:alpha': 0.000454758499724548,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 0.0002597945585926762},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'False',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 2,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 13,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 6,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 65,\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 12,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'distance'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.2531816795290892,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 1549,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'normal',\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'False',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 7,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 16,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 11,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 13,\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 45,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'distance'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'cube',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'False',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 1,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0008866566079920301,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.9788580663449074,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.0050071643467382776,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'parallel',\n",
       "   'feature_preprocessor:fast_ica:fun': 'cube',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'False',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 1,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'distance'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0002485177435445324,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.9159433805754357,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.17144606707198023,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'exp',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 1,\n",
       "   'regressor:k_nearest_neighbors:p': 1,\n",
       "   'regressor:k_nearest_neighbors:weights': 'distance',\n",
       "   'feature_preprocessor:fast_ica:n_components': 696},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'kernel_pca',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.13298241735810967,\n",
       "   'feature_preprocessor:kernel_pca:kernel': 'rbf',\n",
       "   'feature_preprocessor:kernel_pca:n_components': 1489,\n",
       "   'regressor:ridge_regression:alpha': 3.8576135843011463,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 0.033583715713059605,\n",
       "   'feature_preprocessor:kernel_pca:gamma': 0.17045734753422645},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize',\n",
       "   'feature_preprocessor:__choice__': 'kernel_pca',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.01922194687729476,\n",
       "   'feature_preprocessor:kernel_pca:kernel': 'rbf',\n",
       "   'feature_preprocessor:kernel_pca:n_components': 811,\n",
       "   'regressor:ridge_regression:alpha': 0.19225941103954733,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 2.4611942938933287e-05,\n",
       "   'feature_preprocessor:kernel_pca:gamma': 5.25053021043453e-05},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'extra_trees',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 1024,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'uniform',\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'cube',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:extra_trees:bootstrap': 'False',\n",
       "   'regressor:extra_trees:criterion': 'mse',\n",
       "   'regressor:extra_trees:max_depth': 'None',\n",
       "   'regressor:extra_trees:max_features': 0.21427701606528787,\n",
       "   'regressor:extra_trees:max_leaf_nodes': 'None',\n",
       "   'regressor:extra_trees:min_impurity_decrease': 0.0,\n",
       "   'regressor:extra_trees:min_samples_leaf': 17,\n",
       "   'regressor:extra_trees:min_samples_split': 4,\n",
       "   'feature_preprocessor:fast_ica:n_components': 1569},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none',\n",
       "   'feature_preprocessor:__choice__': 'polynomial',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'feature_preprocessor:polynomial:degree': 2,\n",
       "   'feature_preprocessor:polynomial:include_bias': 'False',\n",
       "   'feature_preprocessor:polynomial:interaction_only': 'True',\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 2,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'uniform'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0021689983035149732,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'True',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'mse',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.8916423125520393,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 19,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 3,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 23,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'distance'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'median',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'no_preprocessing',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0009690683970088139,\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 0.05710376411100193,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 10,\n",
       "   'regressor:decision_tree:min_samples_split': 8,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler',\n",
       "   'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression',\n",
       "   'regressor:__choice__': 'k_nearest_neighbors',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.2925697627392644,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.8182233596800187,\n",
       "   'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.1402734161123617,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'True',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'friedman_mse',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.23005230097732696,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 8,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 3,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0,\n",
       "   'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100,\n",
       "   'regressor:k_nearest_neighbors:n_neighbors': 15,\n",
       "   'regressor:k_nearest_neighbors:p': 2,\n",
       "   'regressor:k_nearest_neighbors:weights': 'distance'},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'normalize',\n",
       "   'feature_preprocessor:__choice__': 'random_trees_embedding',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'feature_preprocessor:random_trees_embedding:bootstrap': 'False',\n",
       "   'feature_preprocessor:random_trees_embedding:max_depth': 10,\n",
       "   'feature_preprocessor:random_trees_embedding:max_leaf_nodes': 'None',\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_leaf': 17,\n",
       "   'feature_preprocessor:random_trees_embedding:min_samples_split': 11,\n",
       "   'feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': 1.0,\n",
       "   'feature_preprocessor:random_trees_embedding:n_estimators': 70,\n",
       "   'regressor:ridge_regression:alpha': 0.10350440303319317,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 0.0002564690307008257},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'mean',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'decision_tree',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0035907606973446587,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'exp',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'False',\n",
       "   'regressor:decision_tree:criterion': 'mse',\n",
       "   'regressor:decision_tree:max_depth_factor': 1.3366497428156003,\n",
       "   'regressor:decision_tree:max_features': 1.0,\n",
       "   'regressor:decision_tree:max_leaf_nodes': 'None',\n",
       "   'regressor:decision_tree:min_impurity_decrease': 0.0,\n",
       "   'regressor:decision_tree:min_samples_leaf': 14,\n",
       "   'regressor:decision_tree:min_samples_split': 7,\n",
       "   'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
       "  {'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer',\n",
       "   'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent',\n",
       "   'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax',\n",
       "   'feature_preprocessor:__choice__': 'fast_ica',\n",
       "   'regressor:__choice__': 'ridge_regression',\n",
       "   'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.005855194554950668,\n",
       "   'feature_preprocessor:fast_ica:algorithm': 'deflation',\n",
       "   'feature_preprocessor:fast_ica:fun': 'logcosh',\n",
       "   'feature_preprocessor:fast_ica:whiten': 'True',\n",
       "   'regressor:ridge_regression:alpha': 0.8174643042123263,\n",
       "   'regressor:ridge_regression:fit_intercept': 'True',\n",
       "   'regressor:ridge_regression:tol': 0.00017122445163388547,\n",
       "   'feature_preprocessor:fast_ica:n_components': 1510}],\n",
       " 'rank_test_scores': array([10,  4, 10, 10, 10, 45, 43, 46, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "        10, 10, 44, 10, 10,  5, 10,  1, 10, 10,  3,  7, 10, 10,  6,  9, 10,\n",
       "        10, 10, 10, 10, 10, 10,  2,  7, 10, 10, 10, 10]),\n",
       " 'status': ['Timeout',\n",
       "  'Success',\n",
       "  'Memout',\n",
       "  'Timeout',\n",
       "  'Memout',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Memout',\n",
       "  'Timeout',\n",
       "  'Memout',\n",
       "  'Memout',\n",
       "  'Timeout',\n",
       "  'Timeout',\n",
       "  'Timeout',\n",
       "  'Timeout',\n",
       "  'Timeout',\n",
       "  'Timeout',\n",
       "  'Memout',\n",
       "  'Success',\n",
       "  'Crash',\n",
       "  'Timeout',\n",
       "  'Success',\n",
       "  'Timeout',\n",
       "  'Success',\n",
       "  'Timeout',\n",
       "  'Memout',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Timeout',\n",
       "  'Timeout',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Timeout',\n",
       "  'Timeout',\n",
       "  'Timeout',\n",
       "  'Timeout',\n",
       "  'Timeout',\n",
       "  'Timeout',\n",
       "  'Memout',\n",
       "  'Success',\n",
       "  'Success',\n",
       "  'Timeout',\n",
       "  'Timeout',\n",
       "  'Crash',\n",
       "  'Timeout'],\n",
       " 'budgets': [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " 'param_data_preprocessing:categorical_transformer:categorical_encoding:__choice__': masked_array(data=['one_hot_encoding', 'one_hot_encoding', 'no_encoding',\n",
       "                    'no_encoding', 'no_encoding', 'no_encoding',\n",
       "                    'no_encoding', 'no_encoding', 'no_encoding',\n",
       "                    'one_hot_encoding', 'no_encoding', 'no_encoding',\n",
       "                    'no_encoding', 'one_hot_encoding', 'no_encoding',\n",
       "                    'one_hot_encoding', 'no_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'no_encoding', 'no_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding', 'no_encoding',\n",
       "                    'no_encoding', 'no_encoding', 'one_hot_encoding',\n",
       "                    'no_encoding', 'no_encoding', 'no_encoding',\n",
       "                    'no_encoding', 'one_hot_encoding', 'no_encoding',\n",
       "                    'one_hot_encoding', 'one_hot_encoding',\n",
       "                    'one_hot_encoding', 'no_encoding', 'one_hot_encoding',\n",
       "                    'no_encoding', 'one_hot_encoding', 'no_encoding',\n",
       "                    'no_encoding', 'one_hot_encoding', 'one_hot_encoding'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U16'),\n",
       " 'param_data_preprocessing:categorical_transformer:category_coalescence:__choice__': masked_array(data=['minority_coalescer', 'minority_coalescer',\n",
       "                    'no_coalescense', 'no_coalescense', 'no_coalescense',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'no_coalescense', 'no_coalescense',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'no_coalescense', 'no_coalescense', 'no_coalescense',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'no_coalescense', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'no_coalescense', 'no_coalescense',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'no_coalescense', 'no_coalescense',\n",
       "                    'minority_coalescer', 'minority_coalescer',\n",
       "                    'minority_coalescer', 'no_coalescense',\n",
       "                    'minority_coalescer', 'minority_coalescer'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U18'),\n",
       " 'param_data_preprocessing:numerical_transformer:imputation:strategy': masked_array(data=['mean', 'mean', 'mean', 'median', 'most_frequent',\n",
       "                    'mean', 'median', 'most_frequent', 'mean', 'median',\n",
       "                    'most_frequent', 'median', 'mean', 'mean', 'median',\n",
       "                    'median', 'median', 'mean', 'median', 'median', 'mean',\n",
       "                    'median', 'most_frequent', 'median', 'median', 'mean',\n",
       "                    'mean', 'median', 'most_frequent', 'median', 'median',\n",
       "                    'median', 'mean', 'median', 'most_frequent', 'mean',\n",
       "                    'mean', 'most_frequent', 'most_frequent',\n",
       "                    'most_frequent', 'most_frequent', 'median',\n",
       "                    'most_frequent', 'mean', 'mean', 'most_frequent'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U13'),\n",
       " 'param_data_preprocessing:numerical_transformer:rescaling:__choice__': masked_array(data=['standardize', 'standardize', 'none', 'normalize',\n",
       "                    'quantile_transformer', 'minmax', 'none', 'none',\n",
       "                    'standardize', 'normalize', 'standardize',\n",
       "                    'robust_scaler', 'standardize', 'robust_scaler',\n",
       "                    'standardize', 'minmax', 'robust_scaler',\n",
       "                    'robust_scaler', 'quantile_transformer',\n",
       "                    'robust_scaler', 'standardize', 'robust_scaler',\n",
       "                    'none', 'minmax', 'robust_scaler',\n",
       "                    'quantile_transformer', 'minmax', 'minmax',\n",
       "                    'robust_scaler', 'robust_scaler', 'standardize',\n",
       "                    'standardize', 'quantile_transformer', 'minmax',\n",
       "                    'robust_scaler', 'robust_scaler', 'standardize',\n",
       "                    'standardize', 'quantile_transformer', 'none',\n",
       "                    'minmax', 'minmax', 'robust_scaler', 'normalize',\n",
       "                    'minmax', 'minmax'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U20'),\n",
       " 'param_feature_preprocessor:__choice__': masked_array(data=['no_preprocessing',\n",
       "                    'extra_trees_preproc_for_regression', 'polynomial',\n",
       "                    'fast_ica', 'polynomial', 'random_trees_embedding',\n",
       "                    'random_trees_embedding', 'random_trees_embedding',\n",
       "                    'polynomial', 'feature_agglomeration', 'polynomial',\n",
       "                    'polynomial', 'kitchen_sinks', 'pca',\n",
       "                    'random_trees_embedding', 'random_trees_embedding',\n",
       "                    'feature_agglomeration', 'fast_ica', 'polynomial',\n",
       "                    'extra_trees_preproc_for_regression', 'fast_ica',\n",
       "                    'random_trees_embedding',\n",
       "                    'extra_trees_preproc_for_regression', 'fast_ica',\n",
       "                    'feature_agglomeration', 'random_trees_embedding',\n",
       "                    'polynomial', 'extra_trees_preproc_for_regression',\n",
       "                    'no_preprocessing', 'no_preprocessing',\n",
       "                    'random_trees_embedding', 'random_trees_embedding',\n",
       "                    'random_trees_embedding', 'fast_ica', 'fast_ica',\n",
       "                    'fast_ica', 'kernel_pca', 'kernel_pca', 'fast_ica',\n",
       "                    'polynomial', 'extra_trees_preproc_for_regression',\n",
       "                    'no_preprocessing',\n",
       "                    'extra_trees_preproc_for_regression',\n",
       "                    'random_trees_embedding', 'fast_ica', 'fast_ica'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U34'),\n",
       " 'param_regressor:__choice__': masked_array(data=['random_forest', 'k_nearest_neighbors',\n",
       "                    'decision_tree', 'extra_trees', 'k_nearest_neighbors',\n",
       "                    'k_nearest_neighbors', 'decision_tree',\n",
       "                    'k_nearest_neighbors', 'random_forest',\n",
       "                    'random_forest', 'extra_trees', 'extra_trees',\n",
       "                    'ridge_regression', 'ridge_regression',\n",
       "                    'ridge_regression', 'extra_trees', 'ridge_regression',\n",
       "                    'decision_tree', 'extra_trees', 'decision_tree',\n",
       "                    'ridge_regression', 'random_forest',\n",
       "                    'k_nearest_neighbors', 'extra_trees',\n",
       "                    'k_nearest_neighbors', 'random_forest',\n",
       "                    'random_forest', 'k_nearest_neighbors',\n",
       "                    'decision_tree', 'extra_trees', 'ridge_regression',\n",
       "                    'k_nearest_neighbors', 'k_nearest_neighbors',\n",
       "                    'k_nearest_neighbors', 'k_nearest_neighbors',\n",
       "                    'k_nearest_neighbors', 'ridge_regression',\n",
       "                    'ridge_regression', 'extra_trees',\n",
       "                    'k_nearest_neighbors', 'k_nearest_neighbors',\n",
       "                    'decision_tree', 'k_nearest_neighbors',\n",
       "                    'ridge_regression', 'decision_tree',\n",
       "                    'ridge_regression'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U19'),\n",
       " 'param_data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': masked_array(data=[0.01, 0.0026384245313872353, --, --, --,\n",
       "                    0.008228181948465642, 0.05280394571336593, --, --,\n",
       "                    0.008966101829575291, --, --, --, --,\n",
       "                    0.018706846291046294, --, --, 0.07573471956443811,\n",
       "                    0.006401132329816805, --, 0.00434032235492344, --,\n",
       "                    0.04328008478720413, --, --, 0.0014125663544520652,\n",
       "                    0.08717627580708938, --, --, --, 0.08185943308131388,\n",
       "                    --, 0.2531816795290892, --, 0.0008866566079920301,\n",
       "                    0.0002485177435445324, 0.13298241735810967,\n",
       "                    0.01922194687729476, --, --, 0.0021689983035149732,\n",
       "                    0.0009690683970088139, 0.2925697627392644, --,\n",
       "                    0.0035907606973446587, 0.005855194554950668],\n",
       "              mask=[False, False,  True,  True,  True, False, False,  True,\n",
       "                     True, False,  True,  True,  True,  True, False,  True,\n",
       "                     True, False, False,  True, False,  True, False,  True,\n",
       "                     True, False, False,  True,  True,  True, False,  True,\n",
       "                    False,  True, False, False, False, False,  True,  True,\n",
       "                    False, False, False,  True, False, False],\n",
       "        fill_value=1e+20),\n",
       " 'param_data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': masked_array(data=[--, --, --, --, 782.0, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 802.0, --, --, --, --, --, --,\n",
       "                    1753.0, --, --, --, --, --, --, 1549.0, --, --, --, --,\n",
       "                    --, 1024.0, --, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': masked_array(data=[--, --, --, --, 'normal', --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 'normal', --, --, --, --, --,\n",
       "                    --, 'normal', --, --, --, --, --, --, 'normal', --, --,\n",
       "                    --, --, --, 'uniform', --, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U32'),\n",
       " 'param_data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': masked_array(data=[--, --, --, --, --, --, --, --, --, --, --,\n",
       "                    0.7143371369676014, --, 0.9458586151922455, --, --,\n",
       "                    0.8908649969556265, 0.9222381336818728, --,\n",
       "                    0.9426251414675535, --, 0.9324046202896481, --, --,\n",
       "                    0.9028878306178143, --, --, --, 0.7713495648528115,\n",
       "                    0.8124343120257264, --, --, --, --, 0.9788580663449074,\n",
       "                    0.9159433805754357, --, --, --, --, --, --,\n",
       "                    0.8182233596800187, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True, False,  True,  True,\n",
       "                    False, False,  True, False,  True, False,  True,  True,\n",
       "                    False,  True,  True,  True, False, False,  True,  True,\n",
       "                     True,  True, False, False,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': masked_array(data=[--, --, --, --, --, --, --, --, --, --, --,\n",
       "                    0.04794378208398888, --, 0.033973270518143514, --, --,\n",
       "                    0.23061291159288266, 0.23125703348362994, --,\n",
       "                    0.21098487877827368, --, 0.24070305887016358, --, --,\n",
       "                    0.10562216348863988, --, --, --, 0.010153420179546516,\n",
       "                    0.2645660734387229, --, --, --, --,\n",
       "                    0.0050071643467382776, 0.17144606707198023, --, --, --,\n",
       "                    --, --, --, 0.1402734161123617, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True, False,  True,  True,\n",
       "                    False, False,  True, False,  True, False,  True,  True,\n",
       "                    False,  True,  True,  True, False, False,  True,  True,\n",
       "                     True,  True, False, False,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': masked_array(data=[--, 'True', --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 'True', --, --, 'False', --,\n",
       "                    --, --, --, 'False', --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 'True', --, 'True', --, --, --],\n",
       "              mask=[ True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True, False,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True, False,  True,  True,  True],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U32'),\n",
       " 'param_feature_preprocessor:extra_trees_preproc_for_regression:criterion': masked_array(data=[--, 'friedman_mse', --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 'mse', --, --,\n",
       "                    'friedman_mse', --, --, --, --, 'friedman_mse', --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, 'mse', --,\n",
       "                    'friedman_mse', --, --, --],\n",
       "              mask=[ True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True, False,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True, False,  True,  True,  True],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U32'),\n",
       " 'param_feature_preprocessor:extra_trees_preproc_for_regression:max_depth': masked_array(data=[--, 'None', --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 'None', --, --, 'None', --, --,\n",
       "                    --, --, 'None', --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 'None', --, 'None', --, --, --],\n",
       "              mask=[ True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True, False,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True, False,  True,  True,  True],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U32'),\n",
       " 'param_feature_preprocessor:extra_trees_preproc_for_regression:max_features': masked_array(data=[--, 0.8916423125520393, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 0.2981545058131393,\n",
       "                    --, --, 0.5297983199210101, --, --, --, --,\n",
       "                    0.18379814197130073, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 0.8916423125520393, --,\n",
       "                    0.23005230097732696, --, --, --],\n",
       "              mask=[ True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True, False,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True, False,  True,  True,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': masked_array(data=[--, 'None', --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 'None', --, --, 'None', --, --,\n",
       "                    --, --, 'None', --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 'None', --, 'None', --, --, --],\n",
       "              mask=[ True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True, False,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True, False,  True,  True,  True],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U32'),\n",
       " 'param_feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': masked_array(data=[--, 17.0, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 14.0, --, --, 19.0, --, --, --,\n",
       "                    --, 10.0, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 19.0, --, 8.0, --, --, --],\n",
       "              mask=[ True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True, False,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True, False,  True,  True,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': masked_array(data=[--, 3.0, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 14.0, --, --, 12.0, --, --, --,\n",
       "                    --, 19.0, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 3.0, --, 3.0, --, --, --],\n",
       "              mask=[ True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True, False,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True, False,  True,  True,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': masked_array(data=[--, 0.0, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 0.0, --, --, 0.0, --, --, --,\n",
       "                    --, 0.0, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 0.0, --, 0.0, --, --, --],\n",
       "              mask=[ True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True, False,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True, False,  True,  True,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': masked_array(data=[--, 100.0, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 100.0, --, --, 100.0, --, --,\n",
       "                    --, --, 100.0, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 100.0, --, 100.0, --, --, --],\n",
       "              mask=[ True, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True, False,  True,\n",
       "                     True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True, False,  True,  True,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_feature_preprocessor:fast_ica:algorithm': masked_array(data=[--, --, --, 'deflation', --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 'parallel', --, --,\n",
       "                    'deflation', --, --, 'parallel', --, --, --, --, --,\n",
       "                    --, --, --, --, 'parallel', 'parallel', 'deflation',\n",
       "                    --, --, 'deflation', --, --, --, --, --, 'deflation',\n",
       "                    'deflation'],\n",
       "              mask=[ True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True, False,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False, False, False,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True, False, False],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U32'),\n",
       " 'param_feature_preprocessor:fast_ica:fun': masked_array(data=[--, --, --, 'logcosh', --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, 'exp', --, --, 'exp', --, --,\n",
       "                    'logcosh', --, --, --, --, --, --, --, --, --, 'cube',\n",
       "                    'cube', 'exp', --, --, 'cube', --, --, --, --, --,\n",
       "                    'exp', 'logcosh'],\n",
       "              mask=[ True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True, False,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False, False, False,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True, False, False],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U32'),\n",
       " 'param_feature_preprocessor:fast_ica:whiten': masked_array(data=[--, --, --, 'True', --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 'False', --, --, 'False', --, --,\n",
       "                    'True', --, --, --, --, --, --, --, --, --, 'False',\n",
       "                    'False', 'True', --, --, 'True', --, --, --, --, --,\n",
       "                    'False', 'True'],\n",
       "              mask=[ True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True, False,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False, False, False,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True, False, False],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U32'),\n",
       " 'param_feature_preprocessor:feature_agglomeration:affinity': masked_array(data=[--, --, --, --, --, --, --, --, --, 'manhattan', --,\n",
       "                    --, --, --, --, --, 'manhattan', --, --, --, --, --,\n",
       "                    --, --, 'manhattan', --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U32'),\n",
       " 'param_feature_preprocessor:feature_agglomeration:linkage': masked_array(data=[--, --, --, --, --, --, --, --, --, 'complete', --, --,\n",
       "                    --, --, --, --, 'complete', --, --, --, --, --, --, --,\n",
       "                    'complete', --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U32'),\n",
       " 'param_feature_preprocessor:feature_agglomeration:n_clusters': masked_array(data=[--, --, --, --, --, --, --, --, --, 152.0, --, --, --,\n",
       "                    --, --, --, 341.0, --, --, --, --, --, --, --, 388.0,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_feature_preprocessor:feature_agglomeration:pooling_func': masked_array(data=[--, --, --, --, --, --, --, --, --, 'mean', --, --, --,\n",
       "                    --, --, --, 'mean', --, --, --, --, --, --, --, 'max',\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U32'),\n",
       " 'param_feature_preprocessor:kernel_pca:kernel': masked_array(data=[--, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 'rbf', 'rbf', --, --,\n",
       "                    --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U32'),\n",
       " 'param_feature_preprocessor:kernel_pca:n_components': masked_array(data=[--, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 1489.0, 811.0, --, --,\n",
       "                    --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_feature_preprocessor:kitchen_sinks:gamma': masked_array(data=[--, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    0.00015592108351954417, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_feature_preprocessor:kitchen_sinks:n_components': masked_array(data=[--, --, --, --, --, --, --, --, --, --, --, --, 447.0,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_feature_preprocessor:nystroem_sampler:kernel': masked_array(data=[--, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20,\n",
       "             dtype=float64),\n",
       " 'param_feature_preprocessor:nystroem_sampler:n_components': masked_array(data=[--, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20,\n",
       "             dtype=float64),\n",
       " 'param_feature_preprocessor:pca:keep_variance': masked_array(data=[--, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    0.916501074160355, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_feature_preprocessor:pca:whiten': masked_array(data=[--, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    'True', --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U32'),\n",
       " 'param_feature_preprocessor:polynomial:degree': masked_array(data=[--, --, 2.0, --, 3.0, --, --, --, 2.0, --, 3.0, 3.0,\n",
       "                    --, --, --, --, --, --, 2.0, --, --, --, --, --, --,\n",
       "                    --, 2.0, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 2.0, --, --, --, --, --, --],\n",
       "              mask=[ True,  True, False,  True, False,  True,  True,  True,\n",
       "                    False,  True, False, False,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_feature_preprocessor:polynomial:include_bias': masked_array(data=[--, --, 'True', --, 'True', --, --, --, 'False', --,\n",
       "                    'False', 'True', --, --, --, --, --, --, 'False', --,\n",
       "                    --, --, --, --, --, --, 'True', --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 'False', --, --, --, --, --,\n",
       "                    --],\n",
       "              mask=[ True,  True, False,  True, False,  True,  True,  True,\n",
       "                    False,  True, False, False,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U32'),\n",
       " 'param_feature_preprocessor:polynomial:interaction_only': masked_array(data=[--, --, 'True', --, 'True', --, --, --, 'True', --,\n",
       "                    'False', 'False', --, --, --, --, --, --, 'False', --,\n",
       "                    --, --, --, --, --, --, 'True', --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 'True', --, --, --, --, --, --],\n",
       "              mask=[ True,  True, False,  True, False,  True,  True,  True,\n",
       "                    False,  True, False, False,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U32'),\n",
       " 'param_feature_preprocessor:random_trees_embedding:bootstrap': masked_array(data=[--, --, --, --, --, 'False', 'True', 'False', --, --,\n",
       "                    --, --, --, --, 'True', 'True', --, --, --, --, --,\n",
       "                    'True', --, --, --, 'False', --, --, --, --, 'False',\n",
       "                    'False', 'False', --, --, --, --, --, --, --, --, --,\n",
       "                    --, 'False', --, --],\n",
       "              mask=[ True,  True,  True,  True,  True, False, False, False,\n",
       "                     True,  True,  True,  True,  True,  True, False, False,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True, False, False,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U32'),\n",
       " 'param_feature_preprocessor:random_trees_embedding:max_depth': masked_array(data=[--, --, --, --, --, 8.0, 10.0, 7.0, --, --, --, --, --,\n",
       "                    --, 4.0, 8.0, --, --, --, --, --, 5.0, --, --, --, 5.0,\n",
       "                    --, --, --, --, 8.0, 2.0, 7.0, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 10.0, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True, False, False, False,\n",
       "                     True,  True,  True,  True,  True,  True, False, False,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True, False, False,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_feature_preprocessor:random_trees_embedding:max_leaf_nodes': masked_array(data=[--, --, --, --, --, 'None', 'None', 'None', --, --, --,\n",
       "                    --, --, --, 'None', 'None', --, --, --, --, --, 'None',\n",
       "                    --, --, --, 'None', --, --, --, --, 'None', 'None',\n",
       "                    'None', --, --, --, --, --, --, --, --, --, --, 'None',\n",
       "                    --, --],\n",
       "              mask=[ True,  True,  True,  True,  True, False, False, False,\n",
       "                     True,  True,  True,  True,  True,  True, False, False,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True, False, False,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U32'),\n",
       " 'param_feature_preprocessor:random_trees_embedding:min_samples_leaf': masked_array(data=[--, --, --, --, --, 8.0, 1.0, 15.0, --, --, --, --, --,\n",
       "                    --, 5.0, 14.0, --, --, --, --, --, 7.0, --, --, --,\n",
       "                    1.0, --, --, --, --, 1.0, 13.0, 16.0, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 17.0, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True, False, False, False,\n",
       "                     True,  True,  True,  True,  True,  True, False, False,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True, False, False,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_feature_preprocessor:random_trees_embedding:min_samples_split': masked_array(data=[--, --, --, --, --, 13.0, 8.0, 11.0, --, --, --, --,\n",
       "                    --, --, 16.0, 2.0, --, --, --, --, --, 5.0, --, --, --,\n",
       "                    19.0, --, --, --, --, 12.0, 6.0, 11.0, --, --, --, --,\n",
       "                    --, --, --, --, --, --, 11.0, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True, False, False, False,\n",
       "                     True,  True,  True,  True,  True,  True, False, False,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True, False, False,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_feature_preprocessor:random_trees_embedding:min_weight_fraction_leaf': masked_array(data=[--, --, --, --, --, 1.0, 1.0, 1.0, --, --, --, --, --,\n",
       "                    --, 1.0, 1.0, --, --, --, --, --, 1.0, --, --, --, 1.0,\n",
       "                    --, --, --, --, 1.0, 1.0, 1.0, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 1.0, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True, False, False, False,\n",
       "                     True,  True,  True,  True,  True,  True, False, False,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True, False, False,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_feature_preprocessor:random_trees_embedding:n_estimators': masked_array(data=[--, --, --, --, --, 60.0, 37.0, 37.0, --, --, --, --,\n",
       "                    --, --, 29.0, 16.0, --, --, --, --, --, 77.0, --, --,\n",
       "                    --, 89.0, --, --, --, --, 92.0, 65.0, 13.0, --, --, --,\n",
       "                    --, --, --, --, --, --, --, 70.0, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True, False, False, False,\n",
       "                     True,  True,  True,  True,  True,  True, False, False,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True, False,  True,  True,  True,  True, False, False,\n",
       "                    False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_regressor:decision_tree:criterion': masked_array(data=[--, --, 'friedman_mse', --, --, --, 'friedman_mse', --,\n",
       "                    --, --, --, --, --, --, --, --, --, 'friedman_mse', --,\n",
       "                    'mse', --, --, --, --, --, --, --, --, 'mse', --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, 'mse', --, --,\n",
       "                    'mse', --],\n",
       "              mask=[ True,  True, False,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True, False,  True],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U32'),\n",
       " 'param_regressor:decision_tree:max_depth_factor': masked_array(data=[--, --, 0.7737834642318178, --, --, --,\n",
       "                    0.8105100197700859, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 0.959836402328228, --, 1.776462544426102, --, --,\n",
       "                    --, --, --, --, --, --, 0.2165118379734059, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --,\n",
       "                    0.05710376411100193, --, --, 1.3366497428156003, --],\n",
       "              mask=[ True,  True, False,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True, False,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_regressor:decision_tree:max_features': masked_array(data=[--, --, 1.0, --, --, --, 1.0, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 1.0, --, 1.0, --, --, --, --, --, --,\n",
       "                    --, --, 1.0, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 1.0, --, --, 1.0, --],\n",
       "              mask=[ True,  True, False,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True, False,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_regressor:decision_tree:max_leaf_nodes': masked_array(data=[--, --, 'None', --, --, --, 'None', --, --, --, --, --,\n",
       "                    --, --, --, --, --, 'None', --, 'None', --, --, --, --,\n",
       "                    --, --, --, --, 'None', --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 'None', --, --, 'None', --],\n",
       "              mask=[ True,  True, False,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True, False,  True],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U32'),\n",
       " 'param_regressor:decision_tree:min_impurity_decrease': masked_array(data=[--, --, 0.0, --, --, --, 0.0, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 0.0, --, 0.0, --, --, --, --, --, --,\n",
       "                    --, --, 0.0, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 0.0, --, --, 0.0, --],\n",
       "              mask=[ True,  True, False,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True, False,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_regressor:decision_tree:min_samples_leaf': masked_array(data=[--, --, 13.0, --, --, --, 7.0, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 8.0, --, 4.0, --, --, --, --, --, --,\n",
       "                    --, --, 3.0, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 10.0, --, --, 14.0, --],\n",
       "              mask=[ True,  True, False,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True, False,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_regressor:decision_tree:min_samples_split': masked_array(data=[--, --, 13.0, --, --, --, 20.0, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 6.0, --, 7.0, --, --, --, --, --, --,\n",
       "                    --, --, 17.0, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 8.0, --, --, 7.0, --],\n",
       "              mask=[ True,  True, False,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True, False,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_regressor:decision_tree:min_weight_fraction_leaf': masked_array(data=[--, --, 0.0, --, --, --, 0.0, --, --, --, --, --, --,\n",
       "                    --, --, --, --, 0.0, --, 0.0, --, --, --, --, --, --,\n",
       "                    --, --, 0.0, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 0.0, --, --, 0.0, --],\n",
       "              mask=[ True,  True, False,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True, False,  True,  True, False,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_regressor:extra_trees:bootstrap': masked_array(data=[--, --, --, 'False', --, --, --, --, --, --, 'True',\n",
       "                    'True', --, --, --, 'False', --, --, 'True', --, --,\n",
       "                    --, --, 'False', --, --, --, --, --, 'False', --, --,\n",
       "                    --, --, --, --, --, --, 'False', --, --, --, --, --,\n",
       "                    --, --],\n",
       "              mask=[ True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True, False, False,  True,  True,  True, False,\n",
       "                     True,  True, False,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U32'),\n",
       " 'param_regressor:extra_trees:criterion': masked_array(data=[--, --, --, 'friedman_mse', --, --, --, --, --, --,\n",
       "                    'mae', 'mse', --, --, --, 'mse', --, --, 'mse', --, --,\n",
       "                    --, --, 'mae', --, --, --, --, --, 'mae', --, --, --,\n",
       "                    --, --, --, --, --, 'mse', --, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True, False, False,  True,  True,  True, False,\n",
       "                     True,  True, False,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U32'),\n",
       " 'param_regressor:extra_trees:max_depth': masked_array(data=[--, --, --, 'None', --, --, --, --, --, --, 'None',\n",
       "                    'None', --, --, --, 'None', --, --, 'None', --, --, --,\n",
       "                    --, 'None', --, --, --, --, --, 'None', --, --, --, --,\n",
       "                    --, --, --, --, 'None', --, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True, False, False,  True,  True,  True, False,\n",
       "                     True,  True, False,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U32'),\n",
       " 'param_regressor:extra_trees:max_features': masked_array(data=[--, --, --, 0.889315445488316, --, --, --, --, --, --,\n",
       "                    0.17888418316329135, 0.6624136583910045, --, --, --,\n",
       "                    0.7048082419853497, --, --, 0.7246103277682895, --, --,\n",
       "                    --, --, 0.8241774216692473, --, --, --, --, --,\n",
       "                    0.7096964681218927, --, --, --, --, --, --, --, --,\n",
       "                    0.21427701606528787, --, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True, False, False,  True,  True,  True, False,\n",
       "                     True,  True, False,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_regressor:extra_trees:max_leaf_nodes': masked_array(data=[--, --, --, 'None', --, --, --, --, --, --, 'None',\n",
       "                    'None', --, --, --, 'None', --, --, 'None', --, --, --,\n",
       "                    --, 'None', --, --, --, --, --, 'None', --, --, --, --,\n",
       "                    --, --, --, --, 'None', --, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True, False, False,  True,  True,  True, False,\n",
       "                     True,  True, False,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U32'),\n",
       " 'param_regressor:extra_trees:min_impurity_decrease': masked_array(data=[--, --, --, 0.0, --, --, --, --, --, --, 0.0, 0.0, --,\n",
       "                    --, --, 0.0, --, --, 0.0, --, --, --, --, 0.0, --, --,\n",
       "                    --, --, --, 0.0, --, --, --, --, --, --, --, --, 0.0,\n",
       "                    --, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True, False, False,  True,  True,  True, False,\n",
       "                     True,  True, False,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_regressor:extra_trees:min_samples_leaf': masked_array(data=[--, --, --, 7.0, --, --, --, --, --, --, 12.0, 2.0, --,\n",
       "                    --, --, 1.0, --, --, 9.0, --, --, --, --, 14.0, --, --,\n",
       "                    --, --, --, 17.0, --, --, --, --, --, --, --, --, 17.0,\n",
       "                    --, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True, False, False,  True,  True,  True, False,\n",
       "                     True,  True, False,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_regressor:extra_trees:min_samples_split': masked_array(data=[--, --, --, 8.0, --, --, --, --, --, --, 11.0, 5.0, --,\n",
       "                    --, --, 19.0, --, --, 15.0, --, --, --, --, 2.0, --,\n",
       "                    --, --, --, --, 14.0, --, --, --, --, --, --, --, --,\n",
       "                    4.0, --, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True, False, False,  True,  True,  True, False,\n",
       "                     True,  True, False,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_regressor:k_nearest_neighbors:n_neighbors': masked_array(data=[--, 31.0, --, --, 4.0, 1.0, --, 1.0, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, 6.0, --, 71.0,\n",
       "                    --, --, 28.0, --, --, --, 12.0, 45.0, 1.0, 1.0, 1.0,\n",
       "                    --, --, --, 2.0, 23.0, --, 15.0, --, --, --],\n",
       "              mask=[ True, False,  True,  True, False, False,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                    False,  True,  True, False,  True,  True,  True, False,\n",
       "                    False, False, False, False,  True,  True,  True, False,\n",
       "                    False,  True, False,  True,  True,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_regressor:k_nearest_neighbors:p': masked_array(data=[--, 2.0, --, --, 2.0, 2.0, --, 2.0, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 1.0, --, 1.0, --,\n",
       "                    --, 2.0, --, --, --, 2.0, 2.0, 1.0, 1.0, 1.0, --, --,\n",
       "                    --, 2.0, 2.0, --, 2.0, --, --, --],\n",
       "              mask=[ True, False,  True,  True, False, False,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                    False,  True,  True, False,  True,  True,  True, False,\n",
       "                    False, False, False, False,  True,  True,  True, False,\n",
       "                    False,  True, False,  True,  True,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_regressor:k_nearest_neighbors:weights': masked_array(data=[--, 'uniform', --, --, 'distance', 'uniform', --,\n",
       "                    'uniform', --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, 'uniform', --, 'distance', --, --,\n",
       "                    'distance', --, --, --, 'distance', 'distance',\n",
       "                    'uniform', 'distance', 'distance', --, --, --,\n",
       "                    'uniform', 'distance', --, 'distance', --, --, --],\n",
       "              mask=[ True, False,  True,  True, False, False,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                    False,  True,  True, False,  True,  True,  True, False,\n",
       "                    False, False, False, False,  True,  True,  True, False,\n",
       "                    False,  True, False,  True,  True,  True],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U32'),\n",
       " 'param_regressor:random_forest:bootstrap': masked_array(data=['True', --, --, --, --, --, --, --, 'False', 'False',\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, 'False',\n",
       "                    --, --, --, 'False', 'True', --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --],\n",
       "              mask=[False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True, False, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U5'),\n",
       " 'param_regressor:random_forest:criterion': masked_array(data=['mse', --, --, --, --, --, --, --, 'mae',\n",
       "                    'friedman_mse', --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, 'mae', --, --, --, 'mse', 'mse', --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --],\n",
       "              mask=[False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True, False, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U12'),\n",
       " 'param_regressor:random_forest:max_depth': masked_array(data=['None', --, --, --, --, --, --, --, 'None', 'None', --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, 'None', --, --,\n",
       "                    --, 'None', 'None', --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --],\n",
       "              mask=[False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True, False, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U4'),\n",
       " 'param_regressor:random_forest:max_features': masked_array(data=[1.0, --, --, --, --, --, --, --, 0.9658082569087674,\n",
       "                    0.9552504640093018, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, 0.22676842993049168, --, --, --,\n",
       "                    0.6664361259409552, 0.9888221698889313, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --],\n",
       "              mask=[False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True, False, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_regressor:random_forest:max_leaf_nodes': masked_array(data=['None', --, --, --, --, --, --, --, 'None', 'None', --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, 'None', --, --,\n",
       "                    --, 'None', 'None', --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --],\n",
       "              mask=[False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True, False, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U4'),\n",
       " 'param_regressor:random_forest:min_impurity_decrease': masked_array(data=[0.0, --, --, --, --, --, --, --, 0.0, 0.0, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 0.0, --, --, --, 0.0,\n",
       "                    0.0, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --],\n",
       "              mask=[False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True, False, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_regressor:random_forest:min_samples_leaf': masked_array(data=[1.0, --, --, --, --, --, --, --, 19.0, 9.0, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 14.0, --, --, --, 6.0,\n",
       "                    18.0, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --],\n",
       "              mask=[False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True, False, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_regressor:random_forest:min_samples_split': masked_array(data=[2.0, --, --, --, --, --, --, --, 12.0, 3.0, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 18.0, --, --, --, 11.0,\n",
       "                    11.0, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --],\n",
       "              mask=[False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True, False, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_regressor:random_forest:min_weight_fraction_leaf': masked_array(data=[0.0, --, --, --, --, --, --, --, 0.0, 0.0, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 0.0, --, --, --, 0.0,\n",
       "                    0.0, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --],\n",
       "              mask=[False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                    False, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True, False,  True,  True,\n",
       "                     True, False, False,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_regressor:ridge_regression:alpha': masked_array(data=[--, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    0.26972182640899706, 0.0012978027102532436,\n",
       "                    0.07220695583272739, --, 0.08648702344898193, --, --,\n",
       "                    --, 0.23208682194269747, --, --, --, --, --, --, --,\n",
       "                    --, --, 0.000454758499724548, --, --, --, --, --,\n",
       "                    3.8576135843011463, 0.19225941103954733, --, --, --,\n",
       "                    --, --, 0.10350440303319317, --, 0.8174643042123263],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False, False, False,  True,\n",
       "                    False,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True, False, False,  True,  True,\n",
       "                     True,  True,  True, False,  True, False],\n",
       "        fill_value=1e+20),\n",
       " 'param_regressor:ridge_regression:fit_intercept': masked_array(data=[--, --, --, --, --, --, --, --, --, --, --, --, 'True',\n",
       "                    'True', 'True', --, 'True', --, --, --, 'True', --, --,\n",
       "                    --, --, --, --, --, --, --, 'True', --, --, --, --, --,\n",
       "                    'True', 'True', --, --, --, --, --, 'True', --, 'True'],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False, False, False,  True,\n",
       "                    False,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True, False, False,  True,  True,\n",
       "                     True,  True,  True, False,  True, False],\n",
       "        fill_value='N/A',\n",
       "             dtype='<U32'),\n",
       " 'param_regressor:ridge_regression:tol': masked_array(data=[--, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    0.0049514585167037715, 0.0005436859891957444,\n",
       "                    0.03281504701204836, --, 3.507753673371878e-05, --, --,\n",
       "                    --, 1.0174779784395646e-05, --, --, --, --, --, --, --,\n",
       "                    --, --, 0.0002597945585926762, --, --, --, --, --,\n",
       "                    0.033583715713059605, 2.4611942938933287e-05, --, --,\n",
       "                    --, --, --, 0.0002564690307008257, --,\n",
       "                    0.00017122445163388547],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False, False, False,  True,\n",
       "                    False,  True,  True,  True, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True, False, False,  True,  True,\n",
       "                     True,  True,  True, False,  True, False],\n",
       "        fill_value=1e+20),\n",
       " 'param_feature_preprocessor:fast_ica:n_components': masked_array(data=[--, --, --, 539.0, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, 1916.0, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, 696.0, --, --,\n",
       "                    1569.0, --, --, --, --, --, --, 1510.0],\n",
       "              mask=[ True,  True,  True, False,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True, False,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True, False,  True,  True, False,  True,\n",
       "                     True,  True,  True,  True,  True, False],\n",
       "        fill_value=1e+20),\n",
       " 'param_feature_preprocessor:kernel_pca:coef0': masked_array(data=[--, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20,\n",
       "             dtype=float64),\n",
       " 'param_feature_preprocessor:kernel_pca:degree': masked_array(data=[--, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20,\n",
       "             dtype=float64),\n",
       " 'param_feature_preprocessor:kernel_pca:gamma': masked_array(data=[--, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, 0.17045734753422645,\n",
       "                    5.25053021043453e-05, --, --, --, --, --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False, False,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20),\n",
       " 'param_feature_preprocessor:nystroem_sampler:coef0': masked_array(data=[--, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20,\n",
       "             dtype=float64),\n",
       " 'param_feature_preprocessor:nystroem_sampler:degree': masked_array(data=[--, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20,\n",
       "             dtype=float64),\n",
       " 'param_feature_preprocessor:nystroem_sampler:gamma': masked_array(data=[--, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                    --, --, --, --],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True,  True,  True],\n",
       "        fill_value=1e+20,\n",
       "             dtype=float64)}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_lts.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.46, SimpleRegressionPipeline({'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding', 'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense', 'data_preprocessing:numerical_transformer:imputation:strategy': 'median', 'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler', 'feature_preprocessor:__choice__': 'feature_agglomeration', 'regressor:__choice__': 'k_nearest_neighbors', 'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.9028878306178143, 'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.10562216348863988, 'feature_preprocessor:feature_agglomeration:affinity': 'manhattan', 'feature_preprocessor:feature_agglomeration:linkage': 'complete', 'feature_preprocessor:feature_agglomeration:n_clusters': 388, 'feature_preprocessor:feature_agglomeration:pooling_func': 'max', 'regressor:k_nearest_neighbors:n_neighbors': 71, 'regressor:k_nearest_neighbors:p': 1, 'regressor:k_nearest_neighbors:weights': 'distance'},\n",
      "dataset_properties={\n",
      "  'task': 5,\n",
      "  'sparse': False,\n",
      "  'multioutput': True,\n",
      "  'target_type': 'regression',\n",
      "  'signed': False})), (0.24, SimpleRegressionPipeline({'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding', 'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense', 'data_preprocessing:numerical_transformer:imputation:strategy': 'median', 'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax', 'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression', 'regressor:__choice__': 'k_nearest_neighbors', 'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'False', 'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'friedman_mse', 'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None', 'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.18379814197130073, 'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None', 'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 10, 'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 19, 'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0, 'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100, 'regressor:k_nearest_neighbors:n_neighbors': 28, 'regressor:k_nearest_neighbors:p': 2, 'regressor:k_nearest_neighbors:weights': 'distance'},\n",
      "dataset_properties={\n",
      "  'task': 5,\n",
      "  'sparse': False,\n",
      "  'multioutput': True,\n",
      "  'target_type': 'regression',\n",
      "  'signed': False})), (0.22, SimpleRegressionPipeline({'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding', 'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense', 'data_preprocessing:numerical_transformer:imputation:strategy': 'median', 'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler', 'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression', 'regressor:__choice__': 'decision_tree', 'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.9426251414675535, 'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.21098487877827368, 'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'True', 'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'mse', 'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None', 'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.2981545058131393, 'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None', 'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 14, 'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 14, 'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0, 'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100, 'regressor:decision_tree:criterion': 'mse', 'regressor:decision_tree:max_depth_factor': 1.776462544426102, 'regressor:decision_tree:max_features': 1.0, 'regressor:decision_tree:max_leaf_nodes': 'None', 'regressor:decision_tree:min_impurity_decrease': 0.0, 'regressor:decision_tree:min_samples_leaf': 4, 'regressor:decision_tree:min_samples_split': 7, 'regressor:decision_tree:min_weight_fraction_leaf': 0.0},\n",
      "dataset_properties={\n",
      "  'task': 5,\n",
      "  'sparse': False,\n",
      "  'multioutput': True,\n",
      "  'target_type': 'regression',\n",
      "  'signed': False})), (0.08, SimpleRegressionPipeline({'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding', 'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer', 'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent', 'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none', 'feature_preprocessor:__choice__': 'extra_trees_preproc_for_regression', 'regressor:__choice__': 'k_nearest_neighbors', 'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.04328008478720413, 'feature_preprocessor:extra_trees_preproc_for_regression:bootstrap': 'False', 'feature_preprocessor:extra_trees_preproc_for_regression:criterion': 'friedman_mse', 'feature_preprocessor:extra_trees_preproc_for_regression:max_depth': 'None', 'feature_preprocessor:extra_trees_preproc_for_regression:max_features': 0.5297983199210101, 'feature_preprocessor:extra_trees_preproc_for_regression:max_leaf_nodes': 'None', 'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_leaf': 19, 'feature_preprocessor:extra_trees_preproc_for_regression:min_samples_split': 12, 'feature_preprocessor:extra_trees_preproc_for_regression:min_weight_fraction_leaf': 0.0, 'feature_preprocessor:extra_trees_preproc_for_regression:n_estimators': 100, 'regressor:k_nearest_neighbors:n_neighbors': 6, 'regressor:k_nearest_neighbors:p': 1, 'regressor:k_nearest_neighbors:weights': 'uniform'},\n",
      "dataset_properties={\n",
      "  'task': 5,\n",
      "  'sparse': False,\n",
      "  'multioutput': True,\n",
      "  'target_type': 'regression',\n",
      "  'signed': False}))]\n",
      "auto-sklearn results:\n",
      "  Dataset name: aa79e0f8f25a45feffaf9171fb7d62a5\n",
      "  Metric: r2\n",
      "  Best validation score: 0.332103\n",
      "  Number of target algorithm runs: 46\n",
      "  Number of successful target algorithm runs: 13\n",
      "  Number of crashed target algorithm runs: 2\n",
      "  Number of target algorithms that exceeded the time limit: 23\n",
      "  Number of target algorithms that exceeded the memory limit: 8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(reg_lts.get_models_with_weights())\n",
    "print(reg_lts.sprint_statistics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/anaconda3/envs/autoskdev/lib/python3.7/site-packages/sklearn/base.py:197: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AutoSklearnRegressor(delete_output_folder_after_terminate=False,\n",
       "                     delete_tmp_folder_after_terminate=False,\n",
       "                     disable_evaluator_output=False, ensemble_memory_limit=5120,\n",
       "                     ensemble_nbest=20, ensemble_size=50,\n",
       "                     exclude_estimators='gaussian_process',\n",
       "                     exclude_preprocessors=None, get_smac_object_callback=None,\n",
       "                     include_estimators=None, include_preprocessors=None,\n",
       "                     initial...\n",
       "                     logging_config=None, max_models_on_disc=50,\n",
       "                     metadata_directory=None, metric=None, ml_memory_limit=6144,\n",
       "                     n_jobs=6, output_folder=None, per_run_time_limit=300,\n",
       "                     resampling_strategy=<class 'sklearn.model_selection._split.TimeSeriesSplit'>,\n",
       "                     resampling_strategy_arguments={'folds': 5}, seed=921,\n",
       "                     shared_mode=False, smac_scenario_args=None,\n",
       "                     time_left_for_this_task=1000, tmp_folder=None)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_lts.refit(ftrain_lts, ttrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 606408.0119964308\n",
      "MAE: 308.69294544392847\n",
      "r2_score: 0.527026683437762\n",
      "MSE: 4557.053207206985\n",
      "MAE: 23.82313953311414\n",
      "r2_score: 0.9927859197739062\n"
     ]
    }
   ],
   "source": [
    "ypred_lts = reg_lts.predict(ftest_lts[:250,:])\n",
    "yhat_lts = reg_lts.predict(ftrain_lts)\n",
    "get_eval(ttest.iloc[:250,:], ypred_lts)\n",
    "get_eval(ttrain, yhat_lts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f2eef35e510>]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2c_list_test = []\n",
    "for i in range(192):\n",
    "    o_y = np.transpose(ttest.iloc[i,:].to_numpy().reshape(1,-1))\n",
    "    p_y = np.transpose(ypred_lts[i,:].reshape(1,-1))\n",
    "    r2 = r2_score(o_y, p_y)\n",
    "    r2c_list_test.append(r2)\n",
    "fig = plt.figure(figsize = (16, 7))\n",
    "plt.ylim(-0.5,0.9)\n",
    "plt.plot(r2c_list_test, 'b-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train:1200, test: 450"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tsfresh Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ftrain_tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-8665e3162d6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mreg_tf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mftrain_tf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mttrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'ftrain_tf' is not defined"
     ]
    }
   ],
   "source": [
    "reg_tf = autoreg.AutoSklearnRegressor(time_left_for_this_task=1000,\n",
    "                                           per_run_time_limit=100,\n",
    "                                           initial_configurations_via_metalearning=0,\n",
    "                                           ensemble_size=0, \n",
    "                                           ensemble_nbest=0,\n",
    "                                           ensemble_memory_limit=4048, \n",
    "                                           seed=921, ml_memory_limit=5120, \n",
    "                                           include_estimators=None,\n",
    "                                           exclude_estimators='gaussian_process', \n",
    "                                           include_preprocessors=None, \n",
    "                                           exclude_preprocessors=None, \n",
    "                                           resampling_strategy='cv',\n",
    "                                           resampling_strategy_arguments={'folds':5},\n",
    "                                           tmp_folder=None, \n",
    "                                           output_folder=None, \n",
    "                                           delete_tmp_folder_after_terminate=False, \n",
    "                                           delete_output_folder_after_terminate=False, \n",
    "                                           shared_mode=False, \n",
    "                                           n_jobs = 6, \n",
    "                                           disable_evaluator_output=False, \n",
    "                                           get_smac_object_callback=None, \n",
    "                                           smac_scenario_args=None, \n",
    "                                           logging_config=None,\n",
    "                                           metadata_directory=None)\n",
    "\n",
    "\n",
    "reg_tf.fit(ftrain_tf, ttrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reg_tf.get_models_with_weights())\n",
    "print(reg_tf.sprint_statistics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_tf.refit(ftrain_tf, ttrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred_tf = reg_tf.predict(ftest_tf)\n",
    "yhat_tf = reg_tf.predict(ftrain_tf)\n",
    "get_eval(ttest, ypred_tf)\n",
    "get_eval(ttrain, yhat_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,7))\n",
    "plt.plot(ypred_tf[192,:],'g-')\n",
    "plt.plot(ttest.to_numpy()[192,:], 'ro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lag Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "reg = autoreg.AutoSklearnRegressor(time_left_for_this_task=1000,\n",
    "                                           per_run_time_limit=100,\n",
    "                                           initial_configurations_via_metalearning=0,\n",
    "                                           ensemble_size=50, \n",
    "                                           ensemble_nbest=20,\n",
    "                                           ensemble_memory_limit=4048, \n",
    "                                           seed=921, ml_memory_limit=4096, \n",
    "                                           include_estimators=None,\n",
    "                                           exclude_estimators='gaussian_process', \n",
    "                                           include_preprocessors=None, \n",
    "                                           exclude_preprocessors=None, \n",
    "                                           resampling_strategy='cv',\n",
    "                                           resampling_strategy_arguments={'folds':5},\n",
    "                                           tmp_folder=None, \n",
    "                                           output_folder=None, \n",
    "                                           delete_tmp_folder_after_terminate=False, \n",
    "                                           delete_output_folder_after_terminate=False, \n",
    "                                           shared_mode=False, \n",
    "                                           n_jobs = 6, \n",
    "                                           disable_evaluator_output=False, \n",
    "                                           get_smac_object_callback=None, \n",
    "                                           smac_scenario_args=None, \n",
    "                                           logging_config=None,\n",
    "                                           metadata_directory=None)\n",
    "\n",
    "\n",
    "reg.fit(ftrain, ttrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(reg.get_models_with_weights())\n",
    "print(reg.sprint_statistics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.refit(ftrain, ttrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = reg.predict(ftest)\n",
    "yhat = reg.predict(ftrain)\n",
    "get_eval(ttest, ypred)\n",
    "get_eval(ttrain, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,7))\n",
    "plt.plot(ypred[192,:],'g-')\n",
    "plt.plot(ttest.to_numpy()[192,:], 'ro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lag + tsFresh Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftrain_lts = np.concatenate([ftrain.to_numpy(), ftrain_tf.to_numpy()], axis = 1)\n",
    "ftest_lts = np.concatenate([ftest.to_numpy(), ftest_tf.to_numpy()], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ftrain_lts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-51fedac042fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mreg_lts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mftrain_lts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mttrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'ftrain_lts' is not defined"
     ]
    }
   ],
   "source": [
    "reg_lts = autoreg.AutoSklearnRegressor(time_left_for_this_task=1000,\n",
    "                                           per_run_time_limit=100,\n",
    "                                           initial_configurations_via_metalearning=0,\n",
    "                                           ensemble_size=0, \n",
    "                                           ensemble_nbest=0,\n",
    "                                           ensemble_memory_limit=4048, \n",
    "                                           seed=921, ml_memory_limit=5120, \n",
    "                                           include_estimators=None,\n",
    "                                           exclude_estimators='gaussian_process', \n",
    "                                           include_preprocessors=None, \n",
    "                                           exclude_preprocessors=None, \n",
    "                                           resampling_strategy='cv',\n",
    "                                           resampling_strategy_arguments={'folds':5},\n",
    "                                           tmp_folder=None, \n",
    "                                           output_folder=None, \n",
    "                                           delete_tmp_folder_after_terminate=False, \n",
    "                                           delete_output_folder_after_terminate=False, \n",
    "                                           shared_mode=False, \n",
    "                                           n_jobs = 6, \n",
    "                                           disable_evaluator_output=False, \n",
    "                                           get_smac_object_callback=None, \n",
    "                                           smac_scenario_args=None, \n",
    "                                           logging_config=None,\n",
    "                                           metadata_directory=None)\n",
    "\n",
    "\n",
    "reg_lts.fit(ftrain_lts, ttrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reg_lts.get_models_with_weights())\n",
    "print(reg_lts.sprint_statistics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_lts.refit(ftrain_lts, ttrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred_lts = reg_lts.predict(ftest_lts)\n",
    "yhat_lts = reg_lts.predict(ftrain_lts)\n",
    "get_eval(ttest, ypred_lts)\n",
    "get_eval(ttrain, yhat_lts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,7))\n",
    "plt.plot(ypred_lts[280,:],'g-')\n",
    "plt.plot(ttest.to_numpy()[280,:], 'ro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "n_bootstraps = 50\n",
    "b_x = []\n",
    "b_y = []\n",
    "#for _ in range(n_bootstraps):\n",
    "#    sample_X, sample_y = resample(ftrain, ttrain)\n",
    "#    b_x.append(sample_X)\n",
    "#    b_y.append(sample_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = []\n",
    "\n",
    "#for i, feature in enumerate(b_x):\n",
    "#    reg.refit(feature, b_y[i])\n",
    "#    prediction.append(reg.predict(ftest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (15,7))\n",
    "plt.plot(np.quantile(prediction, 0.8, axis = 0)[100,:], 'g--')\n",
    "plt.plot(np.quantile(prediction, 0.1, axis = 0)[100,:], 'g--')\n",
    "plt.plot(np.quantile(prediction, 0.5, axis = 0)[100,:], 'b-')\n",
    "plt.plot(ttest.to_numpy()[100,:], 'ro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.refit(ftrain, ttrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred_t = reg.predict(ftest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = reg.predict(ftrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "get_eval(ttest.to_numpy(), np.quantile(prediction, 0.5, axis = 0))\n",
    "get_eval(ttrain.to_numpy(), yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (15,7))\n",
    "plt.plot(ypred_t[100,:],'g--')\n",
    "plt.plot(ttest.to_numpy()[100,:], 'ro') \n",
    "\n",
    "fig = plt.figure(figsize = (15,7))\n",
    "plt.plot(yhat[100,:],'g--')\n",
    "plt.plot(ttrain.to_numpy()[100,:], 'ro') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2_list_test = []\n",
    "for i in range(ftest.shape[0]):\n",
    "    o_y = np.transpose(ttest.iloc[i,:].to_numpy().reshape(1,-1))\n",
    "    p_y = np.transpose(ypred_t[i,:].reshape(1,-1))\n",
    "    r2 = r2_score(o_y, p_y)\n",
    "    r2_list_test.append(r2)\n",
    "\n",
    "r2_list_train = []\n",
    "for i in range(ftrain.shape[0]):\n",
    "    o_y = np.transpose(ttrain.iloc[i,:].to_numpy().reshape(1,-1))\n",
    "    p_y = np.transpose(yhat[i,:].reshape(1,-1))\n",
    "    r2 = r2_score(o_y, p_y)\n",
    "    r2_list_train.append(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (16, 7))\n",
    "plt.ylim(0.7)\n",
    "plt.plot(r2_list_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Condidence interval: Bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "n_bootstraps = 50\n",
    "bootstrap_X = []\n",
    "bootstrap_y = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = []\n",
    "\n",
    "for i, feature in enumerate(bootstrap_X):\n",
    "    reg.refit(feature, bootstrap_y[i])\n",
    "    prediction.append(reg.predict(ftest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (15,7))\n",
    "plt.plot(np.quantile(prediction, 0.5, axis = 0)[1,:], 'b-')\n",
    "plt.plot(np.quantile(prediction, 0.95, axis = 0)[1,:], 'g--')\n",
    "plt.plot(np.quantile(prediction, 0.05, axis = 0)[1,:], 'g--')\n",
    "plt.plot(ttest.to_numpy()[1,:], 'ro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confidence interval: Static"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.get_models_with_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load functions.py\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import datetime\n",
    "\n",
    "def plot_conf_static(val_y, val_y_pred, test_y, test_y_pred, n, alpha):\n",
    "    # confidence interval\n",
    "    q_m = np.quantile(val_y - val_y_pred, 0.5, axis = 0)\n",
    "    q_u = np.quantile(val_y - val_y_pred, 1 - alpha/2, axis = 0) - q_m\n",
    "    q_l = q_m - np.quantile(val_y - val_y_pred, alpha/2, axis = 0) \n",
    "        \n",
    "    \n",
    "    ypred_t_ub = test_y_pred  + q_u\n",
    "    ypred_t_lb = test_y_pred  - q_l\n",
    "    # plot\n",
    "    fig = plt.figure(figsize=(16,7))\n",
    "    font = {'family' : 'Lucida Grande',\n",
    "            'weight' : 'bold',\n",
    "            'size'   : 15}\n",
    "    plt.rc('font', **font)\n",
    "    plt.style.use('seaborn')\n",
    "    plt.plot(test_y_pred[n, :].reshape(-1,1), 'gx-',label='Prediction')\n",
    "    plt.plot(ypred_t_ub[n, :].reshape(-1,1), 'g--', label='{} % upper bond'.format((1-alpha/2)*100))\n",
    "    plt.plot(ypred_t_lb[n, :].reshape(-1,1), 'g--', label='{} % lower bond'.format((alpha/2)*100))\n",
    "    plt.plot(test_y.iloc[n, :].to_numpy().reshape(-1,1), 'ro', label='Ground truth')\n",
    "    #plt.fill(np.concatenate([xx, xx[::-1]]),\n",
    "    #         np.concatenate([y_upper, y_lower[::-1]]),\n",
    "    #         alpha=.5, fc='b', ec='None', label='90% prediction interval')\n",
    "    plt.xlabel('hours', **font)\n",
    "    plt.ylabel('KWh', **font)\n",
    "    plt.legend(loc='upper left', fontsize = 15)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def verf_ci_static(alpha, val_y, ypred, ttest, ypred_t):\n",
    "    \n",
    "    q_m = np.quantile(val_y - ypred, 0.5, axis = 0)\n",
    "    q_u = np.quantile(val_y - ypred, 1 - alpha/2, axis = 0) - q_m\n",
    "    q_l = q_m - np.quantile(val_y - ypred, alpha/2, axis = 0) \n",
    "    \n",
    "    precentage_list = []\n",
    "    err_count = 0\n",
    "\n",
    "    for i in range(ttest.shape[0]):\n",
    "        count = 0\n",
    "        for j in range(ttest.shape[1]):\n",
    "            if ttest.iloc[i,j] <=  (ypred_t[i,j] + q_u[j]) and ttest.iloc[i,j] >= (ypred_t[i,j] - q_l[j]):\n",
    "                count += 1\n",
    "        if count/ttest.shape[1] < (1- alpha):\n",
    "            err_count += 1\n",
    "        precentage_list.append(count/ttest.shape[1])\n",
    "\n",
    "    print(\"out_of_bound_pecentage\", err_count/ttest.shape[0])\n",
    "    fig = plt.figure(figsize = (16,7))\n",
    "    font = {'family' : 'Lucida Grande',\n",
    "            'weight' : 'bold',\n",
    "            'size'   : 15}\n",
    "    plt.rc('font', **font)\n",
    "    plt.style.use('seaborn')\n",
    "    plt.xlabel('Number of testing sets', **font)\n",
    "    plt.ylabel('Out_of_bound_error', **font)\n",
    "    plt.plot(precentage_list)\n",
    "\n",
    "    \n",
    "def plot_conf_std_static(val_y, val_y_pred, test_y, test_y_pred, n, ci_term):\n",
    "    # confidence interval\n",
    "    if(ci_term == 1.96):\n",
    "        alpha = 0.05\n",
    "    elif(ci_term == 1.645):\n",
    "        alpha = 0.10\n",
    "    elif(ci_term == 1.28):\n",
    "        alpha = 0.20\n",
    "        \n",
    "    std = np.mean((val_y - val_y_pred)**2)**0.5   \n",
    "    ypred_t_ub = test_y_pred[n,:]  + std*ci_term\n",
    "    ypred_t_lb = test_y_pred[n,:]  - std*ci_term\n",
    "    # plot\n",
    "    fig = plt.figure(figsize=(16,7))\n",
    "    font = {'family' : 'Lucida Grande',\n",
    "            'weight' : 'bold',\n",
    "            'size'   : 15}\n",
    "    plt.rc('font', **font)\n",
    "    plt.style.use('seaborn')\n",
    "    plt.plot(test_y_pred[n, :].reshape(-1,1), 'gx-',label='Prediction')\n",
    "    plt.plot(ypred_t_ub.to_numpy().reshape(-1,1), 'g--', label='{} % upper bond'.format((1-alpha/2)*100))\n",
    "    plt.plot(ypred_t_lb.to_numpy().reshape(-1,1), 'g--', label='{} % lower bond'.format((alpha/2)*100))\n",
    "    plt.plot(test_y.iloc[n, :].to_numpy().reshape(-1,1), 'ro', label='Ground truth')\n",
    "    #plt.fill(np.concatenate([xx, xx[::-1]]),\n",
    "    #         np.concatenate([y_upper, y_lower[::-1]]),\n",
    "    #         alpha=.5, fc='b', ec='None', label='90% prediction interval')\n",
    "    plt.xlabel('hours', **font)\n",
    "    plt.ylabel('KWh', **font)\n",
    "    plt.legend(loc='upper left', fontsize = 15)\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def verf_ci_std_static(ci_term, val_y, ypred, ttest, ypred_t):\n",
    "    \n",
    "    # confidence interval\n",
    "    if(ci_term == 1.96):\n",
    "        alpha = 0.05\n",
    "    elif(ci_term == 1.645):\n",
    "        alpha = 0.10\n",
    "    elif(ci_term == 1.28):\n",
    "        alpha = 0.20\n",
    "    \n",
    "    std = np.mean((val_y-ypred)**2)**0.5\n",
    "    \n",
    "    precentage_list = []\n",
    "    err_count = 0\n",
    "\n",
    "    for i in range(ttest.shape[0]):\n",
    "        count = 0\n",
    "        for j in range(ttest.shape[1]):\n",
    "            if ttest.iloc[i,j] <=  (ypred_t[i,j] + std[j] * ci_term) and ttest.iloc[i,j] >= (ypred_t[i,j] - std[j]*ci_term):\n",
    "                count += 1\n",
    "        if count/ttest.shape[1] < (1- alpha):\n",
    "            err_count += 1\n",
    "        precentage_list.append(count/ttest.shape[1])\n",
    "\n",
    "    print(\"out_of_bound_pecentage\", err_count/ttest.shape[0])\n",
    "    fig = plt.figure(figsize = (16,7))\n",
    "    font = {'family' : 'Lucida Grande',\n",
    "            'weight' : 'bold',\n",
    "            'size'   : 15}\n",
    "    plt.rc('font', **font)\n",
    "    plt.style.use('seaborn')\n",
    "    plt.xlabel('Number of testing sets', **font)\n",
    "    plt.ylabel('Out_of_bound_error', **font)\n",
    "    plt.plot(precentage_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_conf_std_static(ttrain, yhat, ttest, ypred_t, 200,1.96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verf_ci_std_static(1.96, ttrain, yhat, ttest.iloc[:800,:], ypred_t[:800,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_conf_static(ttrain, yhat, ttest, ypred_t, 1000, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "verf_ci_static(0.05, ttrain, yhat, ttest, ypred_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confidence interval: Dynamically fitting error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_reg = autoreg.AutoSklearnRegressor(time_left_for_this_task=1800, \n",
    "                                           per_run_time_limit=600, \n",
    "                                           initial_configurations_via_metalearning=0,\n",
    "                                           ensemble_size=20, \n",
    "                                           ensemble_nbest=10, \n",
    "                                           ensemble_memory_limit=4590, \n",
    "                                           seed=1, ml_memory_limit=5096, \n",
    "                                           include_estimators= None, \n",
    "                                           exclude_estimators=None, \n",
    "                                           include_preprocessors=None, \n",
    "                                           exclude_preprocessors=None, \n",
    "                                           resampling_strategy=KFold,  \n",
    "                                           resampling_strategy_arguments={'n_splits' : 3},\n",
    "                                           tmp_folder=None, \n",
    "                                           output_folder=None, \n",
    "                                           delete_tmp_folder_after_terminate=False, \n",
    "                                           delete_output_folder_after_terminate=False, \n",
    "                                           shared_mode=False, \n",
    "                                           n_jobs = 6, \n",
    "                                           disable_evaluator_output=False, \n",
    "                                           get_smac_object_callback=None, \n",
    "                                           smac_scenario_args=None, \n",
    "                                           logging_config=None,\n",
    "                                           metadata_directory=None)\n",
    "\n",
    "err_reg.fit(ttrain, (ttrain - yhat)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(err_reg.show_models())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(err_reg.sprint_statistics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "etr = ExtraTreesRegressor(n_estimators=100)\n",
    "scores = cross_val_score(etr, val_X, (val_y - yhat)**2, scoring = 'r2', cv=5, n_jobs = 6)\n",
    "print(\"Cross-validated scores:\", scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_conf_dynamic(perror, ttest, ypred, 0, 1.645)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_conf_static(ttest, ypred, ttest, ypred, 0, 1.645)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:autosk07] *",
   "language": "python",
   "name": "conda-env-autosk07-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
